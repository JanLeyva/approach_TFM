{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JanLeyva/approach_TFM/blob/master/Vilio_ERNIE_Vil.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65KBwK5txKiZ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxg1188lxQ_U"
      },
      "source": [
        "#  <font color='#A8EB15'> <b> Vilio-Feature extrction tsv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6b_VyL_2TaX"
      },
      "source": [
        "### <font color='#A8EB15'> Environment characteristics and `Conda env`  if need"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9Hop6LvxPIO",
        "outputId": "8c5fa763-4bd5-40b6-f8d3-d1422798b868"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.7.13\n"
          ]
        }
      ],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!free -m"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yl1ve62oULxy",
        "outputId": "b71a7aaf-aa0f-4e9c-91b0-838374e6c894"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              total        used        free      shared  buff/cache   available\n",
            "Mem:          12986         602       10257           1        2126       12147\n",
            "Swap:             0           0           0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXJTAraH2NUB",
        "outputId": "554457b2-f703-48ae-852f-86e300fb75ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Mon_Oct_12_20:09:46_PDT_2020\n",
            "Cuda compilation tools, release 11.1, V11.1.105\n",
            "Build cuda_11.1.TC455_06.29190527_0\n",
            "Tue May 10 13:40:23 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!/usr/local/cuda/bin/nvcc --version\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "#MINICONDA_INSTALLER_SCRIPT=Miniconda3-4.5.4-Linux-x86_64.sh\n",
        "#MINICONDA_PREFIX=/usr/local\n",
        "#wget https://repo.continuum.io/miniconda/$MINICONDA_INSTALLER_SCRIPT\n",
        "#chmod +x $MINICONDA_INSTALLER_SCRIPT\n",
        "#./$MINICONDA_INSTALLER_SCRIPT -b -f -p $MINICONDA_PREFIX     "
      ],
      "metadata": {
        "id": "0Tcdwr-MRySL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import sys\n",
        "#_ = (sys.path.append(\"/usr/local/lib/python3.6/site-packages\"))"
      ],
      "metadata": {
        "id": "ZMmMQ7EzR9Fy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhKFK3RESIOS",
        "outputId": "5f73ba07-9cc1-4aed-d1a6-1c231edf32b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.7.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioROtCsx2dxM"
      },
      "source": [
        "### <font color='#A8EB15'> Clone repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVEo0-IGxVcs",
        "outputId": "93581eb9-b92b-492a-ae4c-66acf3ef6985"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'vilio'...\n",
            "remote: Enumerating objects: 2956, done.\u001b[K\n",
            "remote: Counting objects: 100% (33/33), done.\u001b[K\n",
            "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
            "remote: Total 2956 (delta 13), reused 21 (delta 9), pack-reused 2923\u001b[K\n",
            "Receiving objects: 100% (2956/2956), 10.65 MiB | 17.64 MiB/s, done.\n",
            "Resolving deltas: 100% (1569/1569), done.\n"
          ]
        }
      ],
      "source": [
        "# clone original repo\n",
        "!git clone https://github.com/JanLeyva/vilio.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "e1KxhxFDxhMZ"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# os.chdir(\"/content/vilio/py-bottom-up-attention\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhPhwAq-xliz",
        "outputId": "e10cc912-490f-499e-fae1-5e1986f82df6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/facebookresearch/fvcore.git (from -r requirements.txt (line 1))\n",
            "  Cloning https://github.com/facebookresearch/fvcore.git to /tmp/pip-req-build-cep4gmgj\n",
            "  Running command git clone -q https://github.com/facebookresearch/fvcore.git /tmp/pip-req-build-cep4gmgj\n",
            "Collecting torch==1.4.0\n",
            "  Downloading torch-1.4.0-cp37-cp37m-manylinux1_x86_64.whl (753.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 753.4 MB 6.9 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.5.0\n",
            "  Downloading torchvision-0.5.0-cp37-cp37m-manylinux1_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 68.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (1.21.6)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (0.29.30)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (4.1.2.30)\n",
            "Collecting yacs>=0.1.6\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 61.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fvcore==0.1.5->-r requirements.txt (line 1)) (4.64.0)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from fvcore==0.1.5->-r requirements.txt (line 1)) (1.1.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from fvcore==0.1.5->-r requirements.txt (line 1)) (7.1.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from fvcore==0.1.5->-r requirements.txt (line 1)) (0.8.9)\n",
            "Collecting iopath>=0.1.7\n",
            "  Downloading iopath-0.1.9-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchvision==0.5.0->-r requirements.txt (line 3)) (1.15.0)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Building wheels for collected packages: fvcore\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5-py3-none-any.whl size=65176 sha256=fbff564c20b8f7342d613653d026b29f2df569e46aae6f36163bf4c03c58e7c9\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-hz5wpjhl/wheels/24/1d/09/8167de727fe5b74f832b6fcb5d9069d8f03ca29f337bfe484d\n",
            "Successfully built fvcore\n",
            "Installing collected packages: pyyaml, portalocker, yacs, torch, iopath, torchvision, fvcore\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.11.0+cu113\n",
            "    Uninstalling torch-1.11.0+cu113:\n",
            "      Successfully uninstalled torch-1.11.0+cu113\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.12.0+cu113\n",
            "    Uninstalling torchvision-0.12.0+cu113:\n",
            "      Successfully uninstalled torchvision-0.12.0+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.4.0 which is incompatible.\n",
            "torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.4.0 which is incompatible.\u001b[0m\n",
            "Successfully installed fvcore-0.1.5 iopath-0.1.9 portalocker-2.4.0 pyyaml-6.0 torch-1.4.0 torchvision-0.5.0 yacs-0.1.8\n"
          ]
        }
      ],
      "source": [
        "# !pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "vXAvUoNOxpZ4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcf8a17e-59c3-4e2e-b73d-b3f0aec009d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI\n",
            "  Cloning https://github.com/cocodataset/cocoapi.git to /tmp/pip-req-build-1ixykqtk\n",
            "  Running command git clone -q https://github.com/cocodataset/cocoapi.git /tmp/pip-req-build-1ixykqtk\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools==2.0) (57.4.0)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.7/dist-packages (from pycocotools==2.0) (0.29.30)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools==2.0) (3.2.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.4.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (0.11.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=2.1.0->pycocotools==2.0) (4.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=2.1.0->pycocotools==2.0) (1.15.0)\n",
            "Building wheels for collected packages: pycocotools\n",
            "  Building wheel for pycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycocotools: filename=pycocotools-2.0-cp37-cp37m-linux_x86_64.whl size=265165 sha256=16fd1ae9f391ae7447b233e9179d44bfa4e1609af7bf6e798ca5f7adab6c676c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-wupbo5em/wheels/e2/6b/1d/344ac773c7495ea0b85eb228bc66daec7400a143a92d36b7b1\n",
            "Successfully built pycocotools\n",
            "Installing collected packages: pycocotools\n",
            "  Attempting uninstall: pycocotools\n",
            "    Found existing installation: pycocotools 2.0.4\n",
            "    Uninstalling pycocotools-2.0.4:\n",
            "      Successfully uninstalled pycocotools-2.0.4\n",
            "Successfully installed pycocotools-2.0\n"
          ]
        }
      ],
      "source": [
        "# !pip install 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4WS12CmuxuEm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "571a6bbf-5926-43cd-b0e7-b73b513b2656"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running build\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib.linux-x86_64-3.7\n",
            "creating build/lib.linux-x86_64-3.7/detectron2\n",
            "copying detectron2/__init__.py -> build/lib.linux-x86_64-3.7/detectron2\n",
            "creating build/lib.linux-x86_64-3.7/detectron2/layers\n",
            "copying detectron2/layers/roi_align.py -> build/lib.linux-x86_64-3.7/detectron2/layers\n",
            "copying detectron2/layers/shape_spec.py -> build/lib.linux-x86_64-3.7/detectron2/layers\n",
            "copying detectron2/layers/roi_align_rotated.py -> build/lib.linux-x86_64-3.7/detectron2/layers\n",
            "copying detectron2/layers/deform_conv.py -> build/lib.linux-x86_64-3.7/detectron2/layers\n",
            "copying detectron2/layers/__init__.py -> build/lib.linux-x86_64-3.7/detectron2/layers\n",
            "copying detectron2/layers/nms.py -> build/lib.linux-x86_64-3.7/detectron2/layers\n",
            "copying detectron2/layers/wrappers.py -> build/lib.linux-x86_64-3.7/detectron2/layers\n",
            "copying detectron2/layers/mask_ops.py -> build/lib.linux-x86_64-3.7/detectron2/layers\n",
            "copying detectron2/layers/rotated_boxes.py -> build/lib.linux-x86_64-3.7/detectron2/layers\n",
            "copying detectron2/layers/batch_norm.py -> build/lib.linux-x86_64-3.7/detectron2/layers\n",
            "creating build/lib.linux-x86_64-3.7/detectron2/checkpoint\n",
            "copying detectron2/checkpoint/detection_checkpoint.py -> build/lib.linux-x86_64-3.7/detectron2/checkpoint\n",
            "copying detectron2/checkpoint/c2_model_loading.py -> build/lib.linux-x86_64-3.7/detectron2/checkpoint\n",
            "copying detectron2/checkpoint/__init__.py -> build/lib.linux-x86_64-3.7/detectron2/checkpoint\n",
            "copying detectron2/checkpoint/catalog.py -> build/lib.linux-x86_64-3.7/detectron2/checkpoint\n",
            "creating build/lib.linux-x86_64-3.7/detectron2/engine\n",
            "copying detectron2/engine/defaults.py -> build/lib.linux-x86_64-3.7/detectron2/engine\n",
            "copying detectron2/engine/train_loop.py -> build/lib.linux-x86_64-3.7/detectron2/engine\n",
            "copying detectron2/engine/hooks.py -> build/lib.linux-x86_64-3.7/detectron2/engine\n",
            "copying detectron2/engine/launch.py -> build/lib.linux-x86_64-3.7/detectron2/engine\n",
            "copying detectron2/engine/__init__.py -> build/lib.linux-x86_64-3.7/detectron2/engine\n",
            "creating build/lib.linux-x86_64-3.7/detectron2/modeling\n",
            "copying detectron2/modeling/box_regression.py -> build/lib.linux-x86_64-3.7/detectron2/modeling\n",
            "copying detectron2/modeling/sampling.py -> build/lib.linux-x86_64-3.7/detectron2/modeling\n",
            "copying detectron2/modeling/anchor_generator.py -> build/lib.linux-x86_64-3.7/detectron2/modeling\n",
            "copying detectron2/modeling/poolers.py -> build/lib.linux-x86_64-3.7/detectron2/modeling\n",
            "copying detectron2/modeling/matcher.py -> build/lib.linux-x86_64-3.7/detectron2/modeling\n",
            "copying detectron2/modeling/postprocessing.py -> build/lib.linux-x86_64-3.7/detectron2/modeling\n",
            "copying detectron2/modeling/test_time_augmentation.py -> build/lib.linux-x86_64-3.7/detectron2/modeling\n",
            "copying detectron2/modeling/__init__.py -> build/lib.linux-x86_64-3.7/detectron2/modeling\n",
            "creating build/lib.linux-x86_64-3.7/detectron2/utils\n",
            "copying detectron2/utils/logger.py -> build/lib.linux-x86_64-3.7/detectron2/utils\n",
            "copying detectron2/utils/comm.py -> build/lib.linux-x86_64-3.7/detectron2/utils\n",
            "copying detectron2/utils/serialize.py -> build/lib.linux-x86_64-3.7/detectron2/utils\n",
            "copying detectron2/utils/memory.py -> build/lib.linux-x86_64-3.7/detectron2/utils\n",
            "copying detectron2/utils/env.py -> build/lib.linux-x86_64-3.7/detectron2/utils\n",
            "copying detectron2/utils/__init__.py -> build/lib.linux-x86_64-3.7/detectron2/utils\n",
            "copying detectron2/utils/events.py -> build/lib.linux-x86_64-3.7/detectron2/utils\n",
            "copying detectron2/utils/registry.py -> build/lib.linux-x86_64-3.7/detectron2/utils\n",
            "copying detectron2/utils/collect_env.py -> build/lib.linux-x86_64-3.7/detectron2/utils\n",
            "copying detectron2/utils/visualizer.py -> build/lib.linux-x86_64-3.7/detectron2/utils\n",
            "copying detectron2/utils/colormap.py -> build/lib.linux-x86_64-3.7/detectron2/utils\n",
            "copying detectron2/utils/video_visualizer.py -> build/lib.linux-x86_64-3.7/detectron2/utils\n",
            "creating build/lib.linux-x86_64-3.7/detectron2/evaluation\n",
            "copying detectron2/evaluation/testing.py -> build/lib.linux-x86_64-3.7/detectron2/evaluation\n",
            "copying detectron2/evaluation/coco_evaluation.py -> build/lib.linux-x86_64-3.7/detectron2/evaluation\n",
            "copying detectron2/evaluation/lvis_evaluation.py -> build/lib.linux-x86_64-3.7/detectron2/evaluation\n",
            "copying detectron2/evaluation/cityscapes_evaluation.py -> build/lib.linux-x86_64-3.7/detectron2/evaluation\n",
            "copying detectron2/evaluation/panoptic_evaluation.py -> build/lib.linux-x86_64-3.7/detectron2/evaluation\n",
            "copying detectron2/evaluation/sem_seg_evaluation.py -> build/lib.linux-x86_64-3.7/detectron2/evaluation\n",
            "copying detectron2/evaluation/evaluator.py -> build/lib.linux-x86_64-3.7/detectron2/evaluation\n",
            "copying detectron2/evaluation/__init__.py -> build/lib.linux-x86_64-3.7/detectron2/evaluation\n",
            "copying detectron2/evaluation/pascal_voc_evaluation.py -> build/lib.linux-x86_64-3.7/detectron2/evaluation\n",
            "creating build/lib.linux-x86_64-3.7/detectron2/config\n",
            "copying detectron2/config/config.py -> build/lib.linux-x86_64-3.7/detectron2/config\n",
            "copying detectron2/config/compat.py -> build/lib.linux-x86_64-3.7/detectron2/config\n",
            "copying detectron2/config/defaults.py -> build/lib.linux-x86_64-3.7/detectron2/config\n",
            "copying detectron2/config/__init__.py -> build/lib.linux-x86_64-3.7/detectron2/config\n",
            "creating build/lib.linux-x86_64-3.7/detectron2/model_zoo\n",
            "copying detectron2/model_zoo/__init__.py -> build/lib.linux-x86_64-3.7/detectron2/model_zoo\n",
            "copying detectron2/model_zoo/model_zoo.py -> build/lib.linux-x86_64-3.7/detectron2/model_zoo\n",
            "creating build/lib.linux-x86_64-3.7/detectron2/structures\n",
            "copying detectron2/structures/boxes.py -> build/lib.linux-x86_64-3.7/detectron2/structures\n",
            "copying detectron2/structures/instances.py -> build/lib.linux-x86_64-3.7/detectron2/structures\n",
            "copying detectron2/structures/keypoints.py -> build/lib.linux-x86_64-3.7/detectron2/structures\n",
            "copying detectron2/structures/__init__.py -> build/lib.linux-x86_64-3.7/detectron2/structures\n",
            "copying detectron2/structures/masks.py -> build/lib.linux-x86_64-3.7/detectron2/structures\n",
            "copying detectron2/structures/rotated_boxes.py -> build/lib.linux-x86_64-3.7/detectron2/structures\n",
            "copying detectron2/structures/image_list.py -> build/lib.linux-x86_64-3.7/detectron2/structures\n",
            "creating build/lib.linux-x86_64-3.7/detectron2/data\n",
            "copying detectron2/data/detection_utils.py -> build/lib.linux-x86_64-3.7/detectron2/data\n",
            "copying detectron2/data/dataset_mapper.py -> build/lib.linux-x86_64-3.7/detectron2/data\n",
            "copying detectron2/data/common.py -> build/lib.linux-x86_64-3.7/detectron2/data\n",
            "copying detectron2/data/__init__.py -> build/lib.linux-x86_64-3.7/detectron2/data\n",
            "copying detectron2/data/build.py -> build/lib.linux-x86_64-3.7/detectron2/data\n",
            "copying detectron2/data/catalog.py -> build/lib.linux-x86_64-3.7/detectron2/data\n",
            "creating build/lib.linux-x86_64-3.7/detectron2/solver\n",
            "copying detectron2/solver/lr_scheduler.py -> build/lib.linux-x86_64-3.7/detectron2/solver\n",
            "copying detectron2/solver/__init__.py -> build/lib.linux-x86_64-3.7/detectron2/solver\n",
            "copying detectron2/solver/build.py -> build/lib.linux-x86_64-3.7/detectron2/solver\n",
            "creating build/lib.linux-x86_64-3.7/detectron2/modeling/meta_arch\n",
            "copying detectron2/modeling/meta_arch/semantic_seg.py -> build/lib.linux-x86_64-3.7/detectron2/modeling/meta_arch\n",
            "copying detectron2/modeling/meta_arch/retinanet.py -> build/lib.linux-x86_64-3.7/detectron2/modeling/meta_arch\n",
            "copying detectron2/modeling/meta_arch/rcnn.py -> build/lib.linux-x86_64-3.7/detectron2/modeling/meta_arch\n",
            "copying detectron2/modeling/meta_arch/__init__.py -> build/lib.linux-x86_64-3.7/detectron2/modeling/meta_arch\n",
            "copying detectron2/modeling/meta_arch/build.py -> build/lib.linux-x86_64-3.7/detectron2/modeling/meta_arch\n",
            "copying detectron2/modeling/meta_arch/panoptic_fpn.py -> build/lib.linux-x86_64-3.7/detectron2/modeling/meta_arch\n",
            "creating build/lib.linux-x86_64-3.7/detectron2/modeling/backbone\n",
            "copying detectron2/modeling/backbone/resnet.py -> build/lib.linux-x86_64-3.7/detectron2/modeling/backbone\n",
            "copying detectron2/modeling/backbone/backbone.py -> build/lib.linux-x86_64-3.7/detectron2/modeling/backbone\n",
            "copying detectron2/modeling/backbone/__init__.py -> build/lib.linux-x86_64-3.7/detectron2/modeling/backbone\n",
            "copying detectron2/modeling/backbone/build.py -> build/lib.linux-x86_64-3.7/detectron2/modeling/backbone\n",
            "copying detectron2/modeling/backbone/fpn.py -> build/lib.linux-x86_64-3.7/detectron2/modeling/backbone\n",
            "creating build/lib.linux-x86_64-3.7/detectron2/modeling/proposal_generator\n",
            "copying detectron2/modeling/proposal_generator/rrpn_outputs.py -> build/lib.linux-x86_64-3.7/detectron2/modeling/proposal_generator\n",
            "copying detectron2/modeling/proposal_generator/rpn.py -> build/lib.linux-x86_64-3.7/detectron2/modeling/proposal_generator\n",
            "copying detectron2/modeling/proposal_generator/__init__.py -> build/lib.linux-x86_64-3.7/detectron2/modeling/proposal_generator\n",
            "copying detectron2/modeling/proposal_generator/proposal_utils.py -> build/lib.linux-x86_64-3.7/detectron2/modeling/proposal_generator\n",
            "copying detectron2/modeling/proposal_generator/build.py -> build/lib.linux-x86_64-3.7/detectron2/modeling/proposal_generator\n",
            "copying detectron2/modeling/proposal_generator/rrpn.py -> build/lib.linux-x86_64-3.7/detectron2/modeling/proposal_generator\n",
            "copying detectron2/modeling/proposal_generator/rpn_outputs.py -> build/lib.linux-x86_64-3.7/detectron2/modeling/proposal_generator\n",
            "creating build/lib.linux-x86_64-3.7/detectron2/modeling/roi_heads\n",
            "copying detectron2/modeling/roi_heads/cascade_rcnn.py -> build/lib.linux-x86_64-3.7/detectron2/modeling/roi_heads\n",
            "copying detectron2/modeling/roi_heads/rotated_fast_rcnn.py -> build/lib.linux-x86_64-3.7/detectron2/modeling/roi_heads\n",
            "copying detectron2/modeling/roi_heads/keypoint_head.py -> build/lib.linux-x86_64-3.7/detectron2/modeling/roi_heads\n",
            "copying detectron2/modeling/roi_heads/box_head.py -> build/lib.linux-x86_64-3.7/detectron2/modeling/roi_heads\n",
            "copying detectron2/modeling/roi_heads/__init__.py -> build/lib.linux-x86_64-3.7/detectron2/modeling/roi_heads\n",
            "copying detectron2/modeling/roi_heads/fast_rcnn.py -> build/lib.linux-x86_64-3.7/detectron2/modeling/roi_heads\n",
            "copying detectron2/modeling/roi_heads/roi_heads.py -> build/lib.linux-x86_64-3.7/detectron2/modeling/roi_heads\n",
            "copying detectron2/modeling/roi_heads/mask_head.py -> build/lib.linux-x86_64-3.7/detectron2/modeling/roi_heads\n",
            "creating build/lib.linux-x86_64-3.7/detectron2/data/datasets\n",
            "copying detectron2/data/datasets/pascal_voc.py -> build/lib.linux-x86_64-3.7/detectron2/data/datasets\n",
            "copying detectron2/data/datasets/register_coco.py -> build/lib.linux-x86_64-3.7/detectron2/data/datasets\n",
            "copying detectron2/data/datasets/cityscapes.py -> build/lib.linux-x86_64-3.7/detectron2/data/datasets\n",
            "copying detectron2/data/datasets/lvis.py -> build/lib.linux-x86_64-3.7/detectron2/data/datasets\n",
            "copying detectron2/data/datasets/lvis_v0_5_categories.py -> build/lib.linux-x86_64-3.7/detectron2/data/datasets\n",
            "copying detectron2/data/datasets/builtin.py -> build/lib.linux-x86_64-3.7/detectron2/data/datasets\n",
            "copying detectron2/data/datasets/builtin_meta.py -> build/lib.linux-x86_64-3.7/detectron2/data/datasets\n",
            "copying detectron2/data/datasets/__init__.py -> build/lib.linux-x86_64-3.7/detectron2/data/datasets\n",
            "copying detectron2/data/datasets/coco.py -> build/lib.linux-x86_64-3.7/detectron2/data/datasets\n",
            "creating build/lib.linux-x86_64-3.7/detectron2/data/samplers\n",
            "copying detectron2/data/samplers/grouped_batch_sampler.py -> build/lib.linux-x86_64-3.7/detectron2/data/samplers\n",
            "copying detectron2/data/samplers/distributed_sampler.py -> build/lib.linux-x86_64-3.7/detectron2/data/samplers\n",
            "copying detectron2/data/samplers/__init__.py -> build/lib.linux-x86_64-3.7/detectron2/data/samplers\n",
            "creating build/lib.linux-x86_64-3.7/detectron2/data/transforms\n",
            "copying detectron2/data/transforms/transform_gen.py -> build/lib.linux-x86_64-3.7/detectron2/data/transforms\n",
            "copying detectron2/data/transforms/__init__.py -> build/lib.linux-x86_64-3.7/detectron2/data/transforms\n",
            "copying detectron2/data/transforms/transform.py -> build/lib.linux-x86_64-3.7/detectron2/data/transforms\n",
            "creating build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs\n",
            "copying detectron2/model_zoo/configs/Base-RCNN-C4.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs\n",
            "copying detectron2/model_zoo/configs/Base-RCNN-DilatedC5.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs\n",
            "copying detectron2/model_zoo/configs/Base-RetinaNet.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs\n",
            "copying detectron2/model_zoo/configs/Base-RCNN-FPN.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs\n",
            "creating build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/LVIS-InstanceSegmentation\n",
            "copying detectron2/model_zoo/configs/LVIS-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/LVIS-InstanceSegmentation\n",
            "copying detectron2/model_zoo/configs/LVIS-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_1x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/LVIS-InstanceSegmentation\n",
            "copying detectron2/model_zoo/configs/LVIS-InstanceSegmentation/mask_rcnn_R_101_FPN_1x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/LVIS-InstanceSegmentation\n",
            "creating build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-Detection\n",
            "copying detectron2/model_zoo/configs/COCO-Detection/retinanet_R_50_FPN_1x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-Detection\n",
            "copying detectron2/model_zoo/configs/COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-Detection\n",
            "copying detectron2/model_zoo/configs/COCO-Detection/faster_rcnn_R_101_C4_3x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-Detection\n",
            "copying detectron2/model_zoo/configs/COCO-Detection/faster_rcnn_R_50_C4_1x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-Detection\n",
            "copying detectron2/model_zoo/configs/COCO-Detection/faster_rcnn_R_50_DC5_3x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-Detection\n",
            "copying detectron2/model_zoo/configs/COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-Detection\n",
            "copying detectron2/model_zoo/configs/COCO-Detection/fast_rcnn_R_50_FPN_1x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-Detection\n",
            "copying detectron2/model_zoo/configs/COCO-Detection/faster_rcnn_R_50_DC5_1x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-Detection\n",
            "copying detectron2/model_zoo/configs/COCO-Detection/faster_rcnn_R_50_FPN_1x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-Detection\n",
            "copying detectron2/model_zoo/configs/COCO-Detection/faster_rcnn_R_50_C4_3x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-Detection\n",
            "copying detectron2/model_zoo/configs/COCO-Detection/rpn_R_50_FPN_1x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-Detection\n",
            "copying detectron2/model_zoo/configs/COCO-Detection/retinanet_R_50_FPN_3x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-Detection\n",
            "copying detectron2/model_zoo/configs/COCO-Detection/retinanet_R_101_FPN_3x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-Detection\n",
            "copying detectron2/model_zoo/configs/COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-Detection\n",
            "copying detectron2/model_zoo/configs/COCO-Detection/faster_rcnn_R_101_DC5_3x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-Detection\n",
            "copying detectron2/model_zoo/configs/COCO-Detection/rpn_R_50_C4_1x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-Detection\n",
            "creating build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/quick_schedules\n",
            "copying detectron2/model_zoo/configs/quick_schedules/mask_rcnn_R_50_C4_instant_test.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/quick_schedules\n",
            "copying detectron2/model_zoo/configs/quick_schedules/semantic_R_50_FPN_inference_acc_test.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/quick_schedules\n",
            "copying detectron2/model_zoo/configs/quick_schedules/fast_rcnn_R_50_FPN_inference_acc_test.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/quick_schedules\n",
            "copying detectron2/model_zoo/configs/quick_schedules/keypoint_rcnn_R_50_FPN_instant_test.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/quick_schedules\n",
            "copying detectron2/model_zoo/configs/quick_schedules/mask_rcnn_R_50_C4_inference_acc_test.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/quick_schedules\n",
            "copying detectron2/model_zoo/configs/quick_schedules/mask_rcnn_R_50_C4_training_acc_test.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/quick_schedules\n",
            "copying detectron2/model_zoo/configs/quick_schedules/mask_rcnn_R_50_DC5_inference_acc_test.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/quick_schedules\n",
            "copying detectron2/model_zoo/configs/quick_schedules/keypoint_rcnn_R_50_FPN_normalized_training_acc_test.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/quick_schedules\n",
            "copying detectron2/model_zoo/configs/quick_schedules/keypoint_rcnn_R_50_FPN_inference_acc_test.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/quick_schedules\n",
            "copying detectron2/model_zoo/configs/quick_schedules/rpn_R_50_FPN_inference_acc_test.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/quick_schedules\n",
            "copying detectron2/model_zoo/configs/quick_schedules/mask_rcnn_R_50_FPN_instant_test.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/quick_schedules\n",
            "copying detectron2/model_zoo/configs/quick_schedules/semantic_R_50_FPN_instant_test.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/quick_schedules\n",
            "copying detectron2/model_zoo/configs/quick_schedules/keypoint_rcnn_R_50_FPN_training_acc_test.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/quick_schedules\n",
            "copying detectron2/model_zoo/configs/quick_schedules/mask_rcnn_R_50_FPN_training_acc_test.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/quick_schedules\n",
            "copying detectron2/model_zoo/configs/quick_schedules/panoptic_fpn_R_50_instant_test.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/quick_schedules\n",
            "copying detectron2/model_zoo/configs/quick_schedules/panoptic_fpn_R_50_inference_acc_test.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/quick_schedules\n",
            "copying detectron2/model_zoo/configs/quick_schedules/semantic_R_50_FPN_training_acc_test.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/quick_schedules\n",
            "copying detectron2/model_zoo/configs/quick_schedules/rpn_R_50_FPN_instant_test.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/quick_schedules\n",
            "copying detectron2/model_zoo/configs/quick_schedules/retinanet_R_50_FPN_instant_test.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/quick_schedules\n",
            "copying detectron2/model_zoo/configs/quick_schedules/retinanet_R_50_FPN_inference_acc_test.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/quick_schedules\n",
            "copying detectron2/model_zoo/configs/quick_schedules/mask_rcnn_R_50_FPN_inference_acc_test.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/quick_schedules\n",
            "copying detectron2/model_zoo/configs/quick_schedules/fast_rcnn_R_50_FPN_instant_test.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/quick_schedules\n",
            "copying detectron2/model_zoo/configs/quick_schedules/panoptic_fpn_R_50_training_acc_test.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/quick_schedules\n",
            "creating build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/Detectron1-Comparisons\n",
            "copying detectron2/model_zoo/configs/Detectron1-Comparisons/mask_rcnn_R_50_FPN_noaug_1x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/Detectron1-Comparisons\n",
            "copying detectron2/model_zoo/configs/Detectron1-Comparisons/faster_rcnn_R_50_FPN_noaug_1x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/Detectron1-Comparisons\n",
            "copying detectron2/model_zoo/configs/Detectron1-Comparisons/keypoint_rcnn_R_50_FPN_1x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/Detectron1-Comparisons\n",
            "creating build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-Keypoints\n",
            "copying detectron2/model_zoo/configs/COCO-Keypoints/keypoint_rcnn_R_101_FPN_3x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-Keypoints\n",
            "copying detectron2/model_zoo/configs/COCO-Keypoints/keypoint_rcnn_X_101_32x8d_FPN_3x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-Keypoints\n",
            "copying detectron2/model_zoo/configs/COCO-Keypoints/Base-Keypoint-RCNN-FPN.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-Keypoints\n",
            "copying detectron2/model_zoo/configs/COCO-Keypoints/keypoint_rcnn_R_50_FPN_1x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-Keypoints\n",
            "copying detectron2/model_zoo/configs/COCO-Keypoints/keypoint_rcnn_R_50_FPN_3x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-Keypoints\n",
            "creating build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-InstanceSegmentation\n",
            "copying detectron2/model_zoo/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_DC5_3x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-InstanceSegmentation\n",
            "copying detectron2/model_zoo/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-InstanceSegmentation\n",
            "copying detectron2/model_zoo/configs/COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-InstanceSegmentation\n",
            "copying detectron2/model_zoo/configs/COCO-InstanceSegmentation/mask_rcnn_R_101_DC5_3x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-InstanceSegmentation\n",
            "copying detectron2/model_zoo/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_DC5_1x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-InstanceSegmentation\n",
            "copying detectron2/model_zoo/configs/COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-InstanceSegmentation\n",
            "copying detectron2/model_zoo/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-InstanceSegmentation\n",
            "copying detectron2/model_zoo/configs/COCO-InstanceSegmentation/mask_rcnn_R_101_C4_3x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-InstanceSegmentation\n",
            "copying detectron2/model_zoo/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_C4_3x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-InstanceSegmentation\n",
            "copying detectron2/model_zoo/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_C4_1x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-InstanceSegmentation\n",
            "creating build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-PanopticSegmentation\n",
            "copying detectron2/model_zoo/configs/COCO-PanopticSegmentation/panoptic_fpn_R_50_1x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-PanopticSegmentation\n",
            "copying detectron2/model_zoo/configs/COCO-PanopticSegmentation/panoptic_fpn_R_50_3x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-PanopticSegmentation\n",
            "copying detectron2/model_zoo/configs/COCO-PanopticSegmentation/panoptic_fpn_R_101_3x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-PanopticSegmentation\n",
            "copying detectron2/model_zoo/configs/COCO-PanopticSegmentation/Base-Panoptic-FPN.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-PanopticSegmentation\n",
            "creating build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/Misc\n",
            "copying detectron2/model_zoo/configs/Misc/mask_rcnn_R_50_FPN_1x_cls_agnostic.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/Misc\n",
            "copying detectron2/model_zoo/configs/Misc/cascade_mask_rcnn_R_50_FPN_1x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/Misc\n",
            "copying detectron2/model_zoo/configs/Misc/mask_rcnn_R_50_FPN_3x_syncbn.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/Misc\n",
            "copying detectron2/model_zoo/configs/Misc/cascade_mask_rcnn_X_152_32x8d_FPN_IN5k_gn_dconv.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/Misc\n",
            "copying detectron2/model_zoo/configs/Misc/mask_rcnn_R_50_FPN_3x_dconv_c3-c5.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/Misc\n",
            "copying detectron2/model_zoo/configs/Misc/scratch_mask_rcnn_R_50_FPN_3x_gn.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/Misc\n",
            "copying detectron2/model_zoo/configs/Misc/cascade_mask_rcnn_R_50_FPN_3x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/Misc\n",
            "copying detectron2/model_zoo/configs/Misc/panoptic_fpn_R_101_dconv_cascade_gn_3x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/Misc\n",
            "copying detectron2/model_zoo/configs/Misc/semantic_R_50_FPN_1x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/Misc\n",
            "copying detectron2/model_zoo/configs/Misc/mask_rcnn_R_50_FPN_1x_dconv_c3-c5.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/Misc\n",
            "copying detectron2/model_zoo/configs/Misc/mask_rcnn_R_50_FPN_3x_gn.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/Misc\n",
            "creating build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/Cityscapes\n",
            "copying detectron2/model_zoo/configs/Cityscapes/mask_rcnn_R_50_FPN.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/Cityscapes\n",
            "creating build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/PascalVOC-Detection\n",
            "copying detectron2/model_zoo/configs/PascalVOC-Detection/faster_rcnn_R_50_C4.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/PascalVOC-Detection\n",
            "copying detectron2/model_zoo/configs/PascalVOC-Detection/faster_rcnn_R_50_FPN.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/PascalVOC-Detection\n",
            "creating build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/VG-Detection\n",
            "copying detectron2/model_zoo/configs/VG-Detection/faster_rcnn_R_101_C4_caffemaxpool.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/VG-Detection\n",
            "copying detectron2/model_zoo/configs/VG-Detection/faster_rcnn_R_101_C4_attr_caffemaxpool.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/VG-Detection\n",
            "copying detectron2/model_zoo/configs/VG-Detection/faster_rcnn_R_101_C4_caffe.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/VG-Detection\n",
            "running build_ext\n",
            "building 'detectron2._C' extension\n",
            "creating build/temp.linux-x86_64-3.7\n",
            "creating build/temp.linux-x86_64-3.7/content\n",
            "creating build/temp.linux-x86_64-3.7/content/vilio\n",
            "creating build/temp.linux-x86_64-3.7/content/vilio/py-bottom-up-attention\n",
            "creating build/temp.linux-x86_64-3.7/content/vilio/py-bottom-up-attention/detectron2\n",
            "creating build/temp.linux-x86_64-3.7/content/vilio/py-bottom-up-attention/detectron2/layers\n",
            "creating build/temp.linux-x86_64-3.7/content/vilio/py-bottom-up-attention/detectron2/layers/csrc\n",
            "creating build/temp.linux-x86_64-3.7/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/box_iou_rotated\n",
            "creating build/temp.linux-x86_64-3.7/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/nms_rotated\n",
            "creating build/temp.linux-x86_64-3.7/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlign\n",
            "creating build/temp.linux-x86_64-3.7/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlignRotated\n",
            "creating build/temp.linux-x86_64-3.7/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_CUDA -I/content/vilio/py-bottom-up-attention/detectron2/layers/csrc -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp -o build/temp.linux-x86_64-3.7/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kint detectron2::deform_conv_forward(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, int, int, int, int, int, int, int, int, int, int, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::\u001b[01;35m\u001b[Kd\u001b[m\u001b[Keprecated_AT_CHECK();                 \\\n",
            "                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:136:5:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "     \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(weight.type().is_cuda(), \"weight tensor is not on GPU!\");\n",
            "     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::deprecated_AT_CHECK(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                 \\\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:136:5:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "     \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(weight.type().is_cuda(), \"weight tensor is not on GPU!\");\n",
            "     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::\u001b[01;35m\u001b[Kd\u001b[m\u001b[Keprecated_AT_CHECK();                 \\\n",
            "                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:137:5:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "     \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(offset.type().is_cuda(), \"offset tensor is not on GPU!\");\n",
            "     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::deprecated_AT_CHECK(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                 \\\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:137:5:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "     \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(offset.type().is_cuda(), \"offset tensor is not on GPU!\");\n",
            "     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kint detectron2::deform_conv_backward_input(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, int, int, int, int, int, int, int, int, int, int, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::\u001b[01;35m\u001b[Kd\u001b[m\u001b[Keprecated_AT_CHECK();                 \\\n",
            "                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:184:5:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "     \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(input.type().is_cuda(), \"input tensor is not on GPU!\");\n",
            "     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::deprecated_AT_CHECK(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                 \\\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:184:5:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "     \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(input.type().is_cuda(), \"input tensor is not on GPU!\");\n",
            "     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::\u001b[01;35m\u001b[Kd\u001b[m\u001b[Keprecated_AT_CHECK();                 \\\n",
            "                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:185:5:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "     \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(weight.type().is_cuda(), \"weight tensor is not on GPU!\");\n",
            "     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::deprecated_AT_CHECK(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                 \\\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:185:5:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "     \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(weight.type().is_cuda(), \"weight tensor is not on GPU!\");\n",
            "     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::\u001b[01;35m\u001b[Kd\u001b[m\u001b[Keprecated_AT_CHECK();                 \\\n",
            "                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:186:5:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "     \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(offset.type().is_cuda(), \"offset tensor is not on GPU!\");\n",
            "     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::deprecated_AT_CHECK(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                 \\\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:186:5:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "     \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(offset.type().is_cuda(), \"offset tensor is not on GPU!\");\n",
            "     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kint detectron2::deform_conv_backward_filter(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, int, int, int, int, int, int, int, int, int, int, float, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::\u001b[01;35m\u001b[Kd\u001b[m\u001b[Keprecated_AT_CHECK();                 \\\n",
            "                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:234:5:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "     \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(input.type().is_cuda(), \"input tensor is not on GPU!\");\n",
            "     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::deprecated_AT_CHECK(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                 \\\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:234:5:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "     \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(input.type().is_cuda(), \"input tensor is not on GPU!\");\n",
            "     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::\u001b[01;35m\u001b[Kd\u001b[m\u001b[Keprecated_AT_CHECK();                 \\\n",
            "                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:235:5:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "     \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(offset.type().is_cuda(), \"offset tensor is not on GPU!\");\n",
            "     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::deprecated_AT_CHECK(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                 \\\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:235:5:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "     \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(offset.type().is_cuda(), \"offset tensor is not on GPU!\");\n",
            "     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid detectron2::modulated_deform_conv_forward(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, int, int, int, int, int, int, int, int, int, int, bool)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::\u001b[01;35m\u001b[Kd\u001b[m\u001b[Keprecated_AT_CHECK();                 \\\n",
            "                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:284:5:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "     \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(weight.type().is_cuda(), \"weight tensor is not on GPU!\");\n",
            "     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::deprecated_AT_CHECK(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                 \\\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:284:5:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "     \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(weight.type().is_cuda(), \"weight tensor is not on GPU!\");\n",
            "     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::\u001b[01;35m\u001b[Kd\u001b[m\u001b[Keprecated_AT_CHECK();                 \\\n",
            "                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:285:5:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "     \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(bias.type().is_cuda(), \"bias tensor is not on GPU!\");\n",
            "     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::deprecated_AT_CHECK(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                 \\\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:285:5:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "     \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(bias.type().is_cuda(), \"bias tensor is not on GPU!\");\n",
            "     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::\u001b[01;35m\u001b[Kd\u001b[m\u001b[Keprecated_AT_CHECK();                 \\\n",
            "                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:286:5:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "     \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(offset.type().is_cuda(), \"offset tensor is not on GPU!\");\n",
            "     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::deprecated_AT_CHECK(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                 \\\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:286:5:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "     \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(offset.type().is_cuda(), \"offset tensor is not on GPU!\");\n",
            "     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid detectron2::modulated_deform_conv_backward(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, int, int, int, int, int, int, int, int, int, int, bool)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::\u001b[01;35m\u001b[Kd\u001b[m\u001b[Keprecated_AT_CHECK();                 \\\n",
            "                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:341:5:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "     \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(input.type().is_cuda(), \"input tensor is not on GPU!\");\n",
            "     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::deprecated_AT_CHECK(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                 \\\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:341:5:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "     \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(input.type().is_cuda(), \"input tensor is not on GPU!\");\n",
            "     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::\u001b[01;35m\u001b[Kd\u001b[m\u001b[Keprecated_AT_CHECK();                 \\\n",
            "                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:342:5:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "     \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(weight.type().is_cuda(), \"weight tensor is not on GPU!\");\n",
            "     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::deprecated_AT_CHECK(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                 \\\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:342:5:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "     \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(weight.type().is_cuda(), \"weight tensor is not on GPU!\");\n",
            "     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::\u001b[01;35m\u001b[Kd\u001b[m\u001b[Keprecated_AT_CHECK();                 \\\n",
            "                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:343:5:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "     \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(bias.type().is_cuda(), \"bias tensor is not on GPU!\");\n",
            "     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::deprecated_AT_CHECK(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                 \\\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:343:5:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "     \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(bias.type().is_cuda(), \"bias tensor is not on GPU!\");\n",
            "     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::\u001b[01;35m\u001b[Kd\u001b[m\u001b[Keprecated_AT_CHECK();                 \\\n",
            "                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:344:5:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "     \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(offset.type().is_cuda(), \"offset tensor is not on GPU!\");\n",
            "     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::deprecated_AT_CHECK(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                 \\\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:344:5:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "     \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(offset.type().is_cuda(), \"offset tensor is not on GPU!\");\n",
            "     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_CUDA -I/content/vilio/py-bottom-up-attention/detectron2/layers/csrc -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/vilio/py-bottom-up-attention/detectron2/layers/csrc/box_iou_rotated/box_iou_rotated_cpu.cpp -o build/temp.linux-x86_64-3.7/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/box_iou_rotated/box_iou_rotated_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_CUDA -I/content/vilio/py-bottom-up-attention/detectron2/layers/csrc -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/vilio/py-bottom-up-attention/detectron2/layers/csrc/nms_rotated/nms_rotated_cpu.cpp -o build/temp.linux-x86_64-3.7/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/nms_rotated/nms_rotated_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/nms_rotated/nms_rotated.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/nms_rotated/nms_rotated_cpu.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/nms_rotated/nms_rotated_cpu.cpp:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:103:56:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     at::ScalarType _st = ::detail::scalar_type(the_type\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                    \\\n",
            "                                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/nms_rotated/nms_rotated_cpu.cpp:67:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_DISPATCH_FLOATING_TYPES\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KAT_DISPATCH_FLOATING_TYPES\u001b[m\u001b[K(dets.type(), \"nms_rotated\", [&] {\n",
            "   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:31:23:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline at::ScalarType \u001b[01;36m\u001b[Kscalar_type\u001b[m\u001b[K(const at::DeprecatedTypeProperties &t) {\n",
            "                       \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_CUDA -I/content/vilio/py-bottom-up-attention/detectron2/layers/csrc -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlign/ROIAlign_cpu.cpp -o build/temp.linux-x86_64-3.7/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlign/ROIAlign_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlign/ROIAlign.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlign/ROIAlign_cpu.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlign/ROIAlign_cpu.cpp:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:116:56:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     at::ScalarType _st = ::detail::scalar_type(the_type\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                    \\\n",
            "                                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlign/ROIAlign_cpu.cpp:429:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_DISPATCH_FLOATING_TYPES_AND_HALF\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"ROIAlign_forward\", [&] {\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:31:23:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline at::ScalarType \u001b[01;36m\u001b[Kscalar_type\u001b[m\u001b[K(const at::DeprecatedTypeProperties &t) {\n",
            "                       \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlign/ROIAlign_cpu.cpp:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:116:56:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     at::ScalarType _st = ::detail::scalar_type(the_type\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                    \\\n",
            "                                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlign/ROIAlign_cpu.cpp:481:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_DISPATCH_FLOATING_TYPES_AND_HALF\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_DISPATCH_FLOATING_TYPES_AND_HALF(grad.type(), \"ROIAlign_forward\", [&] {\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:31:23:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline at::ScalarType \u001b[01;36m\u001b[Kscalar_type\u001b[m\u001b[K(const at::DeprecatedTypeProperties &t) {\n",
            "                       \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_CUDA -I/content/vilio/py-bottom-up-attention/detectron2/layers/csrc -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.cpp -o build/temp.linux-x86_64-3.7/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.cpp:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:116:56:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     at::ScalarType _st = ::detail::scalar_type(the_type\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                    \\\n",
            "                                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.cpp:446:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_DISPATCH_FLOATING_TYPES_AND_HALF\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:31:23:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline at::ScalarType \u001b[01;36m\u001b[Kscalar_type\u001b[m\u001b[K(const at::DeprecatedTypeProperties &t) {\n",
            "                       \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.cpp:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:116:56:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     at::ScalarType _st = ::detail::scalar_type(the_type\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                    \\\n",
            "                                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.cpp:497:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_DISPATCH_FLOATING_TYPES_AND_HALF\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:31:23:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline at::ScalarType \u001b[01;36m\u001b[Kscalar_type\u001b[m\u001b[K(const at::DeprecatedTypeProperties &t) {\n",
            "                       \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/vilio/py-bottom-up-attention/detectron2/layers/csrc -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/vilio/py-bottom-up-attention/detectron2/layers/csrc/box_iou_rotated/box_iou_rotated_cuda.cu -o build/temp.linux-x86_64-3.7/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/box_iou_rotated/box_iou_rotated_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++11\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/vilio/py-bottom-up-attention/detectron2/layers/csrc -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu -o build/temp.linux-x86_64-3.7/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++11\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kint detectron2::deform_conv_forward(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, int, int, int, int, int, int, int, int, int, int, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:136:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_CHECK(weight.\u001b[01;35m\u001b[Ktype().is_cuda(), \"\u001b[m\u001b[Kweight tensor is not on GPU!\");\n",
            "                     \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:136:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_CHECK(weight.type().is_cuda(), \"w\u001b[01;35m\u001b[Ke\u001b[m\u001b[Kight tensor is not on GPU!\");\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:137:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_CHECK(offset.\u001b[01;35m\u001b[Ktype().is_cuda(), \"\u001b[m\u001b[Koffset tensor is not on GPU!\");\n",
            "                     \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:137:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_CHECK(offset.type().is_cuda(), \"o\u001b[01;35m\u001b[Kf\u001b[m\u001b[Kfset tensor is not on GPU!\");\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kint detectron2::deform_conv_backward_input(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, int, int, int, int, int, int, int, int, int, int, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:184:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_CHECK(input.t\u001b[01;35m\u001b[Kype().is_cuda(), \"i\u001b[m\u001b[Knput tensor is not on GPU!\");\n",
            "                     \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:184:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_CHECK(input.type().is_cuda(), \"in\u001b[01;35m\u001b[Kp\u001b[m\u001b[Kut tensor is not on GPU!\");\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:185:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_CHECK(weight.\u001b[01;35m\u001b[Ktype().is_cuda(), \"\u001b[m\u001b[Kweight tensor is not on GPU!\");\n",
            "                     \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:185:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_CHECK(weight.type().is_cuda(), \"w\u001b[01;35m\u001b[Ke\u001b[m\u001b[Kight tensor is not on GPU!\");\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:186:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_CHECK(offset.\u001b[01;35m\u001b[Ktype().is_cuda(), \"\u001b[m\u001b[Koffset tensor is not on GPU!\");\n",
            "                     \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:186:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_CHECK(offset.type().is_cuda(), \"o\u001b[01;35m\u001b[Kf\u001b[m\u001b[Kfset tensor is not on GPU!\");\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kint detectron2::deform_conv_backward_filter(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, int, int, int, int, int, int, int, int, int, int, float, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:234:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_CHECK(input.t\u001b[01;35m\u001b[Kype().is_cuda(), \"i\u001b[m\u001b[Knput tensor is not on GPU!\");\n",
            "                     \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:234:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_CHECK(input.type().is_cuda(), \"in\u001b[01;35m\u001b[Kp\u001b[m\u001b[Kut tensor is not on GPU!\");\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:235:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_CHECK(offset.\u001b[01;35m\u001b[Ktype().is_cuda(), \"\u001b[m\u001b[Koffset tensor is not on GPU!\");\n",
            "                     \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:235:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_CHECK(offset.type().is_cuda(), \"o\u001b[01;35m\u001b[Kf\u001b[m\u001b[Kfset tensor is not on GPU!\");\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid detectron2::modulated_deform_conv_forward(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, int, int, int, int, int, int, int, int, int, int, bool)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:284:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_CHECK(weight.\u001b[01;35m\u001b[Ktype().is_cuda(), \"\u001b[m\u001b[Kweight tensor is not on GPU!\");\n",
            "                     \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:284:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_CHECK(weight.type().is_cuda(), \"w\u001b[01;35m\u001b[Ke\u001b[m\u001b[Kight tensor is not on GPU!\");\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:285:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_CHECK(bias.ty\u001b[01;35m\u001b[Kpe().is_cuda(), \"bi\u001b[m\u001b[Kas tensor is not on GPU!\");\n",
            "                     \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:285:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_CHECK(bias.type().is_cuda(), \"bia\u001b[01;35m\u001b[Ks\u001b[m\u001b[K tensor is not on GPU!\");\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:286:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_CHECK(offset.\u001b[01;35m\u001b[Ktype().is_cuda(), \"\u001b[m\u001b[Koffset tensor is not on GPU!\");\n",
            "                     \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:286:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_CHECK(offset.type().is_cuda(), \"o\u001b[01;35m\u001b[Kf\u001b[m\u001b[Kfset tensor is not on GPU!\");\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid detectron2::modulated_deform_conv_backward(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, int, int, int, int, int, int, int, int, int, int, bool)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:341:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_CHECK(input.t\u001b[01;35m\u001b[Kype().is_cuda(), \"i\u001b[m\u001b[Knput tensor is not on GPU!\");\n",
            "                     \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:341:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_CHECK(input.type().is_cuda(), \"in\u001b[01;35m\u001b[Kp\u001b[m\u001b[Kut tensor is not on GPU!\");\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:342:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_CHECK(weight.\u001b[01;35m\u001b[Ktype().is_cuda(), \"\u001b[m\u001b[Kweight tensor is not on GPU!\");\n",
            "                     \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:342:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_CHECK(weight.type().is_cuda(), \"w\u001b[01;35m\u001b[Ke\u001b[m\u001b[Kight tensor is not on GPU!\");\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:343:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_CHECK(bias.ty\u001b[01;35m\u001b[Kpe().is_cuda(), \"bi\u001b[m\u001b[Kas tensor is not on GPU!\");\n",
            "                     \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:343:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_CHECK(bias.type().is_cuda(), \"bia\u001b[01;35m\u001b[Ks\u001b[m\u001b[K tensor is not on GPU!\");\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:344:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_CHECK(offset.\u001b[01;35m\u001b[Ktype().is_cuda(), \"\u001b[m\u001b[Koffset tensor is not on GPU!\");\n",
            "                     \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:344:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_CHECK(offset.type().is_cuda(), \"o\u001b[01;35m\u001b[Kf\u001b[m\u001b[Kfset tensor is not on GPU!\");\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid detectron2::shape_check(at::Tensor, at::Tensor, at::Tensor*, at::Tensor, int, int, int, int, int, int, int, int, int, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:155:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK(\n",
            "                     \u001b[01;35m\u001b[K^\u001b[m\u001b[K                  \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:155:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK(\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:161:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK(weight.is\u001b[01;35m\u001b[K_contiguous(), \"wei\u001b[m\u001b[Kght tensor has to be contiguous\");\n",
            "                     \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:161:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK(weight.is_contiguous(), \"weig\u001b[01;35m\u001b[Kh\u001b[m\u001b[Kt tensor has to be contiguous\");\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:163:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK(\n",
            "                     \u001b[01;35m\u001b[K^\u001b[m\u001b[K                  \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:163:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK(\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:169:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK(\n",
            "                     \u001b[01;35m\u001b[K^\u001b[m\u001b[K                  \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:169:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK(\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:178:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK(\n",
            "                     \u001b[01;35m\u001b[K^\u001b[m\u001b[K                  \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:178:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK(\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:184:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK(\n",
            "                     \u001b[01;35m\u001b[K^\u001b[m\u001b[K                  \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:184:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK(\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:201:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK(\n",
            "                     \u001b[01;35m\u001b[K^\u001b[m\u001b[K                  \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:201:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK(\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:215:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK(\n",
            "                     \u001b[01;35m\u001b[K^\u001b[m\u001b[K                  \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:215:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK(\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:230:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK(\n",
            "                     \u001b[01;35m\u001b[K^\u001b[m\u001b[K                  \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:230:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK(\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:236:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK(\n",
            "                     \u001b[01;35m\u001b[K^\u001b[m\u001b[K                  \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:236:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK(\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:240:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK(\n",
            "                     \u001b[01;35m\u001b[K^\u001b[m\u001b[K                  \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:240:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK(\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:249:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK(\n",
            "                     \u001b[01;35m\u001b[K^\u001b[m\u001b[K                  \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:249:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK(\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:254:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_CHECK(\n",
            "                     \u001b[01;35m\u001b[K^\u001b[m\u001b[K                  \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:254:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_CHECK(\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:260:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_CHECK(\n",
            "                     \u001b[01;35m\u001b[K^\u001b[m\u001b[K                  \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:260:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_CHECK(\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kint detectron2::deform_conv_forward_cuda(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, int, int, int, int, int, int, int, int, int, int, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:338:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK((offset.s\u001b[01;35m\u001b[Kize(0) == batchSize\u001b[m\u001b[K), \"invalid batch size of offset\");\n",
            "                     \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:338:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK((offset.size(0) == batchSize)\u001b[01;35m\u001b[K,\u001b[m\u001b[K \"invalid batch size of offset\");\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kint detectron2::deform_conv_backward_input_cuda(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, int, int, int, int, int, int, int, int, int, int, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:503:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK((offset.s\u001b[01;35m\u001b[Kize(0) == batchSize\u001b[m\u001b[K), 3, \"invalid batch size of offset\");\n",
            "                     \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:503:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK((offset.size(0) == batchSize)\u001b[01;35m\u001b[K,\u001b[m\u001b[K 3, \"invalid batch size of offset\");\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kint detectron2::deform_conv_backward_parameters_cuda(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, int, int, int, int, int, int, int, int, int, int, float, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:696:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK((offset.s\u001b[01;35m\u001b[Kize(0) == batchSize\u001b[m\u001b[K), \"invalid batch size of offset\");\n",
            "                     \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:696:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK((offset.size(0) == batchSize)\u001b[01;35m\u001b[K,\u001b[m\u001b[K \"invalid batch size of offset\");\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid detectron2::modulated_deform_conv_cuda_forward(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, int, int, int, int, int, int, int, int, int, int, bool)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:823:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK(input.is_\u001b[01;35m\u001b[Kcontiguous(), \"inpu\u001b[m\u001b[Kt tensor has to be contiguous\");\n",
            "                     \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:823:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK(input.is_contiguous(), \"input\u001b[01;35m\u001b[K \u001b[m\u001b[Ktensor has to be contiguous\");\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:824:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK(weight.is\u001b[01;35m\u001b[K_contiguous(), \"wei\u001b[m\u001b[Kght tensor has to be contiguous\");\n",
            "                     \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:824:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK(weight.is_contiguous(), \"weig\u001b[01;35m\u001b[Kh\u001b[m\u001b[Kt tensor has to be contiguous\");\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid detectron2::modulated_deform_conv_cuda_backward(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, int, int, int, int, int, int, int, int, int, int, bool)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:953:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK(input.is_\u001b[01;35m\u001b[Kcontiguous(), \"inpu\u001b[m\u001b[Kt tensor has to be contiguous\");\n",
            "                     \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:953:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK(input.is_contiguous(), \"input\u001b[01;35m\u001b[K \u001b[m\u001b[Ktensor has to be contiguous\");\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:954:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK(weight.is\u001b[01;35m\u001b[K_contiguous(), \"wei\u001b[m\u001b[Kght tensor has to be contiguous\");\n",
            "                     \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:954:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK(weight.is_contiguous(), \"weig\u001b[01;35m\u001b[Kh\u001b[m\u001b[Kt tensor has to be contiguous\");\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/vilio/py-bottom-up-attention/detectron2/layers/csrc -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda_kernel.cu -o build/temp.linux-x86_64-3.7/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++11\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda_kernel.cu:486:100:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:31:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline at::\u001b[m\u001b[KScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda_kernel.cu:555:101:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                     \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:31:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline at::\u001b[m\u001b[KScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda_kernel.cu:625:101:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                     \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:31:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline at::\u001b[m\u001b[KScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda_kernel.cu:1098:100:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:31:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline at::\u001b[m\u001b[KScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda_kernel.cu:1168:101:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                     \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:31:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline at::\u001b[m\u001b[KScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda_kernel.cu:1241:101:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                     \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:31:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline at::\u001b[m\u001b[KScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/vilio/py-bottom-up-attention/detectron2/layers/csrc -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/vilio/py-bottom-up-attention/detectron2/layers/csrc/nms_rotated/nms_rotated_cuda.cu -o build/temp.linux-x86_64-3.7/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/nms_rotated/nms_rotated_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++11\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/nms_rotated/nms_rotated_cuda.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/nms_rotated/nms_rotated_cuda.cu:97:104:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:31:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline at::\u001b[m\u001b[KScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/nms_rotated/nms_rotated_cuda.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/nms_rotated/nms_rotated_cuda.cu:97:350:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                              \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/nms_rotated/nms_rotated_cuda.cu:97:402:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = long int]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                  \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/nms_rotated/nms_rotated_cuda.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/nms_rotated/nms_rotated_cuda.cu:97:639:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/nms_rotated/nms_rotated_cuda.cu:97:691:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = long int]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/nms_rotated/nms_rotated_cuda.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/nms_rotated/nms_rotated_cuda.cu:97:939:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/nms_rotated/nms_rotated_cuda.cu:97:991:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = long int]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/nms_rotated/nms_rotated_cuda.cu:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kat::Tensor detectron2::nms_rotated_cuda(const at::Tensor&, const at::Tensor&, float)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/nms_rotated/nms_rotated_cuda.cu:107:84:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = long int]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   unsigned long long* mask_host = (unsigned long long*)mask_cpu.data<int64_t>();\n",
            "                                                                                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/nms_rotated/nms_rotated_cuda.cu:114:46:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = long int]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   int64_t* keep_out = keep.data<int64_t>();\n",
            "                                              \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/vilio/py-bottom-up-attention/detectron2/layers/csrc -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlign/ROIAlign_cuda.cu -o build/temp.linux-x86_64-3.7/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlign/ROIAlign_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++11\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/vilio/py-bottom-up-attention/detectron2/layers/csrc -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cuda.cu -o build/temp.linux-x86_64-3.7/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++11\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/vilio/py-bottom-up-attention/detectron2/layers/csrc -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/vilio/py-bottom-up-attention/detectron2/layers/csrc/cuda_version.cu -o build/temp.linux-x86_64-3.7/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/cuda_version.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++11\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 -Wl,-Bsymbolic-functions -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.o build/temp.linux-x86_64-3.7/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/box_iou_rotated/box_iou_rotated_cpu.o build/temp.linux-x86_64-3.7/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/nms_rotated/nms_rotated_cpu.o build/temp.linux-x86_64-3.7/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlign/ROIAlign_cpu.o build/temp.linux-x86_64-3.7/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.o build/temp.linux-x86_64-3.7/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/box_iou_rotated/box_iou_rotated_cuda.o build/temp.linux-x86_64-3.7/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.o build/temp.linux-x86_64-3.7/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda_kernel.o build/temp.linux-x86_64-3.7/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/nms_rotated/nms_rotated_cuda.o build/temp.linux-x86_64-3.7/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlign/ROIAlign_cuda.o build/temp.linux-x86_64-3.7/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cuda.o build/temp.linux-x86_64-3.7/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/cuda_version.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.7/detectron2/_C.cpython-37m-x86_64-linux-gnu.so\n",
            "running develop\n",
            "running egg_info\n",
            "creating detectron2.egg-info\n",
            "writing detectron2.egg-info/PKG-INFO\n",
            "writing dependency_links to detectron2.egg-info/dependency_links.txt\n",
            "writing requirements to detectron2.egg-info/requires.txt\n",
            "writing top-level names to detectron2.egg-info/top_level.txt\n",
            "writing manifest file 'detectron2.egg-info/SOURCES.txt'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'detectron2.egg-info/SOURCES.txt'\n",
            "running build_ext\n",
            "copying build/lib.linux-x86_64-3.7/detectron2/_C.cpython-37m-x86_64-linux-gnu.so -> detectron2\n",
            "Creating /usr/local/lib/python3.7/dist-packages/detectron2.egg-link (link to .)\n",
            "Adding detectron2 0.1 to easy-install.pth file\n",
            "\n",
            "Installed /content/vilio/py-bottom-up-attention\n",
            "Processing dependencies for detectron2==0.1\n",
            "Searching for imagesize==1.3.0\n",
            "Best match: imagesize 1.3.0\n",
            "Adding imagesize 1.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for tensorboard==2.8.0\n",
            "Best match: tensorboard 2.8.0\n",
            "Adding tensorboard 2.8.0 to easy-install.pth file\n",
            "Installing tensorboard script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for tqdm==4.64.0\n",
            "Best match: tqdm 4.64.0\n",
            "Adding tqdm 4.64.0 to easy-install.pth file\n",
            "Installing tqdm script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for matplotlib==3.2.2\n",
            "Best match: matplotlib 3.2.2\n",
            "Adding matplotlib 3.2.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for cloudpickle==1.3.0\n",
            "Best match: cloudpickle 1.3.0\n",
            "Adding cloudpickle 1.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for tabulate==0.8.9\n",
            "Best match: tabulate 0.8.9\n",
            "Adding tabulate 0.8.9 to easy-install.pth file\n",
            "Installing tabulate script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for yacs==0.1.8\n",
            "Best match: yacs 0.1.8\n",
            "Adding yacs 0.1.8 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for Pillow==7.1.2\n",
            "Best match: Pillow 7.1.2\n",
            "Adding Pillow 7.1.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for termcolor==1.1.0\n",
            "Best match: termcolor 1.1.0\n",
            "Adding termcolor 1.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for google-auth-oauthlib==0.4.6\n",
            "Best match: google-auth-oauthlib 0.4.6\n",
            "Adding google-auth-oauthlib 0.4.6 to easy-install.pth file\n",
            "Installing google-oauthlib-tool script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for tensorboard-data-server==0.6.1\n",
            "Best match: tensorboard-data-server 0.6.1\n",
            "Adding tensorboard-data-server 0.6.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for Markdown==3.3.7\n",
            "Best match: Markdown 3.3.7\n",
            "Adding Markdown 3.3.7 to easy-install.pth file\n",
            "Installing markdown_py script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for absl-py==1.0.0\n",
            "Best match: absl-py 1.0.0\n",
            "Adding absl-py 1.0.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for numpy==1.21.6\n",
            "Best match: numpy 1.21.6\n",
            "Adding numpy 1.21.6 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.7 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for wheel==0.37.1\n",
            "Best match: wheel 0.37.1\n",
            "Adding wheel 0.37.1 to easy-install.pth file\n",
            "Installing wheel script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for requests==2.23.0\n",
            "Best match: requests 2.23.0\n",
            "Adding requests 2.23.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for protobuf==3.17.3\n",
            "Best match: protobuf 3.17.3\n",
            "Adding protobuf 3.17.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for grpcio==1.46.1\n",
            "Best match: grpcio 1.46.1\n",
            "Adding grpcio 1.46.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for tensorboard-plugin-wit==1.8.1\n",
            "Best match: tensorboard-plugin-wit 1.8.1\n",
            "Adding tensorboard-plugin-wit 1.8.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for google-auth==1.35.0\n",
            "Best match: google-auth 1.35.0\n",
            "Adding google-auth 1.35.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for setuptools==57.4.0\n",
            "Best match: setuptools 57.4.0\n",
            "Adding setuptools 57.4.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for Werkzeug==1.0.1\n",
            "Best match: Werkzeug 1.0.1\n",
            "Adding Werkzeug 1.0.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for kiwisolver==1.4.2\n",
            "Best match: kiwisolver 1.4.2\n",
            "Adding kiwisolver 1.4.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for python-dateutil==2.8.2\n",
            "Best match: python-dateutil 2.8.2\n",
            "Adding python-dateutil 2.8.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for cycler==0.11.0\n",
            "Best match: cycler 0.11.0\n",
            "Adding cycler 0.11.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for pyparsing==3.0.9\n",
            "Best match: pyparsing 3.0.9\n",
            "Adding pyparsing 3.0.9 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for PyYAML==6.0\n",
            "Best match: PyYAML 6.0\n",
            "Adding PyYAML 6.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for requests-oauthlib==1.3.1\n",
            "Best match: requests-oauthlib 1.3.1\n",
            "Adding requests-oauthlib 1.3.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for importlib-metadata==4.11.3\n",
            "Best match: importlib-metadata 4.11.3\n",
            "Adding importlib-metadata 4.11.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for six==1.15.0\n",
            "Best match: six 1.15.0\n",
            "Adding six 1.15.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for idna==2.10\n",
            "Best match: idna 2.10\n",
            "Adding idna 2.10 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for chardet==3.0.4\n",
            "Best match: chardet 3.0.4\n",
            "Adding chardet 3.0.4 to easy-install.pth file\n",
            "Installing chardetect script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for urllib3==1.24.3\n",
            "Best match: urllib3 1.24.3\n",
            "Adding urllib3 1.24.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for certifi==2022.5.18.1\n",
            "Best match: certifi 2022.5.18.1\n",
            "Adding certifi 2022.5.18.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for rsa==4.8\n",
            "Best match: rsa 4.8\n",
            "Adding rsa 4.8 to easy-install.pth file\n",
            "Installing pyrsa-decrypt script to /usr/local/bin\n",
            "Installing pyrsa-encrypt script to /usr/local/bin\n",
            "Installing pyrsa-keygen script to /usr/local/bin\n",
            "Installing pyrsa-priv2pub script to /usr/local/bin\n",
            "Installing pyrsa-sign script to /usr/local/bin\n",
            "Installing pyrsa-verify script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for pyasn1-modules==0.2.8\n",
            "Best match: pyasn1-modules 0.2.8\n",
            "Adding pyasn1-modules 0.2.8 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for cachetools==4.2.4\n",
            "Best match: cachetools 4.2.4\n",
            "Adding cachetools 4.2.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for typing-extensions==4.2.0\n",
            "Best match: typing-extensions 4.2.0\n",
            "Adding typing-extensions 4.2.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for oauthlib==3.2.0\n",
            "Best match: oauthlib 3.2.0\n",
            "Adding oauthlib 3.2.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for zipp==3.8.0\n",
            "Best match: zipp 3.8.0\n",
            "Adding zipp 3.8.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for pyasn1==0.4.8\n",
            "Best match: pyasn1 0.4.8\n",
            "Adding pyasn1 0.4.8 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Finished processing dependencies for detectron2==0.1\n"
          ]
        }
      ],
      "source": [
        "# used for py-bottom-up-attention\n",
        "# !python setup.py build develop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESIwA-mEx7Rv"
      },
      "source": [
        "##  <font color='#A8EB15'> Data Download\n",
        "\n",
        "In order to use **ERNIE-Vil** we need:\n",
        "- Put in `/content/vilio/ernie-vil/data/hm`:\n",
        "  * images and .json files from HM "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "i81B_Lkzy2Ft"
      },
      "outputs": [],
      "source": [
        "# we will put the data in the ernie-vil folder\n",
        "import os\n",
        "os.chdir(\"/content/vilio/ernie-vil/data/hm\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://drive.google.com/file/d/1Dbl-CQI61U3kDzzttE37lgl22b0Ay_nD/view?usp=sharing"
      ],
      "metadata": {
        "id": "b3_qgXY4fN9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!cp /content/drive/MyDrive/dataset/hateful_memes.zip /content/vilio/ernie-vil/data/hm/"
      ],
      "metadata": {
        "id": "5dY-k8cNW4WO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time \n",
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1B5kwn6IW28M03tlOoUdJQ1jFRgSyK6Ya' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1B5kwn6IW28M03tlOoUdJQ1jFRgSyK6Ya\" -O hateful_memes.zip && rm -rf /tmp/cookies.txt"
      ],
      "metadata": {
        "id": "ra00lhIWfT-y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fad1ae4b-06d2-412c-f64d-74422a4db881"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-31 09:46:18--  https://docs.google.com/uc?export=download&confirm=t&id=1B5kwn6IW28M03tlOoUdJQ1jFRgSyK6Ya\n",
            "Resolving docs.google.com (docs.google.com)... 142.250.107.138, 142.250.107.113, 142.250.107.102, ...\n",
            "Connecting to docs.google.com (docs.google.com)|142.250.107.138|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-0c-44-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/rl9n9029ggtdp34bhk25b8u0s10vl3po/1653990375000/01761641334275034120/*/1B5kwn6IW28M03tlOoUdJQ1jFRgSyK6Ya?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2022-05-31 09:46:18--  https://doc-0c-44-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/rl9n9029ggtdp34bhk25b8u0s10vl3po/1653990375000/01761641334275034120/*/1B5kwn6IW28M03tlOoUdJQ1jFRgSyK6Ya?e=download\n",
            "Resolving doc-0c-44-docs.googleusercontent.com (doc-0c-44-docs.googleusercontent.com)... 142.250.99.132, 2607:f8b0:400e:c0c::84\n",
            "Connecting to doc-0c-44-docs.googleusercontent.com (doc-0c-44-docs.googleusercontent.com)|142.250.99.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5045032354 (4.7G) [application/x-zip-compressed]\n",
            "Saving to: ‘hateful_memes.zip’\n",
            "\n",
            "hateful_memes.zip   100%[===================>]   4.70G   105MB/s    in 49s     \n",
            "\n",
            "2022-05-31 09:47:08 (98.2 MB/s) - ‘hateful_memes.zip’ saved [5045032354/5045032354]\n",
            "\n",
            "CPU times: user 716 ms, sys: 157 ms, total: 873 ms\n",
            "Wall time: 49.9 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KGqAg0fux89K"
      },
      "outputs": [],
      "source": [
        "#%%time \n",
        "#!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1XiwUjy9BSwKw2x3eDDOG7e8tHrntj1l3' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1XiwUjy9BSwKw2x3eDDOG7e8tHrntj1l3\" -O hateful_memes.zip && rm -rf /tmp/cookies.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TQ40VtyyuqL",
        "outputId": "70962504-0505-41f4-b482-4bde80dffc2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mSe han truncado las últimas 5000 líneas del flujo de salida.\u001b[0m\n",
            "  inflating: hateful_memes/img/24570.png  \n",
            "  inflating: hateful_memes/img/50734.png  \n",
            "  inflating: hateful_memes/img/85073.png  \n",
            "  inflating: hateful_memes/img/65371.png  \n",
            "  inflating: hateful_memes/img/79305.png  \n",
            "  inflating: hateful_memes/img/56972.png  \n",
            "  inflating: hateful_memes/img/14329.png  \n",
            "  inflating: hateful_memes/img/07685.png  \n",
            "  inflating: hateful_memes/img/69823.png  \n",
            "  inflating: hateful_memes/img/37095.png  \n",
            "  inflating: hateful_memes/img/45201.png  \n",
            "  inflating: hateful_memes/img/96435.png  \n",
            "  inflating: hateful_memes/img/35701.png  \n",
            "  inflating: hateful_memes/img/48106.png  \n",
            "  inflating: hateful_memes/img/17963.png  \n",
            "  inflating: hateful_memes/img/72046.png  \n",
            "  inflating: hateful_memes/img/26983.png  \n",
            "  inflating: hateful_memes/img/27810.png  \n",
            "  inflating: hateful_memes/img/76045.png  \n",
            "  inflating: hateful_memes/img/07865.png  \n",
            "  inflating: hateful_memes/img/91072.png  \n",
            "  inflating: hateful_memes/img/72386.png  \n",
            "  inflating: hateful_memes/img/81079.png  \n",
            "  inflating: hateful_memes/img/64532.png  \n",
            "  inflating: hateful_memes/img/37024.png  \n",
            "  inflating: hateful_memes/img/09852.png  \n",
            "  inflating: hateful_memes/img/60234.png  \n",
            "  inflating: hateful_memes/img/27058.png  \n",
            "  inflating: hateful_memes/img/90378.png  \n",
            "  inflating: hateful_memes/img/21850.png  \n",
            "  inflating: hateful_memes/img/56872.png  \n",
            "  inflating: hateful_memes/img/21047.png  \n",
            "  inflating: hateful_memes/img/82076.png  \n",
            "  inflating: hateful_memes/img/59836.png  \n",
            "  inflating: hateful_memes/img/45891.png  \n",
            "  inflating: hateful_memes/img/42376.png  \n",
            "  inflating: hateful_memes/img/16720.png  \n",
            "  inflating: hateful_memes/img/07632.png  \n",
            "  inflating: hateful_memes/img/04973.png  \n",
            "  inflating: hateful_memes/img/08427.png  \n",
            "  inflating: hateful_memes/img/72504.png  \n",
            "  inflating: hateful_memes/img/28067.png  \n",
            "  inflating: hateful_memes/img/15308.png  \n",
            "  inflating: hateful_memes/img/84015.png  \n",
            "  inflating: hateful_memes/img/59731.png  \n",
            "  inflating: hateful_memes/img/27150.png  \n",
            "  inflating: hateful_memes/img/10438.png  \n",
            "  inflating: hateful_memes/img/72536.png  \n",
            "  inflating: hateful_memes/img/35972.png  \n",
            "  inflating: hateful_memes/img/49307.png  \n",
            "  inflating: hateful_memes/img/01598.png  \n",
            "  inflating: hateful_memes/img/49316.png  \n",
            "  inflating: hateful_memes/img/19526.png  \n",
            "  inflating: hateful_memes/img/75286.png  \n",
            "  inflating: hateful_memes/img/53806.png  \n",
            "  inflating: hateful_memes/img/56810.png  \n",
            "  inflating: hateful_memes/img/53914.png  \n",
            "  inflating: hateful_memes/img/97406.png  \n",
            "  inflating: hateful_memes/img/32896.png  \n",
            "  inflating: hateful_memes/img/89465.png  \n",
            "  inflating: hateful_memes/img/20931.png  \n",
            "  inflating: hateful_memes/img/01564.png  \n",
            "  inflating: hateful_memes/img/65140.png  \n",
            "  inflating: hateful_memes/img/30695.png  \n",
            "  inflating: hateful_memes/img/32570.png  \n",
            "  inflating: hateful_memes/img/78642.png  \n",
            "  inflating: hateful_memes/img/30941.png  \n",
            "  inflating: hateful_memes/img/75832.png  \n",
            "  inflating: hateful_memes/img/02735.png  \n",
            "  inflating: hateful_memes/img/45987.png  \n",
            "  inflating: hateful_memes/img/62458.png  \n",
            "  inflating: hateful_memes/img/98702.png  \n",
            "  inflating: hateful_memes/img/79504.png  \n",
            "  inflating: hateful_memes/img/65283.png  \n",
            "  inflating: hateful_memes/img/27905.png  \n",
            "  inflating: hateful_memes/img/95274.png  \n",
            "  inflating: hateful_memes/img/60538.png  \n",
            "  inflating: hateful_memes/img/85730.png  \n",
            "  inflating: hateful_memes/img/24958.png  \n",
            "  inflating: hateful_memes/img/80912.png  \n",
            "  inflating: hateful_memes/img/91547.png  \n",
            "  inflating: hateful_memes/img/79834.png  \n",
            "  inflating: hateful_memes/img/65274.png  \n",
            "  inflating: hateful_memes/img/14830.png  \n",
            "  inflating: hateful_memes/img/34925.png  \n",
            "  inflating: hateful_memes/img/32017.png  \n",
            "  inflating: hateful_memes/img/85426.png  \n",
            "  inflating: hateful_memes/img/26381.png  \n",
            "  inflating: hateful_memes/img/03861.png  \n",
            "  inflating: hateful_memes/img/37259.png  \n",
            "  inflating: hateful_memes/img/10843.png  \n",
            "  inflating: hateful_memes/img/09132.png  \n",
            "  inflating: hateful_memes/img/43279.png  \n",
            "  inflating: hateful_memes/img/27901.png  \n",
            "  inflating: hateful_memes/img/14632.png  \n",
            "  inflating: hateful_memes/img/14732.png  \n",
            "  inflating: hateful_memes/img/29073.png  \n",
            "  inflating: hateful_memes/img/27438.png  \n",
            "  inflating: hateful_memes/img/03981.png  \n",
            "  inflating: hateful_memes/img/16405.png  \n",
            "  inflating: hateful_memes/img/28406.png  \n",
            "  inflating: hateful_memes/img/69305.png  \n",
            "  inflating: hateful_memes/img/62907.png  \n",
            "  inflating: hateful_memes/img/06243.png  \n",
            "  inflating: hateful_memes/img/03178.png  \n",
            "  inflating: hateful_memes/img/14375.png  \n",
            "  inflating: hateful_memes/img/03528.png  \n",
            "  inflating: hateful_memes/img/45802.png  \n",
            "  inflating: hateful_memes/img/61450.png  \n",
            "  inflating: hateful_memes/img/59340.png  \n",
            "  inflating: hateful_memes/img/07523.png  \n",
            "  inflating: hateful_memes/img/52803.png  \n",
            "  inflating: hateful_memes/img/85716.png  \n",
            "  inflating: hateful_memes/img/18023.png  \n",
            "  inflating: hateful_memes/img/30816.png  \n",
            "  inflating: hateful_memes/img/36104.png  \n",
            "  inflating: hateful_memes/img/04157.png  \n",
            "  inflating: hateful_memes/img/92436.png  \n",
            "  inflating: hateful_memes/img/60729.png  \n",
            "  inflating: hateful_memes/img/40518.png  \n",
            "  inflating: hateful_memes/img/93820.png  \n",
            "  inflating: hateful_memes/img/90186.png  \n",
            "  inflating: hateful_memes/img/90463.png  \n",
            "  inflating: hateful_memes/img/75618.png  \n",
            "  inflating: hateful_memes/img/60134.png  \n",
            "  inflating: hateful_memes/img/94873.png  \n",
            "  inflating: hateful_memes/img/30648.png  \n",
            "  inflating: hateful_memes/img/24108.png  \n",
            "  inflating: hateful_memes/img/06213.png  \n",
            "  inflating: hateful_memes/img/68529.png  \n",
            "  inflating: hateful_memes/img/92874.png  \n",
            "  inflating: hateful_memes/img/20567.png  \n",
            "  inflating: hateful_memes/img/57046.png  \n",
            "  inflating: hateful_memes/img/89107.png  \n",
            "  inflating: hateful_memes/img/20978.png  \n",
            "  inflating: hateful_memes/img/62850.png  \n",
            "  inflating: hateful_memes/img/41298.png  \n",
            "  inflating: hateful_memes/img/94783.png  \n",
            "  inflating: hateful_memes/img/01247.png  \n",
            "  inflating: hateful_memes/img/45370.png  \n",
            "  inflating: hateful_memes/img/52349.png  \n",
            "  inflating: hateful_memes/img/41830.png  \n",
            "  inflating: hateful_memes/img/01892.png  \n",
            "  inflating: hateful_memes/img/62713.png  \n",
            "  inflating: hateful_memes/img/34092.png  \n",
            "  inflating: hateful_memes/img/87406.png  \n",
            "  inflating: hateful_memes/img/61802.png  \n",
            "  inflating: hateful_memes/img/51496.png  \n",
            "  inflating: hateful_memes/img/28401.png  \n",
            "  inflating: hateful_memes/img/26750.png  \n",
            "  inflating: hateful_memes/img/21075.png  \n",
            "  inflating: hateful_memes/img/04982.png  \n",
            "  inflating: hateful_memes/img/41385.png  \n",
            "  inflating: hateful_memes/img/31685.png  \n",
            "  inflating: hateful_memes/img/38794.png  \n",
            "  inflating: hateful_memes/img/46529.png  \n",
            "  inflating: hateful_memes/img/76341.png  \n",
            "  inflating: hateful_memes/img/03849.png  \n",
            "  inflating: hateful_memes/img/26980.png  \n",
            "  inflating: hateful_memes/img/47029.png  \n",
            "  inflating: hateful_memes/img/67234.png  \n",
            "  inflating: hateful_memes/img/43517.png  \n",
            "  inflating: hateful_memes/img/64280.png  \n",
            "  inflating: hateful_memes/img/12867.png  \n",
            "  inflating: hateful_memes/img/31560.png  \n",
            "  inflating: hateful_memes/img/28450.png  \n",
            "  inflating: hateful_memes/img/70164.png  \n",
            "  inflating: hateful_memes/img/31609.png  \n",
            "  inflating: hateful_memes/img/98514.png  \n",
            "  inflating: hateful_memes/img/43928.png  \n",
            "  inflating: hateful_memes/img/92187.png  \n",
            "  inflating: hateful_memes/img/53678.png  \n",
            "  inflating: hateful_memes/img/85679.png  \n",
            "  inflating: hateful_memes/img/24039.png  \n",
            "  inflating: hateful_memes/img/61349.png  \n",
            "  inflating: hateful_memes/img/05172.png  \n",
            "  inflating: hateful_memes/img/48251.png  \n",
            "  inflating: hateful_memes/img/92051.png  \n",
            "  inflating: hateful_memes/img/46509.png  \n",
            "  inflating: hateful_memes/img/75839.png  \n",
            "  inflating: hateful_memes/img/32049.png  \n",
            "  inflating: hateful_memes/img/50861.png  \n",
            "  inflating: hateful_memes/img/30157.png  \n",
            "  inflating: hateful_memes/img/36725.png  \n",
            "  inflating: hateful_memes/img/57162.png  \n",
            "  inflating: hateful_memes/img/36924.png  \n",
            "  inflating: hateful_memes/img/39421.png  \n",
            "  inflating: hateful_memes/img/30476.png  \n",
            "  inflating: hateful_memes/img/19637.png  \n",
            "  inflating: hateful_memes/img/80649.png  \n",
            "  inflating: hateful_memes/img/27639.png  \n",
            "  inflating: hateful_memes/img/86215.png  \n",
            "  inflating: hateful_memes/img/72580.png  \n",
            "  inflating: hateful_memes/img/79856.png  \n",
            "  inflating: hateful_memes/img/62840.png  \n",
            "  inflating: hateful_memes/img/31094.png  \n",
            "  inflating: hateful_memes/img/08531.png  \n",
            "  inflating: hateful_memes/img/61379.png  \n",
            "  inflating: hateful_memes/img/73501.png  \n",
            "  inflating: hateful_memes/img/21584.png  \n",
            "  inflating: hateful_memes/img/29714.png  \n",
            "  inflating: hateful_memes/img/21346.png  \n",
            "  inflating: hateful_memes/img/74326.png  \n",
            "  inflating: hateful_memes/img/83091.png  \n",
            "  inflating: hateful_memes/img/16039.png  \n",
            "  inflating: hateful_memes/img/01943.png  \n",
            "  inflating: hateful_memes/img/06945.png  \n",
            "  inflating: hateful_memes/img/08153.png  \n",
            "  inflating: hateful_memes/img/90583.png  \n",
            "  inflating: hateful_memes/img/76598.png  \n",
            "  inflating: hateful_memes/img/08539.png  \n",
            "  inflating: hateful_memes/img/31975.png  \n",
            "  inflating: hateful_memes/img/73690.png  \n",
            "  inflating: hateful_memes/img/86123.png  \n",
            "  inflating: hateful_memes/img/98716.png  \n",
            "  inflating: hateful_memes/img/97026.png  \n",
            "  inflating: hateful_memes/img/17659.png  \n",
            "  inflating: hateful_memes/img/13706.png  \n",
            "  inflating: hateful_memes/img/72680.png  \n",
            "  inflating: hateful_memes/img/91602.png  \n",
            "  inflating: hateful_memes/img/82647.png  \n",
            "  inflating: hateful_memes/img/21596.png  \n",
            "  inflating: hateful_memes/img/80453.png  \n",
            "  inflating: hateful_memes/img/28597.png  \n",
            "  inflating: hateful_memes/img/23175.png  \n",
            "  inflating: hateful_memes/img/72456.png  \n",
            "  inflating: hateful_memes/img/08612.png  \n",
            "  inflating: hateful_memes/img/36102.png  \n",
            "  inflating: hateful_memes/img/08375.png  \n",
            "  inflating: hateful_memes/img/08137.png  \n",
            "  inflating: hateful_memes/img/09267.png  \n",
            "  inflating: hateful_memes/img/32081.png  \n",
            "  inflating: hateful_memes/img/19345.png  \n",
            "  inflating: hateful_memes/img/43798.png  \n",
            "  inflating: hateful_memes/img/95317.png  \n",
            "  inflating: hateful_memes/img/43810.png  \n",
            "  inflating: hateful_memes/img/85967.png  \n",
            "  inflating: hateful_memes/img/24890.png  \n",
            "  inflating: hateful_memes/img/93261.png  \n",
            "  inflating: hateful_memes/img/49675.png  \n",
            "  inflating: hateful_memes/img/07836.png  \n",
            "  inflating: hateful_memes/img/09357.png  \n",
            "  inflating: hateful_memes/img/94360.png  \n",
            "  inflating: hateful_memes/img/49318.png  \n",
            "  inflating: hateful_memes/img/09624.png  \n",
            "  inflating: hateful_memes/img/82916.png  \n",
            "  inflating: hateful_memes/img/59376.png  \n",
            "  inflating: hateful_memes/img/54730.png  \n",
            "  inflating: hateful_memes/img/20685.png  \n",
            "  inflating: hateful_memes/img/59874.png  \n",
            "  inflating: hateful_memes/img/29385.png  \n",
            "  inflating: hateful_memes/img/61527.png  \n",
            "  inflating: hateful_memes/img/49261.png  \n",
            "  inflating: hateful_memes/img/40312.png  \n",
            "  inflating: hateful_memes/img/67205.png  \n",
            "  inflating: hateful_memes/img/17234.png  \n",
            "  inflating: hateful_memes/img/13906.png  \n",
            "  inflating: hateful_memes/img/46810.png  \n",
            "  inflating: hateful_memes/img/25768.png  \n",
            "  inflating: hateful_memes/img/04876.png  \n",
            "  inflating: hateful_memes/img/98504.png  \n",
            "  inflating: hateful_memes/img/62301.png  \n",
            "  inflating: hateful_memes/img/54912.png  \n",
            "  inflating: hateful_memes/img/01763.png  \n",
            "  inflating: hateful_memes/img/28134.png  \n",
            "  inflating: hateful_memes/img/60592.png  \n",
            "  inflating: hateful_memes/img/19308.png  \n",
            "  inflating: hateful_memes/img/78509.png  \n",
            "  inflating: hateful_memes/img/10583.png  \n",
            "  inflating: hateful_memes/img/86354.png  \n",
            "  inflating: hateful_memes/img/01634.png  \n",
            "  inflating: hateful_memes/img/32907.png  \n",
            "  inflating: hateful_memes/img/83064.png  \n",
            "  inflating: hateful_memes/img/08679.png  \n",
            "  inflating: hateful_memes/img/27946.png  \n",
            "  inflating: hateful_memes/img/90637.png  \n",
            "  inflating: hateful_memes/img/29164.png  \n",
            "  inflating: hateful_memes/img/03418.png  \n",
            "  inflating: hateful_memes/img/85291.png  \n",
            "  inflating: hateful_memes/img/52916.png  \n",
            "  inflating: hateful_memes/img/80321.png  \n",
            "  inflating: hateful_memes/img/70158.png  \n",
            "  inflating: hateful_memes/img/06791.png  \n",
            "  inflating: hateful_memes/img/70182.png  \n",
            "  inflating: hateful_memes/img/82169.png  \n",
            "  inflating: hateful_memes/img/37482.png  \n",
            "  inflating: hateful_memes/img/32106.png  \n",
            "  inflating: hateful_memes/img/71048.png  \n",
            "  inflating: hateful_memes/img/51460.png  \n",
            "  inflating: hateful_memes/img/08319.png  \n",
            "  inflating: hateful_memes/img/15236.png  \n",
            "  inflating: hateful_memes/img/80197.png  \n",
            "  inflating: hateful_memes/img/54018.png  \n",
            "  inflating: hateful_memes/img/26945.png  \n",
            "  inflating: hateful_memes/img/97021.png  \n",
            "  inflating: hateful_memes/img/93741.png  \n",
            "  inflating: hateful_memes/img/67823.png  \n",
            "  inflating: hateful_memes/img/28019.png  \n",
            "  inflating: hateful_memes/img/58419.png  \n",
            "  inflating: hateful_memes/img/74536.png  \n",
            "  inflating: hateful_memes/img/61028.png  \n",
            "  inflating: hateful_memes/img/38954.png  \n",
            "  inflating: hateful_memes/img/59041.png  \n",
            "  inflating: hateful_memes/img/07623.png  \n",
            "  inflating: hateful_memes/img/59342.png  \n",
            "  inflating: hateful_memes/img/68597.png  \n",
            "  inflating: hateful_memes/img/68749.png  \n",
            "  inflating: hateful_memes/img/38164.png  \n",
            "  inflating: hateful_memes/img/63710.png  \n",
            "  inflating: hateful_memes/img/89573.png  \n",
            "  inflating: hateful_memes/img/89571.png  \n",
            "  inflating: hateful_memes/img/94861.png  \n",
            "  inflating: hateful_memes/img/67342.png  \n",
            "  inflating: hateful_memes/img/67014.png  \n",
            "  inflating: hateful_memes/img/80392.png  \n",
            "  inflating: hateful_memes/img/89173.png  \n",
            "  inflating: hateful_memes/img/98537.png  \n",
            "  inflating: hateful_memes/img/87610.png  \n",
            "  inflating: hateful_memes/img/05798.png  \n",
            "  inflating: hateful_memes/img/90162.png  \n",
            "  inflating: hateful_memes/img/03254.png  \n",
            "  inflating: hateful_memes/img/69824.png  \n",
            "  inflating: hateful_memes/img/03571.png  \n",
            "  inflating: hateful_memes/img/70649.png  \n",
            "  inflating: hateful_memes/img/32709.png  \n",
            "  inflating: hateful_memes/img/73125.png  \n",
            "  inflating: hateful_memes/img/62504.png  \n",
            "  inflating: hateful_memes/img/13297.png  \n",
            "  inflating: hateful_memes/img/13724.png  \n",
            "  inflating: hateful_memes/img/58093.png  \n",
            "  inflating: hateful_memes/img/30782.png  \n",
            "  inflating: hateful_memes/img/37859.png  \n",
            "  inflating: hateful_memes/img/26903.png  \n",
            "  inflating: hateful_memes/img/40159.png  \n",
            "  inflating: hateful_memes/img/90342.png  \n",
            "  inflating: hateful_memes/img/53096.png  \n",
            "  inflating: hateful_memes/img/47531.png  \n",
            "  inflating: hateful_memes/img/23645.png  \n",
            "  inflating: hateful_memes/img/02984.png  \n",
            "  inflating: hateful_memes/img/09781.png  \n",
            "  inflating: hateful_memes/img/03275.png  \n",
            "  inflating: hateful_memes/img/59678.png  \n",
            "  inflating: hateful_memes/img/86031.png  \n",
            "  inflating: hateful_memes/img/73254.png  \n",
            "  inflating: hateful_memes/img/45829.png  \n",
            "  inflating: hateful_memes/img/91034.png  \n",
            "  inflating: hateful_memes/img/89517.png  \n",
            "  inflating: hateful_memes/img/40136.png  \n",
            "  inflating: hateful_memes/img/48513.png  \n",
            "  inflating: hateful_memes/img/67831.png  \n",
            "  inflating: hateful_memes/img/83946.png  \n",
            "  inflating: hateful_memes/img/59341.png  \n",
            "  inflating: hateful_memes/img/15269.png  \n",
            "  inflating: hateful_memes/img/38754.png  \n",
            "  inflating: hateful_memes/img/08476.png  \n",
            "  inflating: hateful_memes/img/58176.png  \n",
            "  inflating: hateful_memes/img/48012.png  \n",
            "  inflating: hateful_memes/img/94062.png  \n",
            "  inflating: hateful_memes/img/47532.png  \n",
            "  inflating: hateful_memes/img/70148.png  \n",
            "  inflating: hateful_memes/img/58194.png  \n",
            "  inflating: hateful_memes/img/31250.png  \n",
            "  inflating: hateful_memes/img/20674.png  \n",
            "  inflating: hateful_memes/img/26950.png  \n",
            "  inflating: hateful_memes/img/82704.png  \n",
            "  inflating: hateful_memes/img/78612.png  \n",
            "  inflating: hateful_memes/img/31068.png  \n",
            "  inflating: hateful_memes/img/75308.png  \n",
            "  inflating: hateful_memes/img/64839.png  \n",
            "  inflating: hateful_memes/img/48352.png  \n",
            "  inflating: hateful_memes/img/98526.png  \n",
            "  inflating: hateful_memes/img/86405.png  \n",
            "  inflating: hateful_memes/img/45018.png  \n",
            "  inflating: hateful_memes/img/76892.png  \n",
            "  inflating: hateful_memes/img/42589.png  \n",
            "  inflating: hateful_memes/img/69125.png  \n",
            "  inflating: hateful_memes/img/49510.png  \n",
            "  inflating: hateful_memes/img/79348.png  \n",
            "  inflating: hateful_memes/img/72936.png  \n",
            "  inflating: hateful_memes/img/35287.png  \n",
            "  inflating: hateful_memes/img/82547.png  \n",
            "  inflating: hateful_memes/img/94357.png  \n",
            "  inflating: hateful_memes/img/29380.png  \n",
            "  inflating: hateful_memes/img/27634.png  \n",
            "  inflating: hateful_memes/img/50679.png  \n",
            "  inflating: hateful_memes/img/71920.png  \n",
            "  inflating: hateful_memes/img/54608.png  \n",
            "  inflating: hateful_memes/img/72461.png  \n",
            "  inflating: hateful_memes/img/93076.png  \n",
            "  inflating: hateful_memes/img/50492.png  \n",
            "  inflating: hateful_memes/img/06491.png  \n",
            "  inflating: hateful_memes/img/51396.png  \n",
            "  inflating: hateful_memes/img/04758.png  \n",
            "  inflating: hateful_memes/img/90185.png  \n",
            "  inflating: hateful_memes/img/19234.png  \n",
            "  inflating: hateful_memes/img/57826.png  \n",
            "  inflating: hateful_memes/img/34078.png  \n",
            "  inflating: hateful_memes/img/41037.png  \n",
            "  inflating: hateful_memes/img/92450.png  \n",
            "  inflating: hateful_memes/img/38509.png  \n",
            "  inflating: hateful_memes/img/49387.png  \n",
            "  inflating: hateful_memes/img/09531.png  \n",
            "  inflating: hateful_memes/img/38702.png  \n",
            "  inflating: hateful_memes/img/95176.png  \n",
            "  inflating: hateful_memes/img/34768.png  \n",
            "  inflating: hateful_memes/img/67092.png  \n",
            "  inflating: hateful_memes/img/73406.png  \n",
            "  inflating: hateful_memes/img/53967.png  \n",
            "  inflating: hateful_memes/img/42903.png  \n",
            "  inflating: hateful_memes/img/64935.png  \n",
            "  inflating: hateful_memes/img/31896.png  \n",
            "  inflating: hateful_memes/img/48790.png  \n",
            "  inflating: hateful_memes/img/72469.png  \n",
            "  inflating: hateful_memes/img/94378.png  \n",
            "  inflating: hateful_memes/img/78592.png  \n",
            "  inflating: hateful_memes/img/72591.png  \n",
            "  inflating: hateful_memes/img/76108.png  \n",
            "  inflating: hateful_memes/img/04185.png  \n",
            "  inflating: hateful_memes/img/64189.png  \n",
            "  inflating: hateful_memes/img/13450.png  \n",
            "  inflating: hateful_memes/img/86512.png  \n",
            "  inflating: hateful_memes/img/13962.png  \n",
            "  inflating: hateful_memes/img/54726.png  \n",
            "  inflating: hateful_memes/img/97531.png  \n",
            "  inflating: hateful_memes/img/80921.png  \n",
            "  inflating: hateful_memes/img/97345.png  \n",
            "  inflating: hateful_memes/img/47561.png  \n",
            "  inflating: hateful_memes/img/51029.png  \n",
            "  inflating: hateful_memes/img/07194.png  \n",
            "  inflating: hateful_memes/img/16049.png  \n",
            "  inflating: hateful_memes/img/31602.png  \n",
            "  inflating: hateful_memes/img/02384.png  \n",
            "  inflating: hateful_memes/img/83925.png  \n",
            "  inflating: hateful_memes/img/41796.png  \n",
            "  inflating: hateful_memes/img/07528.png  \n",
            "  inflating: hateful_memes/img/39526.png  \n",
            "  inflating: hateful_memes/img/28463.png  \n",
            "  inflating: hateful_memes/img/94571.png  \n",
            "  inflating: hateful_memes/img/90742.png  \n",
            "  inflating: hateful_memes/img/90576.png  \n",
            "  inflating: hateful_memes/img/94813.png  \n",
            "  inflating: hateful_memes/img/37419.png  \n",
            "  inflating: hateful_memes/img/86509.png  \n",
            "  inflating: hateful_memes/img/89076.png  \n",
            "  inflating: hateful_memes/img/26348.png  \n",
            "  inflating: hateful_memes/img/32981.png  \n",
            "  inflating: hateful_memes/img/62751.png  \n",
            "  inflating: hateful_memes/img/75920.png  \n",
            "  inflating: hateful_memes/img/90247.png  \n",
            "  inflating: hateful_memes/img/84362.png  \n",
            "  inflating: hateful_memes/img/52809.png  \n",
            "  inflating: hateful_memes/img/12376.png  \n",
            "  inflating: hateful_memes/img/57984.png  \n",
            "  inflating: hateful_memes/img/78132.png  \n",
            "  inflating: hateful_memes/img/58706.png  \n",
            "  inflating: hateful_memes/img/39456.png  \n",
            "  inflating: hateful_memes/img/42876.png  \n",
            "  inflating: hateful_memes/img/29463.png  \n",
            "  inflating: hateful_memes/img/36590.png  \n",
            "  inflating: hateful_memes/img/67953.png  \n",
            "  inflating: hateful_memes/img/86052.png  \n",
            "  inflating: hateful_memes/img/37180.png  \n",
            "  inflating: hateful_memes/img/47825.png  \n",
            "  inflating: hateful_memes/img/19426.png  \n",
            "  inflating: hateful_memes/img/29841.png  \n",
            "  inflating: hateful_memes/img/81942.png  \n",
            "  inflating: hateful_memes/img/10486.png  \n",
            "  inflating: hateful_memes/img/50386.png  \n",
            "  inflating: hateful_memes/img/24083.png  \n",
            "  inflating: hateful_memes/img/89326.png  \n",
            "  inflating: hateful_memes/img/41782.png  \n",
            "  inflating: hateful_memes/img/16380.png  \n",
            "  inflating: hateful_memes/img/96345.png  \n",
            "  inflating: hateful_memes/img/81576.png  \n",
            "  inflating: hateful_memes/img/31096.png  \n",
            "  inflating: hateful_memes/img/10274.png  \n",
            "  inflating: hateful_memes/img/45702.png  \n",
            "  inflating: hateful_memes/img/34782.png  \n",
            "  inflating: hateful_memes/img/87501.png  \n",
            "  inflating: hateful_memes/img/27436.png  \n",
            "  inflating: hateful_memes/img/03798.png  \n",
            "  inflating: hateful_memes/img/47629.png  \n",
            "  inflating: hateful_memes/img/12958.png  \n",
            "  inflating: hateful_memes/img/75693.png  \n",
            "  inflating: hateful_memes/img/65401.png  \n",
            "  inflating: hateful_memes/img/98315.png  \n",
            "  inflating: hateful_memes/img/72965.png  \n",
            "  inflating: hateful_memes/img/16798.png  \n",
            "  inflating: hateful_memes/img/49758.png  \n",
            "  inflating: hateful_memes/img/98071.png  \n",
            "  inflating: hateful_memes/img/40125.png  \n",
            "  inflating: hateful_memes/img/70426.png  \n",
            "  inflating: hateful_memes/img/57193.png  \n",
            "  inflating: hateful_memes/img/43089.png  \n",
            "  inflating: hateful_memes/img/46837.png  \n",
            "  inflating: hateful_memes/img/80317.png  \n",
            "  inflating: hateful_memes/img/36201.png  \n",
            "  inflating: hateful_memes/img/62398.png  \n",
            "  inflating: hateful_memes/img/61589.png  \n",
            "  inflating: hateful_memes/img/87052.png  \n",
            "  inflating: hateful_memes/img/13574.png  \n",
            "  inflating: hateful_memes/img/39758.png  \n",
            "  inflating: hateful_memes/img/53219.png  \n",
            "  inflating: hateful_memes/img/36597.png  \n",
            "  inflating: hateful_memes/img/83960.png  \n",
            "  inflating: hateful_memes/img/18307.png  \n",
            "  inflating: hateful_memes/img/63712.png  \n",
            "  inflating: hateful_memes/img/86209.png  \n",
            "  inflating: hateful_memes/img/74652.png  \n",
            "  inflating: hateful_memes/img/96213.png  \n",
            "  inflating: hateful_memes/img/58674.png  \n",
            "  inflating: hateful_memes/img/29351.png  \n",
            "  inflating: hateful_memes/img/79146.png  \n",
            "  inflating: hateful_memes/img/81529.png  \n",
            "  inflating: hateful_memes/img/96431.png  \n",
            "  inflating: hateful_memes/img/31627.png  \n",
            "  inflating: hateful_memes/img/40675.png  \n",
            "  inflating: hateful_memes/img/37658.png  \n",
            "  inflating: hateful_memes/img/63082.png  \n",
            "  inflating: hateful_memes/img/43218.png  \n",
            "  inflating: hateful_memes/img/91268.png  \n",
            "  inflating: hateful_memes/img/40326.png  \n",
            "  inflating: hateful_memes/img/74953.png  \n",
            "  inflating: hateful_memes/img/23578.png  \n",
            "  inflating: hateful_memes/img/46387.png  \n",
            "  inflating: hateful_memes/img/70691.png  \n",
            "  inflating: hateful_memes/img/23514.png  \n",
            "  inflating: hateful_memes/img/54016.png  \n",
            "  inflating: hateful_memes/img/93162.png  \n",
            "  inflating: hateful_memes/img/19860.png  \n",
            "  inflating: hateful_memes/img/80165.png  \n",
            "  inflating: hateful_memes/img/92405.png  \n",
            "  inflating: hateful_memes/img/41860.png  \n",
            "  inflating: hateful_memes/img/21043.png  \n",
            "  inflating: hateful_memes/img/29054.png  \n",
            "  inflating: hateful_memes/img/24580.png  \n",
            "  inflating: hateful_memes/img/83720.png  \n",
            "  inflating: hateful_memes/img/92816.png  \n",
            "  inflating: hateful_memes/img/78351.png  \n",
            "  inflating: hateful_memes/img/39748.png  \n",
            "  inflating: hateful_memes/img/32174.png  \n",
            "  inflating: hateful_memes/img/47581.png  \n",
            "  inflating: hateful_memes/img/03527.png  \n",
            "  inflating: hateful_memes/img/87239.png  \n",
            "  inflating: hateful_memes/img/60834.png  \n",
            "  inflating: hateful_memes/img/83916.png  \n",
            "  inflating: hateful_memes/img/90146.png  \n",
            "  inflating: hateful_memes/img/49603.png  \n",
            "  inflating: hateful_memes/img/07389.png  \n",
            "  inflating: hateful_memes/img/34068.png  \n",
            "  inflating: hateful_memes/img/97261.png  \n",
            "  inflating: hateful_memes/img/83206.png  \n",
            "  inflating: hateful_memes/img/63792.png  \n",
            "  inflating: hateful_memes/img/20948.png  \n",
            "  inflating: hateful_memes/img/86907.png  \n",
            "  inflating: hateful_memes/img/36895.png  \n",
            "  inflating: hateful_memes/img/01268.png  \n",
            "  inflating: hateful_memes/img/91537.png  \n",
            "  inflating: hateful_memes/img/87436.png  \n",
            "  inflating: hateful_memes/img/06198.png  \n",
            "  inflating: hateful_memes/img/86425.png  \n",
            "  inflating: hateful_memes/img/57923.png  \n",
            "  inflating: hateful_memes/img/16042.png  \n",
            "  inflating: hateful_memes/img/30256.png  \n",
            "  inflating: hateful_memes/img/31625.png  \n",
            "  inflating: hateful_memes/img/80976.png  \n",
            "  inflating: hateful_memes/img/25681.png  \n",
            "  inflating: hateful_memes/img/35081.png  \n",
            "  inflating: hateful_memes/img/27803.png  \n",
            "  inflating: hateful_memes/img/86253.png  \n",
            "  inflating: hateful_memes/img/49726.png  \n",
            "  inflating: hateful_memes/img/02789.png  \n",
            "  inflating: hateful_memes/img/51469.png  \n",
            "  inflating: hateful_memes/img/68253.png  \n",
            "  inflating: hateful_memes/img/63951.png  \n",
            "  inflating: hateful_memes/img/58479.png  \n",
            "  inflating: hateful_memes/img/24517.png  \n",
            "  inflating: hateful_memes/img/49128.png  \n",
            "  inflating: hateful_memes/img/53462.png  \n",
            "  inflating: hateful_memes/img/61308.png  \n",
            "  inflating: hateful_memes/img/31687.png  \n",
            "  inflating: hateful_memes/img/43805.png  \n",
            "  inflating: hateful_memes/img/35902.png  \n",
            "  inflating: hateful_memes/img/98421.png  \n",
            "  inflating: hateful_memes/img/85902.png  \n",
            "  inflating: hateful_memes/img/92643.png  \n",
            "  inflating: hateful_memes/img/58317.png  \n",
            "  inflating: hateful_memes/img/71943.png  \n",
            "  inflating: hateful_memes/img/23748.png  \n",
            "  inflating: hateful_memes/img/74038.png  \n",
            "  inflating: hateful_memes/img/51248.png  \n",
            "  inflating: hateful_memes/img/84903.png  \n",
            "  inflating: hateful_memes/img/54368.png  \n",
            "  inflating: hateful_memes/img/57120.png  \n",
            "  inflating: hateful_memes/img/49201.png  \n",
            "  inflating: hateful_memes/img/03745.png  \n",
            "  inflating: hateful_memes/img/65094.png  \n",
            "  inflating: hateful_memes/img/43180.png  \n",
            "  inflating: hateful_memes/img/56739.png  \n",
            "  inflating: hateful_memes/img/47612.png  \n",
            "  inflating: hateful_memes/img/01627.png  \n",
            "  inflating: hateful_memes/img/98362.png  \n",
            "  inflating: hateful_memes/img/08534.png  \n",
            "  inflating: hateful_memes/img/27948.png  \n",
            "  inflating: hateful_memes/img/74890.png  \n",
            "  inflating: hateful_memes/img/02519.png  \n",
            "  inflating: hateful_memes/img/32781.png  \n",
            "  inflating: hateful_memes/img/85306.png  \n",
            "  inflating: hateful_memes/img/78903.png  \n",
            "  inflating: hateful_memes/img/16895.png  \n",
            "  inflating: hateful_memes/img/57418.png  \n",
            "  inflating: hateful_memes/img/51746.png  \n",
            "  inflating: hateful_memes/img/36429.png  \n",
            "  inflating: hateful_memes/img/58297.png  \n",
            "  inflating: hateful_memes/img/58312.png  \n",
            "  inflating: hateful_memes/img/97160.png  \n",
            "  inflating: hateful_memes/img/25714.png  \n",
            "  inflating: hateful_memes/img/57280.png  \n",
            "  inflating: hateful_memes/img/52074.png  \n",
            "  inflating: hateful_memes/img/19034.png  \n",
            "  inflating: hateful_memes/img/38714.png  \n",
            "  inflating: hateful_memes/img/56741.png  \n",
            "  inflating: hateful_memes/img/94581.png  \n",
            "  inflating: hateful_memes/img/42073.png  \n",
            "  inflating: hateful_memes/img/31786.png  \n",
            "  inflating: hateful_memes/img/61489.png  \n",
            "  inflating: hateful_memes/img/59801.png  \n",
            "  inflating: hateful_memes/img/75481.png  \n",
            "  inflating: hateful_memes/img/49360.png  \n",
            "  inflating: hateful_memes/img/78192.png  \n",
            "  inflating: hateful_memes/img/27308.png  \n",
            "  inflating: hateful_memes/img/68759.png  \n",
            "  inflating: hateful_memes/img/67385.png  \n",
            "  inflating: hateful_memes/img/91768.png  \n",
            "  inflating: hateful_memes/img/16253.png  \n",
            "  inflating: hateful_memes/img/53810.png  \n",
            "  inflating: hateful_memes/img/76038.png  \n",
            "  inflating: hateful_memes/img/08964.png  \n",
            "  inflating: hateful_memes/img/84325.png  \n",
            "  inflating: hateful_memes/img/17853.png  \n",
            "  inflating: hateful_memes/img/63159.png  \n",
            "  inflating: hateful_memes/img/65037.png  \n",
            "  inflating: hateful_memes/img/02374.png  \n",
            "  inflating: hateful_memes/img/37681.png  \n",
            "  inflating: hateful_memes/img/02614.png  \n",
            "  inflating: hateful_memes/img/72946.png  \n",
            "  inflating: hateful_memes/img/79134.png  \n",
            "  inflating: hateful_memes/img/21534.png  \n",
            "  inflating: hateful_memes/img/59873.png  \n",
            "  inflating: hateful_memes/img/64172.png  \n",
            "  inflating: hateful_memes/img/47125.png  \n",
            "  inflating: hateful_memes/img/91627.png  \n",
            "  inflating: hateful_memes/img/41539.png  \n",
            "  inflating: hateful_memes/img/28176.png  \n",
            "  inflating: hateful_memes/img/61347.png  \n",
            "  inflating: hateful_memes/img/69518.png  \n",
            "  inflating: hateful_memes/img/58069.png  \n",
            "  inflating: hateful_memes/img/52479.png  \n",
            "  inflating: hateful_memes/img/34728.png  \n",
            "  inflating: hateful_memes/img/34095.png  \n",
            "  inflating: hateful_memes/img/26049.png  \n",
            "  inflating: hateful_memes/img/24875.png  \n",
            "  inflating: hateful_memes/img/03847.png  \n",
            "  inflating: hateful_memes/img/37580.png  \n",
            "  inflating: hateful_memes/img/52473.png  \n",
            "  inflating: hateful_memes/img/69140.png  \n",
            "  inflating: hateful_memes/img/57618.png  \n",
            "  inflating: hateful_memes/img/15872.png  \n",
            "  inflating: hateful_memes/img/78560.png  \n",
            "  inflating: hateful_memes/img/65281.png  \n",
            "  inflating: hateful_memes/img/79680.png  \n",
            "  inflating: hateful_memes/img/19780.png  \n",
            "  inflating: hateful_memes/img/76490.png  \n",
            "  inflating: hateful_memes/img/16297.png  \n",
            "  inflating: hateful_memes/img/95714.png  \n",
            "  inflating: hateful_memes/img/78124.png  \n",
            "  inflating: hateful_memes/img/25748.png  \n",
            "  inflating: hateful_memes/img/78495.png  \n",
            "  inflating: hateful_memes/img/13045.png  \n",
            "  inflating: hateful_memes/img/28516.png  \n",
            "  inflating: hateful_memes/img/01762.png  \n",
            "  inflating: hateful_memes/img/25467.png  \n",
            "  inflating: hateful_memes/img/58276.png  \n",
            "  inflating: hateful_memes/img/54690.png  \n",
            "  inflating: hateful_memes/img/75461.png  \n",
            "  inflating: hateful_memes/img/86457.png  \n",
            "  inflating: hateful_memes/img/19457.png  \n",
            "  inflating: hateful_memes/img/53764.png  \n",
            "  inflating: hateful_memes/img/68325.png  \n",
            "  inflating: hateful_memes/img/31527.png  \n",
            "  inflating: hateful_memes/img/03917.png  \n",
            "  inflating: hateful_memes/img/17634.png  \n",
            "  inflating: hateful_memes/img/58421.png  \n",
            "  inflating: hateful_memes/img/12873.png  \n",
            "  inflating: hateful_memes/img/58904.png  \n",
            "  inflating: hateful_memes/img/51473.png  \n",
            "  inflating: hateful_memes/img/62134.png  \n",
            "  inflating: hateful_memes/img/10489.png  \n",
            "  inflating: hateful_memes/img/05847.png  \n",
            "  inflating: hateful_memes/img/09738.png  \n",
            "  inflating: hateful_memes/img/57869.png  \n",
            "  inflating: hateful_memes/img/96308.png  \n",
            "  inflating: hateful_memes/img/54028.png  \n",
            "  inflating: hateful_memes/img/41527.png  \n",
            "  inflating: hateful_memes/img/36972.png  \n",
            "  inflating: hateful_memes/img/72016.png  \n",
            "  inflating: hateful_memes/img/91468.png  \n",
            "  inflating: hateful_memes/img/05936.png  \n",
            "  inflating: hateful_memes/img/53782.png  \n",
            "  inflating: hateful_memes/img/07658.png  \n",
            "  inflating: hateful_memes/img/65178.png  \n",
            "  inflating: hateful_memes/img/30576.png  \n",
            "  inflating: hateful_memes/img/95427.png  \n",
            "  inflating: hateful_memes/img/46270.png  \n",
            "  inflating: hateful_memes/img/86357.png  \n",
            "  inflating: hateful_memes/img/29316.png  \n",
            "  inflating: hateful_memes/img/67398.png  \n",
            "  inflating: hateful_memes/img/26835.png  \n",
            "  inflating: hateful_memes/img/28964.png  \n",
            "  inflating: hateful_memes/img/19567.png  \n",
            "  inflating: hateful_memes/img/39061.png  \n",
            "  inflating: hateful_memes/img/34091.png  \n",
            "  inflating: hateful_memes/img/60281.png  \n",
            "  inflating: hateful_memes/img/85970.png  \n",
            "  inflating: hateful_memes/img/07983.png  \n",
            "  inflating: hateful_memes/img/29764.png  \n",
            "  inflating: hateful_memes/img/42650.png  \n",
            "  inflating: hateful_memes/img/62739.png  \n",
            "  inflating: hateful_memes/img/05297.png  \n",
            "  inflating: hateful_memes/img/52179.png  \n",
            "  inflating: hateful_memes/img/28491.png  \n",
            "  inflating: hateful_memes/img/10832.png  \n",
            "  inflating: hateful_memes/img/73129.png  \n",
            "  inflating: hateful_memes/img/78062.png  \n",
            "  inflating: hateful_memes/img/50682.png  \n",
            "  inflating: hateful_memes/img/74612.png  \n",
            "  inflating: hateful_memes/img/98531.png  \n",
            "  inflating: hateful_memes/img/28765.png  \n",
            "  inflating: hateful_memes/img/90136.png  \n",
            "  inflating: hateful_memes/img/25413.png  \n",
            "  inflating: hateful_memes/img/69203.png  \n",
            "  inflating: hateful_memes/img/14083.png  \n",
            "  inflating: hateful_memes/img/81349.png  \n",
            "  inflating: hateful_memes/img/86730.png  \n",
            "  inflating: hateful_memes/img/97105.png  \n",
            "  inflating: hateful_memes/img/48302.png  \n",
            "  inflating: hateful_memes/img/79036.png  \n",
            "  inflating: hateful_memes/img/47960.png  \n",
            "  inflating: hateful_memes/img/06824.png  \n",
            "  inflating: hateful_memes/img/27016.png  \n",
            "  inflating: hateful_memes/img/19352.png  \n",
            "  inflating: hateful_memes/img/45263.png  \n",
            "  inflating: hateful_memes/img/24189.png  \n",
            "  inflating: hateful_memes/img/61205.png  \n",
            "  inflating: hateful_memes/img/14598.png  \n",
            "  inflating: hateful_memes/img/81956.png  \n",
            "  inflating: hateful_memes/img/54682.png  \n",
            "  inflating: hateful_memes/img/67810.png  \n",
            "  inflating: hateful_memes/img/30742.png  \n",
            "  inflating: hateful_memes/img/86413.png  \n",
            "  inflating: hateful_memes/img/90276.png  \n",
            "  inflating: hateful_memes/img/58936.png  \n",
            "  inflating: hateful_memes/img/59817.png  \n",
            "  inflating: hateful_memes/img/09238.png  \n",
            "  inflating: hateful_memes/img/54789.png  \n",
            "  inflating: hateful_memes/img/26731.png  \n",
            "  inflating: hateful_memes/img/89104.png  \n",
            "  inflating: hateful_memes/img/25610.png  \n",
            "  inflating: hateful_memes/img/48291.png  \n",
            "  inflating: hateful_memes/img/35097.png  \n",
            "  inflating: hateful_memes/img/10269.png  \n",
            "  inflating: hateful_memes/img/52903.png  \n",
            "  inflating: hateful_memes/img/35478.png  \n",
            "  inflating: hateful_memes/img/02814.png  \n",
            "  inflating: hateful_memes/img/46357.png  \n",
            "  inflating: hateful_memes/img/61752.png  \n",
            "  inflating: hateful_memes/img/26715.png  \n",
            "  inflating: hateful_memes/img/31270.png  \n",
            "  inflating: hateful_memes/img/42351.png  \n",
            "  inflating: hateful_memes/img/05618.png  \n",
            "  inflating: hateful_memes/img/17425.png  \n",
            "  inflating: hateful_memes/img/02571.png  \n",
            "  inflating: hateful_memes/img/81645.png  \n",
            "  inflating: hateful_memes/img/73146.png  \n",
            "  inflating: hateful_memes/img/01926.png  \n",
            "  inflating: hateful_memes/img/58490.png  \n",
            "  inflating: hateful_memes/img/30567.png  \n",
            "  inflating: hateful_memes/img/83076.png  \n",
            "  inflating: hateful_memes/img/36058.png  \n",
            "  inflating: hateful_memes/img/68230.png  \n",
            "  inflating: hateful_memes/img/31805.png  \n",
            "  inflating: hateful_memes/img/71083.png  \n",
            "  inflating: hateful_memes/img/23801.png  \n",
            "  inflating: hateful_memes/img/71905.png  \n",
            "  inflating: hateful_memes/img/61859.png  \n",
            "  inflating: hateful_memes/img/60329.png  \n",
            "  inflating: hateful_memes/img/39285.png  \n",
            "  inflating: hateful_memes/img/02483.png  \n",
            "  inflating: hateful_memes/img/21064.png  \n",
            "  inflating: hateful_memes/img/86217.png  \n",
            "  inflating: hateful_memes/img/75128.png  \n",
            "  inflating: hateful_memes/img/79624.png  \n",
            "  inflating: hateful_memes/img/82903.png  \n",
            "  inflating: hateful_memes/img/20438.png  \n",
            "  inflating: hateful_memes/img/06325.png  \n",
            "  inflating: hateful_memes/img/43520.png  \n",
            "  inflating: hateful_memes/img/79512.png  \n",
            "  inflating: hateful_memes/img/17096.png  \n",
            "  inflating: hateful_memes/img/92473.png  \n",
            "  inflating: hateful_memes/img/32568.png  \n",
            "  inflating: hateful_memes/img/31406.png  \n",
            "  inflating: hateful_memes/img/81320.png  \n",
            "  inflating: hateful_memes/img/78923.png  \n",
            "  inflating: hateful_memes/img/27950.png  \n",
            "  inflating: hateful_memes/img/07239.png  \n",
            "  inflating: hateful_memes/img/58079.png  \n",
            "  inflating: hateful_memes/img/45206.png  \n",
            "  inflating: hateful_memes/img/75104.png  \n",
            "  inflating: hateful_memes/img/61592.png  \n",
            "  inflating: hateful_memes/img/47391.png  \n",
            "  inflating: hateful_memes/img/31794.png  \n",
            "  inflating: hateful_memes/img/83907.png  \n",
            "  inflating: hateful_memes/img/04319.png  \n",
            "  inflating: hateful_memes/img/52108.png  \n",
            "  inflating: hateful_memes/img/27801.png  \n",
            "  inflating: hateful_memes/img/15097.png  \n",
            "  inflating: hateful_memes/img/97162.png  \n",
            "  inflating: hateful_memes/img/97013.png  \n",
            "  inflating: hateful_memes/img/05198.png  \n",
            "  inflating: hateful_memes/img/01498.png  \n",
            "  inflating: hateful_memes/img/03421.png  \n",
            "  inflating: hateful_memes/img/40815.png  \n",
            "  inflating: hateful_memes/img/87309.png  \n",
            "  inflating: hateful_memes/img/50817.png  \n",
            "  inflating: hateful_memes/img/14906.png  \n",
            "  inflating: hateful_memes/img/14582.png  \n",
            "  inflating: hateful_memes/img/89543.png  \n",
            "  inflating: hateful_memes/img/04361.png  \n",
            "  inflating: hateful_memes/img/21607.png  \n",
            "  inflating: hateful_memes/img/49813.png  \n",
            "  inflating: hateful_memes/img/54761.png  \n",
            "  inflating: hateful_memes/img/60931.png  \n",
            "  inflating: hateful_memes/img/23785.png  \n",
            "  inflating: hateful_memes/img/92783.png  \n",
            "  inflating: hateful_memes/img/01459.png  \n",
            "  inflating: hateful_memes/img/87241.png  \n",
            "  inflating: hateful_memes/img/92358.png  \n",
            "  inflating: hateful_memes/img/87645.png  \n",
            "  inflating: hateful_memes/img/79451.png  \n",
            "  inflating: hateful_memes/img/82761.png  \n",
            "  inflating: hateful_memes/img/36974.png  \n",
            "  inflating: hateful_memes/img/30281.png  \n",
            "  inflating: hateful_memes/img/45862.png  \n",
            "  inflating: hateful_memes/img/03926.png  \n",
            "  inflating: hateful_memes/img/38127.png  \n",
            "  inflating: hateful_memes/img/65237.png  \n",
            "  inflating: hateful_memes/img/75493.png  \n",
            "  inflating: hateful_memes/img/72981.png  \n",
            "  inflating: hateful_memes/img/96208.png  \n",
            "  inflating: hateful_memes/img/58613.png  \n",
            "  inflating: hateful_memes/img/90158.png  \n",
            "  inflating: hateful_memes/img/65341.png  \n",
            "  inflating: hateful_memes/img/87432.png  \n",
            "  inflating: hateful_memes/img/54176.png  \n",
            "  inflating: hateful_memes/img/49063.png  \n",
            "  inflating: hateful_memes/img/81395.png  \n",
            "  inflating: hateful_memes/img/50389.png  \n",
            "  inflating: hateful_memes/img/79850.png  \n",
            "  inflating: hateful_memes/img/06547.png  \n",
            "  inflating: hateful_memes/img/34872.png  \n",
            "  inflating: hateful_memes/img/32480.png  \n",
            "  inflating: hateful_memes/img/52340.png  \n",
            "  inflating: hateful_memes/img/60827.png  \n",
            "  inflating: hateful_memes/img/21548.png  \n",
            "  inflating: hateful_memes/img/70935.png  \n",
            "  inflating: hateful_memes/img/04967.png  \n",
            "  inflating: hateful_memes/img/40316.png  \n",
            "  inflating: hateful_memes/img/09128.png  \n",
            "  inflating: hateful_memes/img/16047.png  \n",
            "  inflating: hateful_memes/img/65704.png  \n",
            "  inflating: hateful_memes/img/78039.png  \n",
            "  inflating: hateful_memes/img/94067.png  \n",
            "  inflating: hateful_memes/img/42836.png  \n",
            "  inflating: hateful_memes/img/62174.png  \n",
            "  inflating: hateful_memes/img/85012.png  \n",
            "  inflating: hateful_memes/img/25381.png  \n",
            "  inflating: hateful_memes/img/23875.png  \n",
            "  inflating: hateful_memes/img/38261.png  \n",
            "  inflating: hateful_memes/img/31928.png  \n",
            "  inflating: hateful_memes/img/80713.png  \n",
            "  inflating: hateful_memes/img/70296.png  \n",
            "  inflating: hateful_memes/img/61905.png  \n",
            "  inflating: hateful_memes/img/87941.png  \n",
            "  inflating: hateful_memes/img/47836.png  \n",
            "  inflating: hateful_memes/img/09467.png  \n",
            "  inflating: hateful_memes/img/82195.png  \n",
            "  inflating: hateful_memes/img/50762.png  \n",
            "  inflating: hateful_memes/img/72891.png  \n",
            "  inflating: hateful_memes/img/91052.png  \n",
            "  inflating: hateful_memes/img/34075.png  \n",
            "  inflating: hateful_memes/img/68927.png  \n",
            "  inflating: hateful_memes/img/80195.png  \n",
            "  inflating: hateful_memes/img/89743.png  \n",
            "  inflating: hateful_memes/img/78643.png  \n",
            "  inflating: hateful_memes/img/54972.png  \n",
            "  inflating: hateful_memes/img/47698.png  \n",
            "  inflating: hateful_memes/img/25639.png  \n",
            "  inflating: hateful_memes/img/02537.png  \n",
            "  inflating: hateful_memes/img/82563.png  \n",
            "  inflating: hateful_memes/img/25468.png  \n",
            "  inflating: hateful_memes/img/79314.png  \n",
            "  inflating: hateful_memes/img/26095.png  \n",
            "  inflating: hateful_memes/img/67439.png  \n",
            "  inflating: hateful_memes/img/18963.png  \n",
            "  inflating: hateful_memes/img/36804.png  \n",
            "  inflating: hateful_memes/img/96150.png  \n",
            "  inflating: hateful_memes/img/29308.png  \n",
            "  inflating: hateful_memes/img/90843.png  \n",
            "  inflating: hateful_memes/img/28716.png  \n",
            "  inflating: hateful_memes/img/08369.png  \n",
            "  inflating: hateful_memes/img/54831.png  \n",
            "  inflating: hateful_memes/img/17462.png  \n",
            "  inflating: hateful_memes/img/53084.png  \n",
            "  inflating: hateful_memes/img/80967.png  \n",
            "  inflating: hateful_memes/img/27456.png  \n",
            "  inflating: hateful_memes/img/65041.png  \n",
            "  inflating: hateful_memes/img/15267.png  \n",
            "  inflating: hateful_memes/img/48216.png  \n",
            "  inflating: hateful_memes/img/92086.png  \n",
            "  inflating: hateful_memes/img/41269.png  \n",
            "  inflating: hateful_memes/img/35084.png  \n",
            "  inflating: hateful_memes/img/75468.png  \n",
            "  inflating: hateful_memes/img/18432.png  \n",
            "  inflating: hateful_memes/img/51462.png  \n",
            "  inflating: hateful_memes/img/62083.png  \n",
            "  inflating: hateful_memes/img/61935.png  \n",
            "  inflating: hateful_memes/img/27360.png  \n",
            "  inflating: hateful_memes/img/16278.png  \n",
            "  inflating: hateful_memes/img/19543.png  \n",
            "  inflating: hateful_memes/img/45732.png  \n",
            "  inflating: hateful_memes/img/26481.png  \n",
            "  inflating: hateful_memes/img/93524.png  \n",
            "  inflating: hateful_memes/img/12374.png  \n",
            "  inflating: hateful_memes/img/87165.png  \n",
            "  inflating: hateful_memes/img/97314.png  \n",
            "  inflating: hateful_memes/img/10789.png  \n",
            "  inflating: hateful_memes/img/97610.png  \n",
            "  inflating: hateful_memes/img/53682.png  \n",
            "  inflating: hateful_memes/img/12378.png  \n",
            "  inflating: hateful_memes/img/29046.png  \n",
            "  inflating: hateful_memes/img/87059.png  \n",
            "  inflating: hateful_memes/img/40563.png  \n",
            "  inflating: hateful_memes/img/13492.png  \n",
            "  inflating: hateful_memes/img/15029.png  \n",
            "  inflating: hateful_memes/img/70953.png  \n",
            "  inflating: hateful_memes/img/21348.png  \n",
            "  inflating: hateful_memes/img/83745.png  \n",
            "  inflating: hateful_memes/img/91432.png  \n",
            "  inflating: hateful_memes/img/41875.png  \n",
            "  inflating: hateful_memes/img/39264.png  \n",
            "  inflating: hateful_memes/img/93268.png  \n",
            "  inflating: hateful_memes/img/39652.png  \n",
            "  inflating: hateful_memes/img/18045.png  \n",
            "  inflating: hateful_memes/img/74192.png  \n",
            "  inflating: hateful_memes/img/38524.png  \n",
            "  inflating: hateful_memes/img/04132.png  \n",
            "  inflating: hateful_memes/img/29013.png  \n",
            "  inflating: hateful_memes/img/78014.png  \n",
            "  inflating: hateful_memes/img/57982.png  \n",
            "  inflating: hateful_memes/img/16082.png  \n",
            "  inflating: hateful_memes/img/84916.png  \n",
            "  inflating: hateful_memes/img/05978.png  \n",
            "  inflating: hateful_memes/img/78623.png  \n",
            "  inflating: hateful_memes/img/06795.png  \n",
            "  inflating: hateful_memes/img/65794.png  \n",
            "  inflating: hateful_memes/img/38624.png  \n",
            "  inflating: hateful_memes/img/63580.png  \n",
            "  inflating: hateful_memes/img/61038.png  \n",
            "  inflating: hateful_memes/img/53214.png  \n",
            "  inflating: hateful_memes/img/75846.png  \n",
            "  inflating: hateful_memes/img/60345.png  \n",
            "  inflating: hateful_memes/img/80734.png  \n",
            "  inflating: hateful_memes/img/68450.png  \n",
            "  inflating: hateful_memes/img/34796.png  \n",
            "  inflating: hateful_memes/img/16973.png  \n",
            "  inflating: hateful_memes/img/72150.png  \n",
            "  inflating: hateful_memes/img/20958.png  \n",
            "  inflating: hateful_memes/img/83492.png  \n",
            "  inflating: hateful_memes/img/54692.png  \n",
            "  inflating: hateful_memes/img/06827.png  \n",
            "  inflating: hateful_memes/img/29437.png  \n",
            "  inflating: hateful_memes/img/05498.png  \n",
            "  inflating: hateful_memes/img/18526.png  \n",
            "  inflating: hateful_memes/img/09831.png  \n",
            "  inflating: hateful_memes/img/16520.png  \n",
            "  inflating: hateful_memes/img/83402.png  \n",
            "  inflating: hateful_memes/img/20374.png  \n",
            "  inflating: hateful_memes/img/04765.png  \n",
            "  inflating: hateful_memes/img/27548.png  \n",
            "  inflating: hateful_memes/img/45017.png  \n",
            "  inflating: hateful_memes/img/83124.png  \n",
            "  inflating: hateful_memes/img/41983.png  \n",
            "  inflating: hateful_memes/img/24319.png  \n",
            "  inflating: hateful_memes/img/12657.png  \n",
            "  inflating: hateful_memes/img/47829.png  \n",
            "  inflating: hateful_memes/img/52190.png  \n",
            "  inflating: hateful_memes/img/71596.png  \n",
            "  inflating: hateful_memes/img/92607.png  \n",
            "  inflating: hateful_memes/img/79053.png  \n",
            "  inflating: hateful_memes/img/61597.png  \n",
            "  inflating: hateful_memes/img/38416.png  \n",
            "  inflating: hateful_memes/img/20396.png  \n",
            "  inflating: hateful_memes/img/75186.png  \n",
            "  inflating: hateful_memes/img/27914.png  \n",
            "  inflating: hateful_memes/img/62081.png  \n",
            "  inflating: hateful_memes/img/74502.png  \n",
            "  inflating: hateful_memes/img/13469.png  \n",
            "  inflating: hateful_memes/img/57941.png  \n",
            "  inflating: hateful_memes/img/40821.png  \n",
            "  inflating: hateful_memes/img/29703.png  \n",
            "  inflating: hateful_memes/img/07562.png  \n",
            "  inflating: hateful_memes/img/59420.png  \n",
            "  inflating: hateful_memes/img/71693.png  \n",
            "  inflating: hateful_memes/img/87061.png  \n",
            "  inflating: hateful_memes/img/91273.png  \n",
            "  inflating: hateful_memes/img/47259.png  \n",
            "  inflating: hateful_memes/img/36724.png  \n",
            "  inflating: hateful_memes/img/68520.png  \n",
            "  inflating: hateful_memes/img/34816.png  \n",
            "  inflating: hateful_memes/img/02436.png  \n",
            "  inflating: hateful_memes/img/39504.png  \n",
            "  inflating: hateful_memes/img/26537.png  \n",
            "  inflating: hateful_memes/img/63709.png  \n",
            "  inflating: hateful_memes/img/07125.png  \n",
            "  inflating: hateful_memes/img/10948.png  \n",
            "  inflating: hateful_memes/img/94031.png  \n",
            "  inflating: hateful_memes/img/16283.png  \n",
            "  inflating: hateful_memes/img/81943.png  \n",
            "  inflating: hateful_memes/img/63472.png  \n",
            "  inflating: hateful_memes/img/73256.png  \n",
            "  inflating: hateful_memes/img/38726.png  \n",
            "  inflating: hateful_memes/img/25103.png  \n",
            "  inflating: hateful_memes/img/81054.png  \n",
            "  inflating: hateful_memes/img/38576.png  \n",
            "  inflating: hateful_memes/img/10548.png  \n",
            "  inflating: hateful_memes/img/75068.png  \n",
            "  inflating: hateful_memes/img/15638.png  \n",
            "  inflating: hateful_memes/img/19452.png  \n",
            "  inflating: hateful_memes/img/16894.png  \n",
            "  inflating: hateful_memes/img/80157.png  \n",
            "  inflating: hateful_memes/img/16734.png  \n",
            "  inflating: hateful_memes/img/75209.png  \n",
            "  inflating: hateful_memes/img/75680.png  \n",
            "  inflating: hateful_memes/img/17023.png  \n",
            "  inflating: hateful_memes/img/84901.png  \n",
            "  inflating: hateful_memes/img/71682.png  \n",
            "  inflating: hateful_memes/img/47826.png  \n",
            "  inflating: hateful_memes/img/47098.png  \n",
            "  inflating: hateful_memes/img/85310.png  \n",
            "  inflating: hateful_memes/img/28197.png  \n",
            "  inflating: hateful_memes/img/48710.png  \n",
            "  inflating: hateful_memes/img/79524.png  \n",
            "  inflating: hateful_memes/img/58760.png  \n",
            "  inflating: hateful_memes/img/48917.png  \n",
            "  inflating: hateful_memes/img/92136.png  \n",
            "  inflating: hateful_memes/img/71625.png  \n",
            "  inflating: hateful_memes/img/93128.png  \n",
            "  inflating: hateful_memes/img/12067.png  \n",
            "  inflating: hateful_memes/img/89750.png  \n",
            "  inflating: hateful_memes/img/40721.png  \n",
            "  inflating: hateful_memes/img/98105.png  \n",
            "  inflating: hateful_memes/img/48529.png  \n",
            "  inflating: hateful_memes/img/10384.png  \n",
            "  inflating: hateful_memes/img/51943.png  \n",
            "  inflating: hateful_memes/img/12534.png  \n",
            "  inflating: hateful_memes/img/63210.png  \n",
            "  inflating: hateful_memes/img/98416.png  \n",
            "  inflating: hateful_memes/img/36450.png  \n",
            "  inflating: hateful_memes/img/04712.png  \n",
            "  inflating: hateful_memes/img/10483.png  \n",
            "  inflating: hateful_memes/img/98706.png  \n",
            "  inflating: hateful_memes/img/39078.png  \n",
            "  inflating: hateful_memes/img/98513.png  \n",
            "  inflating: hateful_memes/img/81043.png  \n",
            "  inflating: hateful_memes/img/34675.png  \n",
            "  inflating: hateful_memes/img/19458.png  \n",
            "  inflating: hateful_memes/img/50239.png  \n",
            "  inflating: hateful_memes/img/01643.png  \n",
            "  inflating: hateful_memes/img/32604.png  \n",
            "  inflating: hateful_memes/img/06951.png  \n",
            "  inflating: hateful_memes/img/76032.png  \n",
            "  inflating: hateful_memes/img/71620.png  \n",
            "  inflating: hateful_memes/img/76821.png  \n",
            "  inflating: hateful_memes/img/84269.png  \n",
            "  inflating: hateful_memes/img/21973.png  \n",
            "  inflating: hateful_memes/img/75984.png  \n",
            "  inflating: hateful_memes/img/63859.png  \n",
            "  inflating: hateful_memes/img/47385.png  \n",
            "  inflating: hateful_memes/img/92058.png  \n",
            "  inflating: hateful_memes/img/85976.png  \n",
            "  inflating: hateful_memes/img/78092.png  \n",
            "  inflating: hateful_memes/img/38529.png  \n",
            "  inflating: hateful_memes/img/59701.png  \n",
            "  inflating: hateful_memes/img/03874.png  \n",
            "  inflating: hateful_memes/img/95426.png  \n",
            "  inflating: hateful_memes/img/74912.png  \n",
            "  inflating: hateful_memes/img/90842.png  \n",
            "  inflating: hateful_memes/img/97436.png  \n",
            "  inflating: hateful_memes/img/96270.png  \n",
            "  inflating: hateful_memes/img/60197.png  \n",
            "  inflating: hateful_memes/img/29035.png  \n",
            "  inflating: hateful_memes/img/10385.png  \n",
            "  inflating: hateful_memes/img/46390.png  \n",
            "  inflating: hateful_memes/img/36954.png  \n",
            "  inflating: hateful_memes/img/02795.png  \n",
            "  inflating: hateful_memes/img/17246.png  \n",
            "  inflating: hateful_memes/img/45621.png  \n",
            "  inflating: hateful_memes/img/05827.png  \n",
            "  inflating: hateful_memes/img/52894.png  \n",
            "  inflating: hateful_memes/img/35601.png  \n",
            "  inflating: hateful_memes/img/86320.png  \n",
            "  inflating: hateful_memes/img/16245.png  \n",
            "  inflating: hateful_memes/img/76293.png  \n",
            "  inflating: hateful_memes/img/93521.png  \n",
            "  inflating: hateful_memes/img/52860.png  \n",
            "  inflating: hateful_memes/img/04923.png  \n",
            "  inflating: hateful_memes/img/41276.png  \n",
            "  inflating: hateful_memes/img/51894.png  \n",
            "  inflating: hateful_memes/img/56917.png  \n",
            "  inflating: hateful_memes/img/47615.png  \n",
            "  inflating: hateful_memes/img/05869.png  \n",
            "  inflating: hateful_memes/img/17385.png  \n",
            "  inflating: hateful_memes/img/59217.png  \n",
            "  inflating: hateful_memes/img/23941.png  \n",
            "  inflating: hateful_memes/img/09785.png  \n",
            "  inflating: hateful_memes/img/72160.png  \n",
            "  inflating: hateful_memes/img/51284.png  \n",
            "  inflating: hateful_memes/img/26891.png  \n",
            "  inflating: hateful_memes/img/79185.png  \n",
            "  inflating: hateful_memes/img/50869.png  \n",
            "  inflating: hateful_memes/img/17324.png  \n",
            "  inflating: hateful_memes/img/74318.png  \n",
            "  inflating: hateful_memes/img/06123.png  \n",
            "  inflating: hateful_memes/img/40372.png  \n",
            "  inflating: hateful_memes/img/05614.png  \n",
            "  inflating: hateful_memes/img/35417.png  \n",
            "  inflating: hateful_memes/img/12536.png  \n",
            "  inflating: hateful_memes/img/95078.png  \n",
            "  inflating: hateful_memes/img/76910.png  \n",
            "  inflating: hateful_memes/img/45871.png  \n",
            "  inflating: hateful_memes/img/81026.png  \n",
            "  inflating: hateful_memes/img/32964.png  \n",
            "  inflating: hateful_memes/img/25874.png  \n",
            "  inflating: hateful_memes/img/60971.png  \n",
            "  inflating: hateful_memes/img/78034.png  \n",
            "  inflating: hateful_memes/img/23105.png  \n",
            "  inflating: hateful_memes/img/42538.png  \n",
            "  inflating: hateful_memes/img/70452.png  \n",
            "  inflating: hateful_memes/img/30276.png  \n",
            "  inflating: hateful_memes/img/08423.png  \n",
            "  inflating: hateful_memes/img/17392.png  \n",
            "  inflating: hateful_memes/img/64752.png  \n",
            "  inflating: hateful_memes/img/30714.png  \n",
            "  inflating: hateful_memes/img/96402.png  \n",
            "  inflating: hateful_memes/img/69150.png  \n",
            "  inflating: hateful_memes/img/02983.png  \n",
            "  inflating: hateful_memes/img/47305.png  \n",
            "  inflating: hateful_memes/img/13675.png  \n",
            "  inflating: hateful_memes/img/39051.png  \n",
            "  inflating: hateful_memes/img/45062.png  \n",
            "  inflating: hateful_memes/img/91245.png  \n",
            "  inflating: hateful_memes/img/90627.png  \n",
            "  inflating: hateful_memes/img/56974.png  \n",
            "  inflating: hateful_memes/img/62854.png  \n",
            "  inflating: hateful_memes/img/48703.png  \n",
            "  inflating: hateful_memes/img/37298.png  \n",
            "  inflating: hateful_memes/img/38057.png  \n",
            "  inflating: hateful_memes/img/71634.png  \n",
            "  inflating: hateful_memes/img/83905.png  \n",
            "  inflating: hateful_memes/img/43152.png  \n",
            "  inflating: hateful_memes/img/95237.png  \n",
            "  inflating: hateful_memes/img/53962.png  \n",
            "  inflating: hateful_memes/img/74862.png  \n",
            "  inflating: hateful_memes/img/61037.png  \n",
            "  inflating: hateful_memes/img/10238.png  \n",
            "  inflating: hateful_memes/img/34082.png  \n",
            "  inflating: hateful_memes/img/53249.png  \n",
            "  inflating: hateful_memes/img/98170.png  \n",
            "  inflating: hateful_memes/img/85721.png  \n",
            "  inflating: hateful_memes/img/71480.png  \n",
            "  inflating: hateful_memes/img/03285.png  \n",
            "  inflating: hateful_memes/img/35917.png  \n",
            "  inflating: hateful_memes/img/69410.png  \n",
            "  inflating: hateful_memes/img/08219.png  \n",
            "  inflating: hateful_memes/img/60254.png  \n",
            "  inflating: hateful_memes/img/29756.png  \n",
            "  inflating: hateful_memes/img/24573.png  \n",
            "  inflating: hateful_memes/img/26981.png  \n",
            "  inflating: hateful_memes/img/45120.png  \n",
            "  inflating: hateful_memes/img/71653.png  \n",
            "  inflating: hateful_memes/img/16935.png  \n",
            "  inflating: hateful_memes/img/17860.png  \n",
            "  inflating: hateful_memes/img/80316.png  \n",
            "  inflating: hateful_memes/img/08732.png  \n",
            "  inflating: hateful_memes/img/45960.png  \n",
            "  inflating: hateful_memes/img/16587.png  \n",
            "  inflating: hateful_memes/img/97361.png  \n",
            "  inflating: hateful_memes/img/91348.png  \n",
            "  inflating: hateful_memes/img/50942.png  \n",
            "  inflating: hateful_memes/img/54968.png  \n",
            "  inflating: hateful_memes/img/50689.png  \n",
            "  inflating: hateful_memes/img/19406.png  \n",
            "  inflating: hateful_memes/img/93102.png  \n",
            "  inflating: hateful_memes/img/45978.png  \n",
            "  inflating: hateful_memes/img/08215.png  \n",
            "  inflating: hateful_memes/img/89206.png  \n",
            "  inflating: hateful_memes/img/19358.png  \n",
            "  inflating: hateful_memes/img/63192.png  \n",
            "  inflating: hateful_memes/img/29710.png  \n",
            "  inflating: hateful_memes/img/10743.png  \n",
            "  inflating: hateful_memes/img/20591.png  \n",
            "  inflating: hateful_memes/img/31508.png  \n",
            "  inflating: hateful_memes/img/92104.png  \n",
            "  inflating: hateful_memes/img/32608.png  \n",
            "  inflating: hateful_memes/img/13098.png  \n",
            "  inflating: hateful_memes/img/63845.png  \n",
            "  inflating: hateful_memes/img/07269.png  \n",
            "  inflating: hateful_memes/img/53426.png  \n",
            "  inflating: hateful_memes/img/21486.png  \n",
            "  inflating: hateful_memes/img/34652.png  \n",
            "  inflating: hateful_memes/img/76285.png  \n",
            "  inflating: hateful_memes/img/10732.png  \n",
            "  inflating: hateful_memes/img/50738.png  \n",
            "  inflating: hateful_memes/img/41936.png  \n",
            "  inflating: hateful_memes/img/87563.png  \n",
            "  inflating: hateful_memes/img/69425.png  \n",
            "  inflating: hateful_memes/img/05627.png  \n",
            "  inflating: hateful_memes/img/05874.png  \n",
            "  inflating: hateful_memes/img/52019.png  \n",
            "  inflating: hateful_memes/img/86437.png  \n",
            "  inflating: hateful_memes/img/61980.png  \n",
            "  inflating: hateful_memes/img/37261.png  \n",
            "  inflating: hateful_memes/img/42058.png  \n",
            "  inflating: hateful_memes/img/27816.png  \n",
            "  inflating: hateful_memes/img/30492.png  \n",
            "  inflating: hateful_memes/img/42368.png  \n",
            "  inflating: hateful_memes/img/35408.png  \n",
            "  inflating: hateful_memes/img/27953.png  \n",
            "  inflating: hateful_memes/img/78631.png  \n",
            "  inflating: hateful_memes/img/10748.png  \n",
            "  inflating: hateful_memes/img/87125.png  \n",
            "  inflating: hateful_memes/img/72095.png  \n",
            "  inflating: hateful_memes/img/62917.png  \n",
            "  inflating: hateful_memes/img/94217.png  \n",
            "  inflating: hateful_memes/img/86927.png  \n",
            "  inflating: hateful_memes/img/43792.png  \n",
            "  inflating: hateful_memes/img/63041.png  \n",
            "  inflating: hateful_memes/img/76091.png  \n",
            "  inflating: hateful_memes/img/17932.png  \n",
            "  inflating: hateful_memes/img/64720.png  \n",
            "  inflating: hateful_memes/img/32150.png  \n",
            "  inflating: hateful_memes/img/01349.png  \n",
            "  inflating: hateful_memes/img/60578.png  \n",
            "  inflating: hateful_memes/img/76158.png  \n",
            "  inflating: hateful_memes/img/52864.png  \n",
            "  inflating: hateful_memes/img/03472.png  \n",
            "  inflating: hateful_memes/img/61904.png  \n",
            "  inflating: hateful_memes/img/50163.png  \n",
            "  inflating: hateful_memes/img/20857.png  \n",
            "  inflating: hateful_memes/img/90187.png  \n",
            "  inflating: hateful_memes/img/95720.png  \n",
            "  inflating: hateful_memes/img/48213.png  \n",
            "  inflating: hateful_memes/img/82716.png  \n",
            "  inflating: hateful_memes/img/79250.png  \n",
            "  inflating: hateful_memes/img/17352.png  \n",
            "  inflating: hateful_memes/img/64059.png  \n",
            "  inflating: hateful_memes/img/41623.png  \n",
            "  inflating: hateful_memes/img/17438.png  \n",
            "  inflating: hateful_memes/img/42503.png  \n",
            "  inflating: hateful_memes/img/94501.png  \n",
            "  inflating: hateful_memes/img/09812.png  \n",
            "  inflating: hateful_memes/img/36128.png  \n",
            "  inflating: hateful_memes/img/57619.png  \n",
            "  inflating: hateful_memes/img/43198.png  \n",
            "  inflating: hateful_memes/img/36179.png  \n",
            "  inflating: hateful_memes/img/57638.png  \n",
            "  inflating: hateful_memes/img/62198.png  \n",
            "  inflating: hateful_memes/img/30412.png  \n",
            "  inflating: hateful_memes/img/43759.png  \n",
            "  inflating: hateful_memes/img/73604.png  \n",
            "  inflating: hateful_memes/img/13802.png  \n",
            "  inflating: hateful_memes/img/46790.png  \n",
            "  inflating: hateful_memes/img/37254.png  \n",
            "  inflating: hateful_memes/img/57132.png  \n",
            "  inflating: hateful_memes/img/28759.png  \n",
            "  inflating: hateful_memes/img/90748.png  \n",
            "  inflating: hateful_memes/img/51476.png  \n",
            "  inflating: hateful_memes/img/25107.png  \n",
            "  inflating: hateful_memes/img/50871.png  \n",
            "  inflating: hateful_memes/img/65298.png  \n",
            "  inflating: hateful_memes/img/54689.png  \n",
            "  inflating: hateful_memes/img/09374.png  \n",
            "  inflating: hateful_memes/img/45730.png  \n",
            "  inflating: hateful_memes/img/74215.png  \n",
            "  inflating: hateful_memes/img/02569.png  \n",
            "  inflating: hateful_memes/img/93852.png  \n",
            "  inflating: hateful_memes/img/79586.png  \n",
            "  inflating: hateful_memes/img/32586.png  \n",
            "  inflating: hateful_memes/img/43651.png  \n",
            "  inflating: hateful_memes/img/67348.png  \n",
            "  inflating: hateful_memes/img/09482.png  \n",
            "  inflating: hateful_memes/img/20975.png  \n",
            "  inflating: hateful_memes/img/74350.png  \n",
            "  inflating: hateful_memes/img/02957.png  \n",
            "  inflating: hateful_memes/img/43895.png  \n",
            "  inflating: hateful_memes/img/98316.png  \n",
            "  inflating: hateful_memes/img/87903.png  \n",
            "  inflating: hateful_memes/img/71593.png  \n",
            "  inflating: hateful_memes/img/15076.png  \n",
            "  inflating: hateful_memes/img/20781.png  \n",
            "  inflating: hateful_memes/img/15230.png  \n",
            "  inflating: hateful_memes/img/83517.png  \n",
            "  inflating: hateful_memes/img/73168.png  \n",
            "  inflating: hateful_memes/img/28497.png  \n",
            "  inflating: hateful_memes/img/62357.png  \n",
            "  inflating: hateful_memes/img/24351.png  \n",
            "  inflating: hateful_memes/img/01894.png  \n",
            "  inflating: hateful_memes/img/45109.png  \n",
            "  inflating: hateful_memes/img/18794.png  \n",
            "  inflating: hateful_memes/img/56108.png  \n",
            "  inflating: hateful_memes/img/36417.png  \n",
            "  inflating: hateful_memes/img/69428.png  \n",
            "  inflating: hateful_memes/img/69205.png  \n",
            "  inflating: hateful_memes/img/51789.png  \n",
            "  inflating: hateful_memes/img/81206.png  \n",
            "  inflating: hateful_memes/img/62510.png  \n",
            "  inflating: hateful_memes/img/04863.png  \n",
            "  inflating: hateful_memes/img/25193.png  \n",
            "  inflating: hateful_memes/img/67498.png  \n",
            "  inflating: hateful_memes/img/67091.png  \n",
            "  inflating: hateful_memes/img/61054.png  \n",
            "  inflating: hateful_memes/img/49806.png  \n",
            "  inflating: hateful_memes/img/07415.png  \n",
            "  inflating: hateful_memes/img/63714.png  \n",
            "  inflating: hateful_memes/img/27384.png  \n",
            "  inflating: hateful_memes/img/43971.png  \n",
            "  inflating: hateful_memes/img/60357.png  \n",
            "  inflating: hateful_memes/img/98613.png  \n",
            "  inflating: hateful_memes/img/19420.png  \n",
            "  inflating: hateful_memes/img/36195.png  \n",
            "  inflating: hateful_memes/img/68721.png  \n",
            "  inflating: hateful_memes/img/12045.png  \n",
            "  inflating: hateful_memes/img/75420.png  \n",
            "  inflating: hateful_memes/img/52096.png  \n",
            "  inflating: hateful_memes/img/89126.png  \n",
            "  inflating: hateful_memes/img/35642.png  \n",
            "  inflating: hateful_memes/img/49832.png  \n",
            "  inflating: hateful_memes/img/41853.png  \n",
            "  inflating: hateful_memes/img/02674.png  \n",
            "  inflating: hateful_memes/img/82507.png  \n",
            "  inflating: hateful_memes/img/94718.png  \n",
            "  inflating: hateful_memes/img/38056.png  \n",
            "  inflating: hateful_memes/img/38041.png  \n",
            "  inflating: hateful_memes/img/34162.png  \n",
            "  inflating: hateful_memes/img/72380.png  \n",
            "  inflating: hateful_memes/img/83765.png  \n",
            "  inflating: hateful_memes/img/93401.png  \n",
            "  inflating: hateful_memes/img/09364.png  \n",
            "  inflating: hateful_memes/img/40731.png  \n",
            "  inflating: hateful_memes/img/91234.png  \n",
            "  inflating: hateful_memes/img/81902.png  \n",
            "  inflating: hateful_memes/img/07469.png  \n",
            "  inflating: hateful_memes/img/82419.png  \n",
            "  inflating: hateful_memes/img/28936.png  \n",
            "  inflating: hateful_memes/img/42315.png  \n",
            "  inflating: hateful_memes/img/74205.png  \n",
            "  inflating: hateful_memes/img/14907.png  \n",
            "  inflating: hateful_memes/img/21387.png  \n",
            "  inflating: hateful_memes/img/51293.png  \n",
            "  inflating: hateful_memes/img/07591.png  \n",
            "  inflating: hateful_memes/img/07456.png  \n",
            "  inflating: hateful_memes/img/57430.png  \n",
            "  inflating: hateful_memes/img/18529.png  \n",
            "  inflating: hateful_memes/img/78321.png  \n",
            "  inflating: hateful_memes/img/86249.png  \n",
            "  inflating: hateful_memes/img/92013.png  \n",
            "  inflating: hateful_memes/img/85213.png  \n",
            "  inflating: hateful_memes/img/07218.png  \n",
            "  inflating: hateful_memes/img/28196.png  \n",
            "  inflating: hateful_memes/img/78296.png  \n",
            "  inflating: hateful_memes/img/90465.png  \n",
            "  inflating: hateful_memes/img/90178.png  \n",
            "  inflating: hateful_memes/img/76521.png  \n",
            "  inflating: hateful_memes/img/98401.png  \n",
            "  inflating: hateful_memes/img/12607.png  \n",
            "  inflating: hateful_memes/img/34927.png  \n",
            "  inflating: hateful_memes/img/21963.png  \n",
            "  inflating: hateful_memes/img/54670.png  \n",
            "  inflating: hateful_memes/img/30486.png  \n",
            "  inflating: hateful_memes/img/08179.png  \n",
            "  inflating: hateful_memes/img/63814.png  \n",
            "  inflating: hateful_memes/img/12675.png  \n",
            "  inflating: hateful_memes/img/76850.png  \n",
            "  inflating: hateful_memes/img/69842.png  \n",
            "  inflating: hateful_memes/img/90654.png  \n",
            "  inflating: hateful_memes/img/42975.png  \n",
            "  inflating: hateful_memes/img/90564.png  \n",
            "  inflating: hateful_memes/img/43925.png  \n",
            "  inflating: hateful_memes/img/45316.png  \n",
            "  inflating: hateful_memes/img/81764.png  \n",
            "  inflating: hateful_memes/img/25706.png  \n",
            "  inflating: hateful_memes/img/50714.png  \n",
            "  inflating: hateful_memes/img/46097.png  \n",
            "  inflating: hateful_memes/img/04695.png  \n",
            "  inflating: hateful_memes/img/42958.png  \n",
            "  inflating: hateful_memes/img/18273.png  \n",
            "  inflating: hateful_memes/img/47053.png  \n",
            "  inflating: hateful_memes/img/98015.png  \n",
            "  inflating: hateful_memes/img/90573.png  \n",
            "  inflating: hateful_memes/img/17359.png  \n",
            "  inflating: hateful_memes/img/17356.png  \n",
            "  inflating: hateful_memes/img/20541.png  \n",
            "  inflating: hateful_memes/img/89726.png  \n",
            "  inflating: hateful_memes/img/48539.png  \n",
            "  inflating: hateful_memes/img/86431.png  \n",
            "  inflating: hateful_memes/img/34518.png  \n",
            "  inflating: hateful_memes/img/03197.png  \n",
            "  inflating: hateful_memes/img/26940.png  \n",
            "  inflating: hateful_memes/img/59716.png  \n",
            "  inflating: hateful_memes/img/06291.png  \n",
            "  inflating: hateful_memes/img/21053.png  \n",
            "  inflating: hateful_memes/img/48063.png  \n",
            "  inflating: hateful_memes/img/28639.png  \n",
            "  inflating: hateful_memes/img/05863.png  \n",
            "  inflating: hateful_memes/img/38150.png  \n",
            "  inflating: hateful_memes/img/25498.png  \n",
            "  inflating: hateful_memes/img/49023.png  \n",
            "  inflating: hateful_memes/img/05283.png  \n",
            "  inflating: hateful_memes/img/69421.png  \n",
            "  inflating: hateful_memes/img/45297.png  \n",
            "  inflating: hateful_memes/img/63295.png  \n",
            "  inflating: hateful_memes/img/34975.png  \n",
            "  inflating: hateful_memes/img/94617.png  \n",
            "  inflating: hateful_memes/img/96250.png  \n",
            "  inflating: hateful_memes/img/31592.png  \n",
            "  inflating: hateful_memes/img/47652.png  \n",
            "  inflating: hateful_memes/img/67528.png  \n",
            "  inflating: hateful_memes/img/13587.png  \n",
            "  inflating: hateful_memes/img/48756.png  \n",
            "  inflating: hateful_memes/img/39867.png  \n",
            "  inflating: hateful_memes/img/29067.png  \n",
            "  inflating: hateful_memes/img/30581.png  \n",
            "  inflating: hateful_memes/img/24389.png  \n",
            "  inflating: hateful_memes/img/68472.png  \n",
            "  inflating: hateful_memes/img/09843.png  \n",
            "  inflating: hateful_memes/img/05213.png  \n",
            "  inflating: hateful_memes/img/13856.png  \n",
            "  inflating: hateful_memes/img/65378.png  \n",
            "  inflating: hateful_memes/img/18960.png  \n",
            "  inflating: hateful_memes/img/41972.png  \n",
            "  inflating: hateful_memes/img/71253.png  \n",
            "  inflating: hateful_memes/img/92108.png  \n",
            "  inflating: hateful_memes/img/52183.png  \n",
            "  inflating: hateful_memes/img/15824.png  \n",
            "  inflating: hateful_memes/img/28173.png  \n",
            "  inflating: hateful_memes/img/68954.png  \n",
            "  inflating: hateful_memes/img/57932.png  \n",
            "  inflating: hateful_memes/img/71365.png  \n",
            "  inflating: hateful_memes/img/82603.png  \n",
            "  inflating: hateful_memes/img/79603.png  \n",
            "  inflating: hateful_memes/img/43610.png  \n",
            "  inflating: hateful_memes/img/14697.png  \n",
            "  inflating: hateful_memes/img/17529.png  \n",
            "  inflating: hateful_memes/img/86045.png  \n",
            "  inflating: hateful_memes/img/21456.png  \n",
            "  inflating: hateful_memes/img/42309.png  \n",
            "  inflating: hateful_memes/img/73680.png  \n",
            "  inflating: hateful_memes/img/26379.png  \n",
            "  inflating: hateful_memes/img/94170.png  \n",
            "  inflating: hateful_memes/img/28164.png  \n",
            "  inflating: hateful_memes/img/85920.png  \n",
            "  inflating: hateful_memes/img/09386.png  \n",
            "  inflating: hateful_memes/img/21769.png  \n",
            "  inflating: hateful_memes/img/62031.png  \n",
            "  inflating: hateful_memes/img/12945.png  \n",
            "  inflating: hateful_memes/img/79312.png  \n",
            "  inflating: hateful_memes/img/61938.png  \n",
            "  inflating: hateful_memes/img/01439.png  \n",
            "  inflating: hateful_memes/img/60759.png  \n",
            "  inflating: hateful_memes/img/56287.png  \n",
            "  inflating: hateful_memes/img/63092.png  \n",
            "  inflating: hateful_memes/img/26781.png  \n",
            "  inflating: hateful_memes/img/40512.png  \n",
            "  inflating: hateful_memes/img/43186.png  \n",
            "  inflating: hateful_memes/img/09248.png  \n",
            "  inflating: hateful_memes/img/56124.png  \n",
            "  inflating: hateful_memes/img/70835.png  \n",
            "  inflating: hateful_memes/img/98473.png  \n",
            "  inflating: hateful_memes/img/96054.png  \n",
            "  inflating: hateful_memes/img/89761.png  \n",
            "  inflating: hateful_memes/img/51630.png  \n",
            "  inflating: hateful_memes/img/54936.png  \n",
            "  inflating: hateful_memes/img/78345.png  \n",
            "  inflating: hateful_memes/img/17548.png  \n",
            "  inflating: hateful_memes/img/48512.png  \n",
            "  inflating: hateful_memes/img/67140.png  \n",
            "  inflating: hateful_memes/img/61948.png  \n",
            "  inflating: hateful_memes/img/43052.png  \n",
            "  inflating: hateful_memes/img/85379.png  \n",
            "  inflating: hateful_memes/img/26057.png  \n",
            "  inflating: hateful_memes/img/41296.png  \n",
            "  inflating: hateful_memes/img/78125.png  \n",
            "  inflating: hateful_memes/img/23745.png  \n",
            "  inflating: hateful_memes/img/46359.png  \n",
            "  inflating: hateful_memes/img/08376.png  \n",
            "  inflating: hateful_memes/img/76809.png  \n",
            "  inflating: hateful_memes/img/96284.png  \n",
            "  inflating: hateful_memes/img/14259.png  \n",
            "  inflating: hateful_memes/img/49351.png  \n",
            "  inflating: hateful_memes/img/62391.png  \n",
            "  inflating: hateful_memes/img/37854.png  \n",
            "  inflating: hateful_memes/img/63720.png  \n",
            "  inflating: hateful_memes/img/47896.png  \n",
            "  inflating: hateful_memes/img/63871.png  \n",
            "  inflating: hateful_memes/img/82473.png  \n",
            "  inflating: hateful_memes/img/96872.png  \n",
            "  inflating: hateful_memes/img/93251.png  \n",
            "  inflating: hateful_memes/img/72805.png  \n",
            "  inflating: hateful_memes/img/76592.png  \n",
            "  inflating: hateful_memes/img/15270.png  \n",
            "  inflating: hateful_memes/img/97685.png  \n",
            "  inflating: hateful_memes/img/90367.png  \n",
            "  inflating: hateful_memes/img/26598.png  \n",
            "  inflating: hateful_memes/img/28451.png  \n",
            "  inflating: hateful_memes/img/25416.png  \n",
            "  inflating: hateful_memes/img/13870.png  \n",
            "  inflating: hateful_memes/img/67912.png  \n",
            "  inflating: hateful_memes/img/78619.png  \n",
            "  inflating: hateful_memes/img/12630.png  \n",
            "  inflating: hateful_memes/img/56401.png  \n",
            "  inflating: hateful_memes/img/14920.png  \n",
            "  inflating: hateful_memes/img/87905.png  \n",
            "  inflating: hateful_memes/img/62509.png  \n",
            "  inflating: hateful_memes/img/39860.png  \n",
            "  inflating: hateful_memes/img/23597.png  \n",
            "  inflating: hateful_memes/img/98604.png  \n",
            "  inflating: hateful_memes/img/72061.png  \n",
            "  inflating: hateful_memes/img/26078.png  \n",
            "  inflating: hateful_memes/img/23968.png  \n",
            "  inflating: hateful_memes/img/40256.png  \n",
            "  inflating: hateful_memes/img/40237.png  \n",
            "  inflating: hateful_memes/img/89536.png  \n",
            "  inflating: hateful_memes/img/64027.png  \n",
            "  inflating: hateful_memes/img/60892.png  \n",
            "  inflating: hateful_memes/img/96734.png  \n",
            "  inflating: hateful_memes/img/83754.png  \n",
            "  inflating: hateful_memes/img/91562.png  \n",
            "  inflating: hateful_memes/img/10746.png  \n",
            "  inflating: hateful_memes/img/83591.png  \n",
            "  inflating: hateful_memes/img/92854.png  \n",
            "  inflating: hateful_memes/img/23168.png  \n",
            "  inflating: hateful_memes/img/84951.png  \n",
            "  inflating: hateful_memes/img/20598.png  \n",
            "  inflating: hateful_memes/img/92876.png  \n",
            "  inflating: hateful_memes/img/08645.png  \n",
            "  inflating: hateful_memes/img/38697.png  \n",
            "  inflating: hateful_memes/img/01834.png  \n",
            "  inflating: hateful_memes/img/24197.png  \n",
            "  inflating: hateful_memes/img/09384.png  \n",
            "  inflating: hateful_memes/img/57169.png  \n",
            "  inflating: hateful_memes/img/58407.png  \n",
            "  inflating: hateful_memes/img/04912.png  \n",
            "  inflating: hateful_memes/img/53419.png  \n",
            "  inflating: hateful_memes/img/23954.png  \n",
            "  inflating: hateful_memes/img/60982.png  \n",
            "  inflating: hateful_memes/img/94721.png  \n",
            "  inflating: hateful_memes/img/48930.png  \n",
            "  inflating: hateful_memes/img/78163.png  \n",
            "  inflating: hateful_memes/img/43258.png  \n",
            "  inflating: hateful_memes/img/90817.png  \n",
            "  inflating: hateful_memes/img/95380.png  \n",
            "  inflating: hateful_memes/img/82537.png  \n",
            "  inflating: hateful_memes/img/36501.png  \n",
            "  inflating: hateful_memes/img/31702.png  \n",
            "  inflating: hateful_memes/img/21450.png  \n",
            "  inflating: hateful_memes/img/04687.png  \n",
            "  inflating: hateful_memes/img/09156.png  \n",
            "  inflating: hateful_memes/img/65204.png  \n",
            "  inflating: hateful_memes/img/15648.png  \n",
            "  inflating: hateful_memes/img/91453.png  \n",
            "  inflating: hateful_memes/img/34762.png  \n",
            "  inflating: hateful_memes/img/65289.png  \n",
            "  inflating: hateful_memes/img/69357.png  \n",
            "  inflating: hateful_memes/img/06418.png  \n",
            "  inflating: hateful_memes/img/42317.png  \n",
            "  inflating: hateful_memes/img/27041.png  \n",
            "  inflating: hateful_memes/img/30642.png  \n",
            "  inflating: hateful_memes/img/42673.png  \n",
            "  inflating: hateful_memes/img/87341.png  \n",
            "  inflating: hateful_memes/img/03128.png  \n",
            "  inflating: hateful_memes/img/81254.png  \n",
            "  inflating: hateful_memes/img/62581.png  \n",
            "  inflating: hateful_memes/img/39560.png  \n",
            "  inflating: hateful_memes/img/62571.png  \n",
            "  inflating: hateful_memes/img/97523.png  \n",
            "  inflating: hateful_memes/img/96058.png  \n",
            "  inflating: hateful_memes/img/89056.png  \n",
            "  inflating: hateful_memes/img/10285.png  \n",
            "  inflating: hateful_memes/img/81257.png  \n",
            "  inflating: hateful_memes/img/91026.png  \n",
            "  inflating: hateful_memes/img/81932.png  \n",
            "  inflating: hateful_memes/img/53167.png  \n",
            "  inflating: hateful_memes/img/89527.png  \n",
            "  inflating: hateful_memes/img/87251.png  \n",
            "  inflating: hateful_memes/img/96451.png  \n",
            "  inflating: hateful_memes/img/90183.png  \n",
            "  inflating: hateful_memes/img/72491.png  \n",
            "  inflating: hateful_memes/img/89723.png  \n",
            "  inflating: hateful_memes/img/21604.png  \n",
            "  inflating: hateful_memes/img/09617.png  \n",
            "  inflating: hateful_memes/img/60985.png  \n",
            "  inflating: hateful_memes/img/31694.png  \n",
            "  inflating: hateful_memes/img/54376.png  \n",
            "  inflating: hateful_memes/img/61479.png  \n",
            "  inflating: hateful_memes/img/41283.png  \n",
            "  inflating: hateful_memes/img/16509.png  \n",
            "  inflating: hateful_memes/img/34509.png  \n",
            "  inflating: hateful_memes/img/05387.png  \n",
            "  inflating: hateful_memes/img/54196.png  \n",
            "  inflating: hateful_memes/img/24857.png  \n",
            "  inflating: hateful_memes/img/81692.png  \n",
            "  inflating: hateful_memes/img/12935.png  \n",
            "  inflating: hateful_memes/img/76815.png  \n",
            "  inflating: hateful_memes/img/54701.png  \n",
            "  inflating: hateful_memes/img/63957.png  \n",
            "  inflating: hateful_memes/img/37451.png  \n",
            "  inflating: hateful_memes/img/76083.png  \n",
            "  inflating: hateful_memes/img/53291.png  \n",
            "  inflating: hateful_memes/img/28146.png  \n",
            "  inflating: hateful_memes/img/12495.png  \n",
            "  inflating: hateful_memes/img/70519.png  \n",
            "  inflating: hateful_memes/img/43609.png  \n",
            "  inflating: hateful_memes/img/71395.png  \n",
            "  inflating: hateful_memes/img/52918.png  \n",
            "  inflating: hateful_memes/img/80612.png  \n",
            "  inflating: hateful_memes/img/57698.png  \n",
            "  inflating: hateful_memes/img/90723.png  \n",
            "  inflating: hateful_memes/img/04917.png  \n",
            "  inflating: hateful_memes/img/48295.png  \n",
            "  inflating: hateful_memes/img/37802.png  \n",
            "  inflating: hateful_memes/img/60852.png  \n",
            "  inflating: hateful_memes/img/78263.png  \n",
            "  inflating: hateful_memes/img/13986.png  \n",
            "  inflating: hateful_memes/img/67029.png  \n",
            "  inflating: hateful_memes/img/68943.png  \n",
            "  inflating: hateful_memes/img/46380.png  \n",
            "  inflating: hateful_memes/img/12349.png  \n",
            "  inflating: hateful_memes/img/57148.png  \n",
            "  inflating: hateful_memes/img/21509.png  \n",
            "  inflating: hateful_memes/img/40876.png  \n",
            "  inflating: hateful_memes/img/43728.png  \n",
            "  inflating: hateful_memes/img/94578.png  \n",
            "  inflating: hateful_memes/img/23760.png  \n",
            "  inflating: hateful_memes/img/57490.png  \n",
            "  inflating: hateful_memes/img/78610.png  \n",
            "  inflating: hateful_memes/img/81243.png  \n",
            "  inflating: hateful_memes/img/87065.png  \n",
            "  inflating: hateful_memes/img/36945.png  \n",
            "  inflating: hateful_memes/img/90461.png  \n",
            "  inflating: hateful_memes/img/48523.png  \n",
            "  inflating: hateful_memes/img/71380.png  \n",
            "  inflating: hateful_memes/img/09162.png  \n",
            "  inflating: hateful_memes/img/12594.png  \n",
            "  inflating: hateful_memes/img/23074.png  \n",
            "  inflating: hateful_memes/img/76583.png  \n",
            "  inflating: hateful_memes/img/06948.png  \n",
            "  inflating: hateful_memes/img/10793.png  \n",
            "  inflating: hateful_memes/img/42361.png  \n",
            "  inflating: hateful_memes/img/48153.png  \n",
            "  inflating: hateful_memes/img/43259.png  \n",
            "  inflating: hateful_memes/img/62981.png  \n",
            "  inflating: hateful_memes/img/17034.png  \n",
            "  inflating: hateful_memes/img/32960.png  \n",
            "  inflating: hateful_memes/img/48715.png  \n",
            "  inflating: hateful_memes/img/01524.png  \n",
            "  inflating: hateful_memes/img/61458.png  \n",
            "  inflating: hateful_memes/img/50918.png  \n",
            "  inflating: hateful_memes/img/87403.png  \n",
            "  inflating: hateful_memes/img/20578.png  \n",
            "  inflating: hateful_memes/img/53768.png  \n",
            "  inflating: hateful_memes/img/01284.png  \n",
            "  inflating: hateful_memes/img/87426.png  \n",
            "  inflating: hateful_memes/img/07451.png  \n",
            "  inflating: hateful_memes/img/56082.png  \n",
            "  inflating: hateful_memes/img/68042.png  \n",
            "  inflating: hateful_memes/img/01936.png  \n",
            "  inflating: hateful_memes/img/09461.png  \n",
            "  inflating: hateful_memes/img/75014.png  \n",
            "  inflating: hateful_memes/img/46123.png  \n",
            "  inflating: hateful_memes/img/07426.png  \n",
            "  inflating: hateful_memes/img/17829.png  \n",
            "  inflating: hateful_memes/img/06897.png  \n",
            "  inflating: hateful_memes/img/92710.png  \n",
            "  inflating: hateful_memes/img/12769.png  \n",
            "  inflating: hateful_memes/img/08495.png  \n",
            "  inflating: hateful_memes/img/26394.png  \n",
            "  inflating: hateful_memes/img/68327.png  \n",
            "  inflating: hateful_memes/img/25017.png  \n",
            "  inflating: hateful_memes/img/61823.png  \n",
            "  inflating: hateful_memes/img/31684.png  \n",
            "  inflating: hateful_memes/img/86237.png  \n",
            "  inflating: hateful_memes/img/65714.png  \n",
            "  inflating: hateful_memes/img/29761.png  \n",
            "  inflating: hateful_memes/img/70269.png  \n",
            "  inflating: hateful_memes/img/43816.png  \n",
            "  inflating: hateful_memes/img/20871.png  \n",
            "  inflating: hateful_memes/img/41087.png  \n",
            "  inflating: hateful_memes/img/92417.png  \n",
            "  inflating: hateful_memes/img/07465.png  \n",
            "  inflating: hateful_memes/img/61580.png  \n",
            "  inflating: hateful_memes/img/82693.png  \n",
            "  inflating: hateful_memes/img/81950.png  \n",
            "  inflating: hateful_memes/img/28534.png  \n",
            "  inflating: hateful_memes/img/90614.png  \n",
            "  inflating: hateful_memes/img/18420.png  \n",
            "  inflating: hateful_memes/img/53904.png  \n",
            "  inflating: hateful_memes/img/31629.png  \n",
            "  inflating: hateful_memes/img/07935.png  \n",
            "  inflating: hateful_memes/img/45128.png  \n",
            "  inflating: hateful_memes/img/67084.png  \n",
            "  inflating: hateful_memes/img/35896.png  \n",
            "  inflating: hateful_memes/img/65240.png  \n",
            "  inflating: hateful_memes/img/21978.png  \n",
            "  inflating: hateful_memes/img/49703.png  \n",
            "  inflating: hateful_memes/img/76098.png  \n",
            "  inflating: hateful_memes/img/87209.png  \n",
            "  inflating: hateful_memes/img/85173.png  \n",
            "  inflating: hateful_memes/img/06195.png  \n",
            "  inflating: hateful_memes/img/48320.png  \n",
            "  inflating: hateful_memes/img/82457.png  \n",
            "  inflating: hateful_memes/img/69084.png  \n",
            "  inflating: hateful_memes/img/37569.png  \n",
            "  inflating: hateful_memes/img/28039.png  \n",
            "  inflating: hateful_memes/img/34056.png  \n",
            "  inflating: hateful_memes/img/15847.png  \n",
            "  inflating: hateful_memes/img/52948.png  \n",
            "  inflating: hateful_memes/img/20879.png  \n",
            "  inflating: hateful_memes/img/76431.png  \n",
            "  inflating: hateful_memes/img/93650.png  \n",
            "  inflating: hateful_memes/img/54629.png  \n",
            "  inflating: hateful_memes/img/05792.png  \n",
            "  inflating: hateful_memes/img/42895.png  \n",
            "  inflating: hateful_memes/img/19257.png  \n",
            "  inflating: hateful_memes/img/12356.png  \n",
            "  inflating: hateful_memes/img/20846.png  \n",
            "  inflating: hateful_memes/img/67130.png  \n",
            "  inflating: hateful_memes/img/05398.png  \n",
            "  inflating: hateful_memes/img/47051.png  \n",
            "  inflating: hateful_memes/img/93642.png  \n",
            "  inflating: hateful_memes/img/98530.png  \n",
            "  inflating: hateful_memes/img/10527.png  \n",
            "  inflating: hateful_memes/img/10839.png  \n",
            "  inflating: hateful_memes/img/95386.png  \n",
            "  inflating: hateful_memes/img/14953.png  \n",
            "  inflating: hateful_memes/img/23859.png  \n",
            "  inflating: hateful_memes/img/95038.png  \n",
            "  inflating: hateful_memes/img/39284.png  \n",
            "  inflating: hateful_memes/img/01235.png  \n",
            "  inflating: hateful_memes/img/19427.png  \n",
            "  inflating: hateful_memes/img/95863.png  \n",
            "  inflating: hateful_memes/img/37821.png  \n",
            "  inflating: hateful_memes/img/57302.png  \n",
            "  inflating: hateful_memes/img/61723.png  \n",
            "  inflating: hateful_memes/img/35174.png  \n",
            "  inflating: hateful_memes/img/65201.png  \n",
            "  inflating: hateful_memes/img/89642.png  \n",
            "  inflating: hateful_memes/img/42167.png  \n",
            "  inflating: hateful_memes/img/83976.png  \n",
            "  inflating: hateful_memes/img/76243.png  \n",
            "  inflating: hateful_memes/img/43658.png  \n",
            "  inflating: hateful_memes/img/76819.png  \n",
            "  inflating: hateful_memes/img/57389.png  \n",
            "  inflating: hateful_memes/img/43069.png  \n",
            "  inflating: hateful_memes/img/87513.png  \n",
            "  inflating: hateful_memes/img/67108.png  \n",
            "  inflating: hateful_memes/img/59178.png  \n",
            "  inflating: hateful_memes/img/43087.png  \n",
            "  inflating: hateful_memes/img/71263.png  \n",
            "  inflating: hateful_memes/img/97184.png  \n",
            "  inflating: hateful_memes/img/50498.png  \n",
            "  inflating: hateful_memes/img/24365.png  \n",
            "  inflating: hateful_memes/img/70432.png  \n",
            "  inflating: hateful_memes/img/19752.png  \n",
            "  inflating: hateful_memes/img/94823.png  \n",
            "  inflating: hateful_memes/img/19302.png  \n",
            "  inflating: hateful_memes/img/39470.png  \n",
            "  inflating: hateful_memes/img/52964.png  \n",
            "  inflating: hateful_memes/img/60371.png  \n",
            "  inflating: hateful_memes/img/72608.png  \n",
            "  inflating: hateful_memes/img/21763.png  \n",
            "  inflating: hateful_memes/img/18325.png  \n",
            "  inflating: hateful_memes/img/56981.png  \n",
            "  inflating: hateful_memes/img/76213.png  \n",
            "  inflating: hateful_memes/img/72645.png  \n",
            "  inflating: hateful_memes/img/94180.png  \n",
            "  inflating: hateful_memes/img/84013.png  \n",
            "  inflating: hateful_memes/img/52938.png  \n",
            "  inflating: hateful_memes/img/47208.png  \n",
            "  inflating: hateful_memes/img/93618.png  \n",
            "  inflating: hateful_memes/img/36028.png  \n",
            "  inflating: hateful_memes/img/67025.png  \n",
            "  inflating: hateful_memes/img/91274.png  \n",
            "  inflating: hateful_memes/img/29416.png  \n",
            "  inflating: hateful_memes/img/10579.png  \n",
            "  inflating: hateful_memes/img/12876.png  \n",
            "  inflating: hateful_memes/img/27591.png  \n",
            "  inflating: hateful_memes/img/30267.png  \n",
            "  inflating: hateful_memes/img/69237.png  \n",
            "  inflating: hateful_memes/img/97146.png  \n",
            "  inflating: hateful_memes/img/02631.png  \n",
            "  inflating: hateful_memes/img/04675.png  \n",
            "  inflating: hateful_memes/img/09486.png  \n",
            "  inflating: hateful_memes/img/19540.png  \n",
            "  inflating: hateful_memes/img/74203.png  \n",
            "  inflating: hateful_memes/img/86021.png  \n",
            "  inflating: hateful_memes/img/50461.png  \n",
            "  inflating: hateful_memes/img/16702.png  \n",
            "  inflating: hateful_memes/img/16573.png  \n",
            "  inflating: hateful_memes/img/35264.png  \n",
            "  inflating: hateful_memes/img/18075.png  \n",
            "  inflating: hateful_memes/img/51890.png  \n",
            "  inflating: hateful_memes/img/16759.png  \n",
            "  inflating: hateful_memes/img/82946.png  \n",
            "  inflating: hateful_memes/img/06892.png  \n",
            "  inflating: hateful_memes/img/25180.png  \n",
            "  inflating: hateful_memes/img/95831.png  \n",
            "  inflating: hateful_memes/img/37824.png  \n",
            "  inflating: hateful_memes/img/17643.png  \n",
            "  inflating: hateful_memes/img/59163.png  \n",
            "  inflating: hateful_memes/img/07539.png  \n",
            "  inflating: hateful_memes/img/21504.png  \n",
            "  inflating: hateful_memes/img/34765.png  \n",
            "  inflating: hateful_memes/img/64029.png  \n",
            "  inflating: hateful_memes/img/79105.png  \n",
            "  inflating: hateful_memes/img/57128.png  \n",
            "  inflating: hateful_memes/img/76023.png  \n",
            "  inflating: hateful_memes/img/37924.png  \n",
            "  inflating: hateful_memes/img/12094.png  \n",
            "  inflating: hateful_memes/img/46218.png  \n",
            "  inflating: hateful_memes/img/90365.png  \n",
            "  inflating: hateful_memes/img/48976.png  \n",
            "  inflating: hateful_memes/img/48509.png  \n",
            "  inflating: hateful_memes/img/24658.png  \n",
            "  inflating: hateful_memes/img/23018.png  \n",
            "  inflating: hateful_memes/img/97348.png  \n",
            "  inflating: hateful_memes/img/10627.png  \n",
            "  inflating: hateful_memes/img/36178.png  \n",
            "  inflating: hateful_memes/img/37502.png  \n",
            "  inflating: hateful_memes/img/84097.png  \n",
            "  inflating: hateful_memes/img/79405.png  \n",
            "  inflating: hateful_memes/img/39170.png  \n",
            "  inflating: hateful_memes/img/68254.png  \n",
            "  inflating: hateful_memes/img/43950.png  \n",
            "  inflating: hateful_memes/img/85410.png  \n",
            "  inflating: hateful_memes/img/90236.png  \n",
            "  inflating: hateful_memes/img/56247.png  \n",
            "  inflating: hateful_memes/img/87054.png  \n",
            "  inflating: hateful_memes/img/07286.png  \n",
            "  inflating: hateful_memes/img/68231.png  \n",
            "  inflating: hateful_memes/img/25384.png  \n",
            "  inflating: hateful_memes/img/09643.png  \n",
            "  inflating: hateful_memes/img/63280.png  \n",
            "  inflating: hateful_memes/img/78936.png  \n",
            "  inflating: hateful_memes/img/67051.png  \n",
            "  inflating: hateful_memes/img/45968.png  \n",
            "  inflating: hateful_memes/img/28604.png  \n",
            "  inflating: hateful_memes/img/87925.png  \n",
            "  inflating: hateful_memes/img/51628.png  \n",
            "  inflating: hateful_memes/img/07254.png  \n",
            "  inflating: hateful_memes/img/01548.png  \n",
            "  inflating: hateful_memes/img/05762.png  \n",
            "  inflating: hateful_memes/img/54317.png  \n",
            "  inflating: hateful_memes/img/62580.png  \n",
            "  inflating: hateful_memes/img/62378.png  \n",
            "  inflating: hateful_memes/img/27318.png  \n",
            "  inflating: hateful_memes/img/83560.png  \n",
            "  inflating: hateful_memes/img/15069.png  \n",
            "  inflating: hateful_memes/img/68017.png  \n",
            "  inflating: hateful_memes/img/12784.png  \n",
            "  inflating: hateful_memes/img/28954.png  \n",
            "  inflating: hateful_memes/img/61847.png  \n",
            "  inflating: hateful_memes/img/08517.png  \n",
            "  inflating: hateful_memes/img/24316.png  \n",
            "  inflating: hateful_memes/img/72409.png  \n",
            "  inflating: hateful_memes/img/68917.png  \n",
            "  inflating: hateful_memes/img/57823.png  \n",
            "  inflating: hateful_memes/img/63572.png  \n",
            "  inflating: hateful_memes/img/03291.png  \n",
            "  inflating: hateful_memes/img/51482.png  \n",
            "  inflating: hateful_memes/img/74059.png  \n",
            "  inflating: hateful_memes/img/91708.png  \n",
            "  inflating: hateful_memes/img/85790.png  \n",
            "  inflating: hateful_memes/img/43527.png  \n",
            "  inflating: hateful_memes/img/58609.png  \n",
            "  inflating: hateful_memes/img/56843.png  \n",
            "  inflating: hateful_memes/img/23059.png  \n",
            "  inflating: hateful_memes/img/35678.png  \n",
            "  inflating: hateful_memes/img/64513.png  \n",
            "  inflating: hateful_memes/img/16075.png  \n",
            "  inflating: hateful_memes/img/26198.png  \n",
            "  inflating: hateful_memes/img/93125.png  \n",
            "  inflating: hateful_memes/img/53289.png  \n",
            "  inflating: hateful_memes/img/56280.png  \n",
            "  inflating: hateful_memes/img/87654.png  \n",
            "  inflating: hateful_memes/img/42173.png  \n",
            "  inflating: hateful_memes/img/63582.png  \n",
            "  inflating: hateful_memes/img/57401.png  \n",
            "  inflating: hateful_memes/img/34687.png  \n",
            "  inflating: hateful_memes/img/84502.png  \n",
            "  inflating: hateful_memes/img/03642.png  \n",
            "  inflating: hateful_memes/img/69123.png  \n",
            "  inflating: hateful_memes/img/75840.png  \n",
            "  inflating: hateful_memes/img/80942.png  \n",
            "  inflating: hateful_memes/img/08654.png  \n",
            "  inflating: hateful_memes/img/43615.png  \n",
            "  inflating: hateful_memes/img/27430.png  \n",
            "  inflating: hateful_memes/img/30145.png  \n",
            "  inflating: hateful_memes/img/30621.png  \n",
            "  inflating: hateful_memes/img/52936.png  \n",
            "  inflating: hateful_memes/img/17532.png  \n",
            "  inflating: hateful_memes/img/34901.png  \n",
            "  inflating: hateful_memes/img/18504.png  \n",
            "  inflating: hateful_memes/img/20915.png  \n",
            "  inflating: hateful_memes/img/62147.png  \n",
            "  inflating: hateful_memes/img/51379.png  \n",
            "  inflating: hateful_memes/img/58364.png  \n",
            "  inflating: hateful_memes/img/78956.png  \n",
            "  inflating: hateful_memes/img/67419.png  \n",
            "  inflating: hateful_memes/img/32904.png  \n",
            "  inflating: hateful_memes/img/05349.png  \n",
            "  inflating: hateful_memes/img/13289.png  \n",
            "  inflating: hateful_memes/img/68193.png  \n",
            "  inflating: hateful_memes/img/98256.png  \n",
            "  inflating: hateful_memes/img/29507.png  \n",
            "  inflating: hateful_memes/img/70142.png  \n",
            "  inflating: hateful_memes/img/68137.png  \n",
            "  inflating: hateful_memes/img/72054.png  \n",
            "  inflating: hateful_memes/img/19834.png  \n",
            "  inflating: hateful_memes/img/42091.png  \n",
            "  inflating: hateful_memes/img/37260.png  \n",
            "  inflating: hateful_memes/img/96581.png  \n",
            "  inflating: hateful_memes/img/38271.png  \n",
            "  inflating: hateful_memes/img/04791.png  \n",
            "  inflating: hateful_memes/img/34520.png  \n",
            "  inflating: hateful_memes/img/12678.png  \n",
            "  inflating: hateful_memes/img/20943.png  \n",
            "  inflating: hateful_memes/img/07284.png  \n",
            "  inflating: hateful_memes/img/34972.png  \n",
            "  inflating: hateful_memes/img/10524.png  \n",
            "  inflating: hateful_memes/img/78962.png  \n",
            "  inflating: hateful_memes/img/28517.png  \n",
            "  inflating: hateful_memes/img/58239.png  \n",
            "  inflating: hateful_memes/img/35910.png  \n",
            "  inflating: hateful_memes/img/38095.png  \n",
            "  inflating: hateful_memes/img/57621.png  \n",
            "  inflating: hateful_memes/img/68201.png  \n",
            "  inflating: hateful_memes/img/26043.png  \n",
            "  inflating: hateful_memes/img/47618.png  \n",
            "  inflating: hateful_memes/img/52847.png  \n",
            "  inflating: hateful_memes/img/16259.png  \n",
            "  inflating: hateful_memes/img/73049.png  \n",
            "  inflating: hateful_memes/img/94380.png  \n",
            "  inflating: hateful_memes/img/50968.png  \n",
            "  inflating: hateful_memes/img/79865.png  \n",
            "  inflating: hateful_memes/img/21740.png  \n",
            "  inflating: hateful_memes/img/14892.png  \n",
            "  inflating: hateful_memes/img/14573.png  \n",
            "  inflating: hateful_memes/img/16072.png  \n",
            "  inflating: hateful_memes/img/28574.png  \n",
            "  inflating: hateful_memes/img/38712.png  \n",
            "  inflating: hateful_memes/img/64219.png  \n",
            "  inflating: hateful_memes/img/62498.png  \n",
            "  inflating: hateful_memes/img/31082.png  \n",
            "  inflating: hateful_memes/img/38460.png  \n",
            "  inflating: hateful_memes/img/04126.png  \n",
            "  inflating: hateful_memes/img/47056.png  \n",
            "  inflating: hateful_memes/img/94675.png  \n",
            "  inflating: hateful_memes/img/75290.png  \n",
            "  inflating: hateful_memes/img/57631.png  \n",
            "  inflating: hateful_memes/img/58672.png  \n",
            "  inflating: hateful_memes/img/43185.png  \n",
            "  inflating: hateful_memes/img/06589.png  \n",
            "  inflating: hateful_memes/img/17508.png  \n",
            "  inflating: hateful_memes/img/15738.png  \n",
            "  inflating: hateful_memes/img/79315.png  \n",
            "  inflating: hateful_memes/img/93725.png  \n",
            "  inflating: hateful_memes/img/85192.png  \n",
            "  inflating: hateful_memes/img/25079.png  \n",
            "  inflating: hateful_memes/img/28437.png  \n",
            "  inflating: hateful_memes/img/14275.png  \n",
            "  inflating: hateful_memes/img/36175.png  \n",
            "  inflating: hateful_memes/img/60724.png  \n",
            "  inflating: hateful_memes/img/38401.png  \n",
            "  inflating: hateful_memes/img/65917.png  \n",
            "  inflating: hateful_memes/img/83615.png  \n",
            "  inflating: hateful_memes/img/45269.png  \n",
            "  inflating: hateful_memes/img/84719.png  \n",
            "  inflating: hateful_memes/img/05148.png  \n",
            "  inflating: hateful_memes/img/38902.png  \n",
            "  inflating: hateful_memes/img/59072.png  \n",
            "  inflating: hateful_memes/img/16540.png  \n",
            "  inflating: hateful_memes/img/20314.png  \n",
            "  inflating: hateful_memes/img/17305.png  \n",
            "  inflating: hateful_memes/img/30851.png  \n",
            "  inflating: hateful_memes/img/51237.png  \n",
            "  inflating: hateful_memes/img/41925.png  \n",
            "  inflating: hateful_memes/img/92867.png  \n",
            "  inflating: hateful_memes/img/18597.png  \n",
            "  inflating: hateful_memes/img/17962.png  \n",
            "  inflating: hateful_memes/img/72345.png  \n",
            "  inflating: hateful_memes/img/30519.png  \n",
            "  inflating: hateful_memes/img/56071.png  \n",
            "  inflating: hateful_memes/img/95402.png  \n",
            "  inflating: hateful_memes/img/96240.png  \n",
            "  inflating: hateful_memes/img/15306.png  \n",
            "  inflating: hateful_memes/img/01269.png  \n",
            "  inflating: hateful_memes/img/62804.png  \n",
            "  inflating: hateful_memes/img/34275.png  \n",
            "  inflating: hateful_memes/img/27169.png  \n",
            "  inflating: hateful_memes/img/40791.png  \n",
            "  inflating: hateful_memes/img/19630.png  \n",
            "  inflating: hateful_memes/img/72514.png  \n",
            "  inflating: hateful_memes/img/13798.png  \n",
            "  inflating: hateful_memes/img/51973.png  \n",
            "  inflating: hateful_memes/img/23516.png  \n",
            "  inflating: hateful_memes/img/59784.png  \n",
            "  inflating: hateful_memes/img/51708.png  \n",
            "  inflating: hateful_memes/img/69728.png  \n",
            "  inflating: hateful_memes/img/62904.png  \n",
            "  inflating: hateful_memes/img/90582.png  \n",
            "  inflating: hateful_memes/img/36185.png  \n",
            "  inflating: hateful_memes/img/49021.png  \n",
            "  inflating: hateful_memes/img/89647.png  \n",
            "  inflating: hateful_memes/img/73851.png  \n",
            "  inflating: hateful_memes/img/61495.png  \n",
            "  inflating: hateful_memes/img/48327.png  \n",
            "  inflating: hateful_memes/img/59871.png  \n",
            "  inflating: hateful_memes/img/82459.png  \n",
            "  inflating: hateful_memes/img/21468.png  \n",
            "  inflating: hateful_memes/img/95072.png  \n",
            "  inflating: hateful_memes/img/31925.png  \n",
            "  inflating: hateful_memes/img/46150.png  \n",
            "  inflating: hateful_memes/img/42039.png  \n",
            "  inflating: hateful_memes/img/81305.png  \n",
            "  inflating: hateful_memes/img/95806.png  \n",
            "  inflating: hateful_memes/img/51023.png  \n",
            "  inflating: hateful_memes/img/13695.png  \n",
            "  inflating: hateful_memes/img/62178.png  \n",
            "  inflating: hateful_memes/img/98654.png  \n",
            "  inflating: hateful_memes/img/93142.png  \n",
            "  inflating: hateful_memes/img/48932.png  \n",
            "  inflating: hateful_memes/img/01245.png  \n",
            "  inflating: hateful_memes/img/37620.png  \n",
            "  inflating: hateful_memes/img/02164.png  \n",
            "  inflating: hateful_memes/img/17852.png  \n",
            "  inflating: hateful_memes/img/20815.png  \n",
            "  inflating: hateful_memes/img/02975.png  \n",
            "  inflating: hateful_memes/img/87206.png  \n",
            "  inflating: hateful_memes/img/04138.png  \n",
            "  inflating: hateful_memes/img/36850.png  \n",
            "  inflating: hateful_memes/img/10268.png  \n",
            "  inflating: hateful_memes/img/80974.png  \n",
            "  inflating: hateful_memes/img/90538.png  \n",
            "  inflating: hateful_memes/img/21836.png  \n",
            "  inflating: hateful_memes/img/39217.png  \n",
            "  inflating: hateful_memes/img/26739.png  \n",
            "  inflating: hateful_memes/img/37084.png  \n",
            "  inflating: hateful_memes/img/21658.png  \n",
            "  inflating: hateful_memes/img/70594.png  \n",
            "  inflating: hateful_memes/img/14026.png  \n",
            "  inflating: hateful_memes/img/56123.png  \n",
            "  inflating: hateful_memes/img/46013.png  \n",
            "  inflating: hateful_memes/img/07516.png  \n",
            "  inflating: hateful_memes/img/26410.png  \n",
            "  inflating: hateful_memes/img/17320.png  \n",
            "  inflating: hateful_memes/img/36089.png  \n",
            "  inflating: hateful_memes/img/41962.png  \n",
            "  inflating: hateful_memes/img/41967.png  \n",
            "  inflating: hateful_memes/img/78325.png  \n",
            "  inflating: hateful_memes/img/78420.png  \n",
            "  inflating: hateful_memes/img/24368.png  \n",
            "  inflating: hateful_memes/img/32069.png  \n",
            "  inflating: hateful_memes/img/84360.png  \n",
            "  inflating: hateful_memes/img/62143.png  \n",
            "  inflating: hateful_memes/img/47103.png  \n",
            "  inflating: hateful_memes/img/75894.png  \n",
            "  inflating: hateful_memes/img/14590.png  \n",
            "  inflating: hateful_memes/img/37146.png  \n",
            "  inflating: hateful_memes/img/05249.png  \n",
            "  inflating: hateful_memes/img/18379.png  \n",
            "  inflating: hateful_memes/img/43617.png  \n",
            "  inflating: hateful_memes/img/70561.png  \n",
            "  inflating: hateful_memes/img/32806.png  \n",
            "  inflating: hateful_memes/img/54062.png  \n",
            "  inflating: hateful_memes/img/73198.png  \n",
            "  inflating: hateful_memes/img/12936.png  \n",
            "  inflating: hateful_memes/img/09561.png  \n",
            "  inflating: hateful_memes/img/07258.png  \n",
            "  inflating: hateful_memes/img/85916.png  \n",
            "  inflating: hateful_memes/img/15278.png  \n",
            "  inflating: hateful_memes/img/89140.png  \n",
            "  inflating: hateful_memes/img/26159.png  \n",
            "  inflating: hateful_memes/img/29475.png  \n",
            "  inflating: hateful_memes/img/97142.png  \n",
            "  inflating: hateful_memes/img/61748.png  \n",
            "  inflating: hateful_memes/img/31287.png  \n",
            "  inflating: hateful_memes/img/47935.png  \n",
            "  inflating: hateful_memes/img/96510.png  \n",
            "  inflating: hateful_memes/img/91680.png  \n",
            "  inflating: hateful_memes/img/01492.png  \n",
            "  inflating: hateful_memes/img/42659.png  \n",
            "  inflating: hateful_memes/img/04281.png  \n",
            "  inflating: hateful_memes/img/75962.png  \n",
            "  inflating: hateful_memes/img/10675.png  \n",
            "  inflating: hateful_memes/img/10572.png  \n",
            "  inflating: hateful_memes/img/73489.png  \n",
            "  inflating: hateful_memes/img/52978.png  \n",
            "  inflating: hateful_memes/img/74358.png  \n",
            "  inflating: hateful_memes/img/84910.png  \n",
            "  inflating: hateful_memes/img/31764.png  \n",
            "  inflating: hateful_memes/img/49327.png  \n",
            "  inflating: hateful_memes/img/54108.png  \n",
            "  inflating: hateful_memes/img/95830.png  \n",
            "  inflating: hateful_memes/img/97320.png  \n",
            "  inflating: hateful_memes/img/86013.png  \n",
            "  inflating: hateful_memes/img/81603.png  \n",
            "  inflating: hateful_memes/img/14726.png  \n",
            "  inflating: hateful_memes/img/64853.png  \n",
            "  inflating: hateful_memes/img/46301.png  \n",
            "  inflating: hateful_memes/img/71543.png  \n",
            "  inflating: hateful_memes/img/50184.png  \n",
            "  inflating: hateful_memes/img/70826.png  \n",
            "  inflating: hateful_memes/img/24836.png  \n",
            "  inflating: hateful_memes/img/49180.png  \n",
            "  inflating: hateful_memes/img/92341.png  \n",
            "  inflating: hateful_memes/img/39214.png  \n",
            "  inflating: hateful_memes/img/32965.png  \n",
            "  inflating: hateful_memes/img/98341.png  \n",
            "  inflating: hateful_memes/img/37458.png  \n",
            "  inflating: hateful_memes/img/32957.png  \n",
            "  inflating: hateful_memes/img/46198.png  \n",
            "  inflating: hateful_memes/img/65148.png  \n",
            "  inflating: hateful_memes/img/35429.png  \n",
            "  inflating: hateful_memes/img/86912.png  \n",
            "  inflating: hateful_memes/img/37945.png  \n",
            "  inflating: hateful_memes/img/87954.png  \n",
            "  inflating: hateful_memes/img/03479.png  \n",
            "  inflating: hateful_memes/img/93426.png  \n",
            "  inflating: hateful_memes/img/72658.png  \n",
            "  inflating: hateful_memes/img/14728.png  \n",
            "  inflating: hateful_memes/img/12968.png  \n",
            "  inflating: hateful_memes/img/49385.png  \n",
            "  inflating: hateful_memes/img/60314.png  \n",
            "  inflating: hateful_memes/img/62913.png  \n",
            "  inflating: hateful_memes/img/37284.png  \n",
            "  inflating: hateful_memes/img/89740.png  \n",
            "  inflating: hateful_memes/img/27609.png  \n",
            "  inflating: hateful_memes/img/81423.png  \n",
            "  inflating: hateful_memes/img/90263.png  \n",
            "  inflating: hateful_memes/img/16409.png  \n",
            "  inflating: hateful_memes/img/51209.png  \n",
            "  inflating: hateful_memes/img/81705.png  \n",
            "  inflating: hateful_memes/img/68934.png  \n",
            "  inflating: hateful_memes/img/64037.png  \n",
            "  inflating: hateful_memes/img/81934.png  \n",
            "  inflating: hateful_memes/img/14856.png  \n",
            "  inflating: hateful_memes/img/94150.png  \n",
            "  inflating: hateful_memes/img/89320.png  \n",
            "  inflating: hateful_memes/img/38159.png  \n",
            "  inflating: hateful_memes/img/97180.png  \n",
            "  inflating: hateful_memes/img/97316.png  \n",
            "  inflating: hateful_memes/img/42387.png  \n",
            "  inflating: hateful_memes/img/53278.png  \n",
            "  inflating: hateful_memes/img/58621.png  \n",
            "  inflating: hateful_memes/img/34217.png  \n",
            "  inflating: hateful_memes/img/84629.png  \n",
            "  inflating: hateful_memes/img/75028.png  \n",
            "  inflating: hateful_memes/img/76208.png  \n",
            "  inflating: hateful_memes/img/48965.png  \n",
            "  inflating: hateful_memes/img/90845.png  \n",
            "  inflating: hateful_memes/img/15846.png  \n",
            "  inflating: hateful_memes/img/07268.png  \n",
            "  inflating: hateful_memes/img/71420.png  \n",
            "  inflating: hateful_memes/img/96804.png  \n",
            "  inflating: hateful_memes/img/79825.png  \n",
            "  inflating: hateful_memes/img/40529.png  \n",
            "  inflating: hateful_memes/img/68034.png  \n",
            "  inflating: hateful_memes/img/40561.png  \n",
            "  inflating: hateful_memes/img/68321.png  \n",
            "  inflating: hateful_memes/img/60257.png  \n",
            "  inflating: hateful_memes/img/50816.png  \n",
            "  inflating: hateful_memes/img/65730.png  \n",
            "  inflating: hateful_memes/img/97853.png  \n",
            "  inflating: hateful_memes/img/19238.png  \n",
            "  inflating: hateful_memes/img/79845.png  \n",
            "  inflating: hateful_memes/img/04162.png  \n",
            "  inflating: hateful_memes/img/48031.png  \n",
            "  inflating: hateful_memes/img/25861.png  \n",
            "  inflating: hateful_memes/img/51806.png  \n",
            "  inflating: hateful_memes/img/37056.png  \n",
            "  inflating: hateful_memes/img/24765.png  \n",
            "  inflating: hateful_memes/img/82950.png  \n",
            "  inflating: hateful_memes/img/65130.png  \n",
            "  inflating: hateful_memes/img/46239.png  \n",
            "  inflating: hateful_memes/img/20913.png  \n",
            "  inflating: hateful_memes/img/54093.png  \n",
            "  inflating: hateful_memes/img/70293.png  \n",
            "  inflating: hateful_memes/img/13460.png  \n",
            "  inflating: hateful_memes/img/19206.png  \n",
            "  inflating: hateful_memes/img/64537.png  \n",
            "  inflating: hateful_memes/img/45293.png  \n",
            "  inflating: hateful_memes/img/96873.png  \n",
            "  inflating: hateful_memes/img/81276.png  \n",
            "  inflating: hateful_memes/img/40752.png  \n",
            "  inflating: hateful_memes/img/59467.png  \n",
            "  inflating: hateful_memes/img/31284.png  \n",
            "  inflating: hateful_memes/img/75496.png  \n",
            "  inflating: hateful_memes/img/58491.png  \n",
            "  inflating: hateful_memes/img/75438.png  \n",
            "  inflating: hateful_memes/img/31205.png  \n",
            "  inflating: hateful_memes/img/91856.png  \n",
            "  inflating: hateful_memes/img/82541.png  \n",
            "  inflating: hateful_memes/img/03276.png  \n",
            "  inflating: hateful_memes/img/23657.png  \n",
            "  inflating: hateful_memes/img/14306.png  \n",
            "  inflating: hateful_memes/img/96023.png  \n",
            "  inflating: hateful_memes/img/01649.png  \n",
            "  inflating: hateful_memes/img/93071.png  \n",
            "  inflating: hateful_memes/img/86491.png  \n",
            "  inflating: hateful_memes/img/57146.png  \n",
            "  inflating: hateful_memes/img/13470.png  \n",
            "  inflating: hateful_memes/img/27614.png  \n",
            "  inflating: hateful_memes/img/14837.png  \n",
            "  inflating: hateful_memes/img/90274.png  \n",
            "  inflating: hateful_memes/img/40361.png  \n",
            "  inflating: hateful_memes/img/41863.png  \n",
            "  inflating: hateful_memes/img/70153.png  \n",
            "  inflating: hateful_memes/img/87094.png  \n",
            "  inflating: hateful_memes/img/40693.png  \n",
            "  inflating: hateful_memes/img/62381.png  \n",
            "  inflating: hateful_memes/img/76923.png  \n",
            "  inflating: hateful_memes/img/94278.png  \n",
            "  inflating: hateful_memes/img/51046.png  \n",
            "  inflating: hateful_memes/img/04538.png  \n",
            "  inflating: hateful_memes/img/89430.png  \n",
            "  inflating: hateful_memes/img/20684.png  \n",
            "  inflating: hateful_memes/img/06893.png  \n",
            "  inflating: hateful_memes/img/41362.png  \n",
            "  inflating: hateful_memes/img/14695.png  \n",
            "  inflating: hateful_memes/img/26459.png  \n",
            "  inflating: hateful_memes/img/27506.png  \n",
            "  inflating: hateful_memes/img/30251.png  \n",
            "  inflating: hateful_memes/img/32706.png  \n",
            "  inflating: hateful_memes/img/70645.png  \n",
            "  inflating: hateful_memes/img/46850.png  \n",
            "  inflating: hateful_memes/img/69403.png  \n",
            "  inflating: hateful_memes/img/98736.png  \n",
            "  inflating: hateful_memes/img/08719.png  \n",
            "  inflating: hateful_memes/img/83514.png  \n",
            "  inflating: hateful_memes/img/57831.png  \n",
            "  inflating: hateful_memes/img/46283.png  \n",
            "  inflating: hateful_memes/img/67298.png  \n",
            "  inflating: hateful_memes/img/07918.png  \n",
            "  inflating: hateful_memes/img/13428.png  \n",
            "  inflating: hateful_memes/img/92831.png  \n",
            "  inflating: hateful_memes/img/50142.png  \n",
            "  inflating: hateful_memes/img/97514.png  \n",
            "  inflating: hateful_memes/img/30456.png  \n",
            "  inflating: hateful_memes/img/42638.png  \n",
            "  inflating: hateful_memes/img/13690.png  \n",
            "  inflating: hateful_memes/img/10725.png  \n",
            "  inflating: hateful_memes/img/38071.png  \n",
            "  inflating: hateful_memes/img/76984.png  \n",
            "  inflating: hateful_memes/img/97245.png  \n",
            "  inflating: hateful_memes/img/81624.png  \n",
            "  inflating: hateful_memes/img/64320.png  \n",
            "  inflating: hateful_memes/img/65301.png  \n",
            "  inflating: hateful_memes/img/30571.png  \n",
            "  inflating: hateful_memes/img/07398.png  \n",
            "  inflating: hateful_memes/img/96408.png  \n",
            "  inflating: hateful_memes/img/60895.png  \n",
            "  inflating: hateful_memes/img/21637.png  \n",
            "  inflating: hateful_memes/img/79568.png  \n",
            "  inflating: hateful_memes/img/43976.png  \n",
            "  inflating: hateful_memes/img/29364.png  \n",
            "  inflating: hateful_memes/img/12036.png  \n",
            "  inflating: hateful_memes/img/86075.png  \n",
            "  inflating: hateful_memes/img/54082.png  \n",
            "  inflating: hateful_memes/img/90321.png  \n",
            "  inflating: hateful_memes/img/96502.png  \n",
            "  inflating: hateful_memes/img/80425.png  \n",
            "  inflating: hateful_memes/img/82310.png  \n",
            "  inflating: hateful_memes/img/58971.png  \n",
            "  inflating: hateful_memes/img/69870.png  \n",
            "  inflating: hateful_memes/img/71432.png  \n",
            "  inflating: hateful_memes/img/05279.png  \n",
            "  inflating: hateful_memes/img/96810.png  \n",
            "  inflating: hateful_memes/img/64281.png  \n",
            "  inflating: hateful_memes/img/14657.png  \n",
            "  inflating: hateful_memes/img/07213.png  \n",
            "  inflating: hateful_memes/img/37294.png  \n",
            "  inflating: hateful_memes/img/02845.png  \n",
            "  inflating: hateful_memes/img/51836.png  \n",
            "  inflating: hateful_memes/img/92835.png  \n",
            "  inflating: hateful_memes/img/93750.png  \n",
            "  inflating: hateful_memes/img/03196.png  \n",
            "  inflating: hateful_memes/img/51863.png  \n",
            "  inflating: hateful_memes/img/54389.png  \n",
            "  inflating: hateful_memes/img/51608.png  \n",
            "  inflating: hateful_memes/img/29708.png  \n",
            "  inflating: hateful_memes/img/30618.png  \n",
            "  inflating: hateful_memes/img/71863.png  \n",
            "  inflating: hateful_memes/img/96381.png  \n",
            "  inflating: hateful_memes/img/30249.png  \n",
            "  inflating: hateful_memes/img/30762.png  \n",
            "  inflating: hateful_memes/img/85417.png  \n",
            "  inflating: hateful_memes/img/93051.png  \n",
            "  inflating: hateful_memes/img/37918.png  \n",
            "  inflating: hateful_memes/img/48039.png  \n",
            "  inflating: hateful_memes/img/10659.png  \n",
            "  inflating: hateful_memes/img/69758.png  \n",
            "  inflating: hateful_memes/img/04658.png  \n",
            "  inflating: hateful_memes/img/81752.png  \n",
            "  inflating: hateful_memes/img/21403.png  \n",
            "  inflating: hateful_memes/img/62718.png  \n",
            "  inflating: hateful_memes/img/05741.png  \n",
            "  inflating: hateful_memes/img/78169.png  \n",
            "  inflating: hateful_memes/img/74019.png  \n",
            "  inflating: hateful_memes/img/21345.png  \n",
            "  inflating: hateful_memes/img/60714.png  \n",
            "  inflating: hateful_memes/img/31549.png  \n",
            "  inflating: hateful_memes/img/89473.png  \n",
            "  inflating: hateful_memes/img/63042.png  \n",
            "  inflating: hateful_memes/img/54319.png  \n",
            "  inflating: hateful_memes/img/01324.png  \n",
            "  inflating: hateful_memes/img/90165.png  \n",
            "  inflating: hateful_memes/img/41986.png  \n",
            "  inflating: hateful_memes/img/43680.png  \n",
            "  inflating: hateful_memes/img/52710.png  \n",
            "  inflating: hateful_memes/img/28751.png  \n",
            "  inflating: hateful_memes/img/50361.png  \n",
            "  inflating: hateful_memes/img/15072.png  \n",
            "  inflating: hateful_memes/img/23905.png  \n",
            "  inflating: hateful_memes/img/39028.png  \n",
            "  inflating: hateful_memes/img/47196.png  \n",
            "  inflating: hateful_memes/img/12956.png  \n",
            "  inflating: hateful_memes/img/07219.png  \n",
            "  inflating: hateful_memes/img/62394.png  \n",
            "  inflating: hateful_memes/img/50739.png  \n",
            "  inflating: hateful_memes/img/75048.png  \n",
            "  inflating: hateful_memes/img/34186.png  \n",
            "  inflating: hateful_memes/img/02718.png  \n",
            "  inflating: hateful_memes/img/86372.png  \n",
            "  inflating: hateful_memes/img/34570.png  \n",
            "  inflating: hateful_memes/img/09468.png  \n",
            "  inflating: hateful_memes/img/14569.png  \n",
            "  inflating: hateful_memes/img/83709.png  \n",
            "  inflating: hateful_memes/img/75601.png  \n",
            "  inflating: hateful_memes/img/40896.png  \n",
            "  inflating: hateful_memes/img/36214.png  \n",
            "  inflating: hateful_memes/img/74031.png  \n",
            "  inflating: hateful_memes/img/43128.png  \n",
            "  inflating: hateful_memes/img/49865.png  \n",
            "  inflating: hateful_memes/img/54201.png  \n",
            "  inflating: hateful_memes/img/36870.png  \n",
            "  inflating: hateful_memes/img/87140.png  \n",
            "  inflating: hateful_memes/img/40829.png  \n",
            "  inflating: hateful_memes/img/58361.png  \n",
            "  inflating: hateful_memes/img/25310.png  \n",
            "  inflating: hateful_memes/img/72364.png  \n",
            "  inflating: hateful_memes/img/20671.png  \n",
            "  inflating: hateful_memes/img/84673.png  \n",
            "  inflating: hateful_memes/img/54927.png  \n",
            "  inflating: hateful_memes/img/64590.png  \n",
            "  inflating: hateful_memes/img/72810.png  \n",
            "  inflating: hateful_memes/img/14096.png  \n",
            "  inflating: hateful_memes/img/01567.png  \n",
            "  inflating: hateful_memes/img/16837.png  \n",
            "  inflating: hateful_memes/img/35189.png  \n",
            "  inflating: hateful_memes/img/93487.png  \n",
            "  inflating: hateful_memes/img/21609.png  \n",
            "  inflating: hateful_memes/img/57012.png  \n",
            "  inflating: hateful_memes/img/01392.png  \n",
            "  inflating: hateful_memes/img/35627.png  \n",
            "  inflating: hateful_memes/img/20459.png  \n",
            "  inflating: hateful_memes/img/58371.png  \n",
            "  inflating: hateful_memes/img/85392.png  \n",
            "  inflating: hateful_memes/img/61840.png  \n",
            "  inflating: hateful_memes/img/56091.png  \n",
            "  inflating: hateful_memes/img/05763.png  \n",
            "  inflating: hateful_memes/img/70162.png  \n",
            "  inflating: hateful_memes/img/39610.png  \n",
            "  inflating: hateful_memes/img/71954.png  \n",
            "  inflating: hateful_memes/img/54863.png  \n",
            "  inflating: hateful_memes/img/32746.png  \n",
            "  inflating: hateful_memes/img/54397.png  \n",
            "  inflating: hateful_memes/img/08795.png  \n",
            "  inflating: hateful_memes/img/34281.png  \n",
            "  inflating: hateful_memes/img/97542.png  \n",
            "  inflating: hateful_memes/img/06458.png  \n",
            "  inflating: hateful_memes/img/37865.png  \n",
            "  inflating: hateful_memes/img/05294.png  \n",
            "  inflating: hateful_memes/img/89102.png  \n",
            "  inflating: hateful_memes/img/24038.png  \n",
            "  inflating: hateful_memes/img/97642.png  \n",
            "  inflating: hateful_memes/img/83456.png  \n",
            "  inflating: hateful_memes/img/26031.png  \n",
            "  inflating: hateful_memes/img/36781.png  \n",
            "  inflating: hateful_memes/img/24630.png  \n",
            "  inflating: hateful_memes/img/75139.png  \n",
            "  inflating: hateful_memes/img/42601.png  \n",
            "  inflating: hateful_memes/img/78964.png  \n",
            "  inflating: hateful_memes/img/39710.png  \n",
            "  inflating: hateful_memes/img/57312.png  \n",
            "  inflating: hateful_memes/img/17386.png  \n",
            "  inflating: hateful_memes/img/02578.png  \n",
            "  inflating: hateful_memes/img/82731.png  \n",
            "  inflating: hateful_memes/img/61753.png  \n",
            "  inflating: hateful_memes/img/97502.png  \n",
            "  inflating: hateful_memes/img/24806.png  \n",
            "  inflating: hateful_memes/img/28905.png  \n",
            "  inflating: hateful_memes/img/75439.png  \n",
            "  inflating: hateful_memes/img/41508.png  \n",
            "  inflating: hateful_memes/img/02461.png  \n",
            "  inflating: hateful_memes/img/35497.png  \n",
            "  inflating: hateful_memes/img/27613.png  \n",
            "  inflating: hateful_memes/img/21867.png  \n",
            "  inflating: hateful_memes/img/71463.png  \n",
            "  inflating: hateful_memes/img/68930.png  \n",
            "  inflating: hateful_memes/img/46205.png  \n",
            "  inflating: hateful_memes/img/34096.png  \n",
            "  inflating: hateful_memes/img/10358.png  \n",
            "  inflating: hateful_memes/img/73924.png  \n",
            "  inflating: hateful_memes/img/01794.png  \n",
            "  inflating: hateful_memes/img/26174.png  \n",
            "  inflating: hateful_memes/img/52614.png  \n",
            "  inflating: hateful_memes/img/29478.png  \n",
            "  inflating: hateful_memes/img/05864.png  \n",
            "  inflating: hateful_memes/img/24853.png  \n",
            "  inflating: hateful_memes/img/53260.png  \n",
            "  inflating: hateful_memes/img/43521.png  \n",
            "  inflating: hateful_memes/img/83701.png  \n",
            "  inflating: hateful_memes/img/52748.png  \n",
            "  inflating: hateful_memes/img/54672.png  \n",
            "  inflating: hateful_memes/img/09283.png  \n",
            "  inflating: hateful_memes/img/78594.png  \n",
            "  inflating: hateful_memes/img/46183.png  \n",
            "  inflating: hateful_memes/img/27608.png  \n",
            "  inflating: hateful_memes/img/86749.png  \n",
            "  inflating: hateful_memes/img/83421.png  \n",
            "  inflating: hateful_memes/img/37285.png  \n",
            "  inflating: hateful_memes/img/51389.png  \n",
            "  inflating: hateful_memes/img/13249.png  \n",
            "  inflating: hateful_memes/img/86954.png  \n",
            "  inflating: hateful_memes/img/63152.png  \n",
            "  inflating: hateful_memes/img/06543.png  \n",
            "  inflating: hateful_memes/img/28051.png  \n",
            "  inflating: hateful_memes/img/96752.png  \n",
            "  inflating: hateful_memes/img/19247.png  \n",
            "  inflating: hateful_memes/img/93105.png  \n",
            "  inflating: hateful_memes/img/26014.png  \n",
            "  inflating: hateful_memes/img/16532.png  \n",
            "  inflating: hateful_memes/img/47625.png  \n",
            "  inflating: hateful_memes/img/21903.png  \n",
            "  inflating: hateful_memes/img/34216.png  \n",
            "  inflating: hateful_memes/img/47386.png  \n",
            "  inflating: hateful_memes/img/65187.png  \n",
            "  inflating: hateful_memes/img/59781.png  \n",
            "  inflating: hateful_memes/img/87526.png  \n",
            "  inflating: hateful_memes/img/98463.png  \n",
            "  inflating: hateful_memes/img/13085.png  \n",
            "  inflating: hateful_memes/img/25713.png  \n",
            "  inflating: hateful_memes/img/94352.png  \n",
            "  inflating: hateful_memes/img/71630.png  \n",
            "  inflating: hateful_memes/img/02751.png  \n",
            "  inflating: hateful_memes/img/18730.png  \n",
            "  inflating: hateful_memes/img/56307.png  \n",
            "  inflating: hateful_memes/img/09321.png  \n",
            "  inflating: hateful_memes/img/49638.png  \n",
            "  inflating: hateful_memes/img/74630.png  \n",
            "  inflating: hateful_memes/img/93572.png  \n",
            "  inflating: hateful_memes/img/94230.png  \n",
            "  inflating: hateful_memes/img/81365.png  \n",
            "  inflating: hateful_memes/img/71453.png  \n",
            "  inflating: hateful_memes/img/93152.png  \n",
            "  inflating: hateful_memes/img/45869.png  \n",
            "  inflating: hateful_memes/img/64350.png  \n",
            "  inflating: hateful_memes/img/82719.png  \n",
            "  inflating: hateful_memes/img/75631.png  \n",
            "  inflating: hateful_memes/img/17265.png  \n",
            "  inflating: hateful_memes/img/21904.png  \n",
            "  inflating: hateful_memes/img/12768.png  \n",
            "  inflating: hateful_memes/img/97246.png  \n",
            "  inflating: hateful_memes/img/27056.png  \n",
            "  inflating: hateful_memes/img/05813.png  \n",
            "  inflating: hateful_memes/img/35210.png  \n",
            "  inflating: hateful_memes/img/25340.png  \n",
            "  inflating: hateful_memes/img/59806.png  \n",
            "  inflating: hateful_memes/img/19027.png  \n",
            "  inflating: hateful_memes/img/74218.png  \n",
            "  inflating: hateful_memes/img/08275.png  \n",
            "  inflating: hateful_memes/img/98412.png  \n",
            "  inflating: hateful_memes/img/81063.png  \n",
            "  inflating: hateful_memes/img/02816.png  \n",
            "  inflating: hateful_memes/img/82316.png  \n",
            "  inflating: hateful_memes/img/63052.png  \n",
            "  inflating: hateful_memes/img/45601.png  \n",
            "  inflating: hateful_memes/img/61940.png  \n",
            "  inflating: hateful_memes/img/42597.png  \n",
            "  inflating: hateful_memes/img/31760.png  \n",
            "  inflating: hateful_memes/img/04326.png  \n",
            "  inflating: hateful_memes/img/47205.png  \n",
            "  inflating: hateful_memes/img/64291.png  \n",
            "  inflating: hateful_memes/img/83296.png  \n",
            "  inflating: hateful_memes/img/23746.png  \n",
            "  inflating: hateful_memes/img/67825.png  \n",
            "  inflating: hateful_memes/img/05712.png  \n",
            "  inflating: hateful_memes/img/83415.png  \n",
            "  inflating: hateful_memes/img/29438.png  \n",
            "  inflating: hateful_memes/img/01476.png  \n",
            "  inflating: hateful_memes/img/08725.png  \n",
            "  inflating: hateful_memes/img/53647.png  \n",
            "  inflating: hateful_memes/img/03681.png  \n",
            "  inflating: hateful_memes/img/47831.png  \n",
            "  inflating: hateful_memes/img/25170.png  \n",
            "  inflating: hateful_memes/img/46130.png  \n",
            "  inflating: hateful_memes/img/84517.png  \n",
            "  inflating: hateful_memes/img/02761.png  \n",
            "  inflating: hateful_memes/img/12980.png  \n",
            "  inflating: hateful_memes/img/28561.png  \n",
            "  inflating: hateful_memes/img/35460.png  \n",
            "  inflating: hateful_memes/img/92637.png  \n",
            "  inflating: hateful_memes/img/34215.png  \n",
            "  inflating: hateful_memes/img/84153.png  \n",
            "  inflating: hateful_memes/img/34206.png  \n",
            "  inflating: hateful_memes/img/49671.png  \n",
            "  inflating: hateful_memes/img/63917.png  \n",
            "  inflating: hateful_memes/img/53140.png  \n",
            "  inflating: hateful_memes/img/49762.png  \n",
            "  inflating: hateful_memes/img/56184.png  \n",
            "  inflating: hateful_memes/img/40756.png  \n",
            "  inflating: hateful_memes/img/76103.png  \n",
            "  inflating: hateful_memes/img/05719.png  \n",
            "  inflating: hateful_memes/img/34875.png  \n",
            "  inflating: hateful_memes/img/68019.png  \n",
            "  inflating: hateful_memes/img/94508.png  \n",
            "  inflating: hateful_memes/img/72406.png  \n",
            "  inflating: hateful_memes/img/60487.png  \n",
            "  inflating: hateful_memes/img/37160.png  \n",
            "  inflating: hateful_memes/img/62719.png  \n",
            "  inflating: hateful_memes/img/67531.png  \n",
            "  inflating: hateful_memes/img/83704.png  \n",
            "  inflating: hateful_memes/img/62409.png  \n",
            "  inflating: hateful_memes/img/80231.png  \n",
            "  inflating: hateful_memes/img/51094.png  \n",
            "  inflating: hateful_memes/img/91584.png  \n",
            "  inflating: hateful_memes/img/43859.png  \n",
            "  inflating: hateful_memes/img/14079.png  \n",
            "  inflating: hateful_memes/img/29468.png  \n",
            "  inflating: hateful_memes/img/75360.png  \n",
            "  inflating: hateful_memes/img/01258.png  \n",
            "  inflating: hateful_memes/img/74621.png  \n",
            "  inflating: hateful_memes/img/75918.png  \n",
            "  inflating: hateful_memes/img/80654.png  \n",
            "  inflating: hateful_memes/img/90352.png  \n",
            "  inflating: hateful_memes/img/93586.png  \n",
            "  inflating: hateful_memes/img/76250.png  \n",
            "  inflating: hateful_memes/img/57049.png  \n",
            "  inflating: hateful_memes/img/29158.png  \n",
            "  inflating: hateful_memes/img/03485.png  \n",
            "  inflating: hateful_memes/img/21086.png  \n",
            "  inflating: hateful_memes/img/94620.png  \n",
            "  inflating: hateful_memes/img/34961.png  \n",
            "  inflating: hateful_memes/img/41206.png  \n",
            "  inflating: hateful_memes/img/49168.png  \n",
            "  inflating: hateful_memes/img/49031.png  \n",
            "  inflating: hateful_memes/img/58309.png  \n",
            "  inflating: hateful_memes/img/31590.png  \n",
            "  inflating: hateful_memes/img/51694.png  \n",
            "  inflating: hateful_memes/img/38612.png  \n",
            "  inflating: hateful_memes/img/59870.png  \n",
            "  inflating: hateful_memes/img/59062.png  \n",
            "  inflating: hateful_memes/img/35604.png  \n",
            "  inflating: hateful_memes/img/63974.png  \n",
            "  inflating: hateful_memes/img/76435.png  \n",
            "  inflating: hateful_memes/img/05749.png  \n",
            "  inflating: hateful_memes/img/18406.png  \n",
            "  inflating: hateful_memes/img/74839.png  \n",
            "  inflating: hateful_memes/img/70394.png  \n",
            "  inflating: hateful_memes/img/52863.png  \n",
            "  inflating: hateful_memes/img/24178.png  \n",
            "  inflating: hateful_memes/img/19470.png  \n",
            "  inflating: hateful_memes/img/83470.png  \n",
            "  inflating: hateful_memes/img/72481.png  \n",
            "  inflating: hateful_memes/img/62541.png  \n",
            "  inflating: hateful_memes/img/28350.png  \n",
            "  inflating: hateful_memes/img/19650.png  \n",
            "  inflating: hateful_memes/img/48573.png  \n",
            "  inflating: hateful_memes/img/19032.png  \n",
            "  inflating: hateful_memes/img/81092.png  \n",
            "  inflating: hateful_memes/img/20861.png  \n",
            "  inflating: hateful_memes/img/37864.png  \n",
            "  inflating: hateful_memes/img/89607.png  \n",
            "  inflating: hateful_memes/img/48307.png  \n",
            "  inflating: hateful_memes/img/59876.png  \n",
            "  inflating: hateful_memes/img/30174.png  \n",
            "  inflating: hateful_memes/img/45176.png  \n",
            "  inflating: hateful_memes/img/56812.png  \n",
            "  inflating: hateful_memes/img/71094.png  \n",
            "  inflating: hateful_memes/img/75639.png  \n",
            "  inflating: hateful_memes/img/91586.png  \n",
            "  inflating: hateful_memes/img/04529.png  \n",
            "  inflating: hateful_memes/img/10786.png  \n",
            "  inflating: hateful_memes/img/15839.png  \n",
            "  inflating: hateful_memes/img/23054.png  \n",
            "  inflating: hateful_memes/img/37984.png  \n",
            "  inflating: hateful_memes/img/61048.png  \n",
            "  inflating: hateful_memes/img/53148.png  \n",
            "  inflating: hateful_memes/img/65372.png  \n",
            "  inflating: hateful_memes/img/61092.png  \n",
            "  inflating: hateful_memes/img/03756.png  \n",
            "  inflating: hateful_memes/img/02587.png  \n",
            "  inflating: hateful_memes/img/41672.png  \n",
            "  inflating: hateful_memes/img/60938.png  \n",
            "  inflating: hateful_memes/img/52018.png  \n",
            "  inflating: hateful_memes/img/13960.png  \n",
            "  inflating: hateful_memes/img/69054.png  \n",
            "  inflating: hateful_memes/img/20395.png  \n",
            "  inflating: hateful_memes/img/49083.png  \n",
            "  inflating: hateful_memes/img/17029.png  \n",
            "  inflating: hateful_memes/img/71259.png  \n",
            "  inflating: hateful_memes/img/46827.png  \n",
            "  inflating: hateful_memes/img/17530.png  \n",
            "  inflating: hateful_memes/img/05948.png  \n",
            "  inflating: hateful_memes/img/56248.png  \n",
            "  inflating: hateful_memes/img/17369.png  \n",
            "  inflating: hateful_memes/img/48516.png  \n",
            "  inflating: hateful_memes/img/09465.png  \n",
            "  inflating: hateful_memes/img/63458.png  \n",
            "  inflating: hateful_memes/img/48927.png  \n",
            "  inflating: hateful_memes/img/97250.png  \n",
            "  inflating: hateful_memes/img/86293.png  \n",
            "  inflating: hateful_memes/img/94512.png  \n",
            "  inflating: hateful_memes/img/97045.png  \n",
            "  inflating: hateful_memes/img/75910.png  \n",
            "  inflating: hateful_memes/img/62485.png  \n",
            "  inflating: hateful_memes/img/07291.png  \n",
            "  inflating: hateful_memes/img/28061.png  \n",
            "  inflating: hateful_memes/img/64089.png  \n",
            "  inflating: hateful_memes/img/13276.png  \n",
            "  inflating: hateful_memes/img/01468.png  \n",
            "  inflating: hateful_memes/img/24835.png  \n",
            "  inflating: hateful_memes/img/84379.png  \n",
            "  inflating: hateful_memes/img/78259.png  \n",
            "  inflating: hateful_memes/img/48673.png  \n",
            "  inflating: hateful_memes/img/51208.png  \n",
            "  inflating: hateful_memes/img/28364.png  \n",
            "  inflating: hateful_memes/img/32789.png  \n",
            "  inflating: hateful_memes/img/80397.png  \n",
            "  inflating: hateful_memes/img/75806.png  \n",
            "  inflating: hateful_memes/img/98176.png  \n",
            "  inflating: hateful_memes/img/83219.png  \n",
            "  inflating: hateful_memes/img/54097.png  \n",
            "  inflating: hateful_memes/img/19275.png  \n",
            "  inflating: hateful_memes/img/73819.png  \n",
            "  inflating: hateful_memes/img/07825.png  \n",
            "  inflating: hateful_memes/img/37201.png  \n",
            "  inflating: hateful_memes/img/34756.png  \n",
            "  inflating: hateful_memes/img/02413.png  \n",
            "  inflating: hateful_memes/img/03189.png  \n",
            "  inflating: hateful_memes/img/32945.png  \n",
            "  inflating: hateful_memes/img/19604.png  \n",
            "  inflating: hateful_memes/img/67328.png  \n",
            "  inflating: hateful_memes/img/70143.png  \n",
            "  inflating: hateful_memes/img/21749.png  \n",
            "  inflating: hateful_memes/img/98642.png  \n",
            "  inflating: hateful_memes/img/62589.png  \n",
            "  inflating: hateful_memes/img/51263.png  \n",
            "  inflating: hateful_memes/img/49615.png  \n",
            "  inflating: hateful_memes/img/71965.png  \n",
            "  inflating: hateful_memes/img/06425.png  \n",
            "  inflating: hateful_memes/img/13540.png  \n",
            "  inflating: hateful_memes/img/30896.png  \n",
            "  inflating: hateful_memes/img/68043.png  \n",
            "  inflating: hateful_memes/img/76254.png  \n",
            "  inflating: hateful_memes/img/19647.png  \n",
            "  inflating: hateful_memes/img/26375.png  \n",
            "  inflating: hateful_memes/img/64810.png  \n",
            "  inflating: hateful_memes/img/76145.png  \n",
            "  inflating: hateful_memes/img/79531.png  \n",
            "  inflating: hateful_memes/img/05476.png  \n",
            "  inflating: hateful_memes/img/52761.png  \n",
            "  inflating: hateful_memes/img/18453.png  \n",
            "  inflating: hateful_memes/img/50327.png  \n",
            "  inflating: hateful_memes/img/08571.png  \n",
            "  inflating: hateful_memes/img/90382.png  \n",
            "  inflating: hateful_memes/img/03864.png  \n",
            "  inflating: hateful_memes/img/38215.png  \n",
            "  inflating: hateful_memes/img/57324.png  \n",
            "  inflating: hateful_memes/img/38762.png  \n",
            "  inflating: hateful_memes/img/92430.png  \n",
            "  inflating: hateful_memes/img/81069.png  \n",
            "  inflating: hateful_memes/img/75231.png  \n",
            "  inflating: hateful_memes/img/54891.png  \n",
            "  inflating: hateful_memes/img/13520.png  \n",
            "  inflating: hateful_memes/img/30785.png  \n",
            "  inflating: hateful_memes/img/41027.png  \n",
            "  inflating: hateful_memes/img/52071.png  \n",
            "  inflating: hateful_memes/img/58170.png  \n",
            "  inflating: hateful_memes/img/49801.png  \n",
            "  inflating: hateful_memes/img/71095.png  \n",
            "  inflating: hateful_memes/img/71360.png  \n",
            "  inflating: hateful_memes/img/46938.png  \n",
            "  inflating: hateful_memes/img/61780.png  \n",
            "  inflating: hateful_memes/img/96073.png  \n",
            "  inflating: hateful_memes/img/64127.png  \n",
            "  inflating: hateful_memes/img/04639.png  \n",
            "  inflating: hateful_memes/img/19324.png  \n",
            "  inflating: hateful_memes/img/12839.png  \n",
            "  inflating: hateful_memes/img/73426.png  \n",
            "  inflating: hateful_memes/img/18546.png  \n",
            "  inflating: hateful_memes/img/87160.png  \n",
            "  inflating: hateful_memes/img/07249.png  \n",
            "  inflating: hateful_memes/img/08912.png  \n",
            "  inflating: hateful_memes/img/96405.png  \n",
            "  inflating: hateful_memes/img/46153.png  \n",
            "  inflating: hateful_memes/img/56038.png  \n",
            "  inflating: hateful_memes/img/73028.png  \n",
            "  inflating: hateful_memes/img/24738.png  \n",
            "  inflating: hateful_memes/img/78052.png  \n",
            "  inflating: hateful_memes/img/09387.png  \n",
            "  inflating: hateful_memes/img/43791.png  \n",
            "  inflating: hateful_memes/img/04163.png  \n",
            "  inflating: hateful_memes/img/73615.png  \n",
            "  inflating: hateful_memes/img/26905.png  \n",
            "  inflating: hateful_memes/img/84092.png  \n",
            "  inflating: hateful_memes/img/02497.png  \n",
            "  inflating: hateful_memes/img/86231.png  \n",
            "  inflating: hateful_memes/img/12468.png  \n",
            "  inflating: hateful_memes/img/92584.png  \n",
            "  inflating: hateful_memes/img/49205.png  \n",
            "  inflating: hateful_memes/img/37289.png  \n",
            "  inflating: hateful_memes/img/95071.png  \n",
            "  inflating: hateful_memes/img/42983.png  \n",
            "  inflating: hateful_memes/img/25614.png  \n",
            "  inflating: hateful_memes/img/50487.png  \n",
            "  inflating: hateful_memes/img/86750.png  \n",
            "  inflating: hateful_memes/img/97185.png  \n",
            "  inflating: hateful_memes/img/71529.png  \n",
            "  inflating: hateful_memes/img/69875.png  \n",
            "  inflating: hateful_memes/img/20386.png  \n",
            "  inflating: hateful_memes/img/54720.png  \n",
            "  inflating: hateful_memes/img/40576.png  \n",
            "  inflating: hateful_memes/img/27305.png  \n",
            "  inflating: hateful_memes/img/65103.png  \n",
            "  inflating: hateful_memes/img/17649.png  \n",
            "  inflating: hateful_memes/img/28096.png  \n",
            "  inflating: hateful_memes/img/20859.png  \n",
            "  inflating: hateful_memes/img/94231.png  \n",
            "  inflating: hateful_memes/img/25690.png  \n",
            "  inflating: hateful_memes/img/07486.png  \n",
            "  inflating: hateful_memes/img/30871.png  \n",
            "  inflating: hateful_memes/img/15209.png  \n",
            "  inflating: hateful_memes/img/23971.png  \n",
            "  inflating: hateful_memes/img/32540.png  \n",
            "  inflating: hateful_memes/img/65801.png  \n",
            "  inflating: hateful_memes/img/52106.png  \n",
            "  inflating: hateful_memes/img/87120.png  \n",
            "  inflating: hateful_memes/img/64391.png  \n",
            "  inflating: hateful_memes/img/65189.png  \n",
            "  inflating: hateful_memes/img/81642.png  \n",
            "  inflating: hateful_memes/img/79452.png  \n",
            "  inflating: hateful_memes/img/61953.png  \n",
            "  inflating: hateful_memes/img/97068.png  \n",
            "  inflating: hateful_memes/img/46902.png  \n",
            "  inflating: hateful_memes/img/49650.png  \n",
            "  inflating: hateful_memes/img/61590.png  \n",
            "  inflating: hateful_memes/img/97543.png  \n",
            "  inflating: hateful_memes/img/81926.png  \n",
            "  inflating: hateful_memes/img/87453.png  \n",
            "  inflating: hateful_memes/img/56873.png  \n",
            "  inflating: hateful_memes/img/30168.png  \n",
            "  inflating: hateful_memes/img/61257.png  \n",
            "  inflating: hateful_memes/img/65312.png  \n",
            "  inflating: hateful_memes/img/91730.png  \n",
            "  inflating: hateful_memes/img/60278.png  \n",
            "  inflating: hateful_memes/img/80957.png  \n",
            "  inflating: hateful_memes/img/28396.png  \n",
            "  inflating: hateful_memes/img/79846.png  \n",
            "  inflating: hateful_memes/img/58027.png  \n",
            "  inflating: hateful_memes/img/76012.png  \n",
            "  inflating: hateful_memes/img/19587.png  \n",
            "  inflating: hateful_memes/img/17326.png  \n",
            "  inflating: hateful_memes/img/26530.png  \n",
            "  inflating: hateful_memes/img/65728.png  \n",
            "  inflating: hateful_memes/img/34506.png  \n",
            "  inflating: hateful_memes/img/80395.png  \n",
            "  inflating: hateful_memes/img/35091.png  \n",
            "  inflating: hateful_memes/img/40569.png  \n",
            "  inflating: hateful_memes/img/98163.png  \n",
            "  inflating: hateful_memes/img/62531.png  \n",
            "  inflating: hateful_memes/img/27518.png  \n",
            "  inflating: hateful_memes/img/07824.png  \n",
            "  inflating: hateful_memes/img/16032.png  \n",
            "  inflating: hateful_memes/img/10567.png  \n",
            "  inflating: hateful_memes/img/89267.png  \n",
            "  inflating: hateful_memes/img/61482.png  \n",
            "  inflating: hateful_memes/img/71548.png  \n",
            "  inflating: hateful_memes/img/69487.png  \n",
            "  inflating: hateful_memes/img/16487.png  \n",
            "  inflating: hateful_memes/img/21560.png  \n",
            "  inflating: hateful_memes/img/26419.png  \n",
            "  inflating: hateful_memes/img/42185.png  \n",
            "  inflating: hateful_memes/img/15768.png  \n",
            "  inflating: hateful_memes/img/26543.png  \n",
            "  inflating: hateful_memes/img/90531.png  \n",
            "  inflating: hateful_memes/img/43675.png  \n",
            "  inflating: hateful_memes/img/01469.png  \n",
            "  inflating: hateful_memes/img/26538.png  \n",
            "  inflating: hateful_memes/img/53471.png  \n",
            "  inflating: hateful_memes/img/76581.png  \n",
            "  inflating: hateful_memes/img/31280.png  \n",
            "  inflating: hateful_memes/img/34586.png  \n",
            "  inflating: hateful_memes/img/14603.png  \n",
            "  inflating: hateful_memes/img/68423.png  \n",
            "  inflating: hateful_memes/img/23198.png  \n",
            "  inflating: hateful_memes/img/07694.png  \n",
            "  inflating: hateful_memes/img/42830.png  \n",
            "  inflating: hateful_memes/img/35480.png  \n",
            "  inflating: hateful_memes/img/90814.png  \n",
            "  inflating: hateful_memes/img/53769.png  \n",
            "  inflating: hateful_memes/img/05736.png  \n",
            "  inflating: hateful_memes/img/57821.png  \n",
            "  inflating: hateful_memes/img/85097.png  \n",
            "  inflating: hateful_memes/img/94237.png  \n",
            "  inflating: hateful_memes/img/86925.png  \n",
            "  inflating: hateful_memes/img/72450.png  \n",
            "  inflating: hateful_memes/img/63029.png  \n",
            "  inflating: hateful_memes/img/57093.png  \n",
            "  inflating: hateful_memes/img/78205.png  \n",
            "  inflating: hateful_memes/img/29843.png  \n",
            "  inflating: hateful_memes/img/52069.png  \n",
            "  inflating: hateful_memes/img/84237.png  \n",
            "  inflating: hateful_memes/img/94350.png  \n",
            "  inflating: hateful_memes/img/86059.png  \n",
            "  inflating: hateful_memes/img/32605.png  \n",
            "  inflating: hateful_memes/img/75310.png  \n",
            "  inflating: hateful_memes/img/51479.png  \n",
            "  inflating: hateful_memes/img/07425.png  \n",
            "  inflating: hateful_memes/img/87364.png  \n",
            "  inflating: hateful_memes/img/09715.png  \n",
            "  inflating: hateful_memes/img/18506.png  \n",
            "  inflating: hateful_memes/img/24390.png  \n",
            "  inflating: hateful_memes/img/40286.png  \n",
            "  inflating: hateful_memes/img/20184.png  \n",
            "  inflating: hateful_memes/img/12450.png  \n",
            "  inflating: hateful_memes/img/07926.png  \n",
            "  inflating: hateful_memes/img/25914.png  \n",
            "  inflating: hateful_memes/img/97628.png  \n",
            "  inflating: hateful_memes/img/20736.png  \n",
            "  inflating: hateful_memes/img/09315.png  \n",
            "  inflating: hateful_memes/img/46075.png  \n",
            "  inflating: hateful_memes/img/24601.png  \n",
            "  inflating: hateful_memes/img/90125.png  \n",
            "  inflating: hateful_memes/img/53210.png  \n",
            "  inflating: hateful_memes/img/15328.png  \n",
            "  inflating: hateful_memes/img/37408.png  \n",
            "  inflating: hateful_memes/img/56290.png  \n",
            "  inflating: hateful_memes/img/04786.png  \n",
            "  inflating: hateful_memes/img/29483.png  \n",
            "  inflating: hateful_memes/img/09217.png  \n",
            "  inflating: hateful_memes/img/08162.png  \n",
            "  inflating: hateful_memes/img/18052.png  \n",
            "  inflating: hateful_memes/img/26170.png  \n",
            "  inflating: hateful_memes/img/82604.png  \n",
            "  inflating: hateful_memes/img/48015.png  \n",
            "  inflating: hateful_memes/img/51397.png  \n",
            "  inflating: hateful_memes/img/68213.png  \n",
            "  inflating: hateful_memes/img/76405.png  \n",
            "  inflating: hateful_memes/img/25806.png  \n",
            "  inflating: hateful_memes/img/76894.png  \n",
            "  inflating: hateful_memes/img/38076.png  \n",
            "  inflating: hateful_memes/img/31647.png  \n",
            "  inflating: hateful_memes/img/01456.png  \n",
            "  inflating: hateful_memes/img/04256.png  \n",
            "  inflating: hateful_memes/img/10956.png  \n",
            "  inflating: hateful_memes/img/23815.png  \n",
            "  inflating: hateful_memes/img/18764.png  \n",
            "  inflating: hateful_memes/img/59240.png  \n",
            "  inflating: hateful_memes/img/76305.png  \n",
            "  inflating: hateful_memes/img/59364.png  \n",
            "  inflating: hateful_memes/img/52786.png  \n",
            "  inflating: hateful_memes/img/10362.png  \n",
            "  inflating: hateful_memes/img/12039.png  \n",
            "  inflating: hateful_memes/img/79132.png  \n",
            "  inflating: hateful_memes/img/30761.png  \n",
            "  inflating: hateful_memes/img/09385.png  \n",
            "  inflating: hateful_memes/img/29387.png  \n",
            "  inflating: hateful_memes/img/17469.png  \n",
            "  inflating: hateful_memes/img/29173.png  \n",
            "  inflating: hateful_memes/img/79463.png  \n",
            "  inflating: hateful_memes/img/49315.png  \n",
            "  inflating: hateful_memes/img/42803.png  \n",
            "  inflating: hateful_memes/img/74126.png  \n",
            "  inflating: hateful_memes/img/57861.png  \n",
            "  inflating: hateful_memes/img/64390.png  \n",
            "  inflating: hateful_memes/img/13895.png  \n",
            "  inflating: hateful_memes/img/13958.png  \n",
            "  inflating: hateful_memes/img/49807.png  \n",
            "  inflating: hateful_memes/img/21946.png  \n",
            "  inflating: hateful_memes/img/63025.png  \n",
            "  inflating: hateful_memes/img/72301.png  \n",
            "  inflating: hateful_memes/img/06937.png  \n",
            "  inflating: hateful_memes/img/40761.png  \n",
            "  inflating: hateful_memes/img/34618.png  \n",
            "  inflating: hateful_memes/img/97153.png  \n",
            "  inflating: hateful_memes/img/29376.png  \n",
            "  inflating: hateful_memes/img/16478.png  \n",
            "  inflating: hateful_memes/img/17834.png  \n",
            "  inflating: hateful_memes/img/53184.png  \n",
            "  inflating: hateful_memes/img/08743.png  \n",
            "  inflating: hateful_memes/img/75340.png  \n",
            "  inflating: hateful_memes/img/79182.png  \n",
            "  inflating: hateful_memes/img/68579.png  \n",
            "  inflating: hateful_memes/img/67082.png  \n",
            "  inflating: hateful_memes/img/20971.png  \n",
            "  inflating: hateful_memes/img/86974.png  \n",
            "  inflating: hateful_memes/img/34870.png  \n",
            "  inflating: hateful_memes/img/54709.png  \n",
            "  inflating: hateful_memes/img/69085.png  \n",
            "  inflating: hateful_memes/img/54738.png  \n",
            "  inflating: hateful_memes/img/82137.png  \n",
            "  inflating: hateful_memes/img/12394.png  \n",
            "  inflating: hateful_memes/img/76258.png  \n",
            "  inflating: hateful_memes/img/91208.png  \n",
            "  inflating: hateful_memes/img/92645.png  \n",
            "  inflating: hateful_memes/img/83095.png  \n",
            "  inflating: hateful_memes/img/54316.png  \n",
            "  inflating: hateful_memes/img/71925.png  \n",
            "  inflating: hateful_memes/img/73981.png  \n",
            "  inflating: hateful_memes/img/52960.png  \n",
            "  inflating: hateful_memes/img/02381.png  \n",
            "  inflating: hateful_memes/img/14570.png  \n",
            "  inflating: hateful_memes/img/35247.png  \n",
            "  inflating: hateful_memes/img/18673.png  \n",
            "  inflating: hateful_memes/img/78931.png  \n",
            "  inflating: hateful_memes/img/74801.png  \n",
            "  inflating: hateful_memes/img/91824.png  \n",
            "  inflating: hateful_memes/img/96415.png  \n",
            "  inflating: hateful_memes/img/15489.png  \n",
            "  inflating: hateful_memes/img/28579.png  \n",
            "  inflating: hateful_memes/img/65491.png  \n",
            "  inflating: hateful_memes/img/64198.png  \n",
            "  inflating: hateful_memes/img/05612.png  \n",
            "  inflating: hateful_memes/img/91374.png  \n",
            "  inflating: hateful_memes/img/58301.png  \n",
            "  inflating: hateful_memes/img/42065.png  \n",
            "  inflating: hateful_memes/img/10642.png  \n",
            "  inflating: hateful_memes/img/53017.png  \n",
            "  inflating: hateful_memes/img/47026.png  \n",
            "  inflating: hateful_memes/img/36497.png  \n",
            "  inflating: hateful_memes/img/52036.png  \n",
            "  inflating: hateful_memes/img/29608.png  \n",
            "  inflating: hateful_memes/img/17082.png  \n",
            "  inflating: hateful_memes/img/31907.png  \n",
            "  inflating: hateful_memes/img/84372.png  \n",
            "  inflating: hateful_memes/img/68743.png  \n",
            "  inflating: hateful_memes/img/74312.png  \n",
            "  inflating: hateful_memes/img/90768.png  \n",
            "  inflating: hateful_memes/img/49685.png  \n",
            "  inflating: hateful_memes/img/87564.png  \n",
            "  inflating: hateful_memes/img/38209.png  \n",
            "  inflating: hateful_memes/img/94015.png  \n",
            "  inflating: hateful_memes/img/12350.png  \n",
            "  inflating: hateful_memes/img/04183.png  \n",
            "  inflating: hateful_memes/img/72641.png  \n",
            "  inflating: hateful_memes/img/94372.png  \n",
            "  inflating: hateful_memes/img/93425.png  \n",
            "  inflating: hateful_memes/img/87106.png  \n",
            "  inflating: hateful_memes/img/94013.png  \n",
            "  inflating: hateful_memes/img/19357.png  \n",
            "  inflating: hateful_memes/img/25198.png  \n",
            "  inflating: hateful_memes/img/46759.png  \n",
            "  inflating: hateful_memes/img/59763.png  \n",
            "  inflating: hateful_memes/img/16407.png  \n",
            "  inflating: hateful_memes/img/91526.png  \n",
            "  inflating: hateful_memes/img/05192.png  \n",
            "  inflating: hateful_memes/img/63805.png  \n",
            "  inflating: hateful_memes/img/06125.png  \n",
            "  inflating: hateful_memes/img/24907.png  \n",
            "  inflating: hateful_memes/img/10857.png  \n",
            "  inflating: hateful_memes/img/37250.png  \n",
            "  inflating: hateful_memes/img/37548.png  \n",
            "  inflating: hateful_memes/img/19084.png  \n",
            "  inflating: hateful_memes/img/31420.png  \n",
            "  inflating: hateful_memes/img/21038.png  \n",
            "  inflating: hateful_memes/img/04928.png  \n",
            "  inflating: hateful_memes/img/92836.png  \n",
            "  inflating: hateful_memes/img/52806.png  \n",
            "  inflating: hateful_memes/img/32617.png  \n",
            "  inflating: hateful_memes/img/51467.png  \n",
            "  inflating: hateful_memes/img/64820.png  \n",
            "  inflating: hateful_memes/img/46279.png  \n",
            "  inflating: hateful_memes/img/37560.png  \n",
            "  inflating: hateful_memes/img/61420.png  \n",
            "  inflating: hateful_memes/img/94083.png  \n",
            "  inflating: hateful_memes/img/48396.png  \n",
            "  inflating: hateful_memes/img/52084.png  \n",
            "  inflating: hateful_memes/img/70652.png  \n",
            "  inflating: hateful_memes/img/34721.png  \n",
            "  inflating: hateful_memes/img/32956.png  \n",
            "  inflating: hateful_memes/img/36748.png  \n",
            "  inflating: hateful_memes/img/61378.png  \n",
            "  inflating: hateful_memes/img/07834.png  \n",
            "  inflating: hateful_memes/img/92870.png  \n",
            "  inflating: hateful_memes/img/03971.png  \n",
            "  inflating: hateful_memes/img/50146.png  \n",
            "  inflating: hateful_memes/img/02584.png  \n",
            "  inflating: hateful_memes/img/07265.png  \n",
            "  inflating: hateful_memes/img/67410.png  \n",
            "  inflating: hateful_memes/img/54168.png  \n",
            "  inflating: hateful_memes/img/53108.png  \n",
            "  inflating: hateful_memes/img/01562.png  \n",
            "  inflating: hateful_memes/img/29760.png  \n",
            "  inflating: hateful_memes/img/46783.png  \n",
            "  inflating: hateful_memes/img/92085.png  \n",
            "  inflating: hateful_memes/img/50371.png  \n",
            "  inflating: hateful_memes/img/84135.png  \n",
            "  inflating: hateful_memes/img/67214.png  \n",
            "  inflating: hateful_memes/img/74013.png  \n",
            "  inflating: hateful_memes/img/78652.png  \n",
            "  inflating: hateful_memes/img/24698.png  \n",
            "  inflating: hateful_memes/img/46352.png  \n",
            "  inflating: hateful_memes/img/41068.png  \n",
            "  inflating: hateful_memes/img/19740.png  \n",
            "  inflating: hateful_memes/img/56310.png  \n",
            "  inflating: hateful_memes/img/34218.png  \n",
            "  inflating: hateful_memes/img/51864.png  \n",
            "  inflating: hateful_memes/img/37615.png  \n",
            "  inflating: hateful_memes/img/94085.png  \n",
            "  inflating: hateful_memes/img/15409.png  \n",
            "  inflating: hateful_memes/img/16843.png  \n",
            "  inflating: hateful_memes/img/48236.png  \n",
            "  inflating: hateful_memes/img/04379.png  \n",
            "  inflating: hateful_memes/img/08234.png  \n",
            "  inflating: hateful_memes/img/23685.png  \n",
            "  inflating: hateful_memes/img/60784.png  \n",
            "  inflating: hateful_memes/img/28356.png  \n",
            "  inflating: hateful_memes/img/93410.png  \n",
            "  inflating: hateful_memes/img/30865.png  \n",
            "  inflating: hateful_memes/img/40217.png  \n",
            "  inflating: hateful_memes/img/67892.png  \n",
            "  inflating: hateful_memes/img/27304.png  \n",
            "  inflating: hateful_memes/img/13809.png  \n",
            "  inflating: hateful_memes/img/86401.png  \n",
            "  inflating: hateful_memes/img/45126.png  \n",
            "  inflating: hateful_memes/img/48920.png  \n",
            "  inflating: hateful_memes/img/36578.png  \n",
            "  inflating: hateful_memes/img/49267.png  \n",
            "  inflating: hateful_memes/img/48062.png  \n",
            "  inflating: hateful_memes/img/62573.png  \n",
            "  inflating: hateful_memes/img/48923.png  \n",
            "  inflating: hateful_memes/img/91320.png  \n",
            "  inflating: hateful_memes/img/93164.png  \n",
            "  inflating: hateful_memes/img/38920.png  \n",
            "  inflating: hateful_memes/img/98314.png  \n",
            "  inflating: hateful_memes/img/91540.png  \n",
            "  inflating: hateful_memes/img/23751.png  \n",
            "  inflating: hateful_memes/img/06479.png  \n",
            "  inflating: hateful_memes/img/79316.png  \n",
            "  inflating: hateful_memes/img/48792.png  \n",
            "  inflating: hateful_memes/img/98731.png  \n",
            "  inflating: hateful_memes/img/86024.png  \n",
            "  inflating: hateful_memes/img/63507.png  \n",
            "  inflating: hateful_memes/img/93208.png  \n",
            "  inflating: hateful_memes/img/36752.png  \n",
            "  inflating: hateful_memes/img/81496.png  \n",
            "  inflating: hateful_memes/img/96541.png  \n",
            "  inflating: hateful_memes/img/15902.png  \n",
            "  inflating: hateful_memes/img/89136.png  \n",
            "  inflating: hateful_memes/img/89417.png  \n",
            "  inflating: hateful_memes/img/48260.png  \n",
            "  inflating: hateful_memes/img/82609.png  \n",
            "  inflating: hateful_memes/img/79823.png  \n",
            "  inflating: hateful_memes/img/30982.png  \n",
            "  inflating: hateful_memes/img/06415.png  \n",
            "  inflating: hateful_memes/img/79652.png  \n",
            "  inflating: hateful_memes/img/87924.png  \n",
            "  inflating: hateful_memes/img/40329.png  \n",
            "  inflating: hateful_memes/img/85329.png  \n",
            "  inflating: hateful_memes/img/01953.png  \n",
            "  inflating: hateful_memes/img/60143.png  \n",
            "  inflating: hateful_memes/img/05986.png  \n",
            "  inflating: hateful_memes/img/05126.png  \n",
            "  inflating: hateful_memes/img/35802.png  \n",
            "  inflating: hateful_memes/img/51409.png  \n",
            "  inflating: hateful_memes/img/57463.png  \n",
            "  inflating: hateful_memes/img/89360.png  \n",
            "  inflating: hateful_memes/img/94351.png  \n",
            "  inflating: hateful_memes/img/92581.png  \n",
            "  inflating: hateful_memes/img/46201.png  \n",
            "  inflating: hateful_memes/img/40137.png  \n",
            "  inflating: hateful_memes/img/96312.png  \n",
            "  inflating: hateful_memes/img/84762.png  \n",
            "  inflating: hateful_memes/img/78904.png  \n",
            "  inflating: hateful_memes/img/17398.png  \n",
            "  inflating: hateful_memes/img/65482.png  \n",
            "  inflating: hateful_memes/img/27915.png  \n",
            "  inflating: hateful_memes/img/54837.png  \n",
            "  inflating: hateful_memes/img/56417.png  \n",
            "  inflating: hateful_memes/img/17203.png  \n",
            "  inflating: hateful_memes/img/30675.png  \n",
            "  inflating: hateful_memes/img/70198.png  \n",
            "  inflating: hateful_memes/img/36019.png  \n",
            "  inflating: hateful_memes/img/64071.png  \n",
            "  inflating: hateful_memes/img/82359.png  \n",
            "  inflating: hateful_memes/img/71586.png  \n",
            "  inflating: hateful_memes/img/94158.png  \n",
            "  inflating: hateful_memes/img/54190.png  \n",
            "  inflating: hateful_memes/img/30165.png  \n",
            "  inflating: hateful_memes/img/30864.png  \n",
            "  inflating: hateful_memes/img/19586.png  \n",
            "  inflating: hateful_memes/img/70146.png  \n",
            "  inflating: hateful_memes/img/13095.png  \n",
            "  inflating: hateful_memes/img/08374.png  \n",
            "  inflating: hateful_memes/img/75469.png  \n",
            "  inflating: hateful_memes/img/06427.png  \n",
            "  inflating: hateful_memes/img/89067.png  \n",
            "  inflating: hateful_memes/img/19036.png  \n",
            "  inflating: hateful_memes/img/96371.png  \n",
            "  inflating: hateful_memes/img/34602.png  \n",
            "  inflating: hateful_memes/img/48276.png  \n",
            "  inflating: hateful_memes/img/21408.png  \n",
            "  inflating: hateful_memes/img/96145.png  \n",
            "  inflating: hateful_memes/img/78429.png  \n",
            "  inflating: hateful_memes/img/18732.png  \n",
            "  inflating: hateful_memes/img/53467.png  \n",
            "  inflating: hateful_memes/img/94305.png  \n",
            "  inflating: hateful_memes/img/27154.png  \n",
            "  inflating: hateful_memes/img/84576.png  \n",
            "  inflating: hateful_memes/img/71689.png  \n",
            "  inflating: hateful_memes/img/26590.png  \n",
            "  inflating: hateful_memes/img/42693.png  \n",
            "  inflating: hateful_memes/img/04735.png  \n",
            "  inflating: hateful_memes/img/18564.png  \n",
            "  inflating: hateful_memes/img/28541.png  \n",
            "  inflating: hateful_memes/img/53094.png  \n",
            "  inflating: hateful_memes/img/64735.png  \n",
            "  inflating: hateful_memes/img/97438.png  \n",
            "  inflating: hateful_memes/img/67935.png  \n",
            "  inflating: hateful_memes/img/98564.png  \n",
            "  inflating: hateful_memes/img/21547.png  \n",
            "  inflating: hateful_memes/img/29138.png  \n",
            "  inflating: hateful_memes/img/51934.png  \n",
            "  inflating: hateful_memes/img/78164.png  \n",
            "  inflating: hateful_memes/img/80792.png  \n",
            "  inflating: hateful_memes/img/98035.png  \n",
            "  inflating: hateful_memes/img/67312.png  \n",
            "  inflating: hateful_memes/img/43197.png  \n",
            "  inflating: hateful_memes/img/29706.png  \n",
            "  inflating: hateful_memes/img/71429.png  \n",
            "  inflating: hateful_memes/img/36710.png  \n",
            "  inflating: hateful_memes/img/02937.png  \n",
            "  inflating: hateful_memes/img/72816.png  \n",
            "  inflating: hateful_memes/img/18469.png  \n",
            "  inflating: hateful_memes/img/31892.png  \n",
            "  inflating: hateful_memes/img/23075.png  \n",
            "  inflating: hateful_memes/img/17263.png  \n",
            "  inflating: hateful_memes/img/84120.png  \n",
            "  inflating: hateful_memes/img/93578.png  \n",
            "  inflating: hateful_memes/img/75102.png  \n",
            "  inflating: hateful_memes/img/17248.png  \n",
            "  inflating: hateful_memes/img/72956.png  \n",
            "  inflating: hateful_memes/img/16780.png  \n",
            "  inflating: hateful_memes/img/92573.png  \n",
            "  inflating: hateful_memes/img/86139.png  \n",
            "  inflating: hateful_memes/img/10976.png  \n",
            "  inflating: hateful_memes/img/04892.png  \n",
            "  inflating: hateful_memes/img/35869.png  \n",
            "  inflating: hateful_memes/img/60173.png  \n",
            "  inflating: hateful_memes/img/75981.png  \n",
            "  inflating: hateful_memes/img/52738.png  \n",
            "  inflating: hateful_memes/img/05461.png  \n",
            "  inflating: hateful_memes/img/45739.png  \n",
            "  inflating: hateful_memes/img/04782.png  \n",
            "  inflating: hateful_memes/img/23841.png  \n",
            "  inflating: hateful_memes/img/65741.png  \n",
            "  inflating: hateful_memes/img/30569.png  \n",
            "  inflating: hateful_memes/img/67913.png  \n",
            "  inflating: hateful_memes/img/19384.png  \n",
            "  inflating: hateful_memes/img/81630.png  \n",
            "  inflating: hateful_memes/img/62094.png  \n",
            "  inflating: hateful_memes/img/90524.png  \n",
            "  inflating: hateful_memes/img/71649.png  \n",
            "  inflating: hateful_memes/img/46721.png  \n",
            "  inflating: hateful_memes/img/25710.png  \n",
            "  inflating: hateful_memes/img/34965.png  \n",
            "  inflating: hateful_memes/img/46735.png  \n",
            "  inflating: hateful_memes/img/03568.png  \n",
            "  inflating: hateful_memes/img/31957.png  \n",
            "  inflating: hateful_memes/img/23508.png  \n",
            "  inflating: hateful_memes/img/52431.png  \n",
            "  inflating: hateful_memes/img/28507.png  \n",
            "  inflating: hateful_memes/img/96524.png  \n",
            "  inflating: hateful_memes/img/54391.png  \n",
            "  inflating: hateful_memes/img/47189.png  \n",
            "  inflating: hateful_memes/img/19203.png  \n",
            "  inflating: hateful_memes/img/62934.png  \n",
            "  inflating: hateful_memes/img/27580.png  \n",
            "  inflating: hateful_memes/img/04798.png  \n",
            "  inflating: hateful_memes/img/24061.png  \n",
            "  inflating: hateful_memes/img/45307.png  \n",
            "  inflating: hateful_memes/img/01578.png  \n",
            "  inflating: hateful_memes/img/03692.png  \n",
            "  inflating: hateful_memes/img/08925.png  \n",
            "  inflating: hateful_memes/img/84316.png  \n",
            "  inflating: hateful_memes/img/14067.png  \n",
            "  inflating: hateful_memes/img/01527.png  \n",
            "  inflating: hateful_memes/img/01576.png  \n",
            "  inflating: hateful_memes/img/56104.png  \n",
            "  inflating: hateful_memes/img/17645.png  \n",
            "  inflating: hateful_memes/img/81093.png  \n",
            "  inflating: hateful_memes/img/23046.png  \n",
            "  inflating: hateful_memes/img/29345.png  \n",
            "  inflating: hateful_memes/img/71845.png  \n",
            "  inflating: hateful_memes/img/43691.png  \n",
            "  inflating: hateful_memes/img/56790.png  \n",
            "  inflating: hateful_memes/img/65234.png  \n",
            "  inflating: hateful_memes/img/59130.png  \n",
            "  inflating: hateful_memes/img/58036.png  \n",
            "  inflating: hateful_memes/img/91563.png  \n",
            "  inflating: hateful_memes/img/56291.png  \n",
            "  inflating: hateful_memes/img/76402.png  \n",
            "  inflating: hateful_memes/img/82714.png  \n",
            "  inflating: hateful_memes/img/72910.png  \n",
            "  inflating: hateful_memes/img/45930.png  \n",
            "  inflating: hateful_memes/img/14865.png  \n",
            "  inflating: hateful_memes/img/43701.png  \n",
            "  inflating: hateful_memes/img/65347.png  \n",
            "  inflating: hateful_memes/img/34178.png  \n",
            "  inflating: hateful_memes/img/15749.png  \n",
            "  inflating: hateful_memes/img/10649.png  \n",
            "  inflating: hateful_memes/img/62941.png  \n",
            "  inflating: hateful_memes/img/13287.png  \n",
            "  inflating: hateful_memes/img/47862.png  \n",
            "  inflating: hateful_memes/img/43125.png  \n",
            "  inflating: hateful_memes/img/17652.png  \n",
            "  inflating: hateful_memes/img/97053.png  \n",
            "  inflating: hateful_memes/img/47136.png  \n",
            "  inflating: hateful_memes/img/59402.png  \n",
            "  inflating: hateful_memes/img/16054.png  \n",
            "  inflating: hateful_memes/img/67193.png  \n",
            "  inflating: hateful_memes/img/12547.png  \n",
            "  inflating: hateful_memes/img/13876.png  \n",
            "  inflating: hateful_memes/img/98735.png  \n",
            "  inflating: hateful_memes/img/82437.png  \n",
            "  inflating: hateful_memes/img/63479.png  \n",
            "  inflating: hateful_memes/img/85796.png  \n",
            "  inflating: hateful_memes/img/07452.png  \n",
            "  inflating: hateful_memes/img/30764.png  \n",
            "  inflating: hateful_memes/img/43956.png  \n",
            "  inflating: hateful_memes/img/29178.png  \n",
            "  inflating: hateful_memes/img/75039.png  \n",
            "  inflating: hateful_memes/img/86705.png  \n",
            "  inflating: hateful_memes/img/26837.png  \n",
            "  inflating: hateful_memes/img/30162.png  \n",
            "  inflating: hateful_memes/img/82596.png  \n",
            "  inflating: hateful_memes/img/73956.png  \n",
            "  inflating: hateful_memes/img/50748.png  \n",
            "  inflating: hateful_memes/img/49075.png  \n",
            "  inflating: hateful_memes/img/08937.png  \n",
            "  inflating: hateful_memes/img/08924.png  \n",
            "  inflating: hateful_memes/img/05468.png  \n",
            "  inflating: hateful_memes/img/56912.png  \n",
            "  inflating: hateful_memes/img/84150.png  \n",
            "  inflating: hateful_memes/img/16490.png  \n",
            "  inflating: hateful_memes/img/08269.png  \n",
            "  inflating: hateful_memes/img/68527.png  \n",
            "  inflating: hateful_memes/img/96514.png  \n",
            "  inflating: hateful_memes/img/47913.png  \n",
            "  inflating: hateful_memes/img/17934.png  \n",
            "  inflating: hateful_memes/img/92375.png  \n",
            "  inflating: hateful_memes/img/39528.png  \n",
            "  inflating: hateful_memes/img/58694.png  \n",
            "  inflating: hateful_memes/img/76398.png  \n",
            "  inflating: hateful_memes/img/01465.png  \n",
            "  inflating: hateful_memes/img/54930.png  \n",
            "  inflating: hateful_memes/img/32876.png  \n",
            "  inflating: hateful_memes/img/73154.png  \n",
            "  inflating: hateful_memes/img/71364.png  \n",
            "  inflating: hateful_memes/img/75608.png  \n",
            "  inflating: hateful_memes/img/61274.png  \n",
            "  inflating: hateful_memes/img/50198.png  \n",
            "  inflating: hateful_memes/img/17908.png  \n",
            "  inflating: hateful_memes/img/16593.png  \n",
            "  inflating: hateful_memes/img/78214.png  \n",
            "  inflating: hateful_memes/img/60439.png  \n",
            "  inflating: hateful_memes/img/47369.png  \n",
            "  inflating: hateful_memes/img/65127.png  \n",
            "  inflating: hateful_memes/img/34502.png  \n",
            "  inflating: hateful_memes/img/29508.png  \n",
            "  inflating: hateful_memes/img/93610.png  \n",
            "  inflating: hateful_memes/img/76825.png  \n",
            "  inflating: hateful_memes/img/68751.png  \n",
            "  inflating: hateful_memes/img/73681.png  \n",
            "  inflating: hateful_memes/img/68519.png  \n",
            "  inflating: hateful_memes/img/50823.png  \n",
            "  inflating: hateful_memes/img/52801.png  \n",
            "  inflating: hateful_memes/img/26418.png  \n",
            "  inflating: hateful_memes/img/94786.png  \n",
            "  inflating: hateful_memes/img/31690.png  \n",
            "  inflating: hateful_memes/img/14896.png  \n",
            "  inflating: hateful_memes/img/08621.png  \n",
            "  inflating: hateful_memes/img/93046.png  \n",
            "  inflating: hateful_memes/img/84307.png  \n",
            "  inflating: hateful_memes/img/48957.png  \n",
            "  inflating: hateful_memes/img/52783.png  \n",
            "  inflating: hateful_memes/img/60451.png  \n",
            "  inflating: hateful_memes/img/13679.png  \n",
            "  inflating: hateful_memes/img/57681.png  \n",
            "  inflating: hateful_memes/img/49602.png  \n",
            "  inflating: hateful_memes/img/06712.png  \n",
            "  inflating: hateful_memes/img/28394.png  \n",
            "  inflating: hateful_memes/img/61793.png  \n",
            "  inflating: hateful_memes/img/16892.png  \n",
            "  inflating: hateful_memes/img/37185.png  \n",
            "  inflating: hateful_memes/img/15479.png  \n",
            "  inflating: hateful_memes/img/31526.png  \n",
            "  inflating: hateful_memes/img/80521.png  \n",
            "  inflating: hateful_memes/img/03271.png  \n",
            "  inflating: hateful_memes/img/10537.png  \n",
            "  inflating: hateful_memes/img/42579.png  \n",
            "  inflating: hateful_memes/img/69804.png  \n",
            "  inflating: hateful_memes/img/93015.png  \n",
            "  inflating: hateful_memes/img/50427.png  \n",
            "  inflating: hateful_memes/img/05479.png  \n",
            "  inflating: hateful_memes/img/40865.png  \n",
            "  inflating: hateful_memes/img/36749.png  \n",
            "  inflating: hateful_memes/img/12754.png  \n",
            "  inflating: hateful_memes/img/95263.png  \n",
            "  inflating: hateful_memes/img/18267.png  \n",
            "  inflating: hateful_memes/img/92768.png  \n",
            "  inflating: hateful_memes/img/49120.png  \n",
            "  inflating: hateful_memes/img/49213.png  \n",
            "  inflating: hateful_memes/img/47620.png  \n",
            "  inflating: hateful_memes/img/43207.png  \n",
            "  inflating: hateful_memes/img/07248.png  \n",
            "  inflating: hateful_memes/img/97601.png  \n",
            "  inflating: hateful_memes/img/98724.png  \n",
            "  inflating: hateful_memes/img/40982.png  \n",
            "  inflating: hateful_memes/img/70512.png  \n",
            "  inflating: hateful_memes/img/03581.png  \n",
            "  inflating: hateful_memes/img/98075.png  \n",
            "  inflating: hateful_memes/img/79024.png  \n",
            "  inflating: hateful_memes/img/01793.png  \n",
            "  inflating: hateful_memes/img/78492.png  \n",
            "  inflating: hateful_memes/img/67384.png  \n",
            "  inflating: hateful_memes/img/70654.png  \n",
            "  inflating: hateful_memes/img/18207.png  \n",
            "  inflating: hateful_memes/img/09841.png  \n",
            "  inflating: hateful_memes/img/28935.png  \n",
            "  inflating: hateful_memes/img/04726.png  \n",
            "  inflating: hateful_memes/img/78624.png  \n",
            "  inflating: hateful_memes/img/52097.png  \n",
            "  inflating: hateful_memes/img/08567.png  \n",
            "  inflating: hateful_memes/img/89275.png  \n",
            "  inflating: hateful_memes/img/53624.png  \n",
            "  inflating: hateful_memes/img/35780.png  \n",
            "  inflating: hateful_memes/img/93216.png  \n",
            "  inflating: hateful_memes/img/32415.png  \n",
            "  inflating: hateful_memes/img/10652.png  \n",
            "  inflating: hateful_memes/img/21698.png  \n",
            "  inflating: hateful_memes/img/71320.png  \n",
            "  inflating: hateful_memes/img/09623.png  \n",
            "  inflating: hateful_memes/img/83127.png  \n",
            "  inflating: hateful_memes/img/24395.png  \n",
            "  inflating: hateful_memes/img/52780.png  \n",
            "  inflating: hateful_memes/img/48579.png  \n",
            "  inflating: hateful_memes/img/79610.png  \n",
            "  inflating: hateful_memes/img/72563.png  \n",
            "  inflating: hateful_memes/img/42736.png  \n",
            "  inflating: hateful_memes/img/52469.png  \n",
            "  inflating: hateful_memes/img/08769.png  \n",
            "  inflating: hateful_memes/img/38654.png  \n",
            "  inflating: hateful_memes/img/07438.png  \n",
            "  inflating: hateful_memes/img/14893.png  \n",
            "  inflating: hateful_memes/img/58197.png  \n",
            "  inflating: hateful_memes/img/52603.png  \n",
            "  inflating: hateful_memes/img/04295.png  \n",
            "  inflating: hateful_memes/img/63985.png  \n",
            "  inflating: hateful_memes/img/65108.png  \n",
            "  inflating: hateful_memes/img/67801.png  \n",
            "  inflating: hateful_memes/img/25709.png  \n",
            "  inflating: hateful_memes/img/78314.png  \n",
            "  inflating: hateful_memes/img/20876.png  \n",
            "  inflating: hateful_memes/img/76542.png  \n",
            "  inflating: hateful_memes/img/47912.png  \n",
            "  inflating: hateful_memes/img/63105.png  \n",
            "  inflating: hateful_memes/img/73965.png  \n",
            "  inflating: hateful_memes/img/84639.png  \n",
            "  inflating: hateful_memes/img/75382.png  \n",
            "  inflating: hateful_memes/img/85274.png  \n",
            "  inflating: hateful_memes/img/07354.png  \n",
            "  inflating: hateful_memes/img/02581.png  \n",
            "  inflating: hateful_memes/img/35860.png  \n",
            "  inflating: hateful_memes/img/09174.png  \n",
            "  inflating: hateful_memes/img/64081.png  \n",
            "  inflating: hateful_memes/img/31072.png  \n",
            "  inflating: hateful_memes/img/20513.png  \n",
            "  inflating: hateful_memes/img/83024.png  \n",
            "  inflating: hateful_memes/img/91754.png  \n",
            "  inflating: hateful_memes/img/90471.png  \n",
            "  inflating: hateful_memes/img/27963.png  \n",
            "  inflating: hateful_memes/img/02543.png  \n",
            "  inflating: hateful_memes/img/80319.png  \n",
            "  inflating: hateful_memes/img/90427.png  \n",
            "  inflating: hateful_memes/img/72698.png  \n",
            "  inflating: hateful_memes/img/40198.png  \n",
            "  inflating: hateful_memes/img/25397.png  \n",
            "  inflating: hateful_memes/img/16423.png  \n",
            "  inflating: hateful_memes/img/72598.png  \n",
            "  inflating: hateful_memes/img/65843.png  \n",
            "  inflating: hateful_memes/img/42816.png  \n",
            "  inflating: hateful_memes/img/61280.png  \n",
            "  inflating: hateful_memes/img/98621.png  \n",
            "  inflating: hateful_memes/img/58917.png  \n",
            "  inflating: hateful_memes/img/08524.png  \n",
            "  inflating: hateful_memes/img/42380.png  \n",
            "  inflating: hateful_memes/img/83649.png  \n",
            "  inflating: hateful_memes/img/87592.png  \n",
            "  inflating: hateful_memes/img/35470.png  \n",
            "  inflating: hateful_memes/img/74562.png  \n",
            "  inflating: hateful_memes/img/69304.png  \n",
            "  inflating: hateful_memes/img/10965.png  \n",
            "  inflating: hateful_memes/img/64310.png  \n",
            "  inflating: hateful_memes/img/08961.png  \n",
            "  inflating: hateful_memes/img/02486.png  \n",
            "  inflating: hateful_memes/img/19487.png  \n",
            "  inflating: hateful_memes/img/69873.png  \n",
            "  inflating: hateful_memes/img/80279.png  \n",
            "  inflating: hateful_memes/img/92167.png  \n",
            "  inflating: hateful_memes/img/14260.png  \n",
            "  inflating: hateful_memes/img/53876.png  \n",
            "  inflating: hateful_memes/img/62814.png  \n",
            "  inflating: hateful_memes/img/21078.png  \n",
            "  inflating: hateful_memes/img/06245.png  \n",
            "  inflating: hateful_memes/img/50894.png  \n",
            "  inflating: hateful_memes/img/95817.png  \n",
            "  inflating: hateful_memes/img/27369.png  \n",
            "  inflating: hateful_memes/img/93605.png  \n",
            "  inflating: hateful_memes/img/91056.png  \n",
            "  inflating: hateful_memes/img/14236.png  \n",
            "  inflating: hateful_memes/img/36970.png  \n",
            "  inflating: hateful_memes/img/71563.png  \n",
            "  inflating: hateful_memes/img/95813.png  \n",
            "  inflating: hateful_memes/img/74253.png  \n",
            "  inflating: hateful_memes/img/34072.png  \n",
            "  inflating: hateful_memes/img/40832.png  \n",
            "  inflating: hateful_memes/img/39527.png  \n",
            "  inflating: hateful_memes/img/01829.png  \n",
            "  inflating: hateful_memes/img/78450.png  \n",
            "  inflating: hateful_memes/img/42103.png  \n",
            "  inflating: hateful_memes/img/89406.png  \n",
            "  inflating: hateful_memes/img/69057.png  \n",
            "  inflating: hateful_memes/img/05327.png  \n",
            "  inflating: hateful_memes/img/21780.png  \n",
            "  inflating: hateful_memes/img/74368.png  \n",
            "  inflating: hateful_memes/img/86203.png  \n",
            "  inflating: hateful_memes/img/46872.png  \n",
            "  inflating: hateful_memes/img/07164.png  \n",
            "  inflating: hateful_memes/img/25481.png  \n",
            "  inflating: hateful_memes/img/92437.png  \n",
            "  inflating: hateful_memes/img/52708.png  \n",
            "  inflating: hateful_memes/img/23658.png  \n",
            "  inflating: hateful_memes/img/74206.png  \n",
            "  inflating: hateful_memes/img/16870.png  \n",
            "  inflating: hateful_memes/img/52874.png  \n",
            "  inflating: hateful_memes/img/70825.png  \n",
            "  inflating: hateful_memes/img/20867.png  \n",
            "  inflating: hateful_memes/img/64157.png  \n",
            "  inflating: hateful_memes/img/02471.png  \n",
            "  inflating: hateful_memes/img/73159.png  \n",
            "  inflating: hateful_memes/img/02987.png  \n",
            "  inflating: hateful_memes/img/26549.png  \n",
            "  inflating: hateful_memes/img/76015.png  \n",
            "  inflating: hateful_memes/img/54978.png  \n",
            "  inflating: hateful_memes/img/90657.png  \n",
            "  inflating: hateful_memes/img/94361.png  \n",
            "  inflating: hateful_memes/img/63491.png  \n",
            "  inflating: hateful_memes/img/89567.png  \n",
            "  inflating: hateful_memes/img/59237.png  \n",
            "  inflating: hateful_memes/img/72968.png  \n",
            "  inflating: hateful_memes/img/32564.png  \n",
            "  inflating: hateful_memes/img/25986.png  \n",
            "  inflating: hateful_memes/img/56187.png  \n",
            "  inflating: hateful_memes/img/87324.png  \n",
            "  inflating: hateful_memes/img/89137.png  \n",
            "  inflating: hateful_memes/img/28479.png  \n",
            "  inflating: hateful_memes/img/85204.png  \n",
            "  inflating: hateful_memes/img/42865.png  \n",
            "  inflating: hateful_memes/img/61928.png  \n",
            "  inflating: hateful_memes/img/05781.png  \n",
            "  inflating: hateful_memes/img/27864.png  \n",
            "  inflating: hateful_memes/img/47819.png  \n",
            "  inflating: hateful_memes/img/02683.png  \n",
            "  inflating: hateful_memes/img/07895.png  \n",
            "  inflating: hateful_memes/img/05841.png  \n",
            "  inflating: hateful_memes/img/60217.png  \n",
            "  inflating: hateful_memes/img/17458.png  \n",
            "  inflating: hateful_memes/img/87913.png  \n",
            "  inflating: hateful_memes/img/17843.png  \n",
            "  inflating: hateful_memes/img/46193.png  \n",
            "  inflating: hateful_memes/img/02764.png  \n",
            "  inflating: hateful_memes/img/80925.png  \n",
            "  inflating: hateful_memes/img/94162.png  \n",
            "  inflating: hateful_memes/img/97365.png  \n",
            "  inflating: hateful_memes/img/62093.png  \n",
            "  inflating: hateful_memes/img/57298.png  \n",
            "  inflating: hateful_memes/img/84692.png  \n",
            "  inflating: hateful_memes/img/02185.png  \n",
            "  inflating: hateful_memes/img/07853.png  \n",
            "  inflating: hateful_memes/img/68713.png  \n",
            "  inflating: hateful_memes/img/45082.png  \n",
            "  inflating: hateful_memes/img/38094.png  \n",
            "  inflating: hateful_memes/img/52746.png  \n",
            "  inflating: hateful_memes/img/82450.png  \n",
            "  inflating: hateful_memes/img/12560.png  \n",
            "  inflating: hateful_memes/img/47589.png  \n",
            "  inflating: hateful_memes/img/93548.png  \n",
            "  inflating: hateful_memes/img/39820.png  \n",
            "  inflating: hateful_memes/img/57284.png  \n",
            "  inflating: hateful_memes/img/85271.png  \n",
            "  inflating: hateful_memes/img/82301.png  \n",
            "  inflating: hateful_memes/img/42019.png  \n",
            "  inflating: hateful_memes/img/61932.png  \n",
            "  inflating: hateful_memes/img/36480.png  \n",
            "  inflating: hateful_memes/img/50934.png  \n",
            "  inflating: hateful_memes/img/53012.png  \n",
            "  inflating: hateful_memes/img/65203.png  \n",
            "  inflating: hateful_memes/img/76120.png  \n",
            "  inflating: hateful_memes/img/29863.png  \n",
            "  inflating: hateful_memes/img/78953.png  \n",
            "  inflating: hateful_memes/img/65107.png  \n",
            "  inflating: hateful_memes/img/51304.png  \n",
            "  inflating: hateful_memes/img/68921.png  \n",
            "  inflating: hateful_memes/img/06934.png  \n",
            "  inflating: hateful_memes/img/19256.png  \n",
            "  inflating: hateful_memes/img/76495.png  \n",
            "  inflating: hateful_memes/img/37621.png  \n",
            "  inflating: hateful_memes/img/34985.png  \n",
            "  inflating: hateful_memes/img/60823.png  \n",
            "  inflating: hateful_memes/img/97814.png  \n",
            "  inflating: hateful_memes/img/64905.png  \n",
            "  inflating: hateful_memes/img/85324.png  \n",
            "  inflating: hateful_memes/img/75403.png  \n",
            "  inflating: hateful_memes/img/25718.png  \n",
            "  inflating: hateful_memes/img/50768.png  \n",
            "  inflating: hateful_memes/img/24579.png  \n",
            "  inflating: hateful_memes/img/98670.png  \n",
            "  inflating: hateful_memes/img/96874.png  \n",
            "  inflating: hateful_memes/img/86205.png  \n",
            "  inflating: hateful_memes/img/45069.png  \n",
            "  inflating: hateful_memes/img/97832.png  \n",
            "  inflating: hateful_memes/img/49831.png  \n",
            "  inflating: hateful_memes/img/85190.png  \n",
            "  inflating: hateful_memes/img/01974.png  \n",
            "  inflating: hateful_memes/img/64130.png  \n",
            "  inflating: hateful_memes/img/96317.png  \n",
            "  inflating: hateful_memes/img/56210.png  \n",
            "  inflating: hateful_memes/img/80672.png  \n",
            "  inflating: hateful_memes/img/36281.png  \n",
            "  inflating: hateful_memes/img/04263.png  \n",
            "  inflating: hateful_memes/img/27153.png  \n",
            "  inflating: hateful_memes/img/35096.png  \n",
            "  inflating: hateful_memes/img/49635.png  \n",
            "  inflating: hateful_memes/img/25367.png  \n",
            "  inflating: hateful_memes/img/95203.png  \n",
            "  inflating: hateful_memes/img/79352.png  \n",
            "  inflating: hateful_memes/img/57319.png  \n",
            "  inflating: hateful_memes/img/61827.png  \n",
            "  inflating: hateful_memes/img/75816.png  \n",
            "  inflating: hateful_memes/img/68120.png  \n",
            "  inflating: hateful_memes/img/62107.png  \n",
            "  inflating: hateful_memes/img/41280.png  \n",
            "  inflating: hateful_memes/img/16430.png  \n",
            "  inflating: hateful_memes/img/04153.png  \n",
            "  inflating: hateful_memes/img/48052.png  \n",
            "  inflating: hateful_memes/img/74509.png  \n",
            "  inflating: hateful_memes/img/97624.png  \n",
            "  inflating: hateful_memes/img/83125.png  \n",
            "  inflating: hateful_memes/img/34581.png  \n",
            "  inflating: hateful_memes/img/36021.png  \n",
            "  inflating: hateful_memes/img/92514.png  \n",
            "  inflating: hateful_memes/img/59264.png  \n",
            "  inflating: hateful_memes/img/87290.png  \n",
            "  inflating: hateful_memes/img/30546.png  \n",
            "  inflating: hateful_memes/img/81679.png  \n",
            "  inflating: hateful_memes/img/35781.png  \n",
            "  inflating: hateful_memes/img/26439.png  \n",
            "  inflating: hateful_memes/img/49150.png  \n",
            "  inflating: hateful_memes/img/36470.png  \n",
            "  inflating: hateful_memes/img/14672.png  \n",
            "  inflating: hateful_memes/img/69528.png  \n",
            "  inflating: hateful_memes/img/35684.png  \n",
            "  inflating: hateful_memes/img/63075.png  \n",
            "  inflating: hateful_memes/img/23570.png  \n",
            "  inflating: hateful_memes/img/14238.png  \n",
            "  inflating: hateful_memes/img/73962.png  \n",
            "  inflating: hateful_memes/img/82674.png  \n",
            "  inflating: hateful_memes/img/25719.png  \n",
            "  inflating: hateful_memes/img/95764.png  \n",
            "  inflating: hateful_memes/img/70395.png  \n",
            "  inflating: hateful_memes/img/03612.png  \n",
            "  inflating: hateful_memes/img/51073.png  \n",
            "  inflating: hateful_memes/img/16824.png  \n",
            "  inflating: hateful_memes/img/31059.png  \n",
            "  inflating: hateful_memes/img/70294.png  \n",
            "  inflating: hateful_memes/img/97562.png  \n",
            "  inflating: hateful_memes/img/52476.png  \n",
            "  inflating: hateful_memes/img/53820.png  \n",
            "  inflating: hateful_memes/img/23619.png  \n",
            "  inflating: hateful_memes/img/36508.png  \n",
            "  inflating: hateful_memes/img/56723.png  \n",
            "  inflating: hateful_memes/img/41728.png  \n",
            "  inflating: hateful_memes/img/35907.png  \n",
            "  inflating: hateful_memes/img/37465.png  \n",
            "  inflating: hateful_memes/img/16807.png  \n",
            "  inflating: hateful_memes/img/73601.png  \n",
            "  inflating: hateful_memes/img/92418.png  \n",
            "  inflating: hateful_memes/img/56712.png  \n",
            "  inflating: hateful_memes/img/16385.png  \n",
            "  inflating: hateful_memes/img/89436.png  \n",
            "  inflating: hateful_memes/img/76132.png  \n",
            "  inflating: hateful_memes/img/69380.png  \n",
            "  inflating: hateful_memes/img/75146.png  \n",
            "  inflating: hateful_memes/img/97621.png  \n",
            "  inflating: hateful_memes/img/05768.png  \n",
            "  inflating: hateful_memes/img/03718.png  \n",
            "  inflating: hateful_memes/img/92038.png  \n",
            "  inflating: hateful_memes/img/26914.png  \n",
            "  inflating: hateful_memes/img/69078.png  \n",
            "  inflating: hateful_memes/img/13857.png  \n",
            "  inflating: hateful_memes/img/01694.png  \n",
            "  inflating: hateful_memes/img/09765.png  \n",
            "  inflating: hateful_memes/img/06153.png  \n",
            "  inflating: hateful_memes/img/05142.png  \n",
            "  inflating: hateful_memes/img/36915.png  \n",
            "  inflating: hateful_memes/img/12957.png  \n",
            "  inflating: hateful_memes/img/72541.png  \n",
            "  inflating: hateful_memes/img/97051.png  \n",
            "  inflating: hateful_memes/img/69032.png  \n",
            "  inflating: hateful_memes/img/39851.png  \n",
            "  inflating: hateful_memes/img/20538.png  \n",
            "  inflating: hateful_memes/img/64701.png  \n",
            "  inflating: hateful_memes/img/56243.png  \n",
            "  inflating: hateful_memes/img/73562.png  \n",
            "  inflating: hateful_memes/img/57962.png  \n",
            "  inflating: hateful_memes/img/67180.png  \n",
            "  inflating: hateful_memes/img/93284.png  \n",
            "  inflating: hateful_memes/img/92680.png  \n",
            "  inflating: hateful_memes/img/23715.png  \n",
            "  inflating: hateful_memes/img/34628.png  \n",
            "  inflating: hateful_memes/img/06731.png  \n",
            "  inflating: hateful_memes/img/34910.png  \n",
            "  inflating: hateful_memes/img/53609.png  \n",
            "  inflating: hateful_memes/img/73152.png  \n",
            "  inflating: hateful_memes/img/05832.png  \n",
            "  inflating: hateful_memes/img/80154.png  \n",
            "  inflating: hateful_memes/img/36248.png  \n",
            "  inflating: hateful_memes/img/16052.png  \n",
            "  inflating: hateful_memes/img/34598.png  \n",
            "  inflating: hateful_memes/img/29635.png  \n",
            "  inflating: hateful_memes/img/45810.png  \n",
            "  inflating: hateful_memes/img/21530.png  \n",
            "  inflating: hateful_memes/img/85741.png  \n",
            "  inflating: hateful_memes/img/06825.png  \n",
            "  inflating: hateful_memes/img/47159.png  \n",
            "  inflating: hateful_memes/img/20543.png  \n",
            "  inflating: hateful_memes/img/87126.png  \n",
            "  inflating: hateful_memes/img/71624.png  \n",
            "  inflating: hateful_memes/img/49752.png  \n",
            "  inflating: hateful_memes/img/51862.png  \n",
            "  inflating: hateful_memes/img/94608.png  \n",
            "  inflating: hateful_memes/img/39085.png  \n",
            "  inflating: hateful_memes/img/25830.png  \n",
            "  inflating: hateful_memes/img/46879.png  \n",
            "  inflating: hateful_memes/img/75320.png  \n",
            "  inflating: hateful_memes/img/47506.png  \n",
            "  inflating: hateful_memes/img/16370.png  \n",
            "  inflating: hateful_memes/img/83547.png  \n",
            "  inflating: hateful_memes/img/62974.png  \n",
            "  inflating: hateful_memes/img/07965.png  \n",
            "  inflating: hateful_memes/img/46870.png  \n",
            "  inflating: hateful_memes/img/74810.png  \n",
            "  inflating: hateful_memes/img/23690.png  \n",
            "  inflating: hateful_memes/img/78913.png  \n",
            "  inflating: hateful_memes/img/30185.png  \n",
            "  inflating: hateful_memes/img/49630.png  \n",
            "  inflating: hateful_memes/img/76298.png  \n",
            "  inflating: hateful_memes/img/87620.png  \n",
            "  inflating: hateful_memes/img/50674.png  \n",
            "  inflating: hateful_memes/img/74508.png  \n",
            "  inflating: hateful_memes/img/57348.png  \n",
            "  inflating: hateful_memes/img/76214.png  \n",
            "  inflating: hateful_memes/img/16579.png  \n",
            "  inflating: hateful_memes/img/72984.png  \n",
            "  inflating: hateful_memes/img/15632.png  \n",
            "  inflating: hateful_memes/img/81720.png  \n",
            "  inflating: hateful_memes/img/87219.png  \n",
            "  inflating: hateful_memes/img/32897.png  \n",
            "  inflating: hateful_memes/img/38129.png  \n",
            "  inflating: hateful_memes/img/84017.png  \n",
            "  inflating: hateful_memes/img/13528.png  \n",
            "  inflating: hateful_memes/img/94650.png  \n",
            "  inflating: hateful_memes/img/98374.png  \n",
            "  inflating: hateful_memes/img/89613.png  \n",
            "  inflating: hateful_memes/img/63250.png  \n",
            "  inflating: hateful_memes/img/69327.png  \n",
            "  inflating: hateful_memes/img/78239.png  \n",
            "  inflating: hateful_memes/img/05917.png  \n",
            "  inflating: hateful_memes/img/03984.png  \n",
            "  inflating: hateful_memes/img/35861.png  \n",
            "  inflating: hateful_memes/img/20984.png  \n",
            "  inflating: hateful_memes/img/13457.png  \n",
            "  inflating: hateful_memes/img/89063.png  \n",
            "  inflating: hateful_memes/img/67543.png  \n",
            "  inflating: hateful_memes/img/92741.png  \n",
            "  inflating: hateful_memes/img/39624.png  \n",
            "  inflating: hateful_memes/img/86504.png  \n",
            "  inflating: hateful_memes/img/24135.png  \n",
            "  inflating: hateful_memes/img/15927.png  \n",
            "  inflating: hateful_memes/img/97128.png  \n",
            "  inflating: hateful_memes/img/06842.png  \n",
            "  inflating: hateful_memes/img/05872.png  \n",
            "  inflating: hateful_memes/img/17845.png  \n",
            "  inflating: hateful_memes/img/46920.png  \n",
            "  inflating: hateful_memes/img/23504.png  \n",
            "  inflating: hateful_memes/img/92640.png  \n",
            "  inflating: hateful_memes/img/19730.png  \n",
            "  inflating: hateful_memes/img/98345.png  \n",
            "  inflating: hateful_memes/img/12650.png  \n",
            "  inflating: hateful_memes/img/68742.png  \n",
            "  inflating: hateful_memes/img/07134.png  \n",
            "  inflating: hateful_memes/img/96517.png  \n",
            "  inflating: hateful_memes/img/89512.png  \n",
            "  inflating: hateful_memes/img/31709.png  \n",
            "  inflating: hateful_memes/img/19386.png  \n",
            "  inflating: hateful_memes/img/62351.png  \n",
            "  inflating: hateful_memes/img/84032.png  \n",
            "  inflating: hateful_memes/img/29503.png  \n",
            "  inflating: hateful_memes/img/71035.png  \n",
            "  inflating: hateful_memes/img/47015.png  \n",
            "  inflating: hateful_memes/img/19634.png  \n",
            "  inflating: hateful_memes/img/10853.png  \n",
            "  inflating: hateful_memes/img/23794.png  \n",
            "  inflating: hateful_memes/img/86250.png  \n",
            "  inflating: hateful_memes/img/36592.png  \n",
            "  inflating: hateful_memes/img/08794.png  \n",
            "  inflating: hateful_memes/img/36521.png  \n",
            "  inflating: hateful_memes/img/80251.png  \n",
            "  inflating: hateful_memes/img/02158.png  \n",
            "  inflating: hateful_memes/img/08917.png  \n",
            "  inflating: hateful_memes/img/26930.png  \n",
            "  inflating: hateful_memes/img/37296.png  \n",
            "  inflating: hateful_memes/img/70132.png  \n",
            "  inflating: hateful_memes/img/19873.png  \n",
            "  inflating: hateful_memes/img/32695.png  \n",
            "  inflating: hateful_memes/img/16439.png  \n",
            "  inflating: hateful_memes/img/53187.png  \n",
            "  inflating: hateful_memes/img/04175.png  \n",
            "  inflating: hateful_memes/img/03524.png  \n",
            "  inflating: hateful_memes/img/65124.png  \n",
            "  inflating: hateful_memes/img/21354.png  \n",
            "  inflating: hateful_memes/img/90847.png  \n",
            "  inflating: hateful_memes/img/23154.png  \n",
            "  inflating: hateful_memes/img/14523.png  \n",
            "  inflating: hateful_memes/img/17453.png  \n",
            "  inflating: hateful_memes/img/90875.png  \n",
            "  inflating: hateful_memes/img/31645.png  \n",
            "  inflating: hateful_memes/img/92160.png  \n",
            "  inflating: hateful_memes/img/42810.png  \n",
            "  inflating: hateful_memes/img/10254.png  \n",
            "  inflating: hateful_memes/img/70492.png  \n",
            "  inflating: hateful_memes/img/10723.png  \n",
            "  inflating: hateful_memes/img/80947.png  \n",
            "  inflating: hateful_memes/img/65832.png  \n",
            "  inflating: hateful_memes/img/70341.png  \n",
            "  inflating: hateful_memes/img/49716.png  \n",
            "  inflating: hateful_memes/img/60972.png  \n",
            "  inflating: hateful_memes/img/89042.png  \n",
            "  inflating: hateful_memes/img/02169.png  \n",
            "  inflating: hateful_memes/img/76321.png  \n",
            "  inflating: hateful_memes/img/94185.png  \n",
            "  inflating: hateful_memes/img/39076.png  \n",
            "  inflating: hateful_memes/img/75192.png  \n",
            "  inflating: hateful_memes/img/34795.png  \n",
            "  inflating: hateful_memes/img/30928.png  \n",
            "  inflating: hateful_memes/img/81245.png  \n",
            "  inflating: hateful_memes/img/08172.png  \n",
            "  inflating: hateful_memes/img/31824.png  \n",
            "  inflating: hateful_memes/img/23164.png  \n",
            "  inflating: hateful_memes/img/15394.png  \n",
            "  inflating: hateful_memes/img/62514.png  \n",
            "  inflating: hateful_memes/img/07259.png  \n",
            "  inflating: hateful_memes/img/67852.png  \n",
            "  inflating: hateful_memes/img/20835.png  \n",
            "  inflating: hateful_memes/img/70435.png  \n",
            "  inflating: hateful_memes/img/81625.png  \n",
            "  inflating: hateful_memes/img/75682.png  \n",
            "  inflating: hateful_memes/img/19523.png  \n",
            "  inflating: hateful_memes/img/85421.png  \n",
            "  inflating: hateful_memes/img/16048.png  \n",
            "  inflating: hateful_memes/img/46813.png  \n",
            "  inflating: hateful_memes/img/48617.png  \n",
            "  inflating: hateful_memes/img/54236.png  \n",
            "  inflating: hateful_memes/img/47931.png  \n",
            "  inflating: hateful_memes/img/90827.png  \n",
            "  inflating: hateful_memes/img/96583.png  \n",
            "  inflating: hateful_memes/img/61537.png  \n",
            "  inflating: hateful_memes/img/40239.png  \n",
            "  inflating: hateful_memes/img/78459.png  \n",
            "  inflating: hateful_memes/img/10938.png  \n",
            "  inflating: hateful_memes/img/21650.png  \n",
            "  inflating: hateful_memes/img/82940.png  \n",
            "  inflating: hateful_memes/img/54310.png  \n",
            "  inflating: hateful_memes/img/72146.png  \n",
            "  inflating: hateful_memes/img/32941.png  \n",
            "  inflating: hateful_memes/img/84317.png  \n",
            "  inflating: hateful_memes/img/29348.png  \n",
            "  inflating: hateful_memes/img/72610.png  \n",
            "  inflating: hateful_memes/img/64385.png  \n",
            "  inflating: hateful_memes/img/24651.png  \n",
            "  inflating: hateful_memes/img/13042.png  \n",
            "  inflating: hateful_memes/img/02879.png  \n",
            "  inflating: hateful_memes/img/74096.png  \n",
            "  inflating: hateful_memes/img/72193.png  \n",
            "  inflating: hateful_memes/img/42093.png  \n",
            "  inflating: hateful_memes/img/91648.png  \n",
            "  inflating: hateful_memes/img/58367.png  \n",
            "  inflating: hateful_memes/img/57849.png  \n",
            "  inflating: hateful_memes/img/54962.png  \n",
            "  inflating: hateful_memes/img/58310.png  \n",
            "  inflating: hateful_memes/img/65034.png  \n",
            "  inflating: hateful_memes/img/97506.png  \n",
            "  inflating: hateful_memes/img/97238.png  \n",
            "  inflating: hateful_memes/img/75602.png  \n",
            "  inflating: hateful_memes/img/75392.png  \n",
            "  inflating: hateful_memes/img/04728.png  \n",
            "  inflating: hateful_memes/img/95278.png  \n",
            "  inflating: hateful_memes/img/85642.png  \n",
            "  inflating: hateful_memes/img/60123.png  \n",
            "  inflating: hateful_memes/img/06148.png  \n",
            "  inflating: hateful_memes/img/20936.png  \n",
            "  inflating: hateful_memes/img/19845.png  \n",
            "  inflating: hateful_memes/img/38251.png  \n",
            "  inflating: hateful_memes/img/64539.png  \n",
            "  inflating: hateful_memes/img/76842.png  \n",
            "  inflating: hateful_memes/img/13570.png  \n",
            "  inflating: hateful_memes/img/39427.png  \n",
            "  inflating: hateful_memes/img/12750.png  \n",
            "  inflating: hateful_memes/img/95184.png  \n",
            "  inflating: hateful_memes/img/17495.png  \n",
            "  inflating: hateful_memes/img/41597.png  \n",
            "  inflating: hateful_memes/img/20615.png  \n",
            "  inflating: hateful_memes/img/38046.png  \n",
            "  inflating: hateful_memes/img/23056.png  \n",
            "  inflating: hateful_memes/img/94870.png  \n",
            "  inflating: hateful_memes/img/30246.png  \n",
            "  inflating: hateful_memes/img/57034.png  \n",
            "  inflating: hateful_memes/img/13576.png  \n",
            "  inflating: hateful_memes/img/54801.png  \n",
            "  inflating: hateful_memes/img/89324.png  \n",
            "  inflating: hateful_memes/img/20691.png  \n",
            "  inflating: hateful_memes/img/42897.png  \n",
            "  inflating: hateful_memes/img/69548.png  \n",
            "  inflating: hateful_memes/img/58901.png  \n",
            "  inflating: hateful_memes/img/13650.png  \n",
            "  inflating: hateful_memes/img/91367.png  \n",
            "  inflating: hateful_memes/img/40621.png  \n",
            "  inflating: hateful_memes/img/75160.png  \n",
            "  inflating: hateful_memes/img/02768.png  \n",
            "  inflating: hateful_memes/img/89435.png  \n",
            "  inflating: hateful_memes/img/39612.png  \n",
            "  inflating: hateful_memes/img/83476.png  \n",
            "  inflating: hateful_memes/img/16059.png  \n",
            "  inflating: hateful_memes/img/32698.png  \n",
            "  inflating: hateful_memes/img/10582.png  \n",
            "  inflating: hateful_memes/img/80759.png  \n",
            "  inflating: hateful_memes/img/89741.png  \n",
            "  inflating: hateful_memes/img/38210.png  \n",
            "  inflating: hateful_memes/img/12793.png  \n",
            "  inflating: hateful_memes/img/64215.png  \n",
            "  inflating: hateful_memes/img/63509.png  \n",
            "  inflating: hateful_memes/img/17894.png  \n",
            "  inflating: hateful_memes/img/89532.png  \n",
            "  inflating: hateful_memes/img/63908.png  \n",
            "  inflating: hateful_memes/img/47609.png  \n",
            "  inflating: hateful_memes/img/32791.png  \n",
            "  inflating: hateful_memes/img/75380.png  \n",
            "  inflating: hateful_memes/img/19065.png  \n",
            "  inflating: hateful_memes/img/16280.png  \n",
            "  inflating: hateful_memes/img/36718.png  \n",
            "  inflating: hateful_memes/img/06439.png  \n",
            "  inflating: hateful_memes/img/07652.png  \n",
            "  inflating: hateful_memes/img/04918.png  \n",
            "  inflating: hateful_memes/img/59860.png  \n",
            "  inflating: hateful_memes/img/81439.png  \n",
            "  inflating: hateful_memes/img/83756.png  \n",
            "  inflating: hateful_memes/img/69017.png  \n",
            "  inflating: hateful_memes/img/52386.png  \n",
            "  inflating: hateful_memes/img/36821.png  \n",
            "  inflating: hateful_memes/img/53691.png  \n",
            "  inflating: hateful_memes/img/63784.png  \n",
            "  inflating: hateful_memes/img/86920.png  \n",
            "  inflating: hateful_memes/img/32640.png  \n",
            "  inflating: hateful_memes/img/95062.png  \n",
            "  inflating: hateful_memes/img/79325.png  \n",
            "  inflating: hateful_memes/img/92317.png  \n",
            "  inflating: hateful_memes/img/60427.png  \n",
            "  inflating: hateful_memes/img/50743.png  \n",
            "  inflating: hateful_memes/img/46537.png  \n",
            "  inflating: hateful_memes/img/83527.png  \n",
            "  inflating: hateful_memes/img/05728.png  \n",
            "  inflating: hateful_memes/img/05471.png  \n",
            "  inflating: hateful_memes/img/64051.png  \n",
            "  inflating: hateful_memes/img/24783.png  \n",
            "  inflating: hateful_memes/img/60193.png  \n",
            "  inflating: hateful_memes/img/41607.png  \n",
            "  inflating: hateful_memes/img/37601.png  \n",
            "  inflating: hateful_memes/img/02691.png  \n",
            "  inflating: hateful_memes/img/58260.png  \n",
            "  inflating: hateful_memes/img/67250.png  \n",
            "  inflating: hateful_memes/img/29354.png  \n",
            "  inflating: hateful_memes/img/31657.png  \n",
            "  inflating: hateful_memes/img/76548.png  \n",
            "  inflating: hateful_memes/img/98523.png  \n",
            "  inflating: hateful_memes/img/82760.png  \n",
            "  inflating: hateful_memes/img/03591.png  \n",
            "  inflating: hateful_memes/img/65809.png  \n",
            "  inflating: hateful_memes/img/35967.png  \n",
            "  inflating: hateful_memes/img/90175.png  \n",
            "  inflating: hateful_memes/img/35840.png  \n",
            "  inflating: hateful_memes/img/32647.png  \n",
            "  inflating: hateful_memes/img/41605.png  \n",
            "  inflating: hateful_memes/img/70564.png  \n",
            "  inflating: hateful_memes/img/42953.png  \n",
            "  inflating: hateful_memes/img/30154.png  \n",
            "  inflating: hateful_memes/img/41768.png  \n",
            "  inflating: hateful_memes/img/07315.png  \n",
            "  inflating: hateful_memes/img/68204.png  \n",
            "  inflating: hateful_memes/img/70189.png  \n",
            "  inflating: hateful_memes/img/41057.png  \n",
            "  inflating: hateful_memes/img/31485.png  \n",
            "  inflating: hateful_memes/img/53418.png  \n",
            "  inflating: hateful_memes/img/87320.png  \n",
            "  inflating: hateful_memes/img/45231.png  \n",
            "  inflating: hateful_memes/img/64137.png  \n",
            "  inflating: hateful_memes/img/64283.png  \n",
            "  inflating: hateful_memes/img/86173.png  \n",
            "  inflating: hateful_memes/img/82964.png  \n",
            "  inflating: hateful_memes/img/74361.png  \n",
            "  inflating: hateful_memes/img/48196.png  \n",
            "  inflating: hateful_memes/img/96340.png  \n",
            "  inflating: hateful_memes/img/43271.png  \n",
            "  inflating: hateful_memes/img/94576.png  \n",
            "  inflating: hateful_memes/img/16758.png  \n",
            "  inflating: hateful_memes/img/09316.png  \n",
            "  inflating: hateful_memes/img/42786.png  \n",
            "  inflating: hateful_memes/img/69127.png  \n",
            "  inflating: hateful_memes/img/35490.png  \n",
            "  inflating: hateful_memes/img/75138.png  \n",
            "  inflating: hateful_memes/img/75810.png  \n",
            "  inflating: hateful_memes/img/14276.png  \n",
            "  inflating: hateful_memes/img/97583.png  \n",
            "  inflating: hateful_memes/img/27986.png  \n",
            "  inflating: hateful_memes/img/47309.png  \n",
            "  inflating: hateful_memes/img/74016.png  \n",
            "  inflating: hateful_memes/img/97143.png  \n",
            "  inflating: hateful_memes/img/25097.png  \n",
            "  inflating: hateful_memes/img/23047.png  \n",
            "  inflating: hateful_memes/img/84970.png  \n",
            "  inflating: hateful_memes/img/02149.png  \n",
            "  inflating: hateful_memes/img/91527.png  \n",
            "  inflating: hateful_memes/img/69845.png  \n",
            "  inflating: hateful_memes/img/05928.png  \n",
            "  inflating: hateful_memes/img/34291.png  \n",
            "  inflating: hateful_memes/img/56942.png  \n",
            "  inflating: hateful_memes/img/42153.png  \n",
            "  inflating: hateful_memes/img/76953.png  \n",
            "  inflating: hateful_memes/img/80629.png  \n",
            "  inflating: hateful_memes/img/97520.png  \n",
            "  inflating: hateful_memes/img/90826.png  \n",
            "  inflating: hateful_memes/img/97836.png  \n",
            "  inflating: hateful_memes/img/70231.png  \n",
            "  inflating: hateful_memes/img/76539.png  \n",
            "  inflating: hateful_memes/img/62483.png  \n",
            "  inflating: hateful_memes/img/32701.png  \n",
            "  inflating: hateful_memes/img/96382.png  \n",
            "  inflating: hateful_memes/img/02317.png  \n",
            "  inflating: hateful_memes/img/92483.png  \n",
            "  inflating: hateful_memes/img/87169.png  \n",
            "  inflating: hateful_memes/img/46231.png  \n",
            "  inflating: hateful_memes/img/32416.png  \n",
            "  inflating: hateful_memes/img/40862.png  \n",
            "  inflating: hateful_memes/img/68549.png  \n",
            "  inflating: hateful_memes/img/71042.png  \n",
            "  inflating: hateful_memes/img/83207.png  \n",
            "  inflating: hateful_memes/img/19306.png  \n",
            "  inflating: hateful_memes/img/19653.png  \n",
            "  inflating: hateful_memes/img/08941.png  \n",
            "  inflating: hateful_memes/img/16538.png  \n",
            "  inflating: hateful_memes/img/30915.png  \n",
            "  inflating: hateful_memes/img/48315.png  \n",
            "  inflating: hateful_memes/img/06329.png  \n",
            "  inflating: hateful_memes/img/23519.png  \n",
            "  inflating: hateful_memes/img/84516.png  \n",
            "  inflating: hateful_memes/img/80512.png  \n",
            "  inflating: hateful_memes/img/75216.png  \n",
            "  inflating: hateful_memes/img/78231.png  \n",
            "  inflating: hateful_memes/img/27845.png  \n",
            "  inflating: hateful_memes/img/14263.png  \n",
            "  inflating: hateful_memes/img/50638.png  \n",
            "  inflating: hateful_memes/img/48329.png  \n",
            "  inflating: hateful_memes/img/72864.png  \n",
            "  inflating: hateful_memes/img/64279.png  \n",
            "  inflating: hateful_memes/img/53607.png  \n",
            "  inflating: hateful_memes/img/53089.png  \n",
            "  inflating: hateful_memes/img/69427.png  \n",
            "  inflating: hateful_memes/img/01823.png  \n",
            "  inflating: hateful_memes/img/83257.png  \n",
            "  inflating: hateful_memes/img/57986.png  \n",
            "  inflating: hateful_memes/img/34591.png  \n",
            "  inflating: hateful_memes/img/23197.png  \n",
            "  inflating: hateful_memes/img/52804.png  \n",
            "  inflating: hateful_memes/img/75960.png  \n",
            "  inflating: hateful_memes/img/54137.png  \n",
            "  inflating: hateful_memes/img/91487.png  \n",
            "  inflating: hateful_memes/img/42986.png  \n",
            "  inflating: hateful_memes/img/36982.png  \n",
            "  inflating: hateful_memes/img/61549.png  \n",
            "  inflating: hateful_memes/img/71260.png  \n",
            "  inflating: hateful_memes/img/07392.png  \n",
            "  inflating: hateful_memes/img/70315.png  \n",
            "  inflating: hateful_memes/img/72914.png  \n",
            "  inflating: hateful_memes/img/42853.png  \n",
            "  inflating: hateful_memes/img/61385.png  \n",
            "  inflating: hateful_memes/img/96204.png  \n",
            "  inflating: hateful_memes/img/32691.png  \n",
            "  inflating: hateful_memes/img/04719.png  \n",
            "  inflating: hateful_memes/img/56497.png  \n",
            "  inflating: hateful_memes/img/58476.png  \n",
            "  inflating: hateful_memes/img/45320.png  \n",
            "  inflating: hateful_memes/img/50491.png  \n",
            "  inflating: hateful_memes/img/48205.png  \n",
            "  inflating: hateful_memes/img/98437.png  \n",
            "  inflating: hateful_memes/img/13567.png  \n",
            "  inflating: hateful_memes/img/42813.png  \n",
            "  inflating: hateful_memes/img/43920.png  \n",
            "  inflating: hateful_memes/img/51278.png  \n",
            "  inflating: hateful_memes/img/47605.png  \n",
            "  inflating: hateful_memes/img/04265.png  \n",
            "  inflating: hateful_memes/img/42987.png  \n",
            "  inflating: hateful_memes/img/25780.png  \n",
            "  inflating: hateful_memes/img/14769.png  \n",
            "  inflating: hateful_memes/img/15746.png  \n",
            "  inflating: hateful_memes/img/82701.png  \n",
            "  inflating: hateful_memes/img/71032.png  \n",
            "  inflating: hateful_memes/img/04879.png  \n",
            "  inflating: hateful_memes/img/51802.png  \n",
            "  inflating: hateful_memes/img/79103.png  \n",
            "  inflating: hateful_memes/img/94138.png  \n",
            "  inflating: hateful_memes/img/04971.png  \n",
            "  inflating: hateful_memes/img/56302.png  \n",
            "  inflating: hateful_memes/img/14059.png  \n",
            "  inflating: hateful_memes/img/60913.png  \n",
            "  inflating: hateful_memes/img/20791.png  \n",
            "  inflating: hateful_memes/img/09263.png  \n",
            "  inflating: hateful_memes/img/15324.png  \n",
            "  inflating: hateful_memes/img/07893.png  \n",
            "  inflating: hateful_memes/img/14968.png  \n",
            "  inflating: hateful_memes/img/69087.png  \n",
            "  inflating: hateful_memes/img/86751.png  \n",
            "  inflating: hateful_memes/img/70592.png  \n",
            "  inflating: hateful_memes/img/98637.png  \n",
            "  inflating: hateful_memes/img/93084.png  \n",
            "  inflating: hateful_memes/img/67413.png  \n",
            "  inflating: hateful_memes/img/07693.png  \n",
            "  inflating: hateful_memes/img/37592.png  \n",
            "  inflating: hateful_memes/img/47593.png  \n",
            "  inflating: hateful_memes/img/18257.png  \n",
            "  inflating: hateful_memes/img/96174.png  \n",
            "  inflating: hateful_memes/img/37198.png  \n",
            "  inflating: hateful_memes/img/80941.png  \n",
            "  inflating: hateful_memes/img/05769.png  \n",
            "  inflating: hateful_memes/img/51849.png  \n",
            "  inflating: hateful_memes/img/20634.png  \n",
            "  inflating: hateful_memes/img/04362.png  \n",
            "  inflating: hateful_memes/img/18679.png  \n",
            "  inflating: hateful_memes/img/42015.png  \n",
            "  inflating: hateful_memes/img/56273.png  \n",
            "  inflating: hateful_memes/img/09572.png  \n",
            "  inflating: hateful_memes/img/60527.png  \n",
            "  inflating: hateful_memes/img/05273.png  \n",
            "  inflating: hateful_memes/img/08451.png  \n",
            "  inflating: hateful_memes/img/92308.png  \n",
            "  inflating: hateful_memes/img/31042.png  \n",
            "  inflating: hateful_memes/img/06584.png  \n",
            "  inflating: hateful_memes/img/48635.png  \n",
            "  inflating: hateful_memes/img/79032.png  \n",
            "  inflating: hateful_memes/img/20786.png  \n",
            "  inflating: hateful_memes/img/51368.png  \n",
            "  inflating: hateful_memes/img/94356.png  \n",
            "  inflating: hateful_memes/img/57914.png  \n",
            "  inflating: hateful_memes/img/89632.png  \n",
            "  inflating: hateful_memes/img/34658.png  \n",
            "  inflating: hateful_memes/img/62135.png  \n",
            "  inflating: hateful_memes/img/27805.png  \n",
            "  inflating: hateful_memes/img/79406.png  \n",
            "  inflating: hateful_memes/img/64327.png  \n",
            "  inflating: hateful_memes/img/25904.png  \n",
            "  inflating: hateful_memes/img/45831.png  \n",
            "  inflating: hateful_memes/img/86394.png  \n",
            "  inflating: hateful_memes/img/98271.png  \n",
            "  inflating: hateful_memes/img/68179.png  \n",
            "  inflating: hateful_memes/img/43175.png  \n",
            "  inflating: hateful_memes/img/76253.png  \n",
            "  inflating: hateful_memes/img/28461.png  \n",
            "  inflating: hateful_memes/img/03876.png  \n",
            "  inflating: hateful_memes/img/26378.png  \n",
            "  inflating: hateful_memes/img/46831.png  \n",
            "  inflating: hateful_memes/img/09247.png  \n",
            "  inflating: hateful_memes/img/37420.png  \n",
            "  inflating: hateful_memes/img/17268.png  \n",
            "  inflating: hateful_memes/img/08241.png  \n",
            "  inflating: hateful_memes/img/53941.png  \n",
            "  inflating: hateful_memes/img/25971.png  \n",
            "  inflating: hateful_memes/img/34067.png  \n",
            "  inflating: hateful_memes/img/42860.png  \n",
            "  inflating: hateful_memes/img/98543.png  \n",
            "  inflating: hateful_memes/img/07241.png  \n",
            "  inflating: hateful_memes/img/95086.png  \n",
            "  inflating: hateful_memes/img/39164.png  \n",
            "  inflating: hateful_memes/img/76342.png  \n",
            "  inflating: hateful_memes/img/03928.png  \n",
            "  inflating: hateful_memes/img/92157.png  \n",
            "  inflating: hateful_memes/img/16289.png  \n",
            "  inflating: hateful_memes/img/25368.png  \n",
            "  inflating: hateful_memes/img/74198.png  \n",
            "  inflating: hateful_memes/img/03957.png  \n",
            "  inflating: hateful_memes/img/59623.png  \n",
            "  inflating: hateful_memes/img/57462.png  \n",
            "  inflating: hateful_memes/img/80162.png  \n",
            "  inflating: hateful_memes/img/45379.png  \n",
            "  inflating: hateful_memes/img/84536.png  \n",
            "  inflating: hateful_memes/img/84052.png  \n",
            "  inflating: hateful_memes/img/52068.png  \n",
            "  inflating: hateful_memes/img/63057.png  \n",
            "  inflating: hateful_memes/img/32189.png  \n",
            "  inflating: hateful_memes/img/75362.png  \n",
            "  inflating: hateful_memes/img/86934.png  \n",
            "  inflating: hateful_memes/img/02943.png  \n",
            "  inflating: hateful_memes/img/80916.png  \n",
            "  inflating: hateful_memes/img/40231.png  \n",
            "  inflating: hateful_memes/img/89245.png  \n",
            "  inflating: hateful_memes/img/86179.png  \n",
            "  inflating: hateful_memes/img/34510.png  \n",
            "  inflating: hateful_memes/img/98517.png  \n",
            "  inflating: hateful_memes/img/65740.png  \n",
            "  inflating: hateful_memes/img/65429.png  \n",
            "  inflating: hateful_memes/img/39871.png  \n",
            "  inflating: hateful_memes/img/51682.png  \n",
            "  inflating: hateful_memes/img/02634.png  \n",
            "  inflating: hateful_memes/img/91375.png  \n",
            "  inflating: hateful_memes/img/04897.png  \n",
            "  inflating: hateful_memes/img/14520.png  \n",
            "  inflating: hateful_memes/img/89106.png  \n",
            "  inflating: hateful_memes/img/34065.png  \n",
            "  inflating: hateful_memes/img/61730.png  \n",
            "  inflating: hateful_memes/img/27059.png  \n",
            "  inflating: hateful_memes/img/45708.png  \n",
            "  inflating: hateful_memes/img/69018.png  \n",
            "  inflating: hateful_memes/img/90345.png  \n",
            "  inflating: hateful_memes/img/50341.png  \n",
            "  inflating: hateful_memes/img/13792.png  \n",
            "  inflating: hateful_memes/img/32704.png  \n",
            "  inflating: hateful_memes/img/41538.png  \n",
            "  inflating: hateful_memes/img/91847.png  \n",
            "  inflating: hateful_memes/img/72839.png  \n",
            "  inflating: hateful_memes/img/07649.png  \n",
            "  inflating: hateful_memes/img/87904.png  \n",
            "  inflating: hateful_memes/img/87326.png  \n",
            "  inflating: hateful_memes/img/03125.png  \n",
            "  inflating: hateful_memes/img/71249.png  \n",
            "  inflating: hateful_memes/img/38156.png  \n",
            "  inflating: hateful_memes/img/52316.png  \n",
            "  inflating: hateful_memes/img/83152.png  \n",
            "  inflating: hateful_memes/img/41263.png  \n",
            "  inflating: hateful_memes/img/38072.png  \n",
            "  inflating: hateful_memes/img/72408.png  \n",
            "  inflating: hateful_memes/img/06237.png  \n",
            "  inflating: hateful_memes/img/97512.png  \n",
            "  inflating: hateful_memes/img/64329.png  \n",
            "  inflating: hateful_memes/img/80379.png  \n",
            "  inflating: hateful_memes/img/74923.png  \n",
            "  inflating: hateful_memes/img/78190.png  \n",
            "  inflating: hateful_memes/img/63270.png  \n",
            "  inflating: hateful_memes/img/70845.png  \n",
            "  inflating: hateful_memes/img/09187.png  \n",
            "  inflating: hateful_memes/img/14362.png  \n",
            "  inflating: hateful_memes/img/02156.png  \n",
            "  inflating: hateful_memes/img/75421.png  \n",
            "  inflating: hateful_memes/img/30196.png  \n",
            "  inflating: hateful_memes/img/21704.png  \n",
            "  inflating: hateful_memes/img/10396.png  \n",
            "  inflating: hateful_memes/img/53872.png  \n",
            "  inflating: hateful_memes/img/79368.png  \n",
            "  inflating: hateful_memes/img/46178.png  \n",
            "  inflating: hateful_memes/img/46127.png  \n",
            "  inflating: hateful_memes/img/56738.png  \n",
            "  inflating: hateful_memes/img/83427.png  \n",
            "  inflating: hateful_memes/img/69042.png  \n",
            "  inflating: hateful_memes/img/39281.png  \n",
            "  inflating: hateful_memes/img/60841.png  \n",
            "  inflating: hateful_memes/img/08741.png  \n",
            "  inflating: hateful_memes/img/97860.png  \n",
            "  inflating: hateful_memes/img/91423.png  \n",
            "  inflating: hateful_memes/img/38912.png  \n",
            "  inflating: hateful_memes/img/63920.png  \n",
            "  inflating: hateful_memes/img/50489.png  \n",
            "  inflating: hateful_memes/img/86572.png  \n",
            "  inflating: hateful_memes/img/75482.png  \n",
            "  inflating: hateful_memes/img/13624.png  \n",
            "  inflating: hateful_memes/img/10398.png  \n",
            "  inflating: hateful_memes/img/04569.png  \n",
            "  inflating: hateful_memes/img/74513.png  \n",
            "  inflating: hateful_memes/img/81497.png  \n",
            "  inflating: hateful_memes/img/80537.png  \n",
            "  inflating: hateful_memes/img/49673.png  \n",
            "  inflating: hateful_memes/img/03751.png  \n",
            "  inflating: hateful_memes/img/71983.png  \n",
            "  inflating: hateful_memes/img/72451.png  \n",
            "  inflating: hateful_memes/img/34079.png  \n",
            "  inflating: hateful_memes/img/37429.png  \n",
            "  inflating: hateful_memes/img/48536.png  \n",
            "  inflating: hateful_memes/img/43612.png  \n",
            "  inflating: hateful_memes/img/84927.png  \n",
            "  inflating: hateful_memes/img/89432.png  \n",
            "  inflating: hateful_memes/img/49028.png  \n",
            "  inflating: hateful_memes/img/93786.png  \n",
            "  inflating: hateful_memes/img/45630.png  \n",
            "  inflating: hateful_memes/img/72390.png  \n",
            "  inflating: hateful_memes/img/70356.png  \n",
            "  inflating: hateful_memes/img/42571.png  \n",
            "  inflating: hateful_memes/img/93086.png  \n",
            "  inflating: hateful_memes/img/63124.png  \n",
            "  inflating: hateful_memes/img/92534.png  \n",
            "  inflating: hateful_memes/img/78405.png  \n",
            "  inflating: hateful_memes/img/41308.png  \n",
            "  inflating: hateful_memes/img/19682.png  \n",
            "  inflating: hateful_memes/img/68304.png  \n",
            "  inflating: hateful_memes/img/20957.png  \n",
            "  inflating: hateful_memes/img/95683.png  \n",
            "  inflating: hateful_memes/img/18940.png  \n",
            "  inflating: hateful_memes/img/26185.png  \n",
            "  inflating: hateful_memes/img/71506.png  \n",
            "  inflating: hateful_memes/img/34785.png  \n",
            "  inflating: hateful_memes/img/98751.png  \n",
            "  inflating: hateful_memes/img/60937.png  \n",
            "  inflating: hateful_memes/img/03256.png  \n",
            "  inflating: hateful_memes/img/13620.png  \n",
            "  inflating: hateful_memes/img/13748.png  \n",
            "  inflating: hateful_memes/img/84971.png  \n",
            "  inflating: hateful_memes/img/52031.png  \n",
            "  inflating: hateful_memes/img/54179.png  \n",
            "  inflating: hateful_memes/img/12604.png  \n",
            "  inflating: hateful_memes/img/85473.png  \n",
            "  inflating: hateful_memes/img/18593.png  \n",
            "  inflating: hateful_memes/img/86540.png  \n",
            "  inflating: hateful_memes/img/35724.png  \n",
            "  inflating: hateful_memes/img/65708.png  \n",
            "  inflating: hateful_memes/img/78915.png  \n",
            "  inflating: hateful_memes/img/63017.png  \n",
            "  inflating: hateful_memes/img/65432.png  \n",
            "  inflating: hateful_memes/img/29481.png  \n",
            "  inflating: hateful_memes/img/97213.png  \n",
            "  inflating: hateful_memes/img/29574.png  \n",
            "  inflating: hateful_memes/img/10926.png  \n",
            "  inflating: hateful_memes/img/75142.png  \n",
            "  inflating: hateful_memes/img/60238.png  \n",
            "  inflating: hateful_memes/img/38019.png  \n",
            "  inflating: hateful_memes/img/84107.png  \n",
            "  inflating: hateful_memes/img/85413.png  \n",
            "  inflating: hateful_memes/img/69014.png  \n",
            "  inflating: hateful_memes/img/87520.png  \n",
            "  inflating: hateful_memes/img/98427.png  \n",
            "  inflating: hateful_memes/img/74310.png  \n",
            "  inflating: hateful_memes/img/87902.png  \n",
            "  inflating: hateful_memes/img/53027.png  \n",
            "  inflating: hateful_memes/img/05462.png  \n",
            "  inflating: hateful_memes/img/30264.png  \n",
            "  inflating: hateful_memes/img/83954.png  \n",
            "  inflating: hateful_memes/img/26138.png  \n",
            "  inflating: hateful_memes/img/59714.png  \n",
            "  inflating: hateful_memes/img/10329.png  \n",
            "  inflating: hateful_memes/img/94738.png  \n",
            "  inflating: hateful_memes/img/94625.png  \n",
            "  inflating: hateful_memes/img/74132.png  \n",
            "  inflating: hateful_memes/img/35916.png  \n",
            "  inflating: hateful_memes/img/10784.png  \n",
            "  inflating: hateful_memes/img/94836.png  \n",
            "  inflating: hateful_memes/img/62307.png  \n",
            "  inflating: hateful_memes/img/58321.png  \n",
            "  inflating: hateful_memes/img/72306.png  \n",
            "  inflating: hateful_memes/img/12694.png  \n",
            "  inflating: hateful_memes/img/59478.png  \n",
            "  inflating: hateful_memes/img/36981.png  \n",
            "  inflating: hateful_memes/img/01423.png  \n",
            "  inflating: hateful_memes/img/27895.png  \n",
            "  inflating: hateful_memes/img/45817.png  \n",
            "  inflating: hateful_memes/img/70948.png  \n",
            "  inflating: hateful_memes/img/32657.png  \n",
            "  inflating: hateful_memes/img/46295.png  \n",
            "  inflating: hateful_memes/img/07689.png  \n",
            "  inflating: hateful_memes/img/39478.png  \n",
            "  inflating: hateful_memes/img/12608.png  \n",
            "  inflating: hateful_memes/img/96258.png  \n",
            "  inflating: hateful_memes/img/67138.png  \n",
            "  inflating: hateful_memes/img/93528.png  \n",
            "  inflating: hateful_memes/img/85394.png  \n",
            "  inflating: hateful_memes/img/69751.png  \n",
            "  inflating: hateful_memes/img/50237.png  \n",
            "  inflating: hateful_memes/img/59301.png  \n",
            "  inflating: hateful_memes/img/16845.png  \n",
            "  inflating: hateful_memes/img/89371.png  \n",
            "  inflating: hateful_memes/img/68349.png  \n",
            "  inflating: hateful_memes/img/09413.png  \n",
            "  inflating: hateful_memes/img/05421.png  \n",
            "  inflating: hateful_memes/img/19532.png  \n",
            "  inflating: hateful_memes/img/62085.png  \n",
            "  inflating: hateful_memes/img/68923.png  \n",
            "  inflating: hateful_memes/img/35412.png  \n",
            "  inflating: hateful_memes/img/94651.png  \n",
            "  inflating: hateful_memes/img/14872.png  \n",
            "  inflating: hateful_memes/img/21083.png  \n",
            "  inflating: hateful_memes/img/17953.png  \n",
            "  inflating: hateful_memes/img/27856.png  \n",
            "  inflating: hateful_memes/img/29873.png  \n",
            "  inflating: hateful_memes/img/67983.png  \n",
            "  inflating: hateful_memes/img/74825.png  \n",
            "  inflating: hateful_memes/img/68294.png  \n",
            "  inflating: hateful_memes/img/10389.png  \n",
            "  inflating: hateful_memes/img/96104.png  \n",
            "  inflating: hateful_memes/img/87695.png  \n",
            "  inflating: hateful_memes/img/03124.png  \n",
            "  inflating: hateful_memes/img/14589.png  \n",
            "  inflating: hateful_memes/img/75801.png  \n",
            "  inflating: hateful_memes/img/42653.png  \n",
            "  inflating: hateful_memes/img/57814.png  \n",
            "  inflating: hateful_memes/img/02475.png  \n",
            "  inflating: hateful_memes/img/46730.png  \n",
            "  inflating: hateful_memes/img/70614.png  \n",
            "  inflating: hateful_memes/img/80126.png  \n",
            "  inflating: hateful_memes/img/34016.png  \n",
            "  inflating: hateful_memes/img/32485.png  \n",
            "  inflating: hateful_memes/img/31024.png  \n",
            "  inflating: hateful_memes/img/24306.png  \n",
            "  inflating: hateful_memes/img/63078.png  \n",
            "  inflating: hateful_memes/img/85216.png  \n",
            "  inflating: hateful_memes/img/73205.png  \n",
            "  inflating: hateful_memes/img/71856.png  \n",
            "  inflating: hateful_memes/img/51497.png  \n",
            "  inflating: hateful_memes/img/93405.png  \n",
            "  inflating: hateful_memes/img/82549.png  \n",
            "  inflating: hateful_memes/img/43725.png  \n",
            "  inflating: hateful_memes/img/13697.png  \n",
            "  inflating: hateful_memes/img/56491.png  \n",
            "  inflating: hateful_memes/img/21479.png  \n",
            "  inflating: hateful_memes/img/54812.png  \n",
            "  inflating: hateful_memes/img/74930.png  \n",
            "  inflating: hateful_memes/img/32794.png  \n",
            "  inflating: hateful_memes/img/74298.png  \n",
            "  inflating: hateful_memes/img/56419.png  \n",
            "  inflating: hateful_memes/img/68390.png  \n",
            "  inflating: hateful_memes/img/68745.png  \n",
            "  inflating: hateful_memes/img/23957.png  \n",
            "  inflating: hateful_memes/img/80593.png  \n",
            "  inflating: hateful_memes/img/61234.png  \n",
            "  inflating: hateful_memes/img/28973.png  \n",
            "  inflating: hateful_memes/img/97023.png  \n",
            "  inflating: hateful_memes/img/08469.png  \n",
            "  inflating: hateful_memes/img/34825.png  \n",
            "  inflating: hateful_memes/img/87064.png  \n",
            "  inflating: hateful_memes/img/01682.png  \n",
            "  inflating: hateful_memes/img/52837.png  \n",
            "  inflating: hateful_memes/img/49608.png  \n",
            "  inflating: hateful_memes/img/39704.png  \n",
            "  inflating: hateful_memes/img/16903.png  \n",
            "  inflating: hateful_memes/img/39041.png  \n",
            "  inflating: hateful_memes/img/98547.png  \n",
            "  inflating: hateful_memes/img/16302.png  \n",
            "  inflating: hateful_memes/img/83150.png  \n",
            "  inflating: hateful_memes/img/02793.png  \n",
            "  inflating: hateful_memes/img/86417.png  \n",
            "  inflating: hateful_memes/img/48069.png  \n",
            "  inflating: hateful_memes/img/57326.png  \n",
            "  inflating: hateful_memes/img/53064.png  \n",
            "  inflating: hateful_memes/img/41207.png  \n",
            "  inflating: hateful_memes/img/68374.png  \n",
            "  inflating: hateful_memes/img/51629.png  \n",
            "  inflating: hateful_memes/img/28601.png  \n",
            "  inflating: hateful_memes/img/36708.png  \n",
            "  inflating: hateful_memes/img/57426.png  \n",
            "  inflating: hateful_memes/img/39741.png  \n",
            "  inflating: hateful_memes/img/96380.png  \n",
            "  inflating: hateful_memes/img/38621.png  \n",
            "  inflating: hateful_memes/img/02763.png  \n",
            "  inflating: hateful_memes/img/14802.png  \n",
            "  inflating: hateful_memes/img/70136.png  \n",
            "  inflating: hateful_memes/img/57029.png  \n",
            "  inflating: hateful_memes/img/08943.png  \n",
            "  inflating: hateful_memes/img/62184.png  \n",
            "  inflating: hateful_memes/img/10834.png  \n",
            "  inflating: hateful_memes/img/15892.png  \n",
            "  inflating: hateful_memes/img/13908.png  \n",
            "  inflating: hateful_memes/img/92016.png  \n",
            "  inflating: hateful_memes/img/58906.png  \n",
            "  inflating: hateful_memes/img/14965.png  \n",
            "  inflating: hateful_memes/img/56107.png  \n",
            "  inflating: hateful_memes/img/59031.png  \n",
            "  inflating: hateful_memes/img/82501.png  \n",
            "  inflating: hateful_memes/img/98145.png  \n",
            "  inflating: hateful_memes/img/56327.png  \n",
            "  inflating: hateful_memes/img/81970.png  \n",
            "  inflating: hateful_memes/img/56328.png  \n",
            "  inflating: hateful_memes/img/46580.png  \n",
            "  inflating: hateful_memes/img/97635.png  \n",
            "  inflating: hateful_memes/img/19253.png  \n",
            "  inflating: hateful_memes/img/24716.png  \n",
            "  inflating: hateful_memes/img/96238.png  \n",
            "  inflating: hateful_memes/img/63129.png  \n",
            "  inflating: hateful_memes/img/93042.png  \n",
            "  inflating: hateful_memes/img/42391.png  \n",
            "  inflating: hateful_memes/img/90673.png  \n",
            "  inflating: hateful_memes/img/58916.png  \n",
            "  inflating: hateful_memes/img/63028.png  \n",
            "  inflating: hateful_memes/img/23498.png  \n",
            "  inflating: hateful_memes/img/24130.png  \n",
            "  inflating: hateful_memes/img/32798.png  \n",
            "  inflating: hateful_memes/img/30597.png  \n",
            "  inflating: hateful_memes/img/21869.png  \n",
            "  inflating: hateful_memes/img/76540.png  \n",
            "  inflating: hateful_memes/img/13572.png  \n",
            "  inflating: hateful_memes/img/91462.png  \n",
            "  inflating: hateful_memes/img/06147.png  \n",
            "  inflating: hateful_memes/img/42187.png  \n",
            "  inflating: hateful_memes/img/71439.png  \n",
            "  inflating: hateful_memes/img/08276.png  \n",
            "  inflating: hateful_memes/img/96235.png  \n",
            "  inflating: hateful_memes/img/82379.png  \n",
            "  inflating: hateful_memes/img/21048.png  \n",
            "  inflating: hateful_memes/img/18475.png  \n",
            "  inflating: hateful_memes/img/78401.png  \n",
            "  inflating: hateful_memes/img/69043.png  \n",
            "  inflating: hateful_memes/img/79681.png  \n",
            "  inflating: hateful_memes/img/78035.png  \n",
            "  inflating: hateful_memes/img/84321.png  \n",
            "  inflating: hateful_memes/img/32854.png  \n",
            "  inflating: hateful_memes/img/52304.png  \n",
            "  inflating: hateful_memes/img/53280.png  \n",
            "  inflating: hateful_memes/img/71903.png  \n",
            "  inflating: hateful_memes/img/79413.png  \n",
            "  inflating: hateful_memes/img/36174.png  \n",
            "  inflating: hateful_memes/img/97315.png  \n",
            "  inflating: hateful_memes/img/51738.png  \n",
            "  inflating: hateful_memes/img/53068.png  \n",
            "  inflating: hateful_memes/img/18942.png  \n",
            "  inflating: hateful_memes/img/25461.png  \n",
            "  inflating: hateful_memes/img/67594.png  \n",
            "  inflating: hateful_memes/img/17504.png  \n",
            "  inflating: hateful_memes/img/67538.png  \n",
            "  inflating: hateful_memes/img/70932.png  \n",
            "  inflating: hateful_memes/img/68429.png  \n",
            "  inflating: hateful_memes/img/82973.png  \n",
            "  inflating: hateful_memes/img/17536.png  \n",
            "  inflating: hateful_memes/img/62731.png  \n",
            "  inflating: hateful_memes/img/71628.png  \n",
            "  inflating: hateful_memes/img/19382.png  \n",
            "  inflating: hateful_memes/img/31987.png  \n",
            "  inflating: hateful_memes/img/03854.png  \n",
            "  inflating: hateful_memes/img/51283.png  \n",
            "  inflating: hateful_memes/img/89521.png  \n",
            "  inflating: hateful_memes/img/46078.png  \n",
            "  inflating: hateful_memes/img/67593.png  \n",
            "  inflating: hateful_memes/img/98321.png  \n",
            "  inflating: hateful_memes/img/61725.png  \n",
            "  inflating: hateful_memes/img/07839.png  \n",
            "  inflating: hateful_memes/img/89421.png  \n",
            "  inflating: hateful_memes/img/79150.png  \n",
            "  inflating: hateful_memes/img/69503.png  \n",
            "  inflating: hateful_memes/img/12967.png  \n",
            "  inflating: hateful_memes/img/45189.png  \n",
            "  inflating: hateful_memes/img/85476.png  \n",
            "  inflating: hateful_memes/img/14897.png  \n",
            "  inflating: hateful_memes/img/87234.png  \n",
            "  inflating: hateful_memes/img/47901.png  \n",
            "  inflating: hateful_memes/img/60973.png  \n",
            "  inflating: hateful_memes/img/97564.png  \n",
            "  inflating: hateful_memes/img/51768.png  \n",
            "  inflating: hateful_memes/img/04278.png  \n",
            "  inflating: hateful_memes/img/10492.png  \n",
            "  inflating: hateful_memes/img/60421.png  \n",
            "  inflating: hateful_memes/img/50126.png  \n",
            "  inflating: hateful_memes/img/05942.png  \n",
            "  inflating: hateful_memes/img/96057.png  \n",
            "  inflating: hateful_memes/img/83567.png  \n",
            "  inflating: hateful_memes/img/84270.png  \n",
            "  inflating: hateful_memes/img/69720.png  \n",
            "  inflating: hateful_memes/img/31920.png  \n",
            "  inflating: hateful_memes/img/15478.png  \n",
            "  inflating: hateful_memes/img/69815.png  \n",
            "  inflating: hateful_memes/img/93416.png  \n",
            "  inflating: hateful_memes/img/35104.png  \n",
            "  inflating: hateful_memes/img/25974.png  \n",
            "  inflating: hateful_memes/img/31074.png  \n",
            "  inflating: hateful_memes/img/09423.png  \n",
            "  inflating: hateful_memes/img/67142.png  \n",
            "  inflating: hateful_memes/img/13475.png  \n",
            "  inflating: hateful_memes/img/59321.png  \n",
            "  inflating: hateful_memes/img/05984.png  \n",
            "  inflating: hateful_memes/img/19705.png  \n",
            "  inflating: hateful_memes/img/26489.png  \n",
            "  inflating: hateful_memes/img/95780.png  \n",
            "  inflating: hateful_memes/img/25071.png  \n",
            "  inflating: hateful_memes/img/86910.png  \n",
            "  inflating: hateful_memes/img/37140.png  \n",
            "  inflating: hateful_memes/img/95421.png  \n",
            "  inflating: hateful_memes/img/58306.png  \n",
            "  inflating: hateful_memes/img/20341.png  \n",
            "  inflating: hateful_memes/img/96083.png  \n",
            "  inflating: hateful_memes/img/98276.png  \n",
            "  inflating: hateful_memes/img/65904.png  \n",
            "  inflating: hateful_memes/img/27603.png  \n",
            "  inflating: hateful_memes/img/26738.png  \n",
            "  inflating: hateful_memes/img/67190.png  \n",
            "  inflating: hateful_memes/img/76534.png  \n",
            "  inflating: hateful_memes/img/16354.png  \n",
            "  inflating: hateful_memes/img/57469.png  \n",
            "  inflating: hateful_memes/img/64901.png  \n",
            "  inflating: hateful_memes/img/10539.png  \n",
            "  inflating: hateful_memes/img/35298.png  \n",
            "  inflating: hateful_memes/img/27341.png  \n",
            "  inflating: hateful_memes/img/63578.png  \n",
            "  inflating: hateful_memes/img/41389.png  \n",
            "  inflating: hateful_memes/img/86453.png  \n",
            "  inflating: hateful_memes/img/08297.png  \n",
            "  inflating: hateful_memes/img/81972.png  \n",
            "  inflating: hateful_memes/img/10629.png  \n",
            "  inflating: hateful_memes/img/02146.png  \n",
            "  inflating: hateful_memes/img/70319.png  \n",
            "  inflating: hateful_memes/img/92617.png  \n",
            "  inflating: hateful_memes/img/48517.png  \n",
            "  inflating: hateful_memes/img/45203.png  \n",
            "  inflating: hateful_memes/img/82765.png  \n",
            "  inflating: hateful_memes/img/05918.png  \n",
            "  inflating: hateful_memes/img/52719.png  \n",
            "  inflating: hateful_memes/img/37680.png  \n",
            "  inflating: hateful_memes/img/15368.png  \n",
            "  inflating: hateful_memes/img/58341.png  \n",
            "  inflating: hateful_memes/img/79142.png  \n",
            "  inflating: hateful_memes/img/28674.png  \n",
            "  inflating: hateful_memes/img/31495.png  \n",
            "  inflating: hateful_memes/img/07826.png  \n",
            "  inflating: hateful_memes/img/58091.png  \n",
            "  inflating: hateful_memes/img/67841.png  \n",
            "  inflating: hateful_memes/img/42613.png  \n",
            "  inflating: hateful_memes/img/31752.png  \n",
            "  inflating: hateful_memes/img/25693.png  \n",
            "  inflating: hateful_memes/img/41506.png  \n",
            "  inflating: hateful_memes/img/95024.png  \n",
            "  inflating: hateful_memes/img/35806.png  \n",
            "  inflating: hateful_memes/img/82531.png  \n",
            "  inflating: hateful_memes/img/36751.png  \n",
            "  inflating: hateful_memes/img/40916.png  \n",
            "  inflating: hateful_memes/img/20745.png  \n",
            "  inflating: hateful_memes/img/34670.png  \n",
            "  inflating: hateful_memes/img/06453.png  \n",
            "  inflating: hateful_memes/img/17089.png  \n",
            "  inflating: hateful_memes/img/76932.png  \n",
            "  inflating: hateful_memes/img/95846.png  \n",
            "  inflating: hateful_memes/img/97524.png  \n",
            "  inflating: hateful_memes/img/25917.png  \n",
            "  inflating: hateful_memes/img/16470.png  \n",
            "  inflating: hateful_memes/img/06831.png  \n",
            "  inflating: hateful_memes/img/46302.png  \n",
            "  inflating: hateful_memes/img/64309.png  \n",
            "  inflating: hateful_memes/img/75108.png  \n",
            "  inflating: hateful_memes/img/57043.png  \n",
            "  inflating: hateful_memes/img/95487.png  \n",
            "  inflating: hateful_memes/img/67034.png  \n",
            "  inflating: hateful_memes/img/93502.png  \n",
            "  inflating: hateful_memes/img/07912.png  \n",
            "  inflating: hateful_memes/img/85947.png  \n",
            "  inflating: hateful_memes/img/09713.png  \n",
            "  inflating: hateful_memes/img/95087.png  \n",
            "  inflating: hateful_memes/img/72509.png  \n",
            "  inflating: hateful_memes/img/79124.png  \n",
            "  inflating: hateful_memes/img/14870.png  \n",
            "  inflating: hateful_memes/img/29785.png  \n",
            "  inflating: hateful_memes/img/08761.png  \n",
            "  inflating: hateful_memes/img/16240.png  \n",
            "  inflating: hateful_memes/img/13657.png  \n",
            "  inflating: hateful_memes/img/14750.png  \n",
            "  inflating: hateful_memes/img/27958.png  \n",
            "  inflating: hateful_memes/img/17254.png  \n",
            "  inflating: hateful_memes/img/14762.png  \n",
            "  inflating: hateful_memes/img/98632.png  \n",
            "  inflating: hateful_memes/img/20173.png  \n",
            "  inflating: hateful_memes/img/63185.png  \n",
            "  inflating: hateful_memes/img/89407.png  \n",
            "  inflating: hateful_memes/img/72519.png  \n",
            "  inflating: hateful_memes/img/71869.png  \n",
            "  inflating: hateful_memes/img/87539.png  \n",
            "  inflating: hateful_memes/img/26093.png  \n",
            "  inflating: hateful_memes/img/70123.png  \n",
            "  inflating: hateful_memes/img/72609.png  \n",
            "  inflating: hateful_memes/img/23048.png  \n",
            "  inflating: hateful_memes/img/58426.png  \n",
            "  inflating: hateful_memes/img/80652.png  \n",
            "  inflating: hateful_memes/img/68594.png  \n",
            "  inflating: hateful_memes/img/90481.png  \n",
            "  inflating: hateful_memes/img/07594.png  \n",
            "  inflating: hateful_memes/img/94172.png  \n",
            "  inflating: hateful_memes/img/29150.png  \n",
            "  inflating: hateful_memes/img/47180.png  \n",
            "  inflating: hateful_memes/img/32168.png  \n",
            "  inflating: hateful_memes/img/92075.png  \n",
            "  inflating: hateful_memes/img/54318.png  \n",
            "  inflating: hateful_memes/img/15064.png  \n",
            "  inflating: hateful_memes/img/02853.png  \n",
            "  inflating: hateful_memes/img/28970.png  \n",
            "  inflating: hateful_memes/img/90586.png  \n",
            "  inflating: hateful_memes/img/34807.png  \n",
            "  inflating: hateful_memes/img/43650.png  \n",
            "  inflating: hateful_memes/img/60589.png  \n",
            "  inflating: hateful_memes/img/45286.png  \n",
            "  inflating: hateful_memes/img/16275.png  \n",
            "  inflating: hateful_memes/img/68192.png  \n",
            "  inflating: hateful_memes/img/35924.png  \n",
            "  inflating: hateful_memes/img/72354.png  \n",
            "  inflating: hateful_memes/img/71206.png  \n",
            "  inflating: hateful_memes/img/70268.png  \n",
            "  inflating: hateful_memes/img/20819.png  \n",
            "  inflating: hateful_memes/img/94106.png  \n",
            "  inflating: hateful_memes/img/42861.png  \n",
            "  inflating: hateful_memes/img/94720.png  \n",
            "  inflating: hateful_memes/img/30186.png  \n",
            "  inflating: hateful_memes/img/09825.png  \n",
            "  inflating: hateful_memes/img/05276.png  \n",
            "  inflating: hateful_memes/img/18094.png  \n",
            "  inflating: hateful_memes/img/48652.png  \n",
            "  inflating: hateful_memes/img/02315.png  \n",
            "  inflating: hateful_memes/img/04398.png  \n",
            "  inflating: hateful_memes/img/02367.png  \n",
            "  inflating: hateful_memes/img/89574.png  \n",
            "  inflating: hateful_memes/img/80769.png  \n",
            "  inflating: hateful_memes/img/17590.png  \n",
            "  inflating: hateful_memes/img/10835.png  \n",
            "  inflating: hateful_memes/img/10479.png  \n",
            "  inflating: hateful_memes/img/16437.png  \n",
            "  inflating: hateful_memes/img/98426.png  \n",
            "  inflating: hateful_memes/img/40819.png  \n",
            "  inflating: hateful_memes/img/68154.png  \n",
            "  inflating: hateful_memes/img/30721.png  \n",
            "  inflating: hateful_memes/img/51903.png  \n",
            "  inflating: hateful_memes/img/56019.png  \n",
            "  inflating: hateful_memes/img/74892.png  \n",
            "  inflating: hateful_memes/img/06175.png  \n",
            "  inflating: hateful_memes/img/94205.png  \n",
            "  inflating: hateful_memes/img/69702.png  \n",
            "  inflating: hateful_memes/img/24106.png  \n",
            "  inflating: hateful_memes/img/48326.png  \n",
            "  inflating: hateful_memes/img/47529.png  \n",
            "  inflating: hateful_memes/img/29187.png  \n",
            "  inflating: hateful_memes/img/78659.png  \n",
            "  inflating: hateful_memes/img/43569.png  \n",
            "  inflating: hateful_memes/img/30756.png  \n",
            "  inflating: hateful_memes/img/06483.png  \n",
            "  inflating: hateful_memes/img/72340.png  \n",
            "  inflating: hateful_memes/img/39601.png  \n",
            "  inflating: hateful_memes/img/93462.png  \n",
            "  inflating: hateful_memes/img/70842.png  \n",
            "  inflating: hateful_memes/img/78215.png  \n",
            "  inflating: hateful_memes/img/67194.png  \n",
            "  inflating: hateful_memes/img/19678.png  \n",
            "  inflating: hateful_memes/img/78095.png  \n",
            "  inflating: hateful_memes/img/69731.png  \n",
            "  inflating: hateful_memes/img/10397.png  \n",
            "  inflating: hateful_memes/img/28690.png  \n",
            "  inflating: hateful_memes/img/69273.png  \n",
            "  inflating: hateful_memes/img/01264.png  \n",
            "  inflating: hateful_memes/img/85621.png  \n",
            "  inflating: hateful_memes/img/13964.png  \n",
            "  inflating: hateful_memes/img/75321.png  \n",
            "  inflating: hateful_memes/img/24865.png  \n",
            "  inflating: hateful_memes/img/78534.png  \n",
            "  inflating: hateful_memes/img/04568.png  \n",
            "  inflating: hateful_memes/img/96143.png  \n",
            "  inflating: hateful_memes/img/38764.png  \n",
            "  inflating: hateful_memes/img/73248.png  \n",
            "  inflating: hateful_memes/img/73596.png  \n",
            "  inflating: hateful_memes/img/83504.png  \n",
            "  inflating: hateful_memes/img/87420.png  \n",
            "  inflating: hateful_memes/img/51726.png  \n",
            "  inflating: hateful_memes/img/45216.png  \n",
            "  inflating: hateful_memes/img/80156.png  \n",
            "  inflating: hateful_memes/img/21347.png  \n",
            "  inflating: hateful_memes/img/40987.png  \n",
            "  inflating: hateful_memes/img/81239.png  \n",
            "  inflating: hateful_memes/img/74021.png  \n",
            "  inflating: hateful_memes/img/18074.png  \n",
            "  inflating: hateful_memes/img/25847.png  \n",
            "  inflating: hateful_memes/img/19758.png  \n",
            "  inflating: hateful_memes/img/19243.png  \n",
            "  inflating: hateful_memes/img/41358.png  \n",
            "  inflating: hateful_memes/img/04651.png  \n",
            "  inflating: hateful_memes/img/19840.png  \n",
            "  inflating: hateful_memes/img/82593.png  \n",
            "  inflating: hateful_memes/img/73964.png  \n",
            "  inflating: hateful_memes/img/04298.png  \n",
            "  inflating: hateful_memes/img/41250.png  \n",
            "  inflating: hateful_memes/img/67402.png  \n",
            "  inflating: hateful_memes/img/52168.png  \n",
            "  inflating: hateful_memes/img/25913.png  \n",
            "  inflating: hateful_memes/img/24653.png  \n",
            "  inflating: hateful_memes/img/38590.png  \n",
            "  inflating: hateful_memes/img/25408.png  \n",
            "  inflating: hateful_memes/img/59142.png  \n",
            "  inflating: hateful_memes/img/97263.png  \n",
            "  inflating: hateful_memes/img/24019.png  \n",
            "  inflating: hateful_memes/img/72814.png  \n",
            "  inflating: hateful_memes/img/42608.png  \n",
            "  inflating: hateful_memes/img/26813.png  \n",
            "  inflating: hateful_memes/img/98057.png  \n",
            "  inflating: hateful_memes/img/87016.png  \n",
            "  inflating: hateful_memes/img/58369.png  \n",
            "  inflating: hateful_memes/img/08641.png  \n",
            "  inflating: hateful_memes/img/02538.png  \n",
            "  inflating: hateful_memes/img/78542.png  \n",
            "  inflating: hateful_memes/img/68937.png  \n",
            "  inflating: hateful_memes/img/14859.png  \n",
            "  inflating: hateful_memes/img/13465.png  \n",
            "  inflating: hateful_memes/img/60917.png  \n",
            "  inflating: hateful_memes/img/36142.png  \n",
            "  inflating: hateful_memes/img/64803.png  \n",
            "  inflating: hateful_memes/img/18943.png  \n",
            "  inflating: hateful_memes/img/71892.png  \n",
            "  inflating: hateful_memes/img/69013.png  \n",
            "  inflating: hateful_memes/img/36415.png  \n",
            "  inflating: hateful_memes/img/13875.png  \n",
            "  inflating: hateful_memes/img/91403.png  \n",
            "  inflating: hateful_memes/img/67584.png  \n",
            "  inflating: hateful_memes/img/51783.png  \n",
            "  inflating: hateful_memes/img/98406.png  \n",
            "  inflating: hateful_memes/img/46238.png  \n",
            "  inflating: hateful_memes/img/82713.png  \n",
            "  inflating: hateful_memes/img/79386.png  \n",
            "  inflating: hateful_memes/img/10542.png  \n",
            "  inflating: hateful_memes/img/56948.png  \n",
            "  inflating: hateful_memes/img/09326.png  \n",
            "  inflating: hateful_memes/img/67520.png  \n",
            "  inflating: hateful_memes/img/14367.png  \n",
            "  inflating: hateful_memes/img/30478.png  \n",
            "  inflating: hateful_memes/img/57183.png  \n",
            "  inflating: hateful_memes/img/03246.png  \n",
            "  inflating: hateful_memes/img/41679.png  \n",
            "  inflating: hateful_memes/img/52743.png  \n",
            "  inflating: hateful_memes/img/64032.png  \n",
            "  inflating: hateful_memes/img/72893.png  \n",
            "  inflating: hateful_memes/img/37182.png  \n",
            "  inflating: hateful_memes/img/69015.png  \n",
            "  inflating: hateful_memes/img/70829.png  \n",
            "  inflating: hateful_memes/img/54217.png  \n",
            "  inflating: hateful_memes/img/60721.png  \n",
            "  inflating: hateful_memes/img/87260.png  \n",
            "  inflating: hateful_memes/img/38679.png  \n",
            "  inflating: hateful_memes/img/42398.png  \n",
            "  inflating: hateful_memes/img/80436.png  \n",
            "  inflating: hateful_memes/img/21394.png  \n",
            "  inflating: hateful_memes/img/70936.png  \n",
            "  inflating: hateful_memes/img/25037.png  \n",
            "  inflating: hateful_memes/img/18450.png  \n",
            "  inflating: hateful_memes/img/83074.png  \n",
            "  inflating: hateful_memes/img/54209.png  \n",
            "  inflating: hateful_memes/img/05819.png  \n",
            "  inflating: hateful_memes/img/53491.png  \n",
            "  inflating: hateful_memes/img/95413.png  \n",
            "  inflating: hateful_memes/img/92513.png  \n",
            "  inflating: hateful_memes/img/95872.png  \n",
            "  inflating: hateful_memes/img/20134.png  \n",
            "  inflating: hateful_memes/img/81293.png  \n",
            "  inflating: hateful_memes/img/62471.png  \n",
            "  inflating: hateful_memes/img/65407.png  \n",
            "  inflating: hateful_memes/img/04371.png  \n",
            "  inflating: hateful_memes/img/13640.png  \n",
            "  inflating: hateful_memes/img/90214.png  \n",
            "  inflating: hateful_memes/img/09514.png  \n",
            "  inflating: hateful_memes/img/05716.png  \n",
            "  inflating: hateful_memes/img/23076.png  \n",
            "  inflating: hateful_memes/img/83461.png  \n",
            "  inflating: hateful_memes/img/51670.png  \n",
            "  inflating: hateful_memes/img/05174.png  \n",
            "  inflating: hateful_memes/img/59261.png  \n",
            "  inflating: hateful_memes/img/31765.png  \n",
            "  inflating: hateful_memes/img/76421.png  \n",
            "  inflating: hateful_memes/img/36075.png  \n",
            "  inflating: hateful_memes/img/14038.png  \n",
            "  inflating: hateful_memes/img/28436.png  \n",
            "  inflating: hateful_memes/img/62849.png  \n",
            "  inflating: hateful_memes/img/26084.png  \n",
            "  inflating: hateful_memes/img/35716.png  \n",
            "  inflating: hateful_memes/img/72634.png  \n",
            "  inflating: hateful_memes/img/39854.png  \n",
            "  inflating: hateful_memes/img/97465.png  \n",
            "  inflating: hateful_memes/img/25893.png  \n",
            "  inflating: hateful_memes/img/75210.png  \n",
            "  inflating: hateful_memes/img/41803.png  \n",
            "  inflating: hateful_memes/img/70214.png  \n",
            "  inflating: hateful_memes/img/01472.png  \n",
            "  inflating: hateful_memes/img/62374.png  \n",
            "  inflating: hateful_memes/img/15936.png  \n",
            "  inflating: hateful_memes/img/86952.png  \n",
            "  inflating: hateful_memes/img/54129.png  \n",
            "  inflating: hateful_memes/img/86017.png  \n",
            "  inflating: hateful_memes/img/92147.png  \n",
            "  inflating: hateful_memes/img/34678.png  \n",
            "  inflating: hateful_memes/img/07369.png  \n",
            "  inflating: hateful_memes/img/87340.png  \n",
            "  inflating: hateful_memes/img/65320.png  \n",
            "  inflating: hateful_memes/img/37096.png  \n",
            "  inflating: hateful_memes/img/02349.png  \n",
            "  inflating: hateful_memes/img/59203.png  \n",
            "  inflating: hateful_memes/img/14682.png  \n",
            "  inflating: hateful_memes/img/34596.png  \n",
            "  inflating: hateful_memes/img/86023.png  \n",
            "  inflating: hateful_memes/img/51962.png  \n",
            "  inflating: hateful_memes/img/74951.png  \n",
            "  inflating: hateful_memes/img/83271.png  \n",
            "  inflating: hateful_memes/img/09634.png  \n",
            "  inflating: hateful_memes/img/65829.png  \n",
            "  inflating: hateful_memes/img/39241.png  \n",
            "  inflating: hateful_memes/img/40265.png  \n",
            "  inflating: hateful_memes/img/34170.png  \n",
            "  inflating: hateful_memes/img/08163.png  \n",
            "  inflating: hateful_memes/img/48270.png  \n",
            "  inflating: hateful_memes/img/93082.png  \n",
            "  inflating: hateful_memes/img/32980.png  \n",
            "  inflating: hateful_memes/img/92185.png  \n",
            "  inflating: hateful_memes/img/06749.png  \n",
            "  inflating: hateful_memes/img/76491.png  \n",
            "  inflating: hateful_memes/img/12637.png  \n",
            "  inflating: hateful_memes/img/69534.png  \n",
            "  inflating: hateful_memes/img/92064.png  \n",
            "  inflating: hateful_memes/img/67580.png  \n",
            "  inflating: hateful_memes/img/74061.png  \n",
            "  inflating: hateful_memes/img/90127.png  \n",
            "  inflating: hateful_memes/img/78930.png  \n",
            "  inflating: hateful_memes/img/10952.png  \n",
            "  inflating: hateful_memes/img/02145.png  \n",
            "  inflating: hateful_memes/img/17538.png  \n",
            "  inflating: hateful_memes/img/64870.png  \n",
            "  inflating: hateful_memes/img/13459.png  \n",
            "  inflating: hateful_memes/img/72401.png  \n",
            "  inflating: hateful_memes/img/73982.png  \n",
            "  inflating: hateful_memes/img/34905.png  \n",
            "  inflating: hateful_memes/img/40679.png  \n",
            "  inflating: hateful_memes/img/10345.png  \n",
            "  inflating: hateful_memes/img/02153.png  \n",
            "  inflating: hateful_memes/img/35784.png  \n",
            "  inflating: hateful_memes/img/42179.png  \n",
            "  inflating: hateful_memes/img/06859.png  \n",
            "  inflating: hateful_memes/img/72980.png  \n",
            "  inflating: hateful_memes/img/92631.png  \n",
            "  inflating: hateful_memes/img/74583.png  \n",
            "  inflating: hateful_memes/img/63412.png  \n",
            "  inflating: hateful_memes/img/13046.png  \n",
            "  inflating: hateful_memes/img/67548.png  \n",
            "  inflating: hateful_memes/img/94528.png  \n",
            "  inflating: hateful_memes/img/14783.png  \n",
            "  inflating: hateful_memes/img/09432.png  \n",
            "  inflating: hateful_memes/img/30427.png  \n",
            "  inflating: hateful_memes/img/03987.png  \n",
            "  inflating: hateful_memes/img/42319.png  \n",
            "  inflating: hateful_memes/img/64287.png  \n",
            "  inflating: hateful_memes/img/82673.png  \n",
            "  inflating: hateful_memes/img/73605.png  \n",
            "  inflating: hateful_memes/img/38701.png  \n",
            "  inflating: hateful_memes/img/05372.png  \n",
            "  inflating: hateful_memes/img/72091.png  \n",
            "  inflating: hateful_memes/img/36054.png  \n",
            "  inflating: hateful_memes/img/42936.png  \n",
            "  inflating: hateful_memes/img/02593.png  \n",
            "  inflating: hateful_memes/img/60981.png  \n",
            "  inflating: hateful_memes/img/96785.png  \n",
            "  inflating: hateful_memes/img/71462.png  \n",
            "  inflating: hateful_memes/img/59837.png  \n",
            "  inflating: hateful_memes/img/08147.png  \n",
            "  inflating: hateful_memes/img/35401.png  \n",
            "  inflating: hateful_memes/img/76095.png  \n",
            "  inflating: hateful_memes/img/38720.png  \n",
            "  inflating: hateful_memes/img/56721.png  \n",
            "  inflating: hateful_memes/img/89105.png  \n",
            "  inflating: hateful_memes/img/91243.png  \n",
            "  inflating: hateful_memes/img/21364.png  \n",
            "  inflating: hateful_memes/img/84076.png  \n",
            "  inflating: hateful_memes/img/08695.png  \n",
            "  inflating: hateful_memes/img/85406.png  \n",
            "  inflating: hateful_memes/img/29513.png  \n",
            "  inflating: hateful_memes/img/98124.png  \n",
            "  inflating: hateful_memes/img/52839.png  \n",
            "  inflating: hateful_memes/img/64730.png  \n",
            "  inflating: hateful_memes/img/37609.png  \n",
            "  inflating: hateful_memes/img/81647.png  \n",
            "  inflating: hateful_memes/img/75432.png  \n",
            "  inflating: hateful_memes/img/41268.png  \n",
            "  inflating: hateful_memes/img/96180.png  \n",
            "  inflating: hateful_memes/img/05379.png  \n",
            "  inflating: hateful_memes/img/84537.png  \n",
            "  inflating: hateful_memes/img/38190.png  \n",
            "  inflating: hateful_memes/img/90326.png  \n",
            "  inflating: hateful_memes/img/89701.png  \n",
            "  inflating: hateful_memes/img/18452.png  \n",
            "  inflating: hateful_memes/img/15809.png  \n",
            "  inflating: hateful_memes/img/57094.png  \n",
            "  inflating: hateful_memes/img/71302.png  \n",
            "  inflating: hateful_memes/img/12894.png  \n",
            "  inflating: hateful_memes/img/59360.png  \n",
            "  inflating: hateful_memes/img/84670.png  \n",
            "  inflating: hateful_memes/img/60142.png  \n",
            "  inflating: hateful_memes/img/10536.png  \n",
            "  inflating: hateful_memes/img/89314.png  \n",
            "  inflating: hateful_memes/img/06579.png  \n",
            "  inflating: hateful_memes/img/90413.png  \n",
            "  inflating: hateful_memes/img/81962.png  \n",
            "  inflating: hateful_memes/img/05962.png  \n",
            "  inflating: hateful_memes/img/48160.png  \n",
            "  inflating: hateful_memes/img/25436.png  \n",
            "  inflating: hateful_memes/img/46712.png  \n",
            "  inflating: hateful_memes/img/65207.png  \n",
            "  inflating: hateful_memes/img/40127.png  \n",
            "  inflating: hateful_memes/img/17306.png  \n",
            "  inflating: hateful_memes/img/01325.png  \n",
            "  inflating: hateful_memes/img/96845.png  \n",
            "  inflating: hateful_memes/img/18532.png  \n",
            "  inflating: hateful_memes/img/23419.png  \n",
            "  inflating: hateful_memes/img/97510.png  \n",
            "  inflating: hateful_memes/img/59328.png  \n",
            "  inflating: hateful_memes/img/05238.png  \n",
            "  inflating: hateful_memes/img/37186.png  \n",
            "  inflating: hateful_memes/img/40796.png  \n",
            "  inflating: hateful_memes/img/47938.png  \n",
            "  inflating: hateful_memes/img/85764.png  \n",
            "  inflating: hateful_memes/img/23510.png  \n",
            "  inflating: hateful_memes/img/03962.png  \n",
            "  inflating: hateful_memes/img/37810.png  \n",
            "  inflating: hateful_memes/img/32481.png  \n",
            "  inflating: hateful_memes/img/64150.png  \n",
            "  inflating: hateful_memes/img/38790.png  \n",
            "  inflating: hateful_memes/img/65732.png  \n",
            "  inflating: hateful_memes/img/17345.png  \n",
            "  inflating: hateful_memes/img/67048.png  \n",
            "  inflating: hateful_memes/img/67059.png  \n",
            "  inflating: hateful_memes/img/21309.png  \n",
            "  inflating: hateful_memes/img/24109.png  \n",
            "  inflating: hateful_memes/img/61972.png  \n",
            "  inflating: hateful_memes/img/45367.png  \n",
            "  inflating: hateful_memes/img/50839.png  \n",
            "  inflating: hateful_memes/img/36408.png  \n",
            "  inflating: hateful_memes/img/29684.png  \n",
            "  inflating: hateful_memes/img/58129.png  \n",
            "  inflating: hateful_memes/img/32674.png  \n",
            "  inflating: hateful_memes/img/37459.png  \n",
            "  inflating: hateful_memes/img/41637.png  \n",
            "  inflating: hateful_memes/img/30428.png  \n",
            "  inflating: hateful_memes/dev_seen.jsonl  \n",
            "  inflating: hateful_memes/test_seen.jsonl  \n",
            "  inflating: hateful_memes/dev_unseen.jsonl  \n",
            "  inflating: hateful_memes/train.jsonl  \n",
            "  inflating: hateful_memes/test_unseen.jsonl  \n",
            "CPU times: user 2.32 s, sys: 337 ms, total: 2.65 s\n",
            "Wall time: 2min 11s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "!unzip -P \"pass\" hateful_memes.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Gp-nsomq0ohh"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "mv hateful_memes/* /content/vilio/ernie-vil/data/hm\n",
        "rm -r hateful_memes\n",
        "rm hateful_memes.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/vilio/ernie-vil/data/hm/* /content/vilio/data/"
      ],
      "metadata": {
        "id": "ctPo8l8vd8gP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/vilio/ernie-vil/data/hm/img | wc -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4SJKLRUgoRm",
        "outputId": "91cba4ba-4946-4349-833a-aed605eb4232"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12140\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VxFCb2BLxU8g"
      },
      "outputs": [],
      "source": [
        "# !cp -r /content/vilio/ernie-vil/data/hm/*  /content/vilio/data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHDb7BykfgGU"
      },
      "outputs": [],
      "source": [
        "# only needed if run models that are not ERNIE-Vil\n",
        "\n",
        "# %%bash\n",
        "# mv /content/vilio/ernie-vil/data/hm/*  /content/vilio/data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "khZf5FdKiIE9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a74e399f-2467-488e-b3ab-da44ee91340d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "cp: -r not specified; omitting directory '/content/vilio/data/img'\n"
          ]
        }
      ],
      "source": [
        "# # only needed to run py-bottom-up-attention\n",
        "\n",
        "# %%bash\n",
        "# cp /content/vilio/data/*  /content/vilio/py-bottom-up-attention/data/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/vilio/py-bottom-up-attention/data/* /content/vilio/data/"
      ],
      "metadata": {
        "id": "BPCzWAsKiRCo"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2lPuOuUtiTdU"
      },
      "outputs": [],
      "source": [
        "# %%bash\n",
        "# cp -r /content/vilio/py-bottom-up-attention/data/*  /content/vilio/data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5hnr7uKlqX3_"
      },
      "outputs": [],
      "source": [
        "# !cp -r /content/vilio/data/* /content/vilio/ernie-vil/data/hm/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udCFF9nsxx-O"
      },
      "source": [
        "##  <font color='#A8EB15'> Run Feature extraction\n",
        "\n",
        "*Skip (already runned) - just run !cp to copy features from `drive` to `/content/vilio/ernie-vil/data/hm`* \n",
        "\n",
        "- we must have 5 features needed to run **ERNIE-Vil**:\n",
        "  * hm_vgattr3636.tsv\n",
        "  * hm_vgattr7272.tsv\n",
        "  * hm_vgattr10100.tsv\n",
        "  * hm_vg5050.tsv\n",
        "  * hm_vg10100.tsv\n",
        "\n",
        "  (For the moment we use `hm_vgattr3636.tsv`)\n",
        "  (We gonna generate: `hm_vgattr10100.tsv`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xmlB5gvDGLF3"
      },
      "outputs": [],
      "source": [
        "#!cp /content/drive/MyDrive/hm_vgattr3636.tsv /content/vilio/ernie-vil/data/hm/hm_vgattr3636.tsv\n",
        "#!cp /content/drive/MyDrive/hm_vgattr10100.tsv /content/vilio/ernie-vil/data/hm/hm_vgattr10100.tsv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOofFrnqGLl2"
      },
      "source": [
        "* In case you need extract features RUN cells below changing `--minboxes 36 --maxboxes 36 `"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AYhbhiBMzyr8"
      },
      "outputs": [],
      "source": [
        "os.chdir(\"/content/vilio/py-bottom-up-attention\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_q0CKAID4lNL"
      },
      "source": [
        "In the file `detectron2_mscoco_proposal_maxnms.py` you must modify:\n",
        "\n",
        "* Line 40: './data/' to '/content/vilio/data/' <- ALDREADY modificated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77PuhN9zxzvY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98c5ed23-8495-4d53-c686-54b517e7bb91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Config '/content/vilio/py-bottom-up-attention/configs/VG-Detection/faster_rcnn_R_101_C4_attr_caffemaxpool.yaml' has no VERSION. Assuming it to be compatible with latest v2.\n",
            "Modifications for VG in ResNet Backbone (modeling/backbone/resnet.py):\n",
            "\tUsing pad 0 in stem max_pool instead of pad 1.\n",
            "\n",
            "Modifications for VG in RPN (modeling/proposal_generator/rpn.py):\n",
            "\tUse hidden dim 512 instead fo the same dim as Res4 (1024).\n",
            "\n",
            "Modifications for VG in RoI heads (modeling/roi_heads/roi_heads.py):\n",
            "\t1. Change the stride of conv1 and shortcut in Res5.Block1 from 2 to 1.\n",
            "\t2. Modifying all conv2 with (padding: 1 --> 2) and (dilation: 1 --> 2).\n",
            "\tFor more details, please check 'https://github.com/peteanderson80/bottom-up-attention/blob/master/models/vg/ResNet-101/faster_rcnn_end2end_final/test.prototxt'.\n",
            "\n",
            "Modifications for VG in RoI heads (modeling/roi_heads/fast_rcnn.py))\n",
            "\tEmbedding: 1601 --> 256\tLinear: 2304 --> 512\tLinear: 512 --> 401\n",
            "\n",
            "faster_rcnn_from_caffe_attr.pkl: 262MB [00:09, 28.8MB/s]               \n",
            "100% 12140/12140 [48:18<00:00,  4.19it/s]\n"
          ]
        }
      ],
      "source": [
        "# !python detectron2_mscoco_proposal_maxnms.py --batchsize 4 --split img --weight vgattr --minboxes 36 --maxboxes 36"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !cp /content/vilio/data/hm_vgattr3636.tsv /content/drive/MyDrive/dataset"
      ],
      "metadata": {
        "id": "GXD_m6_PrKsn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9X114XaoqDZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac3d66c4-f895-4958-f3ad-4017d084d4cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Config '/content/vilio/py-bottom-up-attention/configs/VG-Detection/faster_rcnn_R_101_C4_attr_caffemaxpool.yaml' has no VERSION. Assuming it to be compatible with latest v2.\n",
            "Modifications for VG in ResNet Backbone (modeling/backbone/resnet.py):\n",
            "\tUsing pad 0 in stem max_pool instead of pad 1.\n",
            "\n",
            "Modifications for VG in RPN (modeling/proposal_generator/rpn.py):\n",
            "\tUse hidden dim 512 instead fo the same dim as Res4 (1024).\n",
            "\n",
            "Modifications for VG in RoI heads (modeling/roi_heads/roi_heads.py):\n",
            "\t1. Change the stride of conv1 and shortcut in Res5.Block1 from 2 to 1.\n",
            "\t2. Modifying all conv2 with (padding: 1 --> 2) and (dilation: 1 --> 2).\n",
            "\tFor more details, please check 'https://github.com/peteanderson80/bottom-up-attention/blob/master/models/vg/ResNet-101/faster_rcnn_end2end_final/test.prototxt'.\n",
            "\n",
            "Modifications for VG in RoI heads (modeling/roi_heads/fast_rcnn.py))\n",
            "\tEmbedding: 1601 --> 256\tLinear: 2304 --> 512\tLinear: 512 --> 401\n",
            "\n",
            "100% 12140/12140 [47:39<00:00,  4.25it/s]\n"
          ]
        }
      ],
      "source": [
        "# !python detectron2_mscoco_proposal_maxnms.py --batchsize 4 --split img --weight vgattr --minboxes 10 --maxboxes 100"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !cp /content/vilio/data/hm_vgattr10100.tsv /content/drive/MyDrive/dataset"
      ],
      "metadata": {
        "id": "cR4_uU8xr6Rv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVClNfTN2n4t"
      },
      "source": [
        "### <font color=\"#33FFE3\"> Run below in order to get the new features 5050, 7272 and VG features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LC0iNaR90132"
      },
      "outputs": [],
      "source": [
        "# !python detectron2_mscoco_proposal_maxnms.py --batchsize 4 --split img --weight vgattr --minboxes 50 --maxboxes 50 # not used for ernie-vil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OElJ8V0P1MIW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55c19896-82b6-4e00-b75a-3a39292b7186"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Config '/content/vilio/py-bottom-up-attention/configs/VG-Detection/faster_rcnn_R_101_C4_attr_caffemaxpool.yaml' has no VERSION. Assuming it to be compatible with latest v2.\n",
            "Modifications for VG in ResNet Backbone (modeling/backbone/resnet.py):\n",
            "\tUsing pad 0 in stem max_pool instead of pad 1.\n",
            "\n",
            "Modifications for VG in RPN (modeling/proposal_generator/rpn.py):\n",
            "\tUse hidden dim 512 instead fo the same dim as Res4 (1024).\n",
            "\n",
            "Modifications for VG in RoI heads (modeling/roi_heads/roi_heads.py):\n",
            "\t1. Change the stride of conv1 and shortcut in Res5.Block1 from 2 to 1.\n",
            "\t2. Modifying all conv2 with (padding: 1 --> 2) and (dilation: 1 --> 2).\n",
            "\tFor more details, please check 'https://github.com/peteanderson80/bottom-up-attention/blob/master/models/vg/ResNet-101/faster_rcnn_end2end_final/test.prototxt'.\n",
            "\n",
            "Modifications for VG in RoI heads (modeling/roi_heads/fast_rcnn.py))\n",
            "\tEmbedding: 1601 --> 256\tLinear: 2304 --> 512\tLinear: 512 --> 401\n",
            "\n",
            "100% 12140/12140 [51:17<00:00,  3.94it/s]\n"
          ]
        }
      ],
      "source": [
        "# !python detectron2_mscoco_proposal_maxnms.py --batchsize 4 --split img --weight vgattr --minboxes 72 --maxboxes 72"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !cp /content/vilio/data/hm_vgattr7272.tsv /content/drive/MyDrive/dataset"
      ],
      "metadata": {
        "id": "tj5BWYgr4EHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WfcNwf01TP8"
      },
      "source": [
        "* VG feats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8p9_Al-1tFP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9abebff5-eb85-414c-f5a0-51349aaf2aea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Config '/content/vilio/py-bottom-up-attention/configs/VG-Detection/faster_rcnn_R_101_C4_caffemaxpool.yaml' has no VERSION. Assuming it to be compatible with latest v2.\n",
            "Modifications for VG in ResNet Backbone (modeling/backbone/resnet.py):\n",
            "\tUsing pad 0 in stem max_pool instead of pad 1.\n",
            "\n",
            "Modifications for VG in RPN (modeling/proposal_generator/rpn.py):\n",
            "\tUse hidden dim 512 instead fo the same dim as Res4 (1024).\n",
            "\n",
            "Modifications for VG in RoI heads (modeling/roi_heads/roi_heads.py):\n",
            "\t1. Change the stride of conv1 and shortcut in Res5.Block1 from 2 to 1.\n",
            "\t2. Modifying all conv2 with (padding: 1 --> 2) and (dilation: 1 --> 2).\n",
            "\tFor more details, please check 'https://github.com/peteanderson80/bottom-up-attention/blob/master/models/vg/ResNet-101/faster_rcnn_end2end_final/test.prototxt'.\n",
            "\n",
            "faster_rcnn_from_caffe.pkl: 255MB [00:08, 28.7MB/s]               \n",
            "100% 3035/3035 [40:19<00:00,  1.25it/s]\n"
          ]
        }
      ],
      "source": [
        "# !python detectron2_mscoco_proposal_maxnms.py --batchsize 4 --split img --weight vg --minboxes 50 --maxboxes 50 "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !cp /content/vilio/data/hm_vg5050.tsv /content/drive/MyDrive/dataset"
      ],
      "metadata": {
        "id": "9s02k22bh6XP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KrmAkpRW1y8O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83e19705-e307-47a3-a970-e8cf24edf24a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Config '/content/vilio/py-bottom-up-attention/configs/VG-Detection/faster_rcnn_R_101_C4_caffemaxpool.yaml' has no VERSION. Assuming it to be compatible with latest v2.\n",
            "Modifications for VG in ResNet Backbone (modeling/backbone/resnet.py):\n",
            "\tUsing pad 0 in stem max_pool instead of pad 1.\n",
            "\n",
            "Modifications for VG in RPN (modeling/proposal_generator/rpn.py):\n",
            "\tUse hidden dim 512 instead fo the same dim as Res4 (1024).\n",
            "\n",
            "Modifications for VG in RoI heads (modeling/roi_heads/roi_heads.py):\n",
            "\t1. Change the stride of conv1 and shortcut in Res5.Block1 from 2 to 1.\n",
            "\t2. Modifying all conv2 with (padding: 1 --> 2) and (dilation: 1 --> 2).\n",
            "\tFor more details, please check 'https://github.com/peteanderson80/bottom-up-attention/blob/master/models/vg/ResNet-101/faster_rcnn_end2end_final/test.prototxt'.\n",
            "\n",
            "faster_rcnn_from_caffe.pkl: 255MB [00:05, 43.5MB/s]               \n",
            "100% 3035/3035 [38:02<00:00,  1.33it/s]\n"
          ]
        }
      ],
      "source": [
        "# !python detectron2_mscoco_proposal_maxnms.py --batchsize 4 --split img --weight vg --minboxes 10 --maxboxes 100 "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !cp /content/vilio/data/hm_vg10100.tsv /content/drive/MyDrive/dataset"
      ],
      "metadata": {
        "id": "V62boQvai0mf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C41Pvn9cdANW"
      },
      "outputs": [],
      "source": [
        "# !cp /content/vilio/data/hm_vgattr3636.tsv /content/drive/MyDrive/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# in case that we need lmbd features from `mmf`\n",
        "#wget https://www.kaggle.com/datasets/muennighoff/hmfeatureszipfin/download"
      ],
      "metadata": {
        "id": "LUyabhgs59Dc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we cp the features from Drive\n",
        "%%time\n",
        "%%bash\n",
        "\n",
        "\n",
        "# vg\n",
        "cp /content/drive/MyDrive/dataset/ernie-vil-features/hm_vg10100.tsv /content/vilio/data/hm_vg10100.tsv\n",
        "cp /content/drive/MyDrive/dataset/ernie-vil-features/hm_vg5050.tsv /content/vilio/data/hm_vg5050.tsv\n",
        "#vga\n",
        "cp /content/drive/MyDrive/dataset/ernie-vil-features/hm_vgattr3636.tsv /content/vilio/data/hm_vgattr3636.tsv\n",
        "cp /content/drive/MyDrive/dataset/ernie-vil-features/hm_vgattr7272.tsv /content/vilio/data/hm_vgattr7272.tsv\n",
        "cp /content/drive/MyDrive/dataset/ernie-vil-features/hm_vgattr10100.tsv /content/vilio/data/hm_vgattr10100.tsv"
      ],
      "metadata": {
        "id": "AIP-x-N3uIV4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46f69267-f6e1-43f3-998a-4d36dd408f42"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.72 s, sys: 354 ms, total: 2.07 s\n",
            "Wall time: 5min 40s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e_QX1x864BL"
      },
      "source": [
        "##  <font color='#A8EB15'> <b> Modeling </b>\n",
        "\n",
        "\n",
        "#  <font color='#A8EB15'> <b> ERNIE-ViL  </b>\n",
        "###  <font color='#A8EB15'> PaddlePaddle\n",
        "\n",
        "If you choose to run one of the ERNIE models implemented in PaddlePaddle, I'd recommend making a copy of `vilio/ernie-vil/reader/hm_finetuning.py` and making necessary adjustments on the go, while going through the file, such as:\n",
        "\n",
        "- Add function in vilio/ernie-vil/baching/finetune_batching.py\n",
        "- Data handling in vilio/ernie-vil/reader/_tsv_reader.py\n",
        "- Copy the hm conf folder & adjust under vilio/ernie-vil/conf/\n",
        "- Add a data folder for your project at vilio/ernie-vil/data\n",
        "\n",
        "\n",
        "Run `vilio/ernie-vil/bash/training`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Phst9SvBjts1"
      },
      "source": [
        "We modify the bash files: `hm_EL.sh` in order to change ./bash .... to absolute path \"/content/vilio/ernie-vil/bash\".\n",
        "\n",
        "- We must download the pretrained models and put in the propetly folder:\n",
        "  * `/content/vilio/ernie-vil/data/ernielarge/params`\n",
        "  * `/content/vilio/ernie-vil/data/erniesmall/params`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dp2fgvy2-IWd"
      },
      "source": [
        "### <font color='#33F3FF'> Download Pre-trained small (base) ERNIE-Vil\n",
        "\n",
        "We need download two pretrained models for each model (small and large):\n",
        "* Model\n",
        "* VCR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNHtoJ1K7oq1",
        "outputId": "d27f7128-952d-48d1-9a8a-00b49dde83e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-31 10:08:55--  https://ernie-github.cdn.bcebos.com/model-ernie-vil-base-en.1.tar.gz\n",
            "Resolving ernie-github.cdn.bcebos.com (ernie-github.cdn.bcebos.com)... 182.106.158.35, 111.177.8.35\n",
            "Connecting to ernie-github.cdn.bcebos.com (ernie-github.cdn.bcebos.com)|182.106.158.35|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 886162849 (845M) [application/x-gzip]\n",
            "Saving to: ‘model-ernie-vil-base-en.1.tar.gz’\n",
            "\n",
            "model-ernie-vil-bas 100%[===================>] 845.11M  11.3MB/s    in 76s     \n",
            "\n",
            "2022-05-31 10:10:13 (11.1 MB/s) - ‘model-ernie-vil-base-en.1.tar.gz’ saved [886162849/886162849]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os \n",
        "# Download pre-trained small Ernie-ViL\n",
        "os.chdir(\"/content/vilio/ernie-vil/data/erniesmall\")\n",
        "!wget https://ernie-github.cdn.bcebos.com/model-ernie-vil-base-en.1.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "L691WQ6KG_Kr"
      },
      "outputs": [],
      "source": [
        "# unzip only params folder\n",
        "!tar -xzf model-ernie-vil-base-en.1.tar.gz --wildcards --no-anchored '*params*'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "UXkUblAw_M_q"
      },
      "outputs": [],
      "source": [
        "# this unzip all folder\n",
        "# !tar -xf model-ernie-vil-base-en.1.tar.gz "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "S9iPPEGxJSlT"
      },
      "outputs": [],
      "source": [
        "!mv /content/vilio/ernie-vil/data/erniesmall/model-ernie-vil-base-en/* /content/vilio/ernie-vil/data/erniesmall/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "xlLdz1uIJd-q"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "rm model-ernie-vil-base-en.1.tar.gz\n",
        "rm -r model-ernie-vil-base-en"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVhfQPJSJDMf"
      },
      "source": [
        "* VCR pre-trained"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07D-BZ1I775s",
        "outputId": "70ff23eb-b43b-4172-e07f-d8c4d364544a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-31 10:10:26--  https://ernie-github.cdn.bcebos.com/model-ernie-vil-base-VCR-task-pre-en.1.tar.gz\n",
            "Resolving ernie-github.cdn.bcebos.com (ernie-github.cdn.bcebos.com)... 182.106.158.35, 111.177.8.35\n",
            "Connecting to ernie-github.cdn.bcebos.com (ernie-github.cdn.bcebos.com)|182.106.158.35|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 886087681 (845M) [application/x-gzip]\n",
            "Saving to: ‘model-ernie-vil-base-VCR-task-pre-en.1.tar.gz’\n",
            "\n",
            "model-ernie-vil-bas 100%[===================>] 845.04M  8.57MB/s    in 1m 40s  \n",
            "\n",
            "2022-05-31 10:12:08 (8.48 MB/s) - ‘model-ernie-vil-base-VCR-task-pre-en.1.tar.gz’ saved [886087681/886087681]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "os.chdir(\"/content/vilio/ernie-vil/data/erniesmallvcr\")\n",
        "!wget https://ernie-github.cdn.bcebos.com/model-ernie-vil-base-VCR-task-pre-en.1.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "qxflLIf5Haf6"
      },
      "outputs": [],
      "source": [
        "# unzip only params folder\n",
        "!tar -xzf model-ernie-vil-base-VCR-task-pre-en.1.tar.gz --wildcards --no-anchored '*params*'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "EsCVA04XIamS"
      },
      "outputs": [],
      "source": [
        "!mv /content/vilio/ernie-vil/data/erniesmallvcr/model-ernie-vil-base-VCR-task-pre-en/* /content/vilio/ernie-vil/data/erniesmallvcr/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "eCVJHwKCIx-n"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "rm model-ernie-vil-base-VCR-task-pre-en.1.tar.gz\n",
        "rm -r model-ernie-vil-base-VCR-task-pre-en"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbgyMPys-j8W"
      },
      "source": [
        "### <font color='#33F3FF'> Download Pre-trained large ERNIE-Vil <- don't RUN need modifications\n",
        "\n",
        "* Model\n",
        "* VCR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wec8PSdb8hcF"
      },
      "outputs": [],
      "source": [
        "#import os \n",
        "# Download pre-trained large Ernie-ViL\n",
        "#os.chdir(\"/content/vilio/ernie-vil/data/ernielarge\")\n",
        "#!wget https://ernie-github.cdn.bcebos.com/model-ernie-vil-large-en.1.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJa1c07g9hzK"
      },
      "outputs": [],
      "source": [
        "#os.chdir(\"/content/vilio/ernie-vil/data/ernielargevcr\")\n",
        "#!wget https://ernie-github.cdn.bcebos.com/model-ernie-vil-large-VCR-task-pre-en.1.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l70OCx-t2Pix"
      },
      "source": [
        "### <font color='#A8EB15'> <b>  Train ERNIE-Vil Small </b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-9Q3p3H0VSx"
      },
      "source": [
        "#### <font color='#33F3FF'> Install packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "XDV4EF570ZFN"
      },
      "outputs": [],
      "source": [
        "#!pip install -r requirements2.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xp9DwIE20XOP",
        "outputId": "171eec3a-4adc-4017-b282-c7924e5db518"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting imagehash\n",
            "  Downloading ImageHash-4.2.1.tar.gz (812 kB)\n",
            "\u001b[K     |████████████████████████████████| 812 kB 6.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imagehash) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from imagehash) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from imagehash) (1.4.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from imagehash) (7.1.2)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.7/dist-packages (from imagehash) (1.3.0)\n",
            "Building wheels for collected packages: imagehash\n",
            "  Building wheel for imagehash (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for imagehash: filename=ImageHash-4.2.1-py2.py3-none-any.whl size=295206 sha256=1f80f5ca6e5ac1885df5766babd95203e9702ae278cdf734e9b8f0598486d45a\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/d5/59/5e3e297533ddb09407769762985d134135064c6831e29a914e\n",
            "Successfully built imagehash\n",
            "Installing collected packages: imagehash\n",
            "Successfully installed imagehash-4.2.1\n"
          ]
        }
      ],
      "source": [
        "!pip install imagehash"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Z5iM36B0Zn4",
        "outputId": "effedd11-e4f1-4131-ff88-3ff7df0a7f0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting json_lines\n",
            "  Downloading json_lines-0.5.0-py2.py3-none-any.whl (6.8 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from json_lines) (1.15.0)\n",
            "Installing collected packages: json-lines\n",
            "Successfully installed json-lines-0.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install json_lines"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda install numpy==1.14.3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U17jJJDpSGDD",
        "outputId": "bebd3690-7ff3-416e-be7b-e58a15052e7b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: conda: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGhW2y8P0dz7",
        "outputId": "42b8a6d0-3e98-401e-8218-b315fb6b7f04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting paddlepaddle-gpu==1.8.3.post97\n",
            "  Downloading paddlepaddle_gpu-1.8.3.post97-cp37-cp37m-manylinux1_x86_64.whl (404.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 404.9 MB 14 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.7/dist-packages (from paddlepaddle-gpu==1.8.3.post97) (1.21.6)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from paddlepaddle-gpu==1.8.3.post97) (7.1.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from paddlepaddle-gpu==1.8.3.post97) (3.13)\n",
            "Requirement already satisfied: gast>=0.3.3 in /usr/local/lib/python3.7/dist-packages (from paddlepaddle-gpu==1.8.3.post97) (0.5.3)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.7/dist-packages (from paddlepaddle-gpu==1.8.3.post97) (3.3.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from paddlepaddle-gpu==1.8.3.post97) (4.1.2.30)\n",
            "Collecting objgraph\n",
            "  Downloading objgraph-3.5.0-py2.py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.7/dist-packages (from paddlepaddle-gpu==1.8.3.post97) (0.8.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from paddlepaddle-gpu==1.8.3.post97) (3.2.2)\n",
            "Requirement already satisfied: pathlib in /usr/local/lib/python3.7/dist-packages (from paddlepaddle-gpu==1.8.3.post97) (1.0.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from paddlepaddle-gpu==1.8.3.post97) (0.10.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from paddlepaddle-gpu==1.8.3.post97) (3.2.5)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from paddlepaddle-gpu==1.8.3.post97) (2.23.0)\n",
            "Collecting scipy<=1.3.1\n",
            "  Downloading scipy-1.3.1-cp37-cp37m-manylinux1_x86_64.whl (25.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.2 MB 1.4 MB/s \n",
            "\u001b[?25hCollecting rarfile\n",
            "  Downloading rarfile-4.0-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from paddlepaddle-gpu==1.8.3.post97) (4.4.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from paddlepaddle-gpu==1.8.3.post97) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from paddlepaddle-gpu==1.8.3.post97) (3.17.3)\n",
            "Collecting funcsigs\n",
            "  Downloading funcsigs-1.0.2-py2.py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->paddlepaddle-gpu==1.8.3.post97) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->paddlepaddle-gpu==1.8.3.post97) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->paddlepaddle-gpu==1.8.3.post97) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->paddlepaddle-gpu==1.8.3.post97) (2022.5.18.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->paddlepaddle-gpu==1.8.3.post97) (1.4.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->paddlepaddle-gpu==1.8.3.post97) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->paddlepaddle-gpu==1.8.3.post97) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->paddlepaddle-gpu==1.8.3.post97) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->paddlepaddle-gpu==1.8.3.post97) (4.2.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from prettytable->paddlepaddle-gpu==1.8.3.post97) (4.11.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prettytable->paddlepaddle-gpu==1.8.3.post97) (0.2.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->prettytable->paddlepaddle-gpu==1.8.3.post97) (3.8.0)\n",
            "Installing collected packages: scipy, rarfile, objgraph, funcsigs, paddlepaddle-gpu\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed funcsigs-1.0.2 objgraph-3.5.0 paddlepaddle-gpu-1.8.3.post97 rarfile-4.0 scipy-1.3.1\n"
          ]
        }
      ],
      "source": [
        "!pip install paddlepaddle-gpu==1.8.3.post97\n",
        "#!pip install pip install paddlepaddle-gpu "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda install pandas==1.0.5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qv0SM3fqTEay",
        "outputId": "17d377cb-fe67-4dba-d5fa-a31c57d6e942"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: conda: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda install json_lines"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAtokdlZTflQ",
        "outputId": "0ec2a61a-8f26-4d4a-b6a9-ddb7f71c0bcb"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: conda: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rp2Wwp620iwW"
      },
      "source": [
        "#### <font color='#33F3FF'> Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "YtCZIrSNnM3-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir(\"/content/vilio/ernie-vil\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "StFJL__0Zu25"
      },
      "outputs": [],
      "source": [
        "#!bash /content/vilio/ernie-vil/bash/training/ES/hm_ES.sh"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "# vg\n",
        "cp /content/vilio/data/hm_vgattr10100.tsv /content/vilio/ernie-vil/data/hm/hm_vgattr10100.tsv\n",
        "cp /content/vilio/data/hm_vg5050.tsv /content/vilio/ernie-vil/data/hm/hm_vg5050.tsv\n",
        "#vga\n",
        "cp /content/vilio/data/hm_vgattr3636.tsv  /content/vilio/ernie-vil/data/hm/hm_vgattr3636.tsv \n",
        "cp /content/vilio/data/hm_vgattr7272.tsv /content/vilio/ernie-vil/data/hm/hm_vgattr7272.tsv\n",
        "cp /content/vilio/data/hm_vgattr10100.tsv /content/vilio/ernie-vil/data/hm/hm_vgattr10100.tsv"
      ],
      "metadata": {
        "id": "AC55kh38w_79"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbkyYWjJZioj",
        "outputId": "ee613f1e-24b3-4104-9fe0-4de8d926dc11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+ TASK_NAME=hm\n",
            "+ CONF_FILE=conf/hm/model_conf_hm\n",
            "+ VOCAB_PATH=/content/vilio/ernie-vil/data/erniesmall/vocab.txt\n",
            "+ ERNIE_VIL_CONFIG=/content/vilio/ernie-vil/data/erniesmall/ernie_vil_config.base.json\n",
            "+ PRETRAIN_MODELS=/content/vilio/ernie-vil/data/erniesmall/params\n",
            "+ SPLIT=train\n",
            "+ STOP=2500\n",
            "+ source conf/hm/model_conf_hm\n",
            "++ output_model_path=output_hm\n",
            "++ lr_scheduler=manual_warmup_decay\n",
            "++ decay_steps='13308;19962'\n",
            "++ lr_decay_ratio=0.1\n",
            "++ num_train_steps=5000\n",
            "++ SAVE_STEPS=1250\n",
            "++ WARMUP_STEPS=500\n",
            "++ BATCH_SIZE=8\n",
            "++ VALID_STEPS=20000\n",
            "++ LR_RATE=1e-5\n",
            "++ WEIGHT_DECAY=0.01\n",
            "++ MAX_LEN=128\n",
            "+ CUDA_VISIBLE_DEVICES=1\n",
            "+ export FLAGS_fast_eager_deletion_mode=1\n",
            "+ FLAGS_fast_eager_deletion_mode=1\n",
            "+ export FLAGS_eager_delete_tensor_gb=0.0\n",
            "+ FLAGS_eager_delete_tensor_gb=0.0\n",
            "+ export FLAGS_fraction_of_gpu_memory_to_use=0.98\n",
            "+ FLAGS_fraction_of_gpu_memory_to_use=0.98\n",
            "++ echo True\n",
            "++ tr '[A-Z]' '[a-z]'\n",
            "+ e_executor=true\n",
            "++ echo False\n",
            "++ tr '[A-Z]' '[a-z]'\n",
            "+ use_fuse=false\n",
            "+ [[ false == \\t\\r\\u\\e ]]\n",
            "+ TASK_GROUP_JSON=/content/vilio/ernie-vil/conf/hm/task_hm.json\n",
            "++ echo 1\n",
            "++ awk '-F\\t' '{len=split($0,vec,\",\");print len}'\n",
            "+ gpu_cnt=1\n",
            "+ echo gpu_cnt, 1\n",
            "gpu_cnt, 1\n",
            "+ python /content/vilio/ernie-vil/finetune.py --use_cuda True --is_distributed False --use_fast_executor true --nccl_comm_num 1 --batch_size 8 --do_train True --do_test False --task_name hm --vocab_path /content/vilio/ernie-vil/data/erniesmall/vocab.txt --task_group_json /content/vilio/ernie-vil/conf/hm/task_hm.json --lr_scheduler manual_warmup_decay --decay_steps '13308;19962' --lr_decay_ratio 0.1 --num_train_steps 5000 --checkpoints output_hm --save_steps 1250 --init_checkpoint /content/vilio/ernie-vil/data/erniesmall/params --ernie_config_path /content/vilio/ernie-vil/data/erniesmall/ernie_vil_config.base.json --learning_rate 1e-5 --warmup_steps 500 --weight_decay 0.01 --max_seq_len 128 --validation_steps 20000 --skip_steps 10 --split train --stop_steps 2500\n",
            "-----------  Configuration Arguments -----------\n",
            "batch_size: 8\n",
            "checkpoints: output_hm\n",
            "combine: False\n",
            "decay_steps: 13308;19962\n",
            "do_test: False\n",
            "do_train: True\n",
            "do_val: False\n",
            "epoch: 100\n",
            "ernie_config_path: /content/vilio/ernie-vil/data/erniesmall/ernie_vil_config.base.json\n",
            "exp: experiment\n",
            "feature_size: 2048\n",
            "fusion_method: sum\n",
            "hierarchical_allreduce_inter_nranks: 8\n",
            "init_checkpoint: /content/vilio/ernie-vil/data/erniesmall/params\n",
            "is_distributed: False\n",
            "learning_rate: 1e-05\n",
            "lr_decay_dict_file: \n",
            "lr_decay_ratio: 0.1\n",
            "lr_scheduler: manual_warmup_decay\n",
            "max_img_len: 100\n",
            "max_seq_len: 128\n",
            "nccl_comm_num: 1\n",
            "num_features: 50\n",
            "num_train_steps: 5000\n",
            "output_file: \n",
            "result_file: ./res_tmp\n",
            "save_steps: 1250\n",
            "skip_steps: 10\n",
            "split: train\n",
            "stop_steps: 2500\n",
            "subtrain: False\n",
            "task_group_json: /content/vilio/ernie-vil/conf/hm/task_hm.json\n",
            "task_name: hm\n",
            "test_filelist: \n",
            "test_split: test\n",
            "train_filelist: \n",
            "use_cuda: True\n",
            "use_fast_executor: True\n",
            "use_fuse: False\n",
            "use_gpu: True\n",
            "use_hierarchical_allreduce: False\n",
            "valid_filelist: \n",
            "validation_steps: 20000\n",
            "verbose: False\n",
            "vocab_path: /content/vilio/ernie-vil/data/erniesmall/vocab.txt\n",
            "warmup_steps: 500\n",
            "weight_decay: 0.01\n",
            "------------------------------------------------\n",
            "finetuning tasks start\n",
            "attention_probs_dropout_prob: 0.1\n",
            "class_attr_size: 401\n",
            "class_size: 1601\n",
            "co_hidden_size: 1024\n",
            "co_intermediate_size: 1024\n",
            "co_num_attention_heads: 8\n",
            "hidden_act: gelu\n",
            "hidden_dropout_prob: 0.1\n",
            "hidden_size: 768\n",
            "initializer_range: 0.02\n",
            "max_position_embeddings: 512\n",
            "num_attention_heads: 12\n",
            "num_hidden_layers: 12\n",
            "sent_type_vocab_size: 4\n",
            "t_biattention_id: [6, 7, 8, 9, 10, 11]\n",
            "task_type_vocab_size: 16\n",
            "type_vocab_size: 2\n",
            "v_biattention_id: [0, 1, 2, 3, 4, 5]\n",
            "v_hidden_size: 1024\n",
            "v_intermediate_size: 1024\n",
            "v_num_attention_heads: 8\n",
            "vocab_size: 30522\n",
            "------------------------------------------------\n",
            "task:  [{'task': 'HM', 'num_choice': 1, 'annotations_jsonpath_train': '/content/vilio/ernie-vil/data/hm/train.jsonl', 'annotations_jsonpath_dev_seen': '/content/vilio/ernie-vil/data/hm/dev_seenlong.jsonl', 'annotations_jsonpath_traindev': '/content/vilio/ernie-vil/data/hm/traindev.jsonl', 'annotations_jsonpath_test_unseen': '/content/vilio/ernie-vil/data/hm/test_unseenlong.jsonl', 'annotations_jsonpath_test_seen': '/content/vilio/ernie-vil/data/hm/test_seenlong.jsonl', 'feature_lmdb_path': '/content/vilio/ernie-vil/data/hm/HM_img.tsv', 'gt_feature_lmdb_path': '/content/vilio/ernie-vil/data/hm/HM_gt_img.tsv', 'unisex_names_table': '/content/vilio/ernie-vil/data/vcr/unisex_names_table.csv', 'Proprocessor': 'PreprocessorBasic', 'tokenizer_name': 'FullTokenizer', 'fusion_method': 'mul', 'dropout_rate': 0.1, 'max_seq_len': 128, 'use_gt_fea': True, 'shufflekeep_across_task': True, 'shuffle_every_epoch': True, 'task_weight': 1.0, 'task_prefix': 'hm'}]\n",
            "2022-05-31 11:23:03,085-WARNING: paddle.fluid.layers.py_reader() may be deprecated in the near future. Please use paddle.fluid.io.DataLoader.from_generator() instead.\n",
            "/usr/local/lib/python3.7/dist-packages/paddle/fluid/clip.py:779: UserWarning: Caution! 'set_gradient_clip' is not recommended and may be deprecated in future! We recommend a new strategy: set 'grad_clip' when initializing the 'optimizer'. This method can reduce the mistakes, please refer to documention of 'optimizer'.\n",
            "  warnings.warn(\"Caution! 'set_gradient_clip' is not recommended \"\n",
            "theoretical memory usage: \n",
            "(18209.21138906479, 19076.31669330597, 'MB')\n",
            "args.is_distributed: False\n",
            "W0531 11:23:08.712114  1014 device_context.cc:252] Please NOTE: device: 0, CUDA Capability: 60, Driver API Version: 11.2, Runtime API Version: 9.0\n",
            "W0531 11:23:09.068527  1014 device_context.cc:260] device: 0, cuDNN Version: 7.6.\n",
            "Load pretraining parameters from /content/vilio/ernie-vil/data/erniesmall/params.\n",
            "SPLIT: train\n",
            "Start to load Faster-RCNN detected objects from /content/vilio/ernie-vil/data/hm/HM_img.tsv\n",
            "Loaded 8598 images in file /content/vilio/ernie-vil/data/hm/HM_img.tsv in 98 seconds.\n",
            "Start to load Faster-RCNN detected objects from /content/vilio/ernie-vil/data/hm/HM_gt_img.tsv\n",
            "Loaded 8598 images in file /content/vilio/ernie-vil/data/hm/HM_gt_img.tsv in 64 seconds.\n",
            "Load 8598 data from split(s) /content/vilio/ernie-vil/data/hm/train.jsonl.\n",
            "use gt featurre\n",
            "LEN:  8598\n",
            "shuffle epoch 0\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 10, loss: 0.664136, acc: 0.500000\n",
            "steps: 10\n",
            "save_steps: 1250\n",
            "20220531 11:26:11 current learning_rate:0.00000018\n",
            "used_time: 0.23023509979248047\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 20, loss: 0.724785, acc: 0.875000\n",
            "steps: 20\n",
            "save_steps: 1250\n",
            "20220531 11:26:13 current learning_rate:0.00000038\n",
            "used_time: 0.19777488708496094\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 30, loss: 0.696549, acc: 0.750000\n",
            "steps: 30\n",
            "save_steps: 1250\n",
            "20220531 11:26:15 current learning_rate:0.00000058\n",
            "used_time: 0.19838261604309082\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 40, loss: 0.693551, acc: 0.625000\n",
            "steps: 40\n",
            "save_steps: 1250\n",
            "20220531 11:26:17 current learning_rate:0.00000078\n",
            "used_time: 0.21685075759887695\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 50, loss: 0.664206, acc: 0.625000\n",
            "steps: 50\n",
            "save_steps: 1250\n",
            "20220531 11:26:19 current learning_rate:0.00000098\n",
            "used_time: 0.22127866744995117\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 60, loss: 0.677613, acc: 0.625000\n",
            "steps: 60\n",
            "save_steps: 1250\n",
            "20220531 11:26:21 current learning_rate:0.00000118\n",
            "used_time: 0.18825149536132812\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 70, loss: 0.684965, acc: 0.625000\n",
            "steps: 70\n",
            "save_steps: 1250\n",
            "20220531 11:26:23 current learning_rate:0.00000138\n",
            "used_time: 0.2141263484954834\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 80, loss: 0.687593, acc: 0.625000\n",
            "steps: 80\n",
            "save_steps: 1250\n",
            "20220531 11:26:25 current learning_rate:0.00000158\n",
            "used_time: 0.20637917518615723\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 90, loss: 0.664546, acc: 0.750000\n",
            "steps: 90\n",
            "save_steps: 1250\n",
            "20220531 11:26:27 current learning_rate:0.00000178\n",
            "used_time: 0.22624635696411133\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 100, loss: 0.704649, acc: 0.250000\n",
            "steps: 100\n",
            "save_steps: 1250\n",
            "20220531 11:26:29 current learning_rate:0.00000198\n",
            "used_time: 0.19751358032226562\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 110, loss: 0.682069, acc: 0.500000\n",
            "steps: 110\n",
            "save_steps: 1250\n",
            "20220531 11:26:31 current learning_rate:0.00000218\n",
            "used_time: 0.21478009223937988\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 120, loss: 0.695636, acc: 0.375000\n",
            "steps: 120\n",
            "save_steps: 1250\n",
            "20220531 11:26:34 current learning_rate:0.00000238\n",
            "used_time: 0.19235801696777344\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 130, loss: 0.618365, acc: 0.875000\n",
            "steps: 130\n",
            "save_steps: 1250\n",
            "20220531 11:26:36 current learning_rate:0.00000258\n",
            "used_time: 0.23908185958862305\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 140, loss: 0.569076, acc: 0.875000\n",
            "steps: 140\n",
            "save_steps: 1250\n",
            "20220531 11:26:38 current learning_rate:0.00000278\n",
            "used_time: 0.20105409622192383\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 150, loss: 0.725046, acc: 0.375000\n",
            "steps: 150\n",
            "save_steps: 1250\n",
            "20220531 11:26:40 current learning_rate:0.00000298\n",
            "used_time: 0.2160325050354004\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 160, loss: 0.676840, acc: 0.625000\n",
            "steps: 160\n",
            "save_steps: 1250\n",
            "20220531 11:26:42 current learning_rate:0.00000318\n",
            "used_time: 0.21127629280090332\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 170, loss: 0.525697, acc: 0.875000\n",
            "steps: 170\n",
            "save_steps: 1250\n",
            "20220531 11:26:44 current learning_rate:0.00000338\n",
            "used_time: 0.24618816375732422\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 180, loss: 0.574206, acc: 0.875000\n",
            "steps: 180\n",
            "save_steps: 1250\n",
            "20220531 11:26:46 current learning_rate:0.00000358\n",
            "used_time: 0.20292377471923828\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 190, loss: 0.560374, acc: 0.750000\n",
            "steps: 190\n",
            "save_steps: 1250\n",
            "20220531 11:26:48 current learning_rate:0.00000378\n",
            "used_time: 0.20248198509216309\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 200, loss: 0.546022, acc: 0.750000\n",
            "steps: 200\n",
            "save_steps: 1250\n",
            "20220531 11:26:50 current learning_rate:0.00000398\n",
            "used_time: 0.2222123146057129\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 210, loss: 0.687625, acc: 0.500000\n",
            "steps: 210\n",
            "save_steps: 1250\n",
            "20220531 11:26:52 current learning_rate:0.00000418\n",
            "used_time: 0.21638274192810059\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 220, loss: 0.740549, acc: 0.500000\n",
            "steps: 220\n",
            "save_steps: 1250\n",
            "20220531 11:26:54 current learning_rate:0.00000438\n",
            "used_time: 0.1962440013885498\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 230, loss: 0.848807, acc: 0.500000\n",
            "steps: 230\n",
            "save_steps: 1250\n",
            "20220531 11:26:57 current learning_rate:0.00000458\n",
            "used_time: 0.20140337944030762\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 240, loss: 0.798992, acc: 0.375000\n",
            "steps: 240\n",
            "save_steps: 1250\n",
            "20220531 11:26:59 current learning_rate:0.00000478\n",
            "used_time: 0.22268366813659668\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 250, loss: 0.665956, acc: 0.750000\n",
            "steps: 250\n",
            "save_steps: 1250\n",
            "20220531 11:27:01 current learning_rate:0.00000498\n",
            "used_time: 0.25939249992370605\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 260, loss: 0.733732, acc: 0.625000\n",
            "steps: 260\n",
            "save_steps: 1250\n",
            "20220531 11:27:03 current learning_rate:0.00000518\n",
            "used_time: 0.1899585723876953\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 270, loss: 0.587063, acc: 0.625000\n",
            "steps: 270\n",
            "save_steps: 1250\n",
            "20220531 11:27:05 current learning_rate:0.00000538\n",
            "used_time: 0.20491528511047363\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 280, loss: 0.632271, acc: 0.375000\n",
            "steps: 280\n",
            "save_steps: 1250\n",
            "20220531 11:27:07 current learning_rate:0.00000558\n",
            "used_time: 0.2392411231994629\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 290, loss: 0.619872, acc: 0.625000\n",
            "steps: 290\n",
            "save_steps: 1250\n",
            "20220531 11:27:09 current learning_rate:0.00000578\n",
            "used_time: 0.2203686237335205\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 300, loss: 0.363555, acc: 0.625000\n",
            "steps: 300\n",
            "save_steps: 1250\n",
            "20220531 11:27:11 current learning_rate:0.00000598\n",
            "used_time: 0.21342873573303223\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 310, loss: 0.534378, acc: 0.750000\n",
            "steps: 310\n",
            "save_steps: 1250\n",
            "20220531 11:27:13 current learning_rate:0.00000618\n",
            "used_time: 0.22497177124023438\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 320, loss: 0.764014, acc: 0.375000\n",
            "steps: 320\n",
            "save_steps: 1250\n",
            "20220531 11:27:15 current learning_rate:0.00000638\n",
            "used_time: 0.20969176292419434\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 330, loss: 0.655102, acc: 0.500000\n",
            "steps: 330\n",
            "save_steps: 1250\n",
            "20220531 11:27:17 current learning_rate:0.00000658\n",
            "used_time: 0.25491833686828613\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 340, loss: 0.765799, acc: 0.750000\n",
            "steps: 340\n",
            "save_steps: 1250\n",
            "20220531 11:27:19 current learning_rate:0.00000678\n",
            "used_time: 0.20052003860473633\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 350, loss: 0.461307, acc: 0.750000\n",
            "steps: 350\n",
            "save_steps: 1250\n",
            "20220531 11:27:22 current learning_rate:0.00000698\n",
            "used_time: 0.19530487060546875\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 360, loss: 0.878848, acc: 0.500000\n",
            "steps: 360\n",
            "save_steps: 1250\n",
            "20220531 11:27:24 current learning_rate:0.00000718\n",
            "used_time: 0.19819116592407227\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 370, loss: 0.563232, acc: 0.750000\n",
            "steps: 370\n",
            "save_steps: 1250\n",
            "20220531 11:27:26 current learning_rate:0.00000738\n",
            "used_time: 0.28294873237609863\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 380, loss: 0.358858, acc: 0.625000\n",
            "steps: 380\n",
            "save_steps: 1250\n",
            "20220531 11:27:28 current learning_rate:0.00000758\n",
            "used_time: 0.2684919834136963\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 390, loss: 0.366874, acc: 0.875000\n",
            "steps: 390\n",
            "save_steps: 1250\n",
            "20220531 11:27:30 current learning_rate:0.00000778\n",
            "used_time: 0.22320961952209473\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 400, loss: 0.894736, acc: 0.625000\n",
            "steps: 400\n",
            "save_steps: 1250\n",
            "20220531 11:27:32 current learning_rate:0.00000798\n",
            "used_time: 0.2044525146484375\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 410, loss: 0.288868, acc: 0.875000\n",
            "steps: 410\n",
            "save_steps: 1250\n",
            "20220531 11:27:34 current learning_rate:0.00000818\n",
            "used_time: 0.22224044799804688\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 420, loss: 0.204521, acc: 0.625000\n",
            "steps: 420\n",
            "save_steps: 1250\n",
            "20220531 11:27:36 current learning_rate:0.00000838\n",
            "used_time: 0.23952364921569824\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 430, loss: 0.778794, acc: 0.500000\n",
            "steps: 430\n",
            "save_steps: 1250\n",
            "20220531 11:27:38 current learning_rate:0.00000858\n",
            "used_time: 0.18496108055114746\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 440, loss: 0.634745, acc: 0.500000\n",
            "steps: 440\n",
            "save_steps: 1250\n",
            "20220531 11:27:40 current learning_rate:0.00000878\n",
            "used_time: 0.19084477424621582\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 450, loss: 0.525584, acc: 0.625000\n",
            "steps: 450\n",
            "save_steps: 1250\n",
            "20220531 11:27:42 current learning_rate:0.00000898\n",
            "used_time: 0.24154067039489746\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 460, loss: 0.665519, acc: 0.625000\n",
            "steps: 460\n",
            "save_steps: 1250\n",
            "20220531 11:27:44 current learning_rate:0.00000918\n",
            "used_time: 0.18323755264282227\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 470, loss: 0.371264, acc: 0.750000\n",
            "steps: 470\n",
            "save_steps: 1250\n",
            "20220531 11:27:47 current learning_rate:0.00000938\n",
            "used_time: 0.22158169746398926\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 480, loss: 0.554464, acc: 0.875000\n",
            "steps: 480\n",
            "save_steps: 1250\n",
            "20220531 11:27:49 current learning_rate:0.00000958\n",
            "used_time: 0.1932520866394043\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 490, loss: 0.270105, acc: 0.875000\n",
            "steps: 490\n",
            "save_steps: 1250\n",
            "20220531 11:27:51 current learning_rate:0.00000978\n",
            "used_time: 0.23041701316833496\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 500, loss: 0.369654, acc: 0.750000\n",
            "steps: 500\n",
            "save_steps: 1250\n",
            "Train-RCAC 0.5885714285714286\n",
            "20220531 11:27:53 current learning_rate:0.00000998\n",
            "used_time: 0.26110005378723145\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 510, loss: 1.101190, acc: 0.500000\n",
            "steps: 510\n",
            "save_steps: 1250\n",
            "20220531 11:27:55 current learning_rate:0.00001000\n",
            "used_time: 0.2042834758758545\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 520, loss: 0.305462, acc: 0.875000\n",
            "steps: 520\n",
            "save_steps: 1250\n",
            "20220531 11:27:57 current learning_rate:0.00001000\n",
            "used_time: 0.19482707977294922\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 530, loss: 0.761712, acc: 0.375000\n",
            "steps: 530\n",
            "save_steps: 1250\n",
            "20220531 11:27:59 current learning_rate:0.00001000\n",
            "used_time: 0.22408413887023926\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 540, loss: 0.547433, acc: 0.625000\n",
            "steps: 540\n",
            "save_steps: 1250\n",
            "20220531 11:28:01 current learning_rate:0.00001000\n",
            "used_time: 0.18333840370178223\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 550, loss: 0.474476, acc: 0.750000\n",
            "steps: 550\n",
            "save_steps: 1250\n",
            "20220531 11:28:03 current learning_rate:0.00001000\n",
            "used_time: 0.19840645790100098\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 560, loss: 0.448304, acc: 0.750000\n",
            "steps: 560\n",
            "save_steps: 1250\n",
            "20220531 11:28:05 current learning_rate:0.00001000\n",
            "used_time: 0.24632763862609863\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 570, loss: 0.515562, acc: 0.500000\n",
            "steps: 570\n",
            "save_steps: 1250\n",
            "20220531 11:28:08 current learning_rate:0.00001000\n",
            "used_time: 0.24480748176574707\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 580, loss: 0.868105, acc: 0.250000\n",
            "steps: 580\n",
            "save_steps: 1250\n",
            "20220531 11:28:10 current learning_rate:0.00001000\n",
            "used_time: 0.19830632209777832\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 590, loss: 0.443798, acc: 0.625000\n",
            "steps: 590\n",
            "save_steps: 1250\n",
            "20220531 11:28:12 current learning_rate:0.00001000\n",
            "used_time: 0.22573637962341309\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 600, loss: 0.247722, acc: 0.625000\n",
            "steps: 600\n",
            "save_steps: 1250\n",
            "20220531 11:28:14 current learning_rate:0.00001000\n",
            "used_time: 0.20586824417114258\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 610, loss: 0.419900, acc: 0.875000\n",
            "steps: 610\n",
            "save_steps: 1250\n",
            "20220531 11:28:16 current learning_rate:0.00001000\n",
            "used_time: 0.2653160095214844\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 620, loss: 0.577124, acc: 0.625000\n",
            "steps: 620\n",
            "save_steps: 1250\n",
            "20220531 11:28:18 current learning_rate:0.00001000\n",
            "used_time: 0.20961451530456543\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 630, loss: 0.403735, acc: 0.875000\n",
            "steps: 630\n",
            "save_steps: 1250\n",
            "20220531 11:28:20 current learning_rate:0.00001000\n",
            "used_time: 0.22625207901000977\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 640, loss: 0.362419, acc: 0.625000\n",
            "steps: 640\n",
            "save_steps: 1250\n",
            "20220531 11:28:22 current learning_rate:0.00001000\n",
            "used_time: 0.1906719207763672\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 650, loss: 0.793510, acc: 0.625000\n",
            "steps: 650\n",
            "save_steps: 1250\n",
            "20220531 11:28:24 current learning_rate:0.00001000\n",
            "used_time: 0.21552515029907227\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 660, loss: 0.715603, acc: 0.500000\n",
            "steps: 660\n",
            "save_steps: 1250\n",
            "20220531 11:28:26 current learning_rate:0.00001000\n",
            "used_time: 0.20655226707458496\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 670, loss: 0.325353, acc: 0.750000\n",
            "steps: 670\n",
            "save_steps: 1250\n",
            "20220531 11:28:29 current learning_rate:0.00001000\n",
            "used_time: 0.18921899795532227\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 680, loss: 0.346790, acc: 0.750000\n",
            "steps: 680\n",
            "save_steps: 1250\n",
            "20220531 11:28:31 current learning_rate:0.00001000\n",
            "used_time: 0.20513677597045898\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 690, loss: 0.575220, acc: 0.500000\n",
            "steps: 690\n",
            "save_steps: 1250\n",
            "20220531 11:28:33 current learning_rate:0.00001000\n",
            "used_time: 0.2330336570739746\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 700, loss: 0.494147, acc: 1.000000\n",
            "steps: 700\n",
            "save_steps: 1250\n",
            "20220531 11:28:35 current learning_rate:0.00001000\n",
            "used_time: 0.20737314224243164\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 710, loss: 1.399016, acc: 0.250000\n",
            "steps: 710\n",
            "save_steps: 1250\n",
            "20220531 11:28:37 current learning_rate:0.00001000\n",
            "used_time: 0.19309425354003906\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 720, loss: 0.790284, acc: 0.375000\n",
            "steps: 720\n",
            "save_steps: 1250\n",
            "20220531 11:28:39 current learning_rate:0.00001000\n",
            "used_time: 0.22248196601867676\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 730, loss: 0.450281, acc: 0.625000\n",
            "steps: 730\n",
            "save_steps: 1250\n",
            "20220531 11:28:41 current learning_rate:0.00001000\n",
            "used_time: 0.2853820323944092\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 740, loss: 0.221152, acc: 0.750000\n",
            "steps: 740\n",
            "save_steps: 1250\n",
            "20220531 11:28:43 current learning_rate:0.00001000\n",
            "used_time: 0.2160947322845459\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 750, loss: 0.422330, acc: 0.750000\n",
            "steps: 750\n",
            "save_steps: 1250\n",
            "20220531 11:28:45 current learning_rate:0.00001000\n",
            "used_time: 0.22494769096374512\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 760, loss: 0.599672, acc: 0.750000\n",
            "steps: 760\n",
            "save_steps: 1250\n",
            "20220531 11:28:47 current learning_rate:0.00001000\n",
            "used_time: 0.2121410369873047\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 770, loss: 0.562369, acc: 0.625000\n",
            "steps: 770\n",
            "save_steps: 1250\n",
            "20220531 11:28:49 current learning_rate:0.00001000\n",
            "used_time: 0.21945476531982422\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 780, loss: 0.413121, acc: 0.500000\n",
            "steps: 780\n",
            "save_steps: 1250\n",
            "20220531 11:28:51 current learning_rate:0.00001000\n",
            "used_time: 0.2382802963256836\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 790, loss: 0.183866, acc: 1.000000\n",
            "steps: 790\n",
            "save_steps: 1250\n",
            "20220531 11:28:54 current learning_rate:0.00001000\n",
            "used_time: 0.2066953182220459\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 800, loss: 0.165102, acc: 0.875000\n",
            "steps: 800\n",
            "save_steps: 1250\n",
            "20220531 11:28:56 current learning_rate:0.00001000\n",
            "used_time: 0.21700334548950195\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 810, loss: 0.276494, acc: 0.625000\n",
            "steps: 810\n",
            "save_steps: 1250\n",
            "20220531 11:28:58 current learning_rate:0.00001000\n",
            "used_time: 0.2209789752960205\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 820, loss: 0.067580, acc: 0.625000\n",
            "steps: 820\n",
            "save_steps: 1250\n",
            "20220531 11:29:00 current learning_rate:0.00001000\n",
            "used_time: 0.20136523246765137\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 830, loss: 0.246651, acc: 0.625000\n",
            "steps: 830\n",
            "save_steps: 1250\n",
            "20220531 11:29:02 current learning_rate:0.00001000\n",
            "used_time: 0.18930935859680176\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 840, loss: 0.793790, acc: 0.375000\n",
            "steps: 840\n",
            "save_steps: 1250\n",
            "20220531 11:29:04 current learning_rate:0.00001000\n",
            "used_time: 0.1984572410583496\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 850, loss: 0.366744, acc: 0.500000\n",
            "steps: 850\n",
            "save_steps: 1250\n",
            "20220531 11:29:06 current learning_rate:0.00001000\n",
            "used_time: 0.24061799049377441\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 860, loss: 0.336844, acc: 0.500000\n",
            "steps: 860\n",
            "save_steps: 1250\n",
            "20220531 11:29:08 current learning_rate:0.00001000\n",
            "used_time: 0.2308967113494873\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 870, loss: 0.624500, acc: 0.500000\n",
            "steps: 870\n",
            "save_steps: 1250\n",
            "20220531 11:29:10 current learning_rate:0.00001000\n",
            "used_time: 0.21059203147888184\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 880, loss: 0.780799, acc: 0.500000\n",
            "steps: 880\n",
            "save_steps: 1250\n",
            "20220531 11:29:12 current learning_rate:0.00001000\n",
            "used_time: 0.20347309112548828\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 890, loss: 0.772200, acc: 0.625000\n",
            "steps: 890\n",
            "save_steps: 1250\n",
            "20220531 11:29:14 current learning_rate:0.00001000\n",
            "used_time: 0.2432699203491211\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 900, loss: 0.382930, acc: 0.875000\n",
            "steps: 900\n",
            "save_steps: 1250\n",
            "20220531 11:29:16 current learning_rate:0.00001000\n",
            "used_time: 0.23795366287231445\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 910, loss: 0.356247, acc: 0.750000\n",
            "steps: 910\n",
            "save_steps: 1250\n",
            "20220531 11:29:18 current learning_rate:0.00001000\n",
            "used_time: 0.18921709060668945\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 920, loss: 0.531818, acc: 0.375000\n",
            "steps: 920\n",
            "save_steps: 1250\n",
            "20220531 11:29:21 current learning_rate:0.00001000\n",
            "used_time: 0.29457616806030273\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 930, loss: 0.572092, acc: 0.375000\n",
            "steps: 930\n",
            "save_steps: 1250\n",
            "20220531 11:29:23 current learning_rate:0.00001000\n",
            "used_time: 0.3078923225402832\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 940, loss: 0.887906, acc: 0.875000\n",
            "steps: 940\n",
            "save_steps: 1250\n",
            "20220531 11:29:25 current learning_rate:0.00001000\n",
            "used_time: 0.23991751670837402\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 950, loss: 0.384098, acc: 0.750000\n",
            "steps: 950\n",
            "save_steps: 1250\n",
            "20220531 11:29:27 current learning_rate:0.00001000\n",
            "used_time: 0.1900632381439209\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 960, loss: 0.596900, acc: 0.750000\n",
            "steps: 960\n",
            "save_steps: 1250\n",
            "20220531 11:29:29 current learning_rate:0.00001000\n",
            "used_time: 0.18642807006835938\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 970, loss: 0.430222, acc: 0.750000\n",
            "steps: 970\n",
            "save_steps: 1250\n",
            "20220531 11:29:31 current learning_rate:0.00001000\n",
            "used_time: 0.23359894752502441\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 980, loss: 0.901067, acc: 0.375000\n",
            "steps: 980\n",
            "save_steps: 1250\n",
            "20220531 11:29:34 current learning_rate:0.00001000\n",
            "used_time: 0.21518373489379883\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 990, loss: 0.425823, acc: 0.875000\n",
            "steps: 990\n",
            "save_steps: 1250\n",
            "20220531 11:29:36 current learning_rate:0.00001000\n",
            "used_time: 0.2212846279144287\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1000, loss: 0.765806, acc: 0.375000\n",
            "steps: 1000\n",
            "save_steps: 1250\n",
            "Train-RCAC 0.7402376910016978\n",
            "20220531 11:29:38 current learning_rate:0.00001000\n",
            "used_time: 0.22984695434570312\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1010, loss: 0.633836, acc: 0.750000\n",
            "steps: 1010\n",
            "save_steps: 1250\n",
            "20220531 11:29:40 current learning_rate:0.00001000\n",
            "used_time: 0.2416059970855713\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1020, loss: 0.476482, acc: 0.750000\n",
            "steps: 1020\n",
            "save_steps: 1250\n",
            "20220531 11:29:42 current learning_rate:0.00001000\n",
            "used_time: 0.2038562297821045\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1030, loss: 0.607329, acc: 0.625000\n",
            "steps: 1030\n",
            "save_steps: 1250\n",
            "20220531 11:29:44 current learning_rate:0.00001000\n",
            "used_time: 0.19917678833007812\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1040, loss: 0.493449, acc: 0.625000\n",
            "steps: 1040\n",
            "save_steps: 1250\n",
            "20220531 11:29:46 current learning_rate:0.00001000\n",
            "used_time: 0.21422433853149414\n",
            "shuffle epoch 1\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1050, loss: 0.462633, acc: 0.500000\n",
            "steps: 1050\n",
            "save_steps: 1250\n",
            "20220531 11:29:48 current learning_rate:0.00001000\n",
            "used_time: 0.22933101654052734\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1060, loss: 0.538261, acc: 0.500000\n",
            "steps: 1060\n",
            "save_steps: 1250\n",
            "20220531 11:29:50 current learning_rate:0.00001000\n",
            "used_time: 0.2254035472869873\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1070, loss: 0.727297, acc: 0.500000\n",
            "steps: 1070\n",
            "save_steps: 1250\n",
            "20220531 11:29:52 current learning_rate:0.00001000\n",
            "used_time: 0.2220315933227539\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1080, loss: 0.260612, acc: 0.750000\n",
            "steps: 1080\n",
            "save_steps: 1250\n",
            "20220531 11:29:54 current learning_rate:0.00001000\n",
            "used_time: 0.20377850532531738\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1090, loss: 0.456740, acc: 0.500000\n",
            "steps: 1090\n",
            "save_steps: 1250\n",
            "20220531 11:29:56 current learning_rate:0.00001000\n",
            "used_time: 0.2590341567993164\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1100, loss: 0.235002, acc: 0.750000\n",
            "steps: 1100\n",
            "save_steps: 1250\n",
            "20220531 11:29:59 current learning_rate:0.00001000\n",
            "used_time: 0.20208477973937988\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1110, loss: 0.174433, acc: 0.750000\n",
            "steps: 1110\n",
            "save_steps: 1250\n",
            "20220531 11:30:01 current learning_rate:0.00001000\n",
            "used_time: 0.22675418853759766\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1120, loss: 0.719765, acc: 0.750000\n",
            "steps: 1120\n",
            "save_steps: 1250\n",
            "20220531 11:30:03 current learning_rate:0.00001000\n",
            "used_time: 0.21498632431030273\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1130, loss: 0.111538, acc: 0.750000\n",
            "steps: 1130\n",
            "save_steps: 1250\n",
            "20220531 11:30:05 current learning_rate:0.00001000\n",
            "used_time: 0.25533366203308105\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1140, loss: 0.816652, acc: 0.500000\n",
            "steps: 1140\n",
            "save_steps: 1250\n",
            "20220531 11:30:07 current learning_rate:0.00001000\n",
            "used_time: 0.2026839256286621\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1150, loss: 0.915589, acc: 0.625000\n",
            "steps: 1150\n",
            "save_steps: 1250\n",
            "20220531 11:30:09 current learning_rate:0.00001000\n",
            "used_time: 0.20794296264648438\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1160, loss: 0.479366, acc: 0.625000\n",
            "steps: 1160\n",
            "save_steps: 1250\n",
            "20220531 11:30:11 current learning_rate:0.00001000\n",
            "used_time: 0.22997641563415527\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1170, loss: 0.614826, acc: 0.625000\n",
            "steps: 1170\n",
            "save_steps: 1250\n",
            "20220531 11:30:13 current learning_rate:0.00001000\n",
            "used_time: 0.2247629165649414\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1180, loss: 0.053353, acc: 0.500000\n",
            "steps: 1180\n",
            "save_steps: 1250\n",
            "20220531 11:30:15 current learning_rate:0.00001000\n",
            "used_time: 0.2052919864654541\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1190, loss: 0.401959, acc: 0.375000\n",
            "steps: 1190\n",
            "save_steps: 1250\n",
            "20220531 11:30:17 current learning_rate:0.00001000\n",
            "used_time: 0.20475530624389648\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1200, loss: 0.742356, acc: 0.750000\n",
            "steps: 1200\n",
            "save_steps: 1250\n",
            "20220531 11:30:19 current learning_rate:0.00001000\n",
            "used_time: 0.18273377418518066\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1210, loss: 0.235647, acc: 0.750000\n",
            "steps: 1210\n",
            "save_steps: 1250\n",
            "20220531 11:30:21 current learning_rate:0.00001000\n",
            "used_time: 0.24581527709960938\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1220, loss: 0.286314, acc: 0.625000\n",
            "steps: 1220\n",
            "save_steps: 1250\n",
            "20220531 11:30:23 current learning_rate:0.00001000\n",
            "used_time: 0.2007765769958496\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1230, loss: 0.939705, acc: 0.625000\n",
            "steps: 1230\n",
            "save_steps: 1250\n",
            "20220531 11:30:25 current learning_rate:0.00001000\n",
            "used_time: 0.21233725547790527\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1240, loss: 0.387377, acc: 0.500000\n",
            "steps: 1240\n",
            "save_steps: 1250\n",
            "20220531 11:30:27 current learning_rate:0.00001000\n",
            "used_time: 0.20933151245117188\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1250, loss: 0.155545, acc: 0.750000\n",
            "steps: 1250\n",
            "save_steps: 1250\n",
            "20220531 11:30:30 current learning_rate:0.00001000\n",
            "save_path: output_hm/step_1250train\n",
            "used_time: 11.927477836608887\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1260, loss: 0.199532, acc: 0.500000\n",
            "steps: 1260\n",
            "save_steps: 1250\n",
            "20220531 11:30:43 current learning_rate:0.00001000\n",
            "used_time: 0.18648815155029297\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1270, loss: 0.492004, acc: 0.500000\n",
            "steps: 1270\n",
            "save_steps: 1250\n",
            "20220531 11:30:45 current learning_rate:0.00001000\n",
            "used_time: 0.19961237907409668\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1280, loss: 1.328202, acc: 0.625000\n",
            "steps: 1280\n",
            "save_steps: 1250\n",
            "20220531 11:30:48 current learning_rate:0.00001000\n",
            "used_time: 0.2086637020111084\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1290, loss: 0.497846, acc: 0.750000\n",
            "steps: 1290\n",
            "save_steps: 1250\n",
            "20220531 11:30:50 current learning_rate:0.00001000\n",
            "used_time: 0.2125236988067627\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1300, loss: 0.086316, acc: 0.625000\n",
            "steps: 1300\n",
            "save_steps: 1250\n",
            "20220531 11:30:52 current learning_rate:0.00001000\n",
            "used_time: 0.22630071640014648\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1310, loss: 0.024248, acc: 0.625000\n",
            "steps: 1310\n",
            "save_steps: 1250\n",
            "20220531 11:30:54 current learning_rate:0.00001000\n",
            "used_time: 0.18871045112609863\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1320, loss: 0.145089, acc: 0.750000\n",
            "steps: 1320\n",
            "save_steps: 1250\n",
            "20220531 11:30:56 current learning_rate:0.00001000\n",
            "used_time: 0.21243548393249512\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1330, loss: 0.210491, acc: 0.375000\n",
            "steps: 1330\n",
            "save_steps: 1250\n",
            "20220531 11:30:58 current learning_rate:0.00001000\n",
            "used_time: 0.24436736106872559\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1340, loss: 1.242297, acc: 0.625000\n",
            "steps: 1340\n",
            "save_steps: 1250\n",
            "20220531 11:31:00 current learning_rate:0.00001000\n",
            "used_time: 0.2263190746307373\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1350, loss: 0.066874, acc: 0.625000\n",
            "steps: 1350\n",
            "save_steps: 1250\n",
            "20220531 11:31:02 current learning_rate:0.00001000\n",
            "used_time: 0.19781112670898438\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1360, loss: 0.652201, acc: 0.625000\n",
            "steps: 1360\n",
            "save_steps: 1250\n",
            "20220531 11:31:04 current learning_rate:0.00001000\n",
            "used_time: 0.21291327476501465\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1370, loss: 0.325394, acc: 1.000000\n",
            "steps: 1370\n",
            "save_steps: 1250\n",
            "20220531 11:31:06 current learning_rate:0.00001000\n",
            "used_time: 0.23735451698303223\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1380, loss: 0.470118, acc: 0.875000\n",
            "steps: 1380\n",
            "save_steps: 1250\n",
            "20220531 11:31:08 current learning_rate:0.00001000\n",
            "used_time: 0.19959807395935059\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1390, loss: 0.337849, acc: 0.125000\n",
            "steps: 1390\n",
            "save_steps: 1250\n",
            "20220531 11:31:10 current learning_rate:0.00001000\n",
            "used_time: 0.20476698875427246\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1400, loss: 0.697591, acc: 0.750000\n",
            "steps: 1400\n",
            "save_steps: 1250\n",
            "20220531 11:31:13 current learning_rate:0.00001000\n",
            "used_time: 0.21371817588806152\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1410, loss: 0.055442, acc: 0.625000\n",
            "steps: 1410\n",
            "save_steps: 1250\n",
            "20220531 11:31:15 current learning_rate:0.00001000\n",
            "used_time: 0.2432537078857422\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1420, loss: 0.810090, acc: 0.500000\n",
            "steps: 1420\n",
            "save_steps: 1250\n",
            "20220531 11:31:17 current learning_rate:0.00001000\n",
            "used_time: 0.21962380409240723\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1430, loss: 0.590263, acc: 0.500000\n",
            "steps: 1430\n",
            "save_steps: 1250\n",
            "20220531 11:31:19 current learning_rate:0.00001000\n",
            "used_time: 0.20203304290771484\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1440, loss: 0.738641, acc: 0.750000\n",
            "steps: 1440\n",
            "save_steps: 1250\n",
            "20220531 11:31:21 current learning_rate:0.00001000\n",
            "used_time: 0.20971131324768066\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1450, loss: 0.114556, acc: 0.625000\n",
            "steps: 1450\n",
            "save_steps: 1250\n",
            "20220531 11:31:23 current learning_rate:0.00001000\n",
            "used_time: 0.22859859466552734\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1460, loss: 0.127403, acc: 0.750000\n",
            "steps: 1460\n",
            "save_steps: 1250\n",
            "20220531 11:31:25 current learning_rate:0.00001000\n",
            "used_time: 0.1888577938079834\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1470, loss: 0.479928, acc: 0.625000\n",
            "steps: 1470\n",
            "save_steps: 1250\n",
            "20220531 11:31:27 current learning_rate:0.00001000\n",
            "used_time: 0.18203115463256836\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1480, loss: 0.101965, acc: 0.750000\n",
            "steps: 1480\n",
            "save_steps: 1250\n",
            "20220531 11:31:29 current learning_rate:0.00001000\n",
            "used_time: 0.20437026023864746\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1490, loss: 0.373224, acc: 0.750000\n",
            "steps: 1490\n",
            "save_steps: 1250\n",
            "20220531 11:31:31 current learning_rate:0.00001000\n",
            "used_time: 0.24827361106872559\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1500, loss: 0.590041, acc: 0.500000\n",
            "steps: 1500\n",
            "save_steps: 1250\n",
            "Train-RCAC 0.8298611111111112\n",
            "20220531 11:31:34 current learning_rate:0.00001000\n",
            "used_time: 0.2431321144104004\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1510, loss: 0.275292, acc: 0.875000\n",
            "steps: 1510\n",
            "save_steps: 1250\n",
            "20220531 11:31:36 current learning_rate:0.00001000\n",
            "used_time: 0.28307223320007324\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1520, loss: 0.475048, acc: 0.500000\n",
            "steps: 1520\n",
            "save_steps: 1250\n",
            "20220531 11:31:38 current learning_rate:0.00001000\n",
            "used_time: 0.22199654579162598\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1530, loss: 0.051075, acc: 0.625000\n",
            "steps: 1530\n",
            "save_steps: 1250\n",
            "20220531 11:31:40 current learning_rate:0.00001000\n",
            "used_time: 0.23227262496948242\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1540, loss: 0.469920, acc: 0.500000\n",
            "steps: 1540\n",
            "save_steps: 1250\n",
            "20220531 11:31:42 current learning_rate:0.00001000\n",
            "used_time: 0.21357417106628418\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1550, loss: 0.026830, acc: 1.000000\n",
            "steps: 1550\n",
            "save_steps: 1250\n",
            "20220531 11:31:44 current learning_rate:0.00001000\n",
            "used_time: 0.1991441249847412\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1560, loss: 0.337807, acc: 0.625000\n",
            "steps: 1560\n",
            "save_steps: 1250\n",
            "20220531 11:31:46 current learning_rate:0.00001000\n",
            "used_time: 0.21369504928588867\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1570, loss: 0.974978, acc: 0.625000\n",
            "steps: 1570\n",
            "save_steps: 1250\n",
            "20220531 11:31:48 current learning_rate:0.00001000\n",
            "used_time: 0.24996352195739746\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1580, loss: 0.196503, acc: 0.750000\n",
            "steps: 1580\n",
            "save_steps: 1250\n",
            "20220531 11:31:50 current learning_rate:0.00001000\n",
            "used_time: 0.1907789707183838\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1590, loss: 0.179251, acc: 0.625000\n",
            "steps: 1590\n",
            "save_steps: 1250\n",
            "20220531 11:31:53 current learning_rate:0.00001000\n",
            "used_time: 0.22719383239746094\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1600, loss: 0.202688, acc: 0.750000\n",
            "steps: 1600\n",
            "save_steps: 1250\n",
            "20220531 11:31:55 current learning_rate:0.00001000\n",
            "used_time: 0.21645498275756836\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1610, loss: 0.644510, acc: 0.500000\n",
            "steps: 1610\n",
            "save_steps: 1250\n",
            "20220531 11:31:57 current learning_rate:0.00001000\n",
            "used_time: 0.23174214363098145\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1620, loss: 0.091325, acc: 0.875000\n",
            "steps: 1620\n",
            "save_steps: 1250\n",
            "20220531 11:31:59 current learning_rate:0.00001000\n",
            "used_time: 0.22714996337890625\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1630, loss: 0.459691, acc: 0.375000\n",
            "steps: 1630\n",
            "save_steps: 1250\n",
            "20220531 11:32:01 current learning_rate:0.00001000\n",
            "used_time: 0.1877281665802002\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1640, loss: 0.333333, acc: 0.500000\n",
            "steps: 1640\n",
            "save_steps: 1250\n",
            "20220531 11:32:03 current learning_rate:0.00001000\n",
            "used_time: 0.24770712852478027\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1650, loss: 0.295792, acc: 0.500000\n",
            "steps: 1650\n",
            "save_steps: 1250\n",
            "20220531 11:32:05 current learning_rate:0.00001000\n",
            "used_time: 0.23481225967407227\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1660, loss: 0.296237, acc: 0.875000\n",
            "steps: 1660\n",
            "save_steps: 1250\n",
            "20220531 11:32:07 current learning_rate:0.00001000\n",
            "used_time: 0.19852280616760254\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1670, loss: 0.040809, acc: 0.750000\n",
            "steps: 1670\n",
            "save_steps: 1250\n",
            "20220531 11:32:09 current learning_rate:0.00001000\n",
            "used_time: 0.20089292526245117\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1680, loss: 0.102785, acc: 0.875000\n",
            "steps: 1680\n",
            "save_steps: 1250\n",
            "20220531 11:32:12 current learning_rate:0.00001000\n",
            "used_time: 0.2003922462463379\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1690, loss: 0.212752, acc: 0.375000\n",
            "steps: 1690\n",
            "save_steps: 1250\n",
            "20220531 11:32:14 current learning_rate:0.00001000\n",
            "used_time: 0.2730081081390381\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1700, loss: 0.198789, acc: 0.750000\n",
            "steps: 1700\n",
            "save_steps: 1250\n",
            "20220531 11:32:16 current learning_rate:0.00001000\n",
            "used_time: 0.20897769927978516\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1710, loss: 0.021364, acc: 0.750000\n",
            "steps: 1710\n",
            "save_steps: 1250\n",
            "20220531 11:32:18 current learning_rate:0.00001000\n",
            "used_time: 0.20952796936035156\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1720, loss: 0.321264, acc: 0.625000\n",
            "steps: 1720\n",
            "save_steps: 1250\n",
            "20220531 11:32:20 current learning_rate:0.00001000\n",
            "used_time: 0.1939225196838379\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1730, loss: 0.115335, acc: 0.750000\n",
            "steps: 1730\n",
            "save_steps: 1250\n",
            "20220531 11:32:22 current learning_rate:0.00001000\n",
            "used_time: 0.22815513610839844\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1740, loss: 0.399483, acc: 0.375000\n",
            "steps: 1740\n",
            "save_steps: 1250\n",
            "20220531 11:32:24 current learning_rate:0.00001000\n",
            "used_time: 0.18712615966796875\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1750, loss: 1.024409, acc: 0.375000\n",
            "steps: 1750\n",
            "save_steps: 1250\n",
            "20220531 11:32:26 current learning_rate:0.00001000\n",
            "used_time: 0.21972060203552246\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1760, loss: 0.087321, acc: 0.750000\n",
            "steps: 1760\n",
            "save_steps: 1250\n",
            "20220531 11:32:28 current learning_rate:0.00001000\n",
            "used_time: 0.2072005271911621\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1770, loss: 0.972331, acc: 0.500000\n",
            "steps: 1770\n",
            "save_steps: 1250\n",
            "20220531 11:32:31 current learning_rate:0.00001000\n",
            "used_time: 0.23401117324829102\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1780, loss: 0.058214, acc: 0.875000\n",
            "steps: 1780\n",
            "save_steps: 1250\n",
            "20220531 11:32:33 current learning_rate:0.00001000\n",
            "used_time: 0.2086629867553711\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1790, loss: 0.960561, acc: 0.500000\n",
            "steps: 1790\n",
            "save_steps: 1250\n",
            "20220531 11:32:35 current learning_rate:0.00001000\n",
            "used_time: 0.18277287483215332\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1800, loss: 0.433321, acc: 0.875000\n",
            "steps: 1800\n",
            "save_steps: 1250\n",
            "20220531 11:32:37 current learning_rate:0.00001000\n",
            "used_time: 0.19446563720703125\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1810, loss: 0.150324, acc: 0.625000\n",
            "steps: 1810\n",
            "save_steps: 1250\n",
            "20220531 11:32:39 current learning_rate:0.00001000\n",
            "used_time: 0.23109865188598633\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1820, loss: 0.732299, acc: 0.500000\n",
            "steps: 1820\n",
            "save_steps: 1250\n",
            "20220531 11:32:41 current learning_rate:0.00001000\n",
            "used_time: 0.18323159217834473\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1830, loss: 0.107416, acc: 0.750000\n",
            "steps: 1830\n",
            "save_steps: 1250\n",
            "20220531 11:32:43 current learning_rate:0.00001000\n",
            "used_time: 0.24232935905456543\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1840, loss: 0.271835, acc: 0.500000\n",
            "steps: 1840\n",
            "save_steps: 1250\n",
            "20220531 11:32:45 current learning_rate:0.00001000\n",
            "used_time: 0.2118234634399414\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1850, loss: 0.561574, acc: 0.375000\n",
            "steps: 1850\n",
            "save_steps: 1250\n",
            "20220531 11:32:47 current learning_rate:0.00001000\n",
            "used_time: 0.2351393699645996\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1860, loss: 0.240393, acc: 0.750000\n",
            "steps: 1860\n",
            "save_steps: 1250\n",
            "20220531 11:32:49 current learning_rate:0.00001000\n",
            "used_time: 0.20394062995910645\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1870, loss: 0.592809, acc: 0.625000\n",
            "steps: 1870\n",
            "save_steps: 1250\n",
            "20220531 11:32:52 current learning_rate:0.00001000\n",
            "used_time: 0.2424771785736084\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1880, loss: 0.058118, acc: 0.625000\n",
            "steps: 1880\n",
            "save_steps: 1250\n",
            "20220531 11:32:54 current learning_rate:0.00001000\n",
            "used_time: 0.20435047149658203\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1890, loss: 0.028617, acc: 0.625000\n",
            "steps: 1890\n",
            "save_steps: 1250\n",
            "20220531 11:32:56 current learning_rate:0.00001000\n",
            "used_time: 0.24350285530090332\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1900, loss: 0.924984, acc: 0.750000\n",
            "steps: 1900\n",
            "save_steps: 1250\n",
            "20220531 11:32:58 current learning_rate:0.00001000\n",
            "used_time: 0.228590726852417\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1910, loss: 0.596388, acc: 0.625000\n",
            "steps: 1910\n",
            "save_steps: 1250\n",
            "20220531 11:33:00 current learning_rate:0.00001000\n",
            "used_time: 0.21962261199951172\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1920, loss: 0.401975, acc: 0.625000\n",
            "steps: 1920\n",
            "save_steps: 1250\n",
            "20220531 11:33:02 current learning_rate:0.00001000\n",
            "used_time: 0.1926417350769043\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1930, loss: 0.464641, acc: 0.500000\n",
            "steps: 1930\n",
            "save_steps: 1250\n",
            "20220531 11:33:04 current learning_rate:0.00001000\n",
            "used_time: 0.24160218238830566\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1940, loss: 0.161086, acc: 0.875000\n",
            "steps: 1940\n",
            "save_steps: 1250\n",
            "20220531 11:33:06 current learning_rate:0.00001000\n",
            "used_time: 0.18416810035705566\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1950, loss: 1.075162, acc: 0.625000\n",
            "steps: 1950\n",
            "save_steps: 1250\n",
            "20220531 11:33:08 current learning_rate:0.00001000\n",
            "used_time: 0.24131989479064941\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1960, loss: 0.510626, acc: 0.625000\n",
            "steps: 1960\n",
            "save_steps: 1250\n",
            "20220531 11:33:11 current learning_rate:0.00001000\n",
            "used_time: 0.22586417198181152\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1970, loss: 0.143105, acc: 0.750000\n",
            "steps: 1970\n",
            "save_steps: 1250\n",
            "20220531 11:33:13 current learning_rate:0.00001000\n",
            "used_time: 0.22088980674743652\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1980, loss: 0.403241, acc: 0.500000\n",
            "steps: 1980\n",
            "save_steps: 1250\n",
            "20220531 11:33:15 current learning_rate:0.00001000\n",
            "used_time: 0.20739436149597168\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1990, loss: 1.416338, acc: 0.625000\n",
            "steps: 1990\n",
            "save_steps: 1250\n",
            "20220531 11:33:17 current learning_rate:0.00001000\n",
            "used_time: 0.221360445022583\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 2000, loss: 0.159692, acc: 0.500000\n",
            "steps: 2000\n",
            "save_steps: 1250\n",
            "Train-RCAC 0.9166666666666666\n",
            "20220531 11:33:19 current learning_rate:0.00001000\n",
            "used_time: 0.1911773681640625\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 2010, loss: 0.021252, acc: 0.750000\n",
            "steps: 2010\n",
            "save_steps: 1250\n",
            "20220531 11:33:21 current learning_rate:0.00001000\n",
            "used_time: 0.2211616039276123\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 2020, loss: 0.173683, acc: 0.625000\n",
            "steps: 2020\n",
            "save_steps: 1250\n",
            "20220531 11:33:23 current learning_rate:0.00001000\n",
            "used_time: 0.223954439163208\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 2030, loss: 0.272133, acc: 0.875000\n",
            "steps: 2030\n",
            "save_steps: 1250\n",
            "20220531 11:33:25 current learning_rate:0.00001000\n",
            "used_time: 0.18947291374206543\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 2040, loss: 0.491985, acc: 0.625000\n",
            "steps: 2040\n",
            "save_steps: 1250\n",
            "20220531 11:33:27 current learning_rate:0.00001000\n",
            "used_time: 0.21051573753356934\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 2050, loss: 0.336266, acc: 0.625000\n",
            "steps: 2050\n",
            "save_steps: 1250\n",
            "20220531 11:33:29 current learning_rate:0.00001000\n",
            "used_time: 0.22882723808288574\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 2060, loss: 0.178401, acc: 0.750000\n",
            "steps: 2060\n",
            "save_steps: 1250\n",
            "20220531 11:33:31 current learning_rate:0.00001000\n",
            "used_time: 0.2023468017578125\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 2070, loss: 0.289415, acc: 0.875000\n",
            "steps: 2070\n",
            "save_steps: 1250\n",
            "20220531 11:33:34 current learning_rate:0.00001000\n",
            "used_time: 0.20344901084899902\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 2080, loss: 0.556766, acc: 0.500000\n",
            "steps: 2080\n",
            "save_steps: 1250\n",
            "20220531 11:33:36 current learning_rate:0.00001000\n",
            "used_time: 0.28528738021850586\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 2090, loss: 0.335197, acc: 0.875000\n",
            "steps: 2090\n",
            "save_steps: 1250\n",
            "20220531 11:33:38 current learning_rate:0.00001000\n",
            "used_time: 0.23497414588928223\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 2100, loss: 0.869128, acc: 0.375000\n",
            "steps: 2100\n",
            "save_steps: 1250\n",
            "20220531 11:33:40 current learning_rate:0.00001000\n",
            "used_time: 0.21541786193847656\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 2110, loss: 0.612002, acc: 0.500000\n",
            "steps: 2110\n",
            "save_steps: 1250\n",
            "20220531 11:33:42 current learning_rate:0.00001000\n",
            "used_time: 0.2044525146484375\n",
            "shuffle epoch 2\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2120, loss: 0.471194, acc: 0.375000\n",
            "steps: 2120\n",
            "save_steps: 1250\n",
            "20220531 11:33:44 current learning_rate:0.00001000\n",
            "used_time: 0.21483159065246582\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2130, loss: 0.281014, acc: 0.625000\n",
            "steps: 2130\n",
            "save_steps: 1250\n",
            "20220531 11:33:46 current learning_rate:0.00001000\n",
            "used_time: 0.23169183731079102\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2140, loss: 0.584644, acc: 0.500000\n",
            "steps: 2140\n",
            "save_steps: 1250\n",
            "20220531 11:33:48 current learning_rate:0.00001000\n",
            "used_time: 0.2454700469970703\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2150, loss: 0.155735, acc: 0.833333\n",
            "steps: 2150\n",
            "save_steps: 1250\n",
            "20220531 11:33:50 current learning_rate:0.00001000\n",
            "used_time: 0.18004441261291504\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2160, loss: 0.116262, acc: 0.875000\n",
            "steps: 2160\n",
            "save_steps: 1250\n",
            "20220531 11:33:52 current learning_rate:0.00001000\n",
            "used_time: 0.20337176322937012\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2170, loss: 0.025497, acc: 0.500000\n",
            "steps: 2170\n",
            "save_steps: 1250\n",
            "20220531 11:33:54 current learning_rate:0.00001000\n",
            "used_time: 0.25251317024230957\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2180, loss: 0.217390, acc: 0.250000\n",
            "steps: 2180\n",
            "save_steps: 1250\n",
            "20220531 11:33:56 current learning_rate:0.00001000\n",
            "used_time: 0.18825340270996094\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2190, loss: 0.017983, acc: 0.500000\n",
            "steps: 2190\n",
            "save_steps: 1250\n",
            "20220531 11:33:58 current learning_rate:0.00001000\n",
            "used_time: 0.2063751220703125\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2200, loss: 0.004578, acc: 0.875000\n",
            "steps: 2200\n",
            "save_steps: 1250\n",
            "20220531 11:34:01 current learning_rate:0.00001000\n",
            "used_time: 0.18225908279418945\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2210, loss: 0.001998, acc: 0.750000\n",
            "steps: 2210\n",
            "save_steps: 1250\n",
            "20220531 11:34:03 current learning_rate:0.00001000\n",
            "used_time: 0.24318337440490723\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2220, loss: 0.018981, acc: 0.625000\n",
            "steps: 2220\n",
            "save_steps: 1250\n",
            "20220531 11:34:05 current learning_rate:0.00001000\n",
            "used_time: 0.1992189884185791\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2230, loss: 0.238038, acc: 0.625000\n",
            "steps: 2230\n",
            "save_steps: 1250\n",
            "20220531 11:34:07 current learning_rate:0.00001000\n",
            "used_time: 0.18358469009399414\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2240, loss: 0.000562, acc: 0.625000\n",
            "steps: 2240\n",
            "save_steps: 1250\n",
            "20220531 11:34:09 current learning_rate:0.00001000\n",
            "used_time: 0.23931884765625\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2250, loss: 0.863182, acc: 0.625000\n",
            "steps: 2250\n",
            "save_steps: 1250\n",
            "20220531 11:34:11 current learning_rate:0.00001000\n",
            "used_time: 0.25831079483032227\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2260, loss: 0.000725, acc: 0.750000\n",
            "steps: 2260\n",
            "save_steps: 1250\n",
            "20220531 11:34:13 current learning_rate:0.00001000\n",
            "used_time: 0.2052600383758545\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2270, loss: 0.214141, acc: 0.750000\n",
            "steps: 2270\n",
            "save_steps: 1250\n",
            "20220531 11:34:15 current learning_rate:0.00001000\n",
            "used_time: 0.23972201347351074\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2280, loss: 0.002975, acc: 0.750000\n",
            "steps: 2280\n",
            "save_steps: 1250\n",
            "20220531 11:34:17 current learning_rate:0.00001000\n",
            "used_time: 0.2009267807006836\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2290, loss: 0.560829, acc: 0.625000\n",
            "steps: 2290\n",
            "save_steps: 1250\n",
            "20220531 11:34:19 current learning_rate:0.00001000\n",
            "used_time: 0.25837016105651855\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2300, loss: 0.003946, acc: 0.750000\n",
            "steps: 2300\n",
            "save_steps: 1250\n",
            "20220531 11:34:22 current learning_rate:0.00001000\n",
            "used_time: 0.23148465156555176\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2310, loss: 0.670849, acc: 0.625000\n",
            "steps: 2310\n",
            "save_steps: 1250\n",
            "20220531 11:34:24 current learning_rate:0.00001000\n",
            "used_time: 0.20407986640930176\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2320, loss: 0.147551, acc: 0.625000\n",
            "steps: 2320\n",
            "save_steps: 1250\n",
            "20220531 11:34:26 current learning_rate:0.00001000\n",
            "used_time: 0.18422174453735352\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2330, loss: 0.007075, acc: 0.625000\n",
            "steps: 2330\n",
            "save_steps: 1250\n",
            "20220531 11:34:28 current learning_rate:0.00001000\n",
            "used_time: 0.23037958145141602\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2340, loss: 0.499645, acc: 0.875000\n",
            "steps: 2340\n",
            "save_steps: 1250\n",
            "20220531 11:34:30 current learning_rate:0.00001000\n",
            "used_time: 0.2133166790008545\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2350, loss: 0.118171, acc: 0.750000\n",
            "steps: 2350\n",
            "save_steps: 1250\n",
            "20220531 11:34:32 current learning_rate:0.00001000\n",
            "used_time: 0.21289706230163574\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2360, loss: 0.254884, acc: 0.625000\n",
            "steps: 2360\n",
            "save_steps: 1250\n",
            "20220531 11:34:34 current learning_rate:0.00001000\n",
            "used_time: 0.18701744079589844\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2370, loss: 0.755863, acc: 0.375000\n",
            "steps: 2370\n",
            "save_steps: 1250\n",
            "20220531 11:34:36 current learning_rate:0.00001000\n",
            "used_time: 0.2605757713317871\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2380, loss: 0.270219, acc: 0.625000\n",
            "steps: 2380\n",
            "save_steps: 1250\n",
            "20220531 11:34:38 current learning_rate:0.00001000\n",
            "used_time: 0.19561195373535156\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2390, loss: 0.002160, acc: 0.750000\n",
            "steps: 2390\n",
            "save_steps: 1250\n",
            "20220531 11:34:40 current learning_rate:0.00001000\n",
            "used_time: 0.2407395839691162\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2400, loss: 0.027061, acc: 0.625000\n",
            "steps: 2400\n",
            "save_steps: 1250\n",
            "20220531 11:34:42 current learning_rate:0.00001000\n",
            "used_time: 0.19118332862854004\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2410, loss: 0.545701, acc: 0.625000\n",
            "steps: 2410\n",
            "save_steps: 1250\n",
            "20220531 11:34:45 current learning_rate:0.00001000\n",
            "used_time: 0.24523448944091797\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2420, loss: 0.008474, acc: 0.625000\n",
            "steps: 2420\n",
            "save_steps: 1250\n",
            "20220531 11:34:47 current learning_rate:0.00001000\n",
            "used_time: 0.22333002090454102\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2430, loss: 0.215561, acc: 0.625000\n",
            "steps: 2430\n",
            "save_steps: 1250\n",
            "20220531 11:34:49 current learning_rate:0.00001000\n",
            "used_time: 0.19189739227294922\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2440, loss: 0.007731, acc: 0.875000\n",
            "steps: 2440\n",
            "save_steps: 1250\n",
            "20220531 11:34:51 current learning_rate:0.00001000\n",
            "used_time: 0.22242236137390137\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2450, loss: 0.471439, acc: 0.750000\n",
            "steps: 2450\n",
            "save_steps: 1250\n",
            "20220531 11:34:53 current learning_rate:0.00001000\n",
            "used_time: 0.23537659645080566\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2460, loss: 0.110415, acc: 0.625000\n",
            "steps: 2460\n",
            "save_steps: 1250\n",
            "20220531 11:34:55 current learning_rate:0.00001000\n",
            "used_time: 0.20002293586730957\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2470, loss: 0.748509, acc: 0.375000\n",
            "steps: 2470\n",
            "save_steps: 1250\n",
            "20220531 11:34:57 current learning_rate:0.00001000\n",
            "used_time: 0.20313501358032227\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2480, loss: 0.006744, acc: 0.625000\n",
            "steps: 2480\n",
            "save_steps: 1250\n",
            "20220531 11:34:59 current learning_rate:0.00001000\n",
            "used_time: 0.1936194896697998\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2490, loss: 0.002740, acc: 0.750000\n",
            "steps: 2490\n",
            "save_steps: 1250\n",
            "20220531 11:35:02 current learning_rate:0.00001000\n",
            "used_time: 0.26177453994750977\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2500, loss: 0.001540, acc: 0.750000\n",
            "steps: 2500\n",
            "save_steps: 1250\n",
            "Train-RCAC 0.8969298245614035\n",
            "20220531 11:35:04 current learning_rate:0.00001000\n",
            "save_path: output_hm/step_2500train\n",
            "used_time: 11.741562843322754\n",
            "############################WARNING################################### using init_pretraining_params, not init_checkpoint ###### meaning hyper param e.g. lr won't inherit from checkpoint#################################################################W0531 11:35:16.410882  1053 init.cc:216] Warning: PaddlePaddle catches a failure signal, it may not work properly\n",
            "W0531 11:35:16.410945  1053 init.cc:218] You could check whether you killed PaddlePaddle thread/process accidentally or report the case to PaddlePaddle\n",
            "W0531 11:35:16.410977  1053 init.cc:221] The detail failure signal is:\n",
            "\n",
            "W0531 11:35:16.410995  1053 init.cc:224] *** Aborted at 1653996916 (unix time) try \"date -d @1653996916\" if you are using GNU date ***\n",
            "W0531 11:35:16.414598  1053 init.cc:224] PC: @                0x0 (unknown)\n",
            "W0531 11:35:16.416574  1053 init.cc:224] *** SIGABRT (@0x3f6) received by PID 1014 (TID 0x7fd1351bf700) from PID 1014; stack trace: ***\n",
            "W0531 11:35:16.418417  1053 init.cc:224]     @     0x7fd2d958df10 (unknown)\n",
            "W0531 11:35:16.420224  1053 init.cc:224]     @     0x7fd2d958de87 gsignal\n",
            "W0531 11:35:16.422264  1053 init.cc:224]     @     0x7fd2d958f7f1 abort\n",
            "W0531 11:35:16.424661  1053 init.cc:224]     @     0x7fd2d822a10e (unknown)\n",
            "W0531 11:35:16.426430  1053 init.cc:224]     @     0x7fd2d822a356 __gxx_personality_v0\n",
            "W0531 11:35:16.428486  1053 init.cc:224]     @     0x7fd2d7d6a668 (unknown)\n",
            "W0531 11:35:16.430114  1053 init.cc:224]     @     0x7fd2d7d6ac5c _Unwind_ForcedUnwind\n",
            "W0531 11:35:16.431787  1053 init.cc:224]     @     0x7fd2d9341000 __GI___pthread_unwind\n",
            "W0531 11:35:16.433482  1053 init.cc:224]     @     0x7fd2d9338ae5 __pthread_exit\n",
            "W0531 11:35:16.435214  1053 init.cc:224]     @     0x7fd2d967f364 pthread_exit\n",
            "W0531 11:35:16.436172  1053 init.cc:224]     @           0x5e37d8 PyThread_exit_thread\n",
            "W0531 11:35:16.436379  1053 init.cc:224]     @           0x47028a (unknown)\n",
            "W0531 11:35:16.448076  1053 init.cc:224]     @     0x7fd286333019 pybind11::gil_scoped_release::~gil_scoped_release()\n",
            "W0531 11:35:16.449399  1053 init.cc:224]     @     0x7fd28641b3b6 _ZZN8pybind1112cpp_function10initializeIZN6paddle6pybind10BindReaderEPNS_6moduleEEUlRNS2_9operators6reader22LoDTensorBlockingQueueERKSt6vectorINS2_9framework9LoDTensorESaISC_EEE1_bIS9_SG_EINS_4nameENS_9is_methodENS_7siblingENS_10call_guardIINS_18gil_scoped_releaseEEEEEEEvOT_PFT0_DpT1_EDpRKT2_ENUlRNS_6detail13function_callEE1_4_FUNES11_\n",
            "W0531 11:35:16.452939  1053 init.cc:224]     @     0x7fd286350829 pybind11::cpp_function::dispatcher()\n",
            "W0531 11:35:16.453169  1053 init.cc:224]     @           0x593784 _PyMethodDef_RawFastCallKeywords\n",
            "W0531 11:35:16.453313  1053 init.cc:224]     @           0x594731 _PyObject_FastCallKeywords\n",
            "W0531 11:35:16.453514  1053 init.cc:224]     @           0x548cc1 (unknown)\n",
            "W0531 11:35:16.453622  1053 init.cc:224]     @           0x51566f _PyEval_EvalFrameDefault\n",
            "W0531 11:35:16.453760  1053 init.cc:224]     @           0x549e0e _PyEval_EvalCodeWithName\n",
            "W0531 11:35:16.453855  1053 init.cc:224]     @           0x4bcb19 _PyFunction_FastCallDict\n",
            "W0531 11:35:16.453980  1053 init.cc:224]     @           0x5134a6 _PyEval_EvalFrameDefault\n",
            "W0531 11:35:16.454134  1053 init.cc:224]     @           0x593dd7 _PyFunction_FastCallKeywords\n",
            "W0531 11:35:16.454226  1053 init.cc:224]     @           0x511e2c _PyEval_EvalFrameDefault\n",
            "W0531 11:35:16.454375  1053 init.cc:224]     @           0x593dd7 _PyFunction_FastCallKeywords\n",
            "W0531 11:35:16.454555  1053 init.cc:224]     @           0x511e2c _PyEval_EvalFrameDefault\n",
            "W0531 11:35:16.454705  1053 init.cc:224]     @           0x4bc98a _PyFunction_FastCallDict\n",
            "W0531 11:35:16.454937  1053 init.cc:224]     @           0x59c019 (unknown)\n",
            "W0531 11:35:16.455194  1053 init.cc:224]     @           0x595ef6 PyObject_Call\n",
            "W0531 11:35:16.455387  1053 init.cc:224]     @           0x5d5393 (unknown)\n",
            "W0531 11:35:16.455587  1053 init.cc:224]     @           0x5e3137 (unknown)\n",
            "W0531 11:35:16.457448  1053 init.cc:224]     @     0x7fd2d93376db start_thread\n",
            "/content/vilio/ernie-vil/run_finetuning.sh: line 64:  1014 Aborted                 (core dumped) python /content/vilio/ernie-vil/finetune.py --use_cuda \"True\" --is_distributed \"False\" --use_fast_executor ${e_executor-\"True\"} --nccl_comm_num ${nccl_comm_num:-\"1\"} --batch_size $((BATCH_SIZE/gpu_cnt)) --do_train \"True\" --do_test \"False\" --task_name ${TASK_NAME} --vocab_path ${VOCAB_PATH} --task_group_json ${TASK_GROUP_JSON} --lr_scheduler ${lr_scheduler} --decay_steps ${decay_steps-\"\"} --lr_decay_ratio ${lr_decay_ratio-0.1} --num_train_steps ${num_train_steps} --checkpoints $output_model_path --save_steps ${SAVE_STEPS} --init_checkpoint ${PRETRAIN_MODELS} --ernie_config_path ${ERNIE_VIL_CONFIG} --learning_rate ${LR_RATE} --warmup_steps ${WARMUP_STEPS} --weight_decay ${WEIGHT_DECAY:-0} --max_seq_len ${MAX_LEN} --validation_steps ${VALID_STEPS} --skip_steps 10 --split ${SPLIT} --stop_steps ${STOP}\n",
            "-----------  Configuration Arguments -----------\n",
            "batch_size: 8\n",
            "checkpoints: checkpoints\n",
            "combine: False\n",
            "decay_steps: \n",
            "do_test: True\n",
            "do_train: False\n",
            "do_val: False\n",
            "epoch: 100\n",
            "ernie_config_path: /content/vilio/ernie-vil/data/erniesmall/ernie_vil_config.base.json\n",
            "exp: ES36\n",
            "feature_size: 2048\n",
            "fusion_method: sum\n",
            "hierarchical_allreduce_inter_nranks: 8\n",
            "init_checkpoint: /content/vilio/ernie-vil/output_hm/step_2500train\n",
            "is_distributed: False\n",
            "learning_rate: 0.0001\n",
            "lr_decay_dict_file: \n",
            "lr_decay_ratio: 0.1\n",
            "lr_scheduler: linear_warmup_decay\n",
            "max_img_len: 100\n",
            "max_seq_len: 128\n",
            "nccl_comm_num: 1\n",
            "num_features: 50\n",
            "num_train_steps: 1000000\n",
            "output_file: \n",
            "result_file: /content/vilio/ernie-vil/data/log\n",
            "save_steps: 100\n",
            "skip_steps: 10\n",
            "split: dev_seen\n",
            "stop_steps: 5000\n",
            "subtrain: False\n",
            "task_group_json: /content/vilio/ernie-vil/conf/hm/task_hm.json\n",
            "task_name: hm\n",
            "test_filelist: \n",
            "test_split: val\n",
            "train_filelist: \n",
            "use_cuda: True\n",
            "use_fast_executor: True\n",
            "use_fuse: False\n",
            "use_gpu: True\n",
            "use_hierarchical_allreduce: False\n",
            "valid_filelist: \n",
            "validation_steps: 6000\n",
            "verbose: False\n",
            "vocab_path: /content/vilio/ernie-vil/data/erniesmall/vocab.txt\n",
            "warmup_steps: 0\n",
            "weight_decay: 0.01\n",
            "------------------------------------------------\n",
            "finetuning tasks start\n",
            "attention_probs_dropout_prob: 0.1\n",
            "class_attr_size: 401\n",
            "class_size: 1601\n",
            "co_hidden_size: 1024\n",
            "co_intermediate_size: 1024\n",
            "co_num_attention_heads: 8\n",
            "hidden_act: gelu\n",
            "hidden_dropout_prob: 0.1\n",
            "hidden_size: 768\n",
            "initializer_range: 0.02\n",
            "max_position_embeddings: 512\n",
            "num_attention_heads: 12\n",
            "num_hidden_layers: 12\n",
            "sent_type_vocab_size: 4\n",
            "t_biattention_id: [6, 7, 8, 9, 10, 11]\n",
            "task_type_vocab_size: 16\n",
            "type_vocab_size: 2\n",
            "v_biattention_id: [0, 1, 2, 3, 4, 5]\n",
            "v_hidden_size: 1024\n",
            "v_intermediate_size: 1024\n",
            "v_num_attention_heads: 8\n",
            "vocab_size: 30522\n",
            "------------------------------------------------\n",
            "task:  [{'task': 'HM', 'num_choice': 1, 'annotations_jsonpath_train': '/content/vilio/ernie-vil/data/hm/train.jsonl', 'annotations_jsonpath_dev_seen': '/content/vilio/ernie-vil/data/hm/dev_seenlong.jsonl', 'annotations_jsonpath_traindev': '/content/vilio/ernie-vil/data/hm/traindev.jsonl', 'annotations_jsonpath_test_unseen': '/content/vilio/ernie-vil/data/hm/test_unseenlong.jsonl', 'annotations_jsonpath_test_seen': '/content/vilio/ernie-vil/data/hm/test_seenlong.jsonl', 'feature_lmdb_path': '/content/vilio/ernie-vil/data/hm/HM_img.tsv', 'gt_feature_lmdb_path': '/content/vilio/ernie-vil/data/hm/HM_gt_img.tsv', 'unisex_names_table': '/content/vilio/ernie-vil/data/vcr/unisex_names_table.csv', 'Proprocessor': 'PreprocessorBasic', 'tokenizer_name': 'FullTokenizer', 'fusion_method': 'mul', 'dropout_rate': 0.1, 'max_seq_len': 128, 'use_gt_fea': True, 'shufflekeep_across_task': True, 'shuffle_every_epoch': True, 'task_weight': 1.0, 'task_prefix': 'hm'}]\n",
            "2022-05-31 11:35:21,055-WARNING: paddle.fluid.layers.py_reader() may be deprecated in the near future. Please use paddle.fluid.io.DataLoader.from_generator() instead.\n",
            "theoretical memory usage: \n",
            "(3678.2632896423343, 3853.418684387207, 'MB')\n",
            "args.is_distributed: False\n",
            "W0531 11:35:22.832428  1089 device_context.cc:252] Please NOTE: device: 0, CUDA Capability: 60, Driver API Version: 11.2, Runtime API Version: 9.0\n",
            "W0531 11:35:22.850033  1089 device_context.cc:260] device: 0, cuDNN Version: 7.6.\n",
            "SPLIT: dev_seen\n",
            "Start to load Faster-RCNN detected objects from /content/vilio/ernie-vil/data/hm/HM_img.tsv\n",
            "Loaded 500 images in file /content/vilio/ernie-vil/data/hm/HM_img.tsv in 85 seconds.\n",
            "Start to load Faster-RCNN detected objects from /content/vilio/ernie-vil/data/hm/HM_gt_img.tsv\n",
            "Loaded 500 images in file /content/vilio/ernie-vil/data/hm/HM_gt_img.tsv in 56 seconds.\n",
            "Load 650 data from split(s) /content/vilio/ernie-vil/data/hm/dev_seenlong.jsonl.\n",
            "use gt featurre\n",
            "LEN:  650\n",
            "Load pretraining parameters from /content/vilio/ernie-vil/output_hm/step_2500train.\n",
            "testing on hm val split\n",
            "task name list :  ['mean_0.tmp_0', 'accuracy_0.tmp_0', 'arg_max_0.tmp_0', 'read_file_0.tmp_9', 'read_file_0.tmp_8', 'reshape2_120.tmp_0']\n",
            "cur_step: 10 cur_acc: 0.1125\n",
            "cur_step: 20 cur_acc: 0.31875\n",
            "cur_step: 30 cur_acc: 0.35833333333333334\n",
            "cur_step: 40 cur_acc: 0.43125\n",
            "cur_step: 50 cur_acc: 0.4675\n",
            "cur_step: 60 cur_acc: 0.49583333333333335\n",
            "cur_step: 70 cur_acc: 0.45714285714285713\n",
            "cur_step: 80 cur_acc: 0.4609375\n",
            "EXCEPTING\n",
            "LEN: 500 500\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 500 entries, 0 to 499\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   id      500 non-null    int64  \n",
            " 1   proba   500 non-null    float32\n",
            " 2   label   500 non-null    int64  \n",
            "dtypes: float32(1), int64(2)\n",
            "memory usage: 9.9 KB\n",
            "None\n",
            "average_acc: 0.4609375\n",
            "rocauc: 0.7894571358388602\n",
            "+ TASK_NAME=hm\n",
            "+ CONF_FILE=conf/hm/model_conf_hm\n",
            "+ VOCAB_PATH=/content/vilio/ernie-vil/data/erniesmall/vocab.txt\n",
            "+ ERNIE_VIL_CONFIG=/content/vilio/ernie-vil/data/erniesmall/ernie_vil_config.base.json\n",
            "+ PRETRAIN_MODELS=/content/vilio/ernie-vil/data/erniesmall/params\n",
            "+ SPLIT=traindev\n",
            "+ STOP=2500\n",
            "+ source conf/hm/model_conf_hm\n",
            "++ output_model_path=output_hm\n",
            "++ lr_scheduler=manual_warmup_decay\n",
            "++ decay_steps='13308;19962'\n",
            "++ lr_decay_ratio=0.1\n",
            "++ num_train_steps=5000\n",
            "++ SAVE_STEPS=1250\n",
            "++ WARMUP_STEPS=500\n",
            "++ BATCH_SIZE=8\n",
            "++ VALID_STEPS=20000\n",
            "++ LR_RATE=1e-5\n",
            "++ WEIGHT_DECAY=0.01\n",
            "++ MAX_LEN=128\n",
            "+ CUDA_VISIBLE_DEVICES=1\n",
            "+ export FLAGS_fast_eager_deletion_mode=1\n",
            "+ FLAGS_fast_eager_deletion_mode=1\n",
            "+ export FLAGS_eager_delete_tensor_gb=0.0\n",
            "+ FLAGS_eager_delete_tensor_gb=0.0\n",
            "+ export FLAGS_fraction_of_gpu_memory_to_use=0.98\n",
            "+ FLAGS_fraction_of_gpu_memory_to_use=0.98\n",
            "++ echo True\n",
            "++ tr '[A-Z]' '[a-z]'\n",
            "+ e_executor=true\n",
            "++ echo False\n",
            "++ tr '[A-Z]' '[a-z]'\n",
            "+ use_fuse=false\n",
            "+ [[ false == \\t\\r\\u\\e ]]\n",
            "+ TASK_GROUP_JSON=/content/vilio/ernie-vil/conf/hm/task_hm.json\n",
            "++ echo 1\n",
            "++ awk '-F\\t' '{len=split($0,vec,\",\");print len}'\n",
            "+ gpu_cnt=1\n",
            "+ echo gpu_cnt, 1\n",
            "gpu_cnt, 1\n",
            "+ python /content/vilio/ernie-vil/finetune.py --use_cuda True --is_distributed False --use_fast_executor true --nccl_comm_num 1 --batch_size 8 --do_train True --do_test False --task_name hm --vocab_path /content/vilio/ernie-vil/data/erniesmall/vocab.txt --task_group_json /content/vilio/ernie-vil/conf/hm/task_hm.json --lr_scheduler manual_warmup_decay --decay_steps '13308;19962' --lr_decay_ratio 0.1 --num_train_steps 5000 --checkpoints output_hm --save_steps 1250 --init_checkpoint /content/vilio/ernie-vil/data/erniesmall/params --ernie_config_path /content/vilio/ernie-vil/data/erniesmall/ernie_vil_config.base.json --learning_rate 1e-5 --warmup_steps 500 --weight_decay 0.01 --max_seq_len 128 --validation_steps 20000 --skip_steps 10 --split traindev --stop_steps 2500\n",
            "-----------  Configuration Arguments -----------\n",
            "batch_size: 8\n",
            "checkpoints: output_hm\n",
            "combine: False\n",
            "decay_steps: 13308;19962\n",
            "do_test: False\n",
            "do_train: True\n",
            "do_val: False\n",
            "epoch: 100\n",
            "ernie_config_path: /content/vilio/ernie-vil/data/erniesmall/ernie_vil_config.base.json\n",
            "exp: experiment\n",
            "feature_size: 2048\n",
            "fusion_method: sum\n",
            "hierarchical_allreduce_inter_nranks: 8\n",
            "init_checkpoint: /content/vilio/ernie-vil/data/erniesmall/params\n",
            "is_distributed: False\n",
            "learning_rate: 1e-05\n",
            "lr_decay_dict_file: \n",
            "lr_decay_ratio: 0.1\n",
            "lr_scheduler: manual_warmup_decay\n",
            "max_img_len: 100\n",
            "max_seq_len: 128\n",
            "nccl_comm_num: 1\n",
            "num_features: 50\n",
            "num_train_steps: 5000\n",
            "output_file: \n",
            "result_file: ./res_tmp\n",
            "save_steps: 1250\n",
            "skip_steps: 10\n",
            "split: traindev\n",
            "stop_steps: 2500\n",
            "subtrain: False\n",
            "task_group_json: /content/vilio/ernie-vil/conf/hm/task_hm.json\n",
            "task_name: hm\n",
            "test_filelist: \n",
            "test_split: test\n",
            "train_filelist: \n",
            "use_cuda: True\n",
            "use_fast_executor: True\n",
            "use_fuse: False\n",
            "use_gpu: True\n",
            "use_hierarchical_allreduce: False\n",
            "valid_filelist: \n",
            "validation_steps: 20000\n",
            "verbose: False\n",
            "vocab_path: /content/vilio/ernie-vil/data/erniesmall/vocab.txt\n",
            "warmup_steps: 500\n",
            "weight_decay: 0.01\n",
            "------------------------------------------------\n",
            "finetuning tasks start\n",
            "attention_probs_dropout_prob: 0.1\n",
            "class_attr_size: 401\n",
            "class_size: 1601\n",
            "co_hidden_size: 1024\n",
            "co_intermediate_size: 1024\n",
            "co_num_attention_heads: 8\n",
            "hidden_act: gelu\n",
            "hidden_dropout_prob: 0.1\n",
            "hidden_size: 768\n",
            "initializer_range: 0.02\n",
            "max_position_embeddings: 512\n",
            "num_attention_heads: 12\n",
            "num_hidden_layers: 12\n",
            "sent_type_vocab_size: 4\n",
            "t_biattention_id: [6, 7, 8, 9, 10, 11]\n",
            "task_type_vocab_size: 16\n",
            "type_vocab_size: 2\n",
            "v_biattention_id: [0, 1, 2, 3, 4, 5]\n",
            "v_hidden_size: 1024\n",
            "v_intermediate_size: 1024\n",
            "v_num_attention_heads: 8\n",
            "vocab_size: 30522\n",
            "------------------------------------------------\n",
            "task:  [{'task': 'HM', 'num_choice': 1, 'annotations_jsonpath_train': '/content/vilio/ernie-vil/data/hm/train.jsonl', 'annotations_jsonpath_dev_seen': '/content/vilio/ernie-vil/data/hm/dev_seenlong.jsonl', 'annotations_jsonpath_traindev': '/content/vilio/ernie-vil/data/hm/traindev.jsonl', 'annotations_jsonpath_test_unseen': '/content/vilio/ernie-vil/data/hm/test_unseenlong.jsonl', 'annotations_jsonpath_test_seen': '/content/vilio/ernie-vil/data/hm/test_seenlong.jsonl', 'feature_lmdb_path': '/content/vilio/ernie-vil/data/hm/HM_img.tsv', 'gt_feature_lmdb_path': '/content/vilio/ernie-vil/data/hm/HM_gt_img.tsv', 'unisex_names_table': '/content/vilio/ernie-vil/data/vcr/unisex_names_table.csv', 'Proprocessor': 'PreprocessorBasic', 'tokenizer_name': 'FullTokenizer', 'fusion_method': 'mul', 'dropout_rate': 0.1, 'max_seq_len': 128, 'use_gt_fea': True, 'shufflekeep_across_task': True, 'shuffle_every_epoch': True, 'task_weight': 1.0, 'task_prefix': 'hm'}]\n",
            "2022-05-31 11:38:09,666-WARNING: paddle.fluid.layers.py_reader() may be deprecated in the near future. Please use paddle.fluid.io.DataLoader.from_generator() instead.\n",
            "/usr/local/lib/python3.7/dist-packages/paddle/fluid/clip.py:779: UserWarning: Caution! 'set_gradient_clip' is not recommended and may be deprecated in future! We recommend a new strategy: set 'grad_clip' when initializing the 'optimizer'. This method can reduce the mistakes, please refer to documention of 'optimizer'.\n",
            "  warnings.warn(\"Caution! 'set_gradient_clip' is not recommended \"\n",
            "theoretical memory usage: \n",
            "(18209.21138906479, 19076.31669330597, 'MB')\n",
            "args.is_distributed: False\n",
            "W0531 11:38:15.324613  1135 device_context.cc:252] Please NOTE: device: 0, CUDA Capability: 60, Driver API Version: 11.2, Runtime API Version: 9.0\n",
            "W0531 11:38:15.330468  1135 device_context.cc:260] device: 0, cuDNN Version: 7.6.\n",
            "Load pretraining parameters from /content/vilio/ernie-vil/data/erniesmall/params.\n",
            "SPLIT: traindev\n",
            "Start to load Faster-RCNN detected objects from /content/vilio/ernie-vil/data/hm/HM_img.tsv\n",
            "Loaded 9098 images in file /content/vilio/ernie-vil/data/hm/HM_img.tsv in 96 seconds.\n",
            "Start to load Faster-RCNN detected objects from /content/vilio/ernie-vil/data/hm/HM_gt_img.tsv\n",
            "Loaded 9098 images in file /content/vilio/ernie-vil/data/hm/HM_gt_img.tsv in 65 seconds.\n",
            "Load 9598 data from split(s) /content/vilio/ernie-vil/data/hm/traindev.jsonl.\n",
            "use gt featurre\n",
            "LEN:  9598\n",
            "shuffle epoch 0\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 10, loss: 0.671109, acc: 0.625000\n",
            "steps: 10\n",
            "save_steps: 1250\n",
            "20220531 11:41:11 current learning_rate:0.00000018\n",
            "used_time: 0.23368144035339355\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 20, loss: 0.595579, acc: 0.875000\n",
            "steps: 20\n",
            "save_steps: 1250\n",
            "20220531 11:41:13 current learning_rate:0.00000038\n",
            "used_time: 0.19184255599975586\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 30, loss: 0.744442, acc: 0.625000\n",
            "steps: 30\n",
            "save_steps: 1250\n",
            "20220531 11:41:15 current learning_rate:0.00000058\n",
            "used_time: 0.1842212677001953\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 40, loss: 0.818078, acc: 0.625000\n",
            "steps: 40\n",
            "save_steps: 1250\n",
            "20220531 11:41:18 current learning_rate:0.00000078\n",
            "used_time: 0.23555946350097656\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 50, loss: 0.735971, acc: 0.750000\n",
            "steps: 50\n",
            "save_steps: 1250\n",
            "20220531 11:41:20 current learning_rate:0.00000098\n",
            "used_time: 0.29541563987731934\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 60, loss: 0.638841, acc: 0.625000\n",
            "steps: 60\n",
            "save_steps: 1250\n",
            "20220531 11:41:22 current learning_rate:0.00000118\n",
            "used_time: 0.1960926055908203\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 70, loss: 0.745737, acc: 0.375000\n",
            "steps: 70\n",
            "save_steps: 1250\n",
            "20220531 11:41:24 current learning_rate:0.00000138\n",
            "used_time: 0.21624326705932617\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 80, loss: 0.681214, acc: 0.625000\n",
            "steps: 80\n",
            "save_steps: 1250\n",
            "20220531 11:41:26 current learning_rate:0.00000158\n",
            "used_time: 0.20889568328857422\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 90, loss: 0.679445, acc: 0.625000\n",
            "steps: 90\n",
            "save_steps: 1250\n",
            "20220531 11:41:29 current learning_rate:0.00000178\n",
            "used_time: 0.23743057250976562\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 100, loss: 0.678570, acc: 0.625000\n",
            "steps: 100\n",
            "save_steps: 1250\n",
            "20220531 11:41:31 current learning_rate:0.00000198\n",
            "used_time: 0.20373916625976562\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 110, loss: 0.759948, acc: 0.375000\n",
            "steps: 110\n",
            "save_steps: 1250\n",
            "20220531 11:41:33 current learning_rate:0.00000218\n",
            "used_time: 0.19380688667297363\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 120, loss: 0.613261, acc: 1.000000\n",
            "steps: 120\n",
            "save_steps: 1250\n",
            "20220531 11:41:35 current learning_rate:0.00000238\n",
            "used_time: 0.19517731666564941\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 130, loss: 0.615405, acc: 0.875000\n",
            "steps: 130\n",
            "save_steps: 1250\n",
            "20220531 11:41:37 current learning_rate:0.00000258\n",
            "used_time: 0.2258164882659912\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 140, loss: 0.692603, acc: 0.625000\n",
            "steps: 140\n",
            "save_steps: 1250\n",
            "20220531 11:41:39 current learning_rate:0.00000278\n",
            "used_time: 0.2015373706817627\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 150, loss: 0.762842, acc: 0.500000\n",
            "steps: 150\n",
            "save_steps: 1250\n",
            "20220531 11:41:41 current learning_rate:0.00000298\n",
            "used_time: 0.19347119331359863\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 160, loss: 0.554247, acc: 0.875000\n",
            "steps: 160\n",
            "save_steps: 1250\n",
            "20220531 11:41:43 current learning_rate:0.00000318\n",
            "used_time: 0.2201981544494629\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 170, loss: 0.697443, acc: 0.500000\n",
            "steps: 170\n",
            "save_steps: 1250\n",
            "20220531 11:41:45 current learning_rate:0.00000338\n",
            "used_time: 0.24803972244262695\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 180, loss: 0.699388, acc: 0.625000\n",
            "steps: 180\n",
            "save_steps: 1250\n",
            "20220531 11:41:47 current learning_rate:0.00000358\n",
            "used_time: 0.19290685653686523\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 190, loss: 0.599262, acc: 0.875000\n",
            "steps: 190\n",
            "save_steps: 1250\n",
            "20220531 11:41:49 current learning_rate:0.00000378\n",
            "used_time: 0.2080984115600586\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 200, loss: 0.567559, acc: 0.750000\n",
            "steps: 200\n",
            "save_steps: 1250\n",
            "20220531 11:41:52 current learning_rate:0.00000398\n",
            "used_time: 0.21972227096557617\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 210, loss: 0.606201, acc: 0.875000\n",
            "steps: 210\n",
            "save_steps: 1250\n",
            "20220531 11:41:54 current learning_rate:0.00000418\n",
            "used_time: 0.2483048439025879\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 220, loss: 0.643663, acc: 0.750000\n",
            "steps: 220\n",
            "save_steps: 1250\n",
            "20220531 11:41:56 current learning_rate:0.00000438\n",
            "used_time: 0.1985619068145752\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 230, loss: 0.565774, acc: 0.750000\n",
            "steps: 230\n",
            "save_steps: 1250\n",
            "20220531 11:41:58 current learning_rate:0.00000458\n",
            "used_time: 0.21405649185180664\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 240, loss: 0.512019, acc: 0.875000\n",
            "steps: 240\n",
            "save_steps: 1250\n",
            "20220531 11:42:00 current learning_rate:0.00000478\n",
            "used_time: 0.1946125030517578\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 250, loss: 0.700534, acc: 0.625000\n",
            "steps: 250\n",
            "save_steps: 1250\n",
            "20220531 11:42:02 current learning_rate:0.00000498\n",
            "used_time: 0.23331260681152344\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 260, loss: 0.551690, acc: 0.875000\n",
            "steps: 260\n",
            "save_steps: 1250\n",
            "20220531 11:42:04 current learning_rate:0.00000518\n",
            "used_time: 0.21248221397399902\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 270, loss: 0.773889, acc: 0.500000\n",
            "steps: 270\n",
            "save_steps: 1250\n",
            "20220531 11:42:06 current learning_rate:0.00000538\n",
            "used_time: 0.19362926483154297\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 280, loss: 0.651480, acc: 0.625000\n",
            "steps: 280\n",
            "save_steps: 1250\n",
            "20220531 11:42:08 current learning_rate:0.00000558\n",
            "used_time: 0.18851780891418457\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 290, loss: 0.519079, acc: 0.750000\n",
            "steps: 290\n",
            "save_steps: 1250\n",
            "20220531 11:42:10 current learning_rate:0.00000578\n",
            "used_time: 0.22720074653625488\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 300, loss: 0.534605, acc: 0.750000\n",
            "steps: 300\n",
            "save_steps: 1250\n",
            "20220531 11:42:12 current learning_rate:0.00000598\n",
            "used_time: 0.1935901641845703\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 310, loss: 0.630510, acc: 0.625000\n",
            "steps: 310\n",
            "save_steps: 1250\n",
            "20220531 11:42:15 current learning_rate:0.00000618\n",
            "used_time: 0.2206425666809082\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 320, loss: 0.590753, acc: 0.625000\n",
            "steps: 320\n",
            "save_steps: 1250\n",
            "20220531 11:42:17 current learning_rate:0.00000638\n",
            "used_time: 0.2050480842590332\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 330, loss: 0.605527, acc: 0.750000\n",
            "steps: 330\n",
            "save_steps: 1250\n",
            "20220531 11:42:19 current learning_rate:0.00000658\n",
            "used_time: 0.21698236465454102\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 340, loss: 0.602224, acc: 0.750000\n",
            "steps: 340\n",
            "save_steps: 1250\n",
            "20220531 11:42:21 current learning_rate:0.00000678\n",
            "used_time: 0.19913530349731445\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 350, loss: 0.823621, acc: 0.500000\n",
            "steps: 350\n",
            "save_steps: 1250\n",
            "20220531 11:42:23 current learning_rate:0.00000698\n",
            "used_time: 0.1926250457763672\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 360, loss: 0.504511, acc: 0.875000\n",
            "steps: 360\n",
            "save_steps: 1250\n",
            "20220531 11:42:25 current learning_rate:0.00000718\n",
            "used_time: 0.18451857566833496\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 370, loss: 0.423172, acc: 0.875000\n",
            "steps: 370\n",
            "save_steps: 1250\n",
            "20220531 11:42:27 current learning_rate:0.00000738\n",
            "used_time: 0.21596169471740723\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 380, loss: 0.540539, acc: 0.625000\n",
            "steps: 380\n",
            "save_steps: 1250\n",
            "20220531 11:42:29 current learning_rate:0.00000758\n",
            "used_time: 0.24208736419677734\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 390, loss: 0.511476, acc: 0.625000\n",
            "steps: 390\n",
            "save_steps: 1250\n",
            "20220531 11:42:31 current learning_rate:0.00000778\n",
            "used_time: 0.21245360374450684\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 400, loss: 0.731062, acc: 0.625000\n",
            "steps: 400\n",
            "save_steps: 1250\n",
            "20220531 11:42:33 current learning_rate:0.00000798\n",
            "used_time: 0.20437335968017578\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 410, loss: 0.605110, acc: 0.625000\n",
            "steps: 410\n",
            "save_steps: 1250\n",
            "20220531 11:42:35 current learning_rate:0.00000818\n",
            "used_time: 0.23923683166503906\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 420, loss: 0.650106, acc: 0.500000\n",
            "steps: 420\n",
            "save_steps: 1250\n",
            "20220531 11:42:38 current learning_rate:0.00000838\n",
            "used_time: 0.1863713264465332\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 430, loss: 0.705451, acc: 0.375000\n",
            "steps: 430\n",
            "save_steps: 1250\n",
            "20220531 11:42:40 current learning_rate:0.00000858\n",
            "used_time: 0.1923837661743164\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 440, loss: 0.505959, acc: 0.625000\n",
            "steps: 440\n",
            "save_steps: 1250\n",
            "20220531 11:42:42 current learning_rate:0.00000878\n",
            "used_time: 0.20002388954162598\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 450, loss: 0.488742, acc: 0.750000\n",
            "steps: 450\n",
            "save_steps: 1250\n",
            "20220531 11:42:44 current learning_rate:0.00000898\n",
            "used_time: 0.22310996055603027\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 460, loss: 0.641099, acc: 0.375000\n",
            "steps: 460\n",
            "save_steps: 1250\n",
            "20220531 11:42:46 current learning_rate:0.00000918\n",
            "used_time: 0.25136494636535645\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 470, loss: 0.725677, acc: 0.750000\n",
            "steps: 470\n",
            "save_steps: 1250\n",
            "20220531 11:42:48 current learning_rate:0.00000938\n",
            "used_time: 0.2122495174407959\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 480, loss: 0.675409, acc: 0.500000\n",
            "steps: 480\n",
            "save_steps: 1250\n",
            "20220531 11:42:50 current learning_rate:0.00000958\n",
            "used_time: 0.21003508567810059\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 490, loss: 0.976166, acc: 0.750000\n",
            "steps: 490\n",
            "save_steps: 1250\n",
            "20220531 11:42:52 current learning_rate:0.00000978\n",
            "used_time: 0.25788116455078125\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 500, loss: 0.663178, acc: 0.875000\n",
            "steps: 500\n",
            "save_steps: 1250\n",
            "Train-RCAC 0.5657894736842106\n",
            "20220531 11:42:54 current learning_rate:0.00000998\n",
            "used_time: 0.2391071319580078\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 510, loss: 0.698880, acc: 0.375000\n",
            "steps: 510\n",
            "save_steps: 1250\n",
            "20220531 11:42:56 current learning_rate:0.00001000\n",
            "used_time: 0.2014625072479248\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 520, loss: 0.845696, acc: 0.625000\n",
            "steps: 520\n",
            "save_steps: 1250\n",
            "20220531 11:42:58 current learning_rate:0.00001000\n",
            "used_time: 0.21320009231567383\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 530, loss: 0.686688, acc: 0.375000\n",
            "steps: 530\n",
            "save_steps: 1250\n",
            "20220531 11:43:01 current learning_rate:0.00001000\n",
            "used_time: 0.24022364616394043\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 540, loss: 0.678336, acc: 0.625000\n",
            "steps: 540\n",
            "save_steps: 1250\n",
            "20220531 11:43:03 current learning_rate:0.00001000\n",
            "used_time: 0.18730735778808594\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 550, loss: 0.578240, acc: 0.375000\n",
            "steps: 550\n",
            "save_steps: 1250\n",
            "20220531 11:43:05 current learning_rate:0.00001000\n",
            "used_time: 0.1996920108795166\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 560, loss: 0.683472, acc: 0.375000\n",
            "steps: 560\n",
            "save_steps: 1250\n",
            "20220531 11:43:07 current learning_rate:0.00001000\n",
            "used_time: 0.20426273345947266\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 570, loss: 0.472708, acc: 0.625000\n",
            "steps: 570\n",
            "save_steps: 1250\n",
            "20220531 11:43:09 current learning_rate:0.00001000\n",
            "used_time: 0.22373175621032715\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 580, loss: 0.518020, acc: 0.625000\n",
            "steps: 580\n",
            "save_steps: 1250\n",
            "20220531 11:43:11 current learning_rate:0.00001000\n",
            "used_time: 0.20104217529296875\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 590, loss: 0.603933, acc: 0.500000\n",
            "steps: 590\n",
            "save_steps: 1250\n",
            "20220531 11:43:13 current learning_rate:0.00001000\n",
            "used_time: 0.21544718742370605\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 600, loss: 0.601458, acc: 0.875000\n",
            "steps: 600\n",
            "save_steps: 1250\n",
            "20220531 11:43:15 current learning_rate:0.00001000\n",
            "used_time: 0.1956343650817871\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 610, loss: 0.288921, acc: 0.875000\n",
            "steps: 610\n",
            "save_steps: 1250\n",
            "20220531 11:43:17 current learning_rate:0.00001000\n",
            "used_time: 0.23683786392211914\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 620, loss: 0.547063, acc: 0.500000\n",
            "steps: 620\n",
            "save_steps: 1250\n",
            "20220531 11:43:19 current learning_rate:0.00001000\n",
            "used_time: 0.22060942649841309\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 630, loss: 0.391008, acc: 0.750000\n",
            "steps: 630\n",
            "save_steps: 1250\n",
            "20220531 11:43:21 current learning_rate:0.00001000\n",
            "used_time: 0.2064361572265625\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 640, loss: 0.312450, acc: 0.750000\n",
            "steps: 640\n",
            "save_steps: 1250\n",
            "20220531 11:43:24 current learning_rate:0.00001000\n",
            "used_time: 0.2027912139892578\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 650, loss: 0.361420, acc: 0.500000\n",
            "steps: 650\n",
            "save_steps: 1250\n",
            "20220531 11:43:26 current learning_rate:0.00001000\n",
            "used_time: 0.23594379425048828\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 660, loss: 0.253874, acc: 0.625000\n",
            "steps: 660\n",
            "save_steps: 1250\n",
            "20220531 11:43:28 current learning_rate:0.00001000\n",
            "used_time: 0.1854844093322754\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 670, loss: 0.485265, acc: 0.750000\n",
            "steps: 670\n",
            "save_steps: 1250\n",
            "20220531 11:43:30 current learning_rate:0.00001000\n",
            "used_time: 0.2140347957611084\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 680, loss: 0.739870, acc: 0.625000\n",
            "steps: 680\n",
            "save_steps: 1250\n",
            "20220531 11:43:32 current learning_rate:0.00001000\n",
            "used_time: 0.23098516464233398\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 690, loss: 0.743306, acc: 0.375000\n",
            "steps: 690\n",
            "save_steps: 1250\n",
            "20220531 11:43:34 current learning_rate:0.00001000\n",
            "used_time: 0.26476216316223145\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 700, loss: 0.571860, acc: 0.625000\n",
            "steps: 700\n",
            "save_steps: 1250\n",
            "20220531 11:43:36 current learning_rate:0.00001000\n",
            "used_time: 0.19997501373291016\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 710, loss: 0.417681, acc: 0.750000\n",
            "steps: 710\n",
            "save_steps: 1250\n",
            "20220531 11:43:38 current learning_rate:0.00001000\n",
            "used_time: 0.20559406280517578\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 720, loss: 0.400011, acc: 0.875000\n",
            "steps: 720\n",
            "save_steps: 1250\n",
            "20220531 11:43:40 current learning_rate:0.00001000\n",
            "used_time: 0.2512061595916748\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 730, loss: 0.556014, acc: 0.750000\n",
            "steps: 730\n",
            "save_steps: 1250\n",
            "20220531 11:43:43 current learning_rate:0.00001000\n",
            "used_time: 0.24297189712524414\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 740, loss: 0.234152, acc: 0.875000\n",
            "steps: 740\n",
            "save_steps: 1250\n",
            "20220531 11:43:45 current learning_rate:0.00001000\n",
            "used_time: 0.22126102447509766\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 750, loss: 0.579055, acc: 0.500000\n",
            "steps: 750\n",
            "save_steps: 1250\n",
            "20220531 11:43:47 current learning_rate:0.00001000\n",
            "used_time: 0.22510623931884766\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 760, loss: 1.027983, acc: 0.625000\n",
            "steps: 760\n",
            "save_steps: 1250\n",
            "20220531 11:43:49 current learning_rate:0.00001000\n",
            "used_time: 0.1850423812866211\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 770, loss: 0.582666, acc: 0.625000\n",
            "steps: 770\n",
            "save_steps: 1250\n",
            "20220531 11:43:51 current learning_rate:0.00001000\n",
            "used_time: 0.22974014282226562\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 780, loss: 0.283169, acc: 0.750000\n",
            "steps: 780\n",
            "save_steps: 1250\n",
            "20220531 11:43:53 current learning_rate:0.00001000\n",
            "used_time: 0.18734979629516602\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 790, loss: 0.450009, acc: 0.500000\n",
            "steps: 790\n",
            "save_steps: 1250\n",
            "20220531 11:43:55 current learning_rate:0.00001000\n",
            "used_time: 0.20066261291503906\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 800, loss: 0.274785, acc: 0.625000\n",
            "steps: 800\n",
            "save_steps: 1250\n",
            "20220531 11:43:57 current learning_rate:0.00001000\n",
            "used_time: 0.2186260223388672\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 810, loss: 0.576348, acc: 0.750000\n",
            "steps: 810\n",
            "save_steps: 1250\n",
            "20220531 11:43:59 current learning_rate:0.00001000\n",
            "used_time: 0.23778986930847168\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 820, loss: 0.553495, acc: 0.250000\n",
            "steps: 820\n",
            "save_steps: 1250\n",
            "20220531 11:44:01 current learning_rate:0.00001000\n",
            "used_time: 0.2033677101135254\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 830, loss: 0.419396, acc: 0.625000\n",
            "steps: 830\n",
            "save_steps: 1250\n",
            "20220531 11:44:04 current learning_rate:0.00001000\n",
            "used_time: 0.18860769271850586\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 840, loss: 0.181462, acc: 0.875000\n",
            "steps: 840\n",
            "save_steps: 1250\n",
            "20220531 11:44:06 current learning_rate:0.00001000\n",
            "used_time: 0.1885361671447754\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 850, loss: 0.273297, acc: 0.750000\n",
            "steps: 850\n",
            "save_steps: 1250\n",
            "20220531 11:44:08 current learning_rate:0.00001000\n",
            "used_time: 0.22745513916015625\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 860, loss: 1.005038, acc: 0.625000\n",
            "steps: 860\n",
            "save_steps: 1250\n",
            "20220531 11:44:10 current learning_rate:0.00001000\n",
            "used_time: 0.1953737735748291\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 870, loss: 0.301303, acc: 0.625000\n",
            "steps: 870\n",
            "save_steps: 1250\n",
            "20220531 11:44:12 current learning_rate:0.00001000\n",
            "used_time: 0.19911646842956543\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 880, loss: 1.028454, acc: 0.375000\n",
            "steps: 880\n",
            "save_steps: 1250\n",
            "20220531 11:44:14 current learning_rate:0.00001000\n",
            "used_time: 0.21856355667114258\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 890, loss: 0.560258, acc: 0.500000\n",
            "steps: 890\n",
            "save_steps: 1250\n",
            "20220531 11:44:16 current learning_rate:0.00001000\n",
            "used_time: 0.2714698314666748\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 900, loss: 1.191537, acc: 0.500000\n",
            "steps: 900\n",
            "save_steps: 1250\n",
            "20220531 11:44:18 current learning_rate:0.00001000\n",
            "used_time: 0.20222020149230957\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 910, loss: 0.440723, acc: 0.750000\n",
            "steps: 910\n",
            "save_steps: 1250\n",
            "20220531 11:44:20 current learning_rate:0.00001000\n",
            "used_time: 0.2135012149810791\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 920, loss: 0.204827, acc: 0.875000\n",
            "steps: 920\n",
            "save_steps: 1250\n",
            "20220531 11:44:22 current learning_rate:0.00001000\n",
            "used_time: 0.1963653564453125\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 930, loss: 0.285531, acc: 0.250000\n",
            "steps: 930\n",
            "save_steps: 1250\n",
            "20220531 11:44:24 current learning_rate:0.00001000\n",
            "used_time: 0.2296123504638672\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 940, loss: 0.350949, acc: 0.625000\n",
            "steps: 940\n",
            "save_steps: 1250\n",
            "20220531 11:44:26 current learning_rate:0.00001000\n",
            "used_time: 0.2060251235961914\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 950, loss: 0.458869, acc: 0.750000\n",
            "steps: 950\n",
            "save_steps: 1250\n",
            "20220531 11:44:28 current learning_rate:0.00001000\n",
            "used_time: 0.2229020595550537\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 960, loss: 0.531325, acc: 0.500000\n",
            "steps: 960\n",
            "save_steps: 1250\n",
            "20220531 11:44:31 current learning_rate:0.00001000\n",
            "used_time: 0.21459269523620605\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 970, loss: 0.186511, acc: 0.375000\n",
            "steps: 970\n",
            "save_steps: 1250\n",
            "20220531 11:44:33 current learning_rate:0.00001000\n",
            "used_time: 0.235365629196167\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 980, loss: 0.486848, acc: 0.625000\n",
            "steps: 980\n",
            "save_steps: 1250\n",
            "20220531 11:44:35 current learning_rate:0.00001000\n",
            "used_time: 0.17512798309326172\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 990, loss: 0.495665, acc: 0.875000\n",
            "steps: 990\n",
            "save_steps: 1250\n",
            "20220531 11:44:37 current learning_rate:0.00001000\n",
            "used_time: 0.21168303489685059\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1000, loss: 0.471829, acc: 0.625000\n",
            "steps: 1000\n",
            "save_steps: 1250\n",
            "Train-RCAC 0.8253119429590018\n",
            "20220531 11:44:39 current learning_rate:0.00001000\n",
            "used_time: 0.20865702629089355\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1010, loss: 0.951411, acc: 0.625000\n",
            "steps: 1010\n",
            "save_steps: 1250\n",
            "20220531 11:44:41 current learning_rate:0.00001000\n",
            "used_time: 0.23369073867797852\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1020, loss: 0.179204, acc: 0.750000\n",
            "steps: 1020\n",
            "save_steps: 1250\n",
            "20220531 11:44:43 current learning_rate:0.00001000\n",
            "used_time: 0.1857917308807373\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1030, loss: 0.437059, acc: 0.750000\n",
            "steps: 1030\n",
            "save_steps: 1250\n",
            "20220531 11:44:45 current learning_rate:0.00001000\n",
            "used_time: 0.2215898036956787\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1040, loss: 0.266889, acc: 0.375000\n",
            "steps: 1040\n",
            "save_steps: 1250\n",
            "20220531 11:44:47 current learning_rate:0.00001000\n",
            "used_time: 0.17954421043395996\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1050, loss: 0.314310, acc: 0.500000\n",
            "steps: 1050\n",
            "save_steps: 1250\n",
            "20220531 11:44:49 current learning_rate:0.00001000\n",
            "used_time: 0.24101495742797852\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1060, loss: 0.399938, acc: 0.625000\n",
            "steps: 1060\n",
            "save_steps: 1250\n",
            "20220531 11:44:51 current learning_rate:0.00001000\n",
            "used_time: 0.2196636199951172\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1070, loss: 0.414943, acc: 0.500000\n",
            "steps: 1070\n",
            "save_steps: 1250\n",
            "20220531 11:44:53 current learning_rate:0.00001000\n",
            "used_time: 0.19855737686157227\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1080, loss: 0.187546, acc: 1.000000\n",
            "steps: 1080\n",
            "save_steps: 1250\n",
            "20220531 11:44:55 current learning_rate:0.00001000\n",
            "used_time: 0.2073349952697754\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1090, loss: 1.074386, acc: 0.375000\n",
            "steps: 1090\n",
            "save_steps: 1250\n",
            "20220531 11:44:58 current learning_rate:0.00001000\n",
            "used_time: 0.24019265174865723\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1100, loss: 0.728096, acc: 0.625000\n",
            "steps: 1100\n",
            "save_steps: 1250\n",
            "20220531 11:45:00 current learning_rate:0.00001000\n",
            "used_time: 0.20437335968017578\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1110, loss: 0.392543, acc: 0.375000\n",
            "steps: 1110\n",
            "save_steps: 1250\n",
            "20220531 11:45:02 current learning_rate:0.00001000\n",
            "used_time: 0.21405935287475586\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1120, loss: 0.504899, acc: 0.500000\n",
            "steps: 1120\n",
            "save_steps: 1250\n",
            "20220531 11:45:04 current learning_rate:0.00001000\n",
            "used_time: 0.1832447052001953\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1130, loss: 0.301577, acc: 0.375000\n",
            "steps: 1130\n",
            "save_steps: 1250\n",
            "20220531 11:45:06 current learning_rate:0.00001000\n",
            "used_time: 0.25553345680236816\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1140, loss: 0.922247, acc: 0.625000\n",
            "steps: 1140\n",
            "save_steps: 1250\n",
            "20220531 11:45:08 current learning_rate:0.00001000\n",
            "used_time: 0.2216811180114746\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1150, loss: 0.340035, acc: 0.750000\n",
            "steps: 1150\n",
            "save_steps: 1250\n",
            "20220531 11:45:10 current learning_rate:0.00001000\n",
            "used_time: 0.20063495635986328\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1160, loss: 0.607856, acc: 0.625000\n",
            "steps: 1160\n",
            "save_steps: 1250\n",
            "20220531 11:45:12 current learning_rate:0.00001000\n",
            "used_time: 0.20195460319519043\n",
            "shuffle epoch 1\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1170, loss: 0.270924, acc: 0.500000\n",
            "steps: 1170\n",
            "save_steps: 1250\n",
            "20220531 11:45:14 current learning_rate:0.00001000\n",
            "used_time: 0.2219986915588379\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1180, loss: 0.972689, acc: 0.750000\n",
            "steps: 1180\n",
            "save_steps: 1250\n",
            "20220531 11:45:16 current learning_rate:0.00001000\n",
            "used_time: 0.19023537635803223\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1190, loss: 0.489836, acc: 0.750000\n",
            "steps: 1190\n",
            "save_steps: 1250\n",
            "20220531 11:45:18 current learning_rate:0.00001000\n",
            "used_time: 0.20161104202270508\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1200, loss: 0.413848, acc: 0.500000\n",
            "steps: 1200\n",
            "save_steps: 1250\n",
            "20220531 11:45:20 current learning_rate:0.00001000\n",
            "used_time: 0.17473959922790527\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1210, loss: 0.233498, acc: 0.500000\n",
            "steps: 1210\n",
            "save_steps: 1250\n",
            "20220531 11:45:22 current learning_rate:0.00001000\n",
            "used_time: 0.2511420249938965\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1220, loss: 0.032285, acc: 1.000000\n",
            "steps: 1220\n",
            "save_steps: 1250\n",
            "20220531 11:45:25 current learning_rate:0.00001000\n",
            "used_time: 0.1916203498840332\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1230, loss: 0.407014, acc: 0.625000\n",
            "steps: 1230\n",
            "save_steps: 1250\n",
            "20220531 11:45:27 current learning_rate:0.00001000\n",
            "used_time: 0.19890117645263672\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1240, loss: 0.279390, acc: 0.375000\n",
            "steps: 1240\n",
            "save_steps: 1250\n",
            "20220531 11:45:29 current learning_rate:0.00001000\n",
            "used_time: 0.1927814483642578\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1250, loss: 0.771887, acc: 0.625000\n",
            "steps: 1250\n",
            "save_steps: 1250\n",
            "20220531 11:45:31 current learning_rate:0.00001000\n",
            "save_path: output_hm/step_1250traindev\n",
            "used_time: 11.733433246612549\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1260, loss: 0.430575, acc: 0.375000\n",
            "steps: 1260\n",
            "save_steps: 1250\n",
            "20220531 11:45:44 current learning_rate:0.00001000\n",
            "used_time: 0.20415711402893066\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1270, loss: 0.539731, acc: 0.875000\n",
            "steps: 1270\n",
            "save_steps: 1250\n",
            "20220531 11:45:46 current learning_rate:0.00001000\n",
            "used_time: 0.18757867813110352\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1280, loss: 0.694007, acc: 0.625000\n",
            "steps: 1280\n",
            "save_steps: 1250\n",
            "20220531 11:45:49 current learning_rate:0.00001000\n",
            "used_time: 0.24124813079833984\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1290, loss: 0.540486, acc: 0.500000\n",
            "steps: 1290\n",
            "save_steps: 1250\n",
            "20220531 11:45:51 current learning_rate:0.00001000\n",
            "used_time: 0.23743057250976562\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1300, loss: 0.780740, acc: 0.250000\n",
            "steps: 1300\n",
            "save_steps: 1250\n",
            "20220531 11:45:53 current learning_rate:0.00001000\n",
            "used_time: 0.19619417190551758\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1310, loss: 0.033869, acc: 0.750000\n",
            "steps: 1310\n",
            "save_steps: 1250\n",
            "20220531 11:45:55 current learning_rate:0.00001000\n",
            "used_time: 0.19495415687561035\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1320, loss: 0.945863, acc: 0.500000\n",
            "steps: 1320\n",
            "save_steps: 1250\n",
            "20220531 11:45:57 current learning_rate:0.00001000\n",
            "used_time: 0.1835618019104004\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1330, loss: 0.650322, acc: 0.750000\n",
            "steps: 1330\n",
            "save_steps: 1250\n",
            "20220531 11:45:59 current learning_rate:0.00001000\n",
            "used_time: 0.21411967277526855\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1340, loss: 0.091175, acc: 0.500000\n",
            "steps: 1340\n",
            "save_steps: 1250\n",
            "20220531 11:46:01 current learning_rate:0.00001000\n",
            "used_time: 0.19817352294921875\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1350, loss: 0.243490, acc: 0.500000\n",
            "steps: 1350\n",
            "save_steps: 1250\n",
            "20220531 11:46:03 current learning_rate:0.00001000\n",
            "used_time: 0.19701433181762695\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1360, loss: 0.245180, acc: 0.750000\n",
            "steps: 1360\n",
            "save_steps: 1250\n",
            "20220531 11:46:05 current learning_rate:0.00001000\n",
            "used_time: 0.20607638359069824\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1370, loss: 0.905519, acc: 0.625000\n",
            "steps: 1370\n",
            "save_steps: 1250\n",
            "20220531 11:46:07 current learning_rate:0.00001000\n",
            "used_time: 0.237959623336792\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1380, loss: 0.735477, acc: 0.500000\n",
            "steps: 1380\n",
            "save_steps: 1250\n",
            "20220531 11:46:10 current learning_rate:0.00001000\n",
            "used_time: 0.20374083518981934\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1390, loss: 0.120450, acc: 0.875000\n",
            "steps: 1390\n",
            "save_steps: 1250\n",
            "20220531 11:46:12 current learning_rate:0.00001000\n",
            "used_time: 0.22069835662841797\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1400, loss: 0.261827, acc: 0.625000\n",
            "steps: 1400\n",
            "save_steps: 1250\n",
            "20220531 11:46:14 current learning_rate:0.00001000\n",
            "used_time: 0.18501877784729004\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1410, loss: 0.463187, acc: 0.500000\n",
            "steps: 1410\n",
            "save_steps: 1250\n",
            "20220531 11:46:16 current learning_rate:0.00001000\n",
            "used_time: 0.23302865028381348\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1420, loss: 0.214560, acc: 0.500000\n",
            "steps: 1420\n",
            "save_steps: 1250\n",
            "20220531 11:46:18 current learning_rate:0.00001000\n",
            "used_time: 0.19620609283447266\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1430, loss: 0.452415, acc: 0.750000\n",
            "steps: 1430\n",
            "save_steps: 1250\n",
            "20220531 11:46:20 current learning_rate:0.00001000\n",
            "used_time: 0.20779728889465332\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1440, loss: 0.192853, acc: 0.750000\n",
            "steps: 1440\n",
            "save_steps: 1250\n",
            "20220531 11:46:22 current learning_rate:0.00001000\n",
            "used_time: 0.20815753936767578\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1450, loss: 0.539334, acc: 0.750000\n",
            "steps: 1450\n",
            "save_steps: 1250\n",
            "20220531 11:46:24 current learning_rate:0.00001000\n",
            "used_time: 0.23398327827453613\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1460, loss: 0.195385, acc: 0.375000\n",
            "steps: 1460\n",
            "save_steps: 1250\n",
            "20220531 11:46:26 current learning_rate:0.00001000\n",
            "used_time: 0.22684144973754883\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1470, loss: 0.190776, acc: 0.875000\n",
            "steps: 1470\n",
            "save_steps: 1250\n",
            "20220531 11:46:28 current learning_rate:0.00001000\n",
            "used_time: 0.19115972518920898\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1480, loss: 0.760988, acc: 0.625000\n",
            "steps: 1480\n",
            "save_steps: 1250\n",
            "20220531 11:46:30 current learning_rate:0.00001000\n",
            "used_time: 0.18945860862731934\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1490, loss: 0.093742, acc: 0.625000\n",
            "steps: 1490\n",
            "save_steps: 1250\n",
            "20220531 11:46:33 current learning_rate:0.00001000\n",
            "used_time: 0.2583591938018799\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1500, loss: 0.264658, acc: 0.750000\n",
            "steps: 1500\n",
            "save_steps: 1250\n",
            "Train-RCAC 0.9343185550082101\n",
            "20220531 11:46:35 current learning_rate:0.00001000\n",
            "used_time: 0.1860029697418213\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1510, loss: 0.851900, acc: 0.500000\n",
            "steps: 1510\n",
            "save_steps: 1250\n",
            "20220531 11:46:37 current learning_rate:0.00001000\n",
            "used_time: 0.1871964931488037\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1520, loss: 0.462060, acc: 0.625000\n",
            "steps: 1520\n",
            "save_steps: 1250\n",
            "20220531 11:46:39 current learning_rate:0.00001000\n",
            "used_time: 0.21182489395141602\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1530, loss: 0.152179, acc: 0.750000\n",
            "steps: 1530\n",
            "save_steps: 1250\n",
            "20220531 11:46:41 current learning_rate:0.00001000\n",
            "used_time: 0.22589349746704102\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1540, loss: 0.295230, acc: 0.750000\n",
            "steps: 1540\n",
            "save_steps: 1250\n",
            "20220531 11:46:43 current learning_rate:0.00001000\n",
            "used_time: 0.20580697059631348\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1550, loss: 0.227960, acc: 0.500000\n",
            "steps: 1550\n",
            "save_steps: 1250\n",
            "20220531 11:46:45 current learning_rate:0.00001000\n",
            "used_time: 0.20446348190307617\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1560, loss: 0.479798, acc: 0.625000\n",
            "steps: 1560\n",
            "save_steps: 1250\n",
            "20220531 11:46:47 current learning_rate:0.00001000\n",
            "used_time: 0.19169878959655762\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1570, loss: 0.125664, acc: 0.500000\n",
            "steps: 1570\n",
            "save_steps: 1250\n",
            "20220531 11:46:49 current learning_rate:0.00001000\n",
            "used_time: 0.2353048324584961\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1580, loss: 0.162881, acc: 0.625000\n",
            "steps: 1580\n",
            "save_steps: 1250\n",
            "20220531 11:46:51 current learning_rate:0.00001000\n",
            "used_time: 0.2145693302154541\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1590, loss: 0.566074, acc: 0.750000\n",
            "steps: 1590\n",
            "save_steps: 1250\n",
            "20220531 11:46:53 current learning_rate:0.00001000\n",
            "used_time: 0.18421506881713867\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1600, loss: 0.045462, acc: 0.500000\n",
            "steps: 1600\n",
            "save_steps: 1250\n",
            "20220531 11:46:55 current learning_rate:0.00001000\n",
            "used_time: 0.21067023277282715\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1610, loss: 0.475770, acc: 0.875000\n",
            "steps: 1610\n",
            "save_steps: 1250\n",
            "20220531 11:46:57 current learning_rate:0.00001000\n",
            "used_time: 0.2388603687286377\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1620, loss: 0.068339, acc: 0.875000\n",
            "steps: 1620\n",
            "save_steps: 1250\n",
            "20220531 11:47:00 current learning_rate:0.00001000\n",
            "used_time: 0.19823503494262695\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1630, loss: 0.476398, acc: 0.375000\n",
            "steps: 1630\n",
            "save_steps: 1250\n",
            "20220531 11:47:02 current learning_rate:0.00001000\n",
            "used_time: 0.22741436958312988\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1640, loss: 0.248121, acc: 0.875000\n",
            "steps: 1640\n",
            "save_steps: 1250\n",
            "20220531 11:47:04 current learning_rate:0.00001000\n",
            "used_time: 0.18998169898986816\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1650, loss: 0.500401, acc: 0.625000\n",
            "steps: 1650\n",
            "save_steps: 1250\n",
            "20220531 11:47:06 current learning_rate:0.00001000\n",
            "used_time: 0.2246241569519043\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1660, loss: 0.075571, acc: 0.500000\n",
            "steps: 1660\n",
            "save_steps: 1250\n",
            "20220531 11:47:08 current learning_rate:0.00001000\n",
            "used_time: 0.24237632751464844\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1670, loss: 0.464825, acc: 0.375000\n",
            "steps: 1670\n",
            "save_steps: 1250\n",
            "20220531 11:47:10 current learning_rate:0.00001000\n",
            "used_time: 0.22472643852233887\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1680, loss: 0.081310, acc: 0.625000\n",
            "steps: 1680\n",
            "save_steps: 1250\n",
            "20220531 11:47:13 current learning_rate:0.00001000\n",
            "used_time: 0.2355644702911377\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1690, loss: 0.797126, acc: 0.750000\n",
            "steps: 1690\n",
            "save_steps: 1250\n",
            "20220531 11:47:15 current learning_rate:0.00001000\n",
            "used_time: 0.22741436958312988\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1700, loss: 0.735426, acc: 0.750000\n",
            "steps: 1700\n",
            "save_steps: 1250\n",
            "20220531 11:47:17 current learning_rate:0.00001000\n",
            "used_time: 0.22067928314208984\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1710, loss: 0.185584, acc: 0.750000\n",
            "steps: 1710\n",
            "save_steps: 1250\n",
            "20220531 11:47:19 current learning_rate:0.00001000\n",
            "used_time: 0.21132230758666992\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1720, loss: 0.439814, acc: 0.625000\n",
            "steps: 1720\n",
            "save_steps: 1250\n",
            "20220531 11:47:21 current learning_rate:0.00001000\n",
            "used_time: 0.20623040199279785\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1730, loss: 0.159635, acc: 0.375000\n",
            "steps: 1730\n",
            "save_steps: 1250\n",
            "20220531 11:47:24 current learning_rate:0.00001000\n",
            "used_time: 0.2326970100402832\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1740, loss: 0.159947, acc: 0.750000\n",
            "steps: 1740\n",
            "save_steps: 1250\n",
            "20220531 11:47:26 current learning_rate:0.00001000\n",
            "used_time: 0.20990681648254395\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1750, loss: 0.109757, acc: 0.750000\n",
            "steps: 1750\n",
            "save_steps: 1250\n",
            "20220531 11:47:28 current learning_rate:0.00001000\n",
            "used_time: 0.21899938583374023\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1760, loss: 0.196831, acc: 0.625000\n",
            "steps: 1760\n",
            "save_steps: 1250\n",
            "20220531 11:47:30 current learning_rate:0.00001000\n",
            "used_time: 0.18593406677246094\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1770, loss: 0.266010, acc: 0.750000\n",
            "steps: 1770\n",
            "save_steps: 1250\n",
            "20220531 11:47:32 current learning_rate:0.00001000\n",
            "used_time: 0.23498749732971191\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1780, loss: 0.172085, acc: 0.625000\n",
            "steps: 1780\n",
            "save_steps: 1250\n",
            "20220531 11:47:34 current learning_rate:0.00001000\n",
            "used_time: 0.22261476516723633\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1790, loss: 0.465528, acc: 0.750000\n",
            "steps: 1790\n",
            "save_steps: 1250\n",
            "20220531 11:47:36 current learning_rate:0.00001000\n",
            "used_time: 0.2020888328552246\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1800, loss: 0.335753, acc: 0.625000\n",
            "steps: 1800\n",
            "save_steps: 1250\n",
            "20220531 11:47:38 current learning_rate:0.00001000\n",
            "used_time: 0.21388554573059082\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1810, loss: 0.228774, acc: 0.625000\n",
            "steps: 1810\n",
            "save_steps: 1250\n",
            "20220531 11:47:40 current learning_rate:0.00001000\n",
            "used_time: 0.23316454887390137\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1820, loss: 0.389657, acc: 0.750000\n",
            "steps: 1820\n",
            "save_steps: 1250\n",
            "20220531 11:47:42 current learning_rate:0.00001000\n",
            "used_time: 0.19371867179870605\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1830, loss: 0.397681, acc: 0.750000\n",
            "steps: 1830\n",
            "save_steps: 1250\n",
            "20220531 11:47:44 current learning_rate:0.00001000\n",
            "used_time: 0.20110273361206055\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1840, loss: 0.033199, acc: 0.625000\n",
            "steps: 1840\n",
            "save_steps: 1250\n",
            "20220531 11:47:46 current learning_rate:0.00001000\n",
            "used_time: 0.21090269088745117\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1850, loss: 0.021750, acc: 0.750000\n",
            "steps: 1850\n",
            "save_steps: 1250\n",
            "20220531 11:47:49 current learning_rate:0.00001000\n",
            "used_time: 0.27228879928588867\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1860, loss: 0.052726, acc: 0.625000\n",
            "steps: 1860\n",
            "save_steps: 1250\n",
            "20220531 11:47:51 current learning_rate:0.00001000\n",
            "used_time: 0.2547941207885742\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1870, loss: 0.456134, acc: 0.750000\n",
            "steps: 1870\n",
            "save_steps: 1250\n",
            "20220531 11:47:53 current learning_rate:0.00001000\n",
            "used_time: 0.2047290802001953\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1880, loss: 0.622660, acc: 0.875000\n",
            "steps: 1880\n",
            "save_steps: 1250\n",
            "20220531 11:47:55 current learning_rate:0.00001000\n",
            "used_time: 0.20187735557556152\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1890, loss: 0.098415, acc: 0.750000\n",
            "steps: 1890\n",
            "save_steps: 1250\n",
            "20220531 11:47:57 current learning_rate:0.00001000\n",
            "used_time: 0.252713680267334\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1900, loss: 0.068449, acc: 0.625000\n",
            "steps: 1900\n",
            "save_steps: 1250\n",
            "20220531 11:47:59 current learning_rate:0.00001000\n",
            "used_time: 0.1908717155456543\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1910, loss: 0.960486, acc: 0.500000\n",
            "steps: 1910\n",
            "save_steps: 1250\n",
            "20220531 11:48:01 current learning_rate:0.00001000\n",
            "used_time: 0.22631406784057617\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1920, loss: 0.039997, acc: 0.625000\n",
            "steps: 1920\n",
            "save_steps: 1250\n",
            "20220531 11:48:03 current learning_rate:0.00001000\n",
            "used_time: 0.1951918601989746\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1930, loss: 0.426670, acc: 0.750000\n",
            "steps: 1930\n",
            "save_steps: 1250\n",
            "20220531 11:48:05 current learning_rate:0.00001000\n",
            "used_time: 0.24120497703552246\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1940, loss: 0.527743, acc: 0.500000\n",
            "steps: 1940\n",
            "save_steps: 1250\n",
            "20220531 11:48:07 current learning_rate:0.00001000\n",
            "used_time: 0.21854519844055176\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1950, loss: 0.212331, acc: 0.500000\n",
            "steps: 1950\n",
            "save_steps: 1250\n",
            "20220531 11:48:09 current learning_rate:0.00001000\n",
            "used_time: 0.21806120872497559\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1960, loss: 0.683268, acc: 0.625000\n",
            "steps: 1960\n",
            "save_steps: 1250\n",
            "20220531 11:48:11 current learning_rate:0.00001000\n",
            "used_time: 0.20786404609680176\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1970, loss: 0.891789, acc: 0.625000\n",
            "steps: 1970\n",
            "save_steps: 1250\n",
            "20220531 11:48:14 current learning_rate:0.00001000\n",
            "used_time: 0.24223828315734863\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1980, loss: 0.204352, acc: 0.750000\n",
            "steps: 1980\n",
            "save_steps: 1250\n",
            "20220531 11:48:16 current learning_rate:0.00001000\n",
            "used_time: 0.2164914608001709\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1990, loss: 0.063941, acc: 0.500000\n",
            "steps: 1990\n",
            "save_steps: 1250\n",
            "20220531 11:48:18 current learning_rate:0.00001000\n",
            "used_time: 0.22153496742248535\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2000, loss: 0.101516, acc: 0.625000\n",
            "steps: 2000\n",
            "save_steps: 1250\n",
            "Train-RCAC 0.9695238095238095\n",
            "20220531 11:48:20 current learning_rate:0.00001000\n",
            "used_time: 0.18790364265441895\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2010, loss: 0.106279, acc: 0.500000\n",
            "steps: 2010\n",
            "save_steps: 1250\n",
            "20220531 11:48:22 current learning_rate:0.00001000\n",
            "used_time: 0.23593568801879883\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2020, loss: 0.132217, acc: 0.625000\n",
            "steps: 2020\n",
            "save_steps: 1250\n",
            "20220531 11:48:24 current learning_rate:0.00001000\n",
            "used_time: 0.18717169761657715\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2030, loss: 0.516976, acc: 0.375000\n",
            "steps: 2030\n",
            "save_steps: 1250\n",
            "20220531 11:48:26 current learning_rate:0.00001000\n",
            "used_time: 0.2227306365966797\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2040, loss: 0.647078, acc: 0.375000\n",
            "steps: 2040\n",
            "save_steps: 1250\n",
            "20220531 11:48:28 current learning_rate:0.00001000\n",
            "used_time: 0.247330904006958\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2050, loss: 0.155655, acc: 0.375000\n",
            "steps: 2050\n",
            "save_steps: 1250\n",
            "20220531 11:48:30 current learning_rate:0.00001000\n",
            "used_time: 0.24086689949035645\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2060, loss: 0.474792, acc: 0.750000\n",
            "steps: 2060\n",
            "save_steps: 1250\n",
            "20220531 11:48:32 current learning_rate:0.00001000\n",
            "used_time: 0.2288041114807129\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2070, loss: 0.371056, acc: 0.625000\n",
            "steps: 2070\n",
            "save_steps: 1250\n",
            "20220531 11:48:34 current learning_rate:0.00001000\n",
            "used_time: 0.1828620433807373\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2080, loss: 0.489195, acc: 0.750000\n",
            "steps: 2080\n",
            "save_steps: 1250\n",
            "20220531 11:48:37 current learning_rate:0.00001000\n",
            "used_time: 0.22718453407287598\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2090, loss: 0.221417, acc: 0.750000\n",
            "steps: 2090\n",
            "save_steps: 1250\n",
            "20220531 11:48:39 current learning_rate:0.00001000\n",
            "used_time: 0.24167108535766602\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2100, loss: 0.059496, acc: 0.750000\n",
            "steps: 2100\n",
            "save_steps: 1250\n",
            "20220531 11:48:41 current learning_rate:0.00001000\n",
            "used_time: 0.20604681968688965\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2110, loss: 0.956959, acc: 0.500000\n",
            "steps: 2110\n",
            "save_steps: 1250\n",
            "20220531 11:48:43 current learning_rate:0.00001000\n",
            "used_time: 0.18353605270385742\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2120, loss: 0.074510, acc: 0.625000\n",
            "steps: 2120\n",
            "save_steps: 1250\n",
            "20220531 11:48:45 current learning_rate:0.00001000\n",
            "used_time: 0.18417119979858398\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2130, loss: 0.103400, acc: 0.500000\n",
            "steps: 2130\n",
            "save_steps: 1250\n",
            "20220531 11:48:47 current learning_rate:0.00001000\n",
            "used_time: 0.23282194137573242\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2140, loss: 0.280521, acc: 0.125000\n",
            "steps: 2140\n",
            "save_steps: 1250\n",
            "20220531 11:48:49 current learning_rate:0.00001000\n",
            "used_time: 0.20790839195251465\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2150, loss: 0.187049, acc: 0.750000\n",
            "steps: 2150\n",
            "save_steps: 1250\n",
            "20220531 11:48:51 current learning_rate:0.00001000\n",
            "used_time: 0.16977977752685547\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2160, loss: 0.210797, acc: 0.625000\n",
            "steps: 2160\n",
            "save_steps: 1250\n",
            "20220531 11:48:53 current learning_rate:0.00001000\n",
            "used_time: 0.21325445175170898\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2170, loss: 0.494891, acc: 0.750000\n",
            "steps: 2170\n",
            "save_steps: 1250\n",
            "20220531 11:48:55 current learning_rate:0.00001000\n",
            "used_time: 0.23540830612182617\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2180, loss: 0.053209, acc: 0.625000\n",
            "steps: 2180\n",
            "save_steps: 1250\n",
            "20220531 11:48:58 current learning_rate:0.00001000\n",
            "used_time: 0.2058734893798828\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2190, loss: 0.694441, acc: 0.625000\n",
            "steps: 2190\n",
            "save_steps: 1250\n",
            "20220531 11:49:00 current learning_rate:0.00001000\n",
            "used_time: 0.1728065013885498\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2200, loss: 0.170838, acc: 0.750000\n",
            "steps: 2200\n",
            "save_steps: 1250\n",
            "20220531 11:49:02 current learning_rate:0.00001000\n",
            "used_time: 0.22909140586853027\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2210, loss: 0.694769, acc: 0.625000\n",
            "steps: 2210\n",
            "save_steps: 1250\n",
            "20220531 11:49:04 current learning_rate:0.00001000\n",
            "used_time: 0.23795843124389648\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2220, loss: 0.075207, acc: 0.625000\n",
            "steps: 2220\n",
            "save_steps: 1250\n",
            "20220531 11:49:06 current learning_rate:0.00001000\n",
            "used_time: 0.1952500343322754\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2230, loss: 0.401827, acc: 0.625000\n",
            "steps: 2230\n",
            "save_steps: 1250\n",
            "20220531 11:49:08 current learning_rate:0.00001000\n",
            "used_time: 0.1977987289428711\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2240, loss: 0.637656, acc: 0.625000\n",
            "steps: 2240\n",
            "save_steps: 1250\n",
            "20220531 11:49:10 current learning_rate:0.00001000\n",
            "used_time: 0.20344781875610352\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2250, loss: 0.398162, acc: 0.500000\n",
            "steps: 2250\n",
            "save_steps: 1250\n",
            "20220531 11:49:12 current learning_rate:0.00001000\n",
            "used_time: 0.2466585636138916\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2260, loss: 0.327593, acc: 0.625000\n",
            "steps: 2260\n",
            "save_steps: 1250\n",
            "20220531 11:49:14 current learning_rate:0.00001000\n",
            "used_time: 0.22315764427185059\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2270, loss: 0.372982, acc: 0.625000\n",
            "steps: 2270\n",
            "save_steps: 1250\n",
            "20220531 11:49:16 current learning_rate:0.00001000\n",
            "used_time: 0.1918778419494629\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2280, loss: 0.488144, acc: 0.750000\n",
            "steps: 2280\n",
            "save_steps: 1250\n",
            "20220531 11:49:18 current learning_rate:0.00001000\n",
            "used_time: 0.20242977142333984\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2290, loss: 0.350729, acc: 0.375000\n",
            "steps: 2290\n",
            "save_steps: 1250\n",
            "20220531 11:49:20 current learning_rate:0.00001000\n",
            "used_time: 0.23159265518188477\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2300, loss: 0.290722, acc: 0.125000\n",
            "steps: 2300\n",
            "save_steps: 1250\n",
            "20220531 11:49:23 current learning_rate:0.00001000\n",
            "used_time: 0.2002544403076172\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2310, loss: 0.766408, acc: 0.500000\n",
            "steps: 2310\n",
            "save_steps: 1250\n",
            "20220531 11:49:25 current learning_rate:0.00001000\n",
            "used_time: 0.2081611156463623\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2320, loss: 0.196710, acc: 0.500000\n",
            "steps: 2320\n",
            "save_steps: 1250\n",
            "20220531 11:49:27 current learning_rate:0.00001000\n",
            "used_time: 0.19868707656860352\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2330, loss: 0.462752, acc: 0.500000\n",
            "steps: 2330\n",
            "save_steps: 1250\n",
            "20220531 11:49:29 current learning_rate:0.00001000\n",
            "used_time: 0.23239803314208984\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2340, loss: 0.176198, acc: 0.500000\n",
            "steps: 2340\n",
            "save_steps: 1250\n",
            "20220531 11:49:31 current learning_rate:0.00001000\n",
            "used_time: 0.20988678932189941\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2350, loss: 0.137809, acc: 0.750000\n",
            "steps: 2350\n",
            "save_steps: 1250\n",
            "20220531 11:49:33 current learning_rate:0.00001000\n",
            "used_time: 0.18576598167419434\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2360, loss: 0.132410, acc: 0.625000\n",
            "steps: 2360\n",
            "save_steps: 1250\n",
            "20220531 11:49:35 current learning_rate:0.00001000\n",
            "used_time: 0.19388079643249512\n",
            "shuffle epoch 2\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2370, loss: 0.342497, acc: 0.500000\n",
            "steps: 2370\n",
            "save_steps: 1250\n",
            "20220531 11:49:37 current learning_rate:0.00001000\n",
            "used_time: 0.21550202369689941\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2380, loss: 0.136104, acc: 0.625000\n",
            "steps: 2380\n",
            "save_steps: 1250\n",
            "20220531 11:49:39 current learning_rate:0.00001000\n",
            "used_time: 0.20406460762023926\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2390, loss: 0.149418, acc: 0.750000\n",
            "steps: 2390\n",
            "save_steps: 1250\n",
            "20220531 11:49:41 current learning_rate:0.00001000\n",
            "used_time: 0.2206888198852539\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2400, loss: 0.255062, acc: 0.333333\n",
            "steps: 2400\n",
            "save_steps: 1250\n",
            "20220531 11:49:43 current learning_rate:0.00001000\n",
            "used_time: 0.17701435089111328\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2410, loss: 0.585523, acc: 0.625000\n",
            "steps: 2410\n",
            "save_steps: 1250\n",
            "20220531 11:49:46 current learning_rate:0.00001000\n",
            "used_time: 0.21625995635986328\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2420, loss: 0.210235, acc: 0.875000\n",
            "steps: 2420\n",
            "save_steps: 1250\n",
            "20220531 11:49:48 current learning_rate:0.00001000\n",
            "used_time: 0.21233248710632324\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2430, loss: 0.673645, acc: 0.500000\n",
            "steps: 2430\n",
            "save_steps: 1250\n",
            "20220531 11:49:50 current learning_rate:0.00001000\n",
            "used_time: 0.20856261253356934\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2440, loss: 0.008158, acc: 0.750000\n",
            "steps: 2440\n",
            "save_steps: 1250\n",
            "20220531 11:49:52 current learning_rate:0.00001000\n",
            "used_time: 0.20000410079956055\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2450, loss: 1.028428, acc: 0.500000\n",
            "steps: 2450\n",
            "save_steps: 1250\n",
            "20220531 11:49:54 current learning_rate:0.00001000\n",
            "used_time: 0.23885393142700195\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2460, loss: 0.786939, acc: 0.500000\n",
            "steps: 2460\n",
            "save_steps: 1250\n",
            "20220531 11:49:56 current learning_rate:0.00001000\n",
            "used_time: 0.2050940990447998\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2470, loss: 0.026145, acc: 0.625000\n",
            "steps: 2470\n",
            "save_steps: 1250\n",
            "20220531 11:49:58 current learning_rate:0.00001000\n",
            "used_time: 0.20396137237548828\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2480, loss: 0.222496, acc: 0.250000\n",
            "steps: 2480\n",
            "save_steps: 1250\n",
            "20220531 11:50:00 current learning_rate:0.00001000\n",
            "used_time: 0.18432188034057617\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2490, loss: 0.053083, acc: 0.625000\n",
            "steps: 2490\n",
            "save_steps: 1250\n",
            "20220531 11:50:02 current learning_rate:0.00001000\n",
            "used_time: 0.2434678077697754\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2500, loss: 0.002422, acc: 0.875000\n",
            "steps: 2500\n",
            "save_steps: 1250\n",
            "Train-RCAC 0.9210950080515298\n",
            "20220531 11:50:04 current learning_rate:0.00001000\n",
            "save_path: output_hm/step_2500traindev\n",
            "used_time: 11.830321073532104\n",
            "############################WARNING################################### using init_pretraining_params, not init_checkpoint ###### meaning hyper param e.g. lr won't inherit from checkpoint#################################################################W0531 11:50:17.104163  1170 init.cc:216] Warning: PaddlePaddle catches a failure signal, it may not work properly\n",
            "W0531 11:50:17.104234  1170 init.cc:218] You could check whether you killed PaddlePaddle thread/process accidentally or report the case to PaddlePaddle\n",
            "W0531 11:50:17.104254  1170 init.cc:221] The detail failure signal is:\n",
            "\n",
            "W0531 11:50:17.104274  1170 init.cc:224] *** Aborted at 1653997817 (unix time) try \"date -d @1653997817\" if you are using GNU date ***\n",
            "W0531 11:50:17.106562  1170 init.cc:224] PC: @                0x0 (unknown)\n",
            "W0531 11:50:17.107023  1170 init.cc:224] *** SIGABRT (@0x46f) received by PID 1135 (TID 0x7fd354c3f700) from PID 1135; stack trace: ***\n",
            "W0531 11:50:17.109117  1170 init.cc:224]     @     0x7fd4f9632f10 (unknown)\n",
            "W0531 11:50:17.110810  1170 init.cc:224]     @     0x7fd4f9632e87 gsignal\n",
            "W0531 11:50:17.112780  1170 init.cc:224]     @     0x7fd4f96347f1 abort\n",
            "W0531 11:50:17.114634  1170 init.cc:224]     @     0x7fd4f82cf10e (unknown)\n",
            "W0531 11:50:17.116219  1170 init.cc:224]     @     0x7fd4f82cf356 __gxx_personality_v0\n",
            "W0531 11:50:17.117882  1170 init.cc:224]     @     0x7fd4f7e0f668 (unknown)\n",
            "W0531 11:50:17.119455  1170 init.cc:224]     @     0x7fd4f7e0fc5c _Unwind_ForcedUnwind\n",
            "W0531 11:50:17.121048  1170 init.cc:224]     @     0x7fd4f93e6000 __GI___pthread_unwind\n",
            "W0531 11:50:17.122669  1170 init.cc:224]     @     0x7fd4f93ddae5 __pthread_exit\n",
            "W0531 11:50:17.124631  1170 init.cc:224]     @     0x7fd4f9724364 pthread_exit\n",
            "W0531 11:50:17.124881  1170 init.cc:224]     @           0x5e37d8 PyThread_exit_thread\n",
            "W0531 11:50:17.125182  1170 init.cc:224]     @           0x47028a (unknown)\n",
            "W0531 11:50:17.137461  1170 init.cc:224]     @     0x7fd4a63d8019 pybind11::gil_scoped_release::~gil_scoped_release()\n",
            "W0531 11:50:17.141018  1170 init.cc:224]     @     0x7fd4a64c03b6 _ZZN8pybind1112cpp_function10initializeIZN6paddle6pybind10BindReaderEPNS_6moduleEEUlRNS2_9operators6reader22LoDTensorBlockingQueueERKSt6vectorINS2_9framework9LoDTensorESaISC_EEE1_bIS9_SG_EINS_4nameENS_9is_methodENS_7siblingENS_10call_guardIINS_18gil_scoped_releaseEEEEEEEvOT_PFT0_DpT1_EDpRKT2_ENUlRNS_6detail13function_callEE1_4_FUNES11_\n",
            "W0531 11:50:17.153558  1170 init.cc:224]     @     0x7fd4a63f5829 pybind11::cpp_function::dispatcher()\n",
            "W0531 11:50:17.153761  1170 init.cc:224]     @           0x593784 _PyMethodDef_RawFastCallKeywords\n",
            "W0531 11:50:17.153913  1170 init.cc:224]     @           0x594731 _PyObject_FastCallKeywords\n",
            "W0531 11:50:17.154114  1170 init.cc:224]     @           0x548cc1 (unknown)\n",
            "W0531 11:50:17.154232  1170 init.cc:224]     @           0x51566f _PyEval_EvalFrameDefault\n",
            "W0531 11:50:17.154369  1170 init.cc:224]     @           0x549e0e _PyEval_EvalCodeWithName\n",
            "W0531 11:50:17.154525  1170 init.cc:224]     @           0x4bcb19 _PyFunction_FastCallDict\n",
            "W0531 11:50:17.154624  1170 init.cc:224]     @           0x5134a6 _PyEval_EvalFrameDefault\n",
            "W0531 11:50:17.154825  1170 init.cc:224]     @           0x593dd7 _PyFunction_FastCallKeywords\n",
            "W0531 11:50:17.154964  1170 init.cc:224]     @           0x511e2c _PyEval_EvalFrameDefault\n",
            "W0531 11:50:17.155239  1170 init.cc:224]     @           0x593dd7 _PyFunction_FastCallKeywords\n",
            "W0531 11:50:17.155367  1170 init.cc:224]     @           0x511e2c _PyEval_EvalFrameDefault\n",
            "W0531 11:50:17.155541  1170 init.cc:224]     @           0x4bc98a _PyFunction_FastCallDict\n",
            "W0531 11:50:17.155743  1170 init.cc:224]     @           0x59c019 (unknown)\n",
            "W0531 11:50:17.156131  1170 init.cc:224]     @           0x595ef6 PyObject_Call\n",
            "W0531 11:50:17.160472  1170 init.cc:224]     @           0x5d5393 (unknown)\n",
            "W0531 11:50:17.160681  1170 init.cc:224]     @           0x5e3137 (unknown)\n",
            "W0531 11:50:17.162379  1170 init.cc:224]     @     0x7fd4f93dc6db start_thread\n",
            "/content/vilio/ernie-vil/run_finetuning.sh: line 64:  1135 Aborted                 (core dumped) python /content/vilio/ernie-vil/finetune.py --use_cuda \"True\" --is_distributed \"False\" --use_fast_executor ${e_executor-\"True\"} --nccl_comm_num ${nccl_comm_num:-\"1\"} --batch_size $((BATCH_SIZE/gpu_cnt)) --do_train \"True\" --do_test \"False\" --task_name ${TASK_NAME} --vocab_path ${VOCAB_PATH} --task_group_json ${TASK_GROUP_JSON} --lr_scheduler ${lr_scheduler} --decay_steps ${decay_steps-\"\"} --lr_decay_ratio ${lr_decay_ratio-0.1} --num_train_steps ${num_train_steps} --checkpoints $output_model_path --save_steps ${SAVE_STEPS} --init_checkpoint ${PRETRAIN_MODELS} --ernie_config_path ${ERNIE_VIL_CONFIG} --learning_rate ${LR_RATE} --warmup_steps ${WARMUP_STEPS} --weight_decay ${WEIGHT_DECAY:-0} --max_seq_len ${MAX_LEN} --validation_steps ${VALID_STEPS} --skip_steps 10 --split ${SPLIT} --stop_steps ${STOP}\n",
            "-----------  Configuration Arguments -----------\n",
            "batch_size: 8\n",
            "checkpoints: checkpoints\n",
            "combine: False\n",
            "decay_steps: \n",
            "do_test: True\n",
            "do_train: False\n",
            "do_val: False\n",
            "epoch: 100\n",
            "ernie_config_path: /content/vilio/ernie-vil/data/erniesmall/ernie_vil_config.base.json\n",
            "exp: ES36\n",
            "feature_size: 2048\n",
            "fusion_method: sum\n",
            "hierarchical_allreduce_inter_nranks: 8\n",
            "init_checkpoint: /content/vilio/ernie-vil/output_hm/step_2500traindev\n",
            "is_distributed: False\n",
            "learning_rate: 0.0001\n",
            "lr_decay_dict_file: \n",
            "lr_decay_ratio: 0.1\n",
            "lr_scheduler: linear_warmup_decay\n",
            "max_img_len: 100\n",
            "max_seq_len: 128\n",
            "nccl_comm_num: 1\n",
            "num_features: 50\n",
            "num_train_steps: 1000000\n",
            "output_file: \n",
            "result_file: /content/vilio/ernie-vil/data/log\n",
            "save_steps: 100\n",
            "skip_steps: 10\n",
            "split: test_seen\n",
            "stop_steps: 5000\n",
            "subtrain: False\n",
            "task_group_json: /content/vilio/ernie-vil/conf/hm/task_hm.json\n",
            "task_name: hm\n",
            "test_filelist: \n",
            "test_split: val\n",
            "train_filelist: \n",
            "use_cuda: True\n",
            "use_fast_executor: True\n",
            "use_fuse: False\n",
            "use_gpu: True\n",
            "use_hierarchical_allreduce: False\n",
            "valid_filelist: \n",
            "validation_steps: 6000\n",
            "verbose: False\n",
            "vocab_path: /content/vilio/ernie-vil/data/erniesmall/vocab.txt\n",
            "warmup_steps: 0\n",
            "weight_decay: 0.01\n",
            "------------------------------------------------\n",
            "finetuning tasks start\n",
            "attention_probs_dropout_prob: 0.1\n",
            "class_attr_size: 401\n",
            "class_size: 1601\n",
            "co_hidden_size: 1024\n",
            "co_intermediate_size: 1024\n",
            "co_num_attention_heads: 8\n",
            "hidden_act: gelu\n",
            "hidden_dropout_prob: 0.1\n",
            "hidden_size: 768\n",
            "initializer_range: 0.02\n",
            "max_position_embeddings: 512\n",
            "num_attention_heads: 12\n",
            "num_hidden_layers: 12\n",
            "sent_type_vocab_size: 4\n",
            "t_biattention_id: [6, 7, 8, 9, 10, 11]\n",
            "task_type_vocab_size: 16\n",
            "type_vocab_size: 2\n",
            "v_biattention_id: [0, 1, 2, 3, 4, 5]\n",
            "v_hidden_size: 1024\n",
            "v_intermediate_size: 1024\n",
            "v_num_attention_heads: 8\n",
            "vocab_size: 30522\n",
            "------------------------------------------------\n",
            "task:  [{'task': 'HM', 'num_choice': 1, 'annotations_jsonpath_train': '/content/vilio/ernie-vil/data/hm/train.jsonl', 'annotations_jsonpath_dev_seen': '/content/vilio/ernie-vil/data/hm/dev_seenlong.jsonl', 'annotations_jsonpath_traindev': '/content/vilio/ernie-vil/data/hm/traindev.jsonl', 'annotations_jsonpath_test_unseen': '/content/vilio/ernie-vil/data/hm/test_unseenlong.jsonl', 'annotations_jsonpath_test_seen': '/content/vilio/ernie-vil/data/hm/test_seenlong.jsonl', 'feature_lmdb_path': '/content/vilio/ernie-vil/data/hm/HM_img.tsv', 'gt_feature_lmdb_path': '/content/vilio/ernie-vil/data/hm/HM_gt_img.tsv', 'unisex_names_table': '/content/vilio/ernie-vil/data/vcr/unisex_names_table.csv', 'Proprocessor': 'PreprocessorBasic', 'tokenizer_name': 'FullTokenizer', 'fusion_method': 'mul', 'dropout_rate': 0.1, 'max_seq_len': 128, 'use_gt_fea': True, 'shufflekeep_across_task': True, 'shuffle_every_epoch': True, 'task_weight': 1.0, 'task_prefix': 'hm'}]\n",
            "2022-05-31 11:50:21,459-WARNING: paddle.fluid.layers.py_reader() may be deprecated in the near future. Please use paddle.fluid.io.DataLoader.from_generator() instead.\n",
            "theoretical memory usage: \n",
            "(3678.2632896423343, 3853.418684387207, 'MB')\n",
            "args.is_distributed: False\n",
            "W0531 11:50:22.601374  1200 device_context.cc:252] Please NOTE: device: 0, CUDA Capability: 60, Driver API Version: 11.2, Runtime API Version: 9.0\n",
            "W0531 11:50:22.617097  1200 device_context.cc:260] device: 0, cuDNN Version: 7.6.\n",
            "SPLIT: test_seen\n",
            "Start to load Faster-RCNN detected objects from /content/vilio/ernie-vil/data/hm/HM_img.tsv\n",
            "Loaded 1000 images in file /content/vilio/ernie-vil/data/hm/HM_img.tsv in 83 seconds.\n",
            "Start to load Faster-RCNN detected objects from /content/vilio/ernie-vil/data/hm/HM_gt_img.tsv\n",
            "Loaded 1000 images in file /content/vilio/ernie-vil/data/hm/HM_gt_img.tsv in 56 seconds.\n",
            "Load 1300 data from split(s) /content/vilio/ernie-vil/data/hm/test_seenlong.jsonl.\n",
            "use gt featurre\n",
            "LEN:  1300\n",
            "Load pretraining parameters from /content/vilio/ernie-vil/output_hm/step_2500traindev.\n",
            "testing on hm val split\n",
            "task name list :  ['mean_0.tmp_0', 'accuracy_0.tmp_0', 'arg_max_0.tmp_0', 'read_file_0.tmp_9', 'read_file_0.tmp_8', 'reshape2_120.tmp_0']\n",
            "cur_step: 10 cur_acc: 0.9875\n",
            "cur_step: 20 cur_acc: 0.99375\n",
            "cur_step: 30 cur_acc: 0.9958333333333333\n",
            "cur_step: 40 cur_acc: 0.996875\n",
            "cur_step: 50 cur_acc: 0.9975\n",
            "cur_step: 60 cur_acc: 0.9979166666666667\n",
            "cur_step: 70 cur_acc: 0.9982142857142857\n",
            "cur_step: 80 cur_acc: 0.9984375\n",
            "cur_step: 90 cur_acc: 0.9986111111111111\n",
            "cur_step: 100 cur_acc: 0.99875\n",
            "cur_step: 110 cur_acc: 0.9988636363636364\n",
            "cur_step: 120 cur_acc: 0.9989583333333333\n",
            "cur_step: 130 cur_acc: 0.9980769230769231\n",
            "cur_step: 140 cur_acc: 0.9982142857142857\n",
            "cur_step: 150 cur_acc: 0.9983333333333333\n",
            "cur_step: 160 cur_acc: 0.9984375\n",
            "EXCEPTING\n",
            "LEN: 1000 1000\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   id      1000 non-null   int64  \n",
            " 1   proba   1000 non-null   float32\n",
            " 2   label   1000 non-null   int64  \n",
            "dtypes: float32(1), int64(2)\n",
            "memory usage: 19.7 KB\n",
            "None\n",
            "average_acc: 0.9984375\n",
            "rocauc: 0.877151799687011\n",
            "-----------  Configuration Arguments -----------\n",
            "batch_size: 8\n",
            "checkpoints: checkpoints\n",
            "combine: False\n",
            "decay_steps: \n",
            "do_test: True\n",
            "do_train: False\n",
            "do_val: False\n",
            "epoch: 100\n",
            "ernie_config_path: /content/vilio/ernie-vil/data/erniesmall/ernie_vil_config.base.json\n",
            "exp: ES36\n",
            "feature_size: 2048\n",
            "fusion_method: sum\n",
            "hierarchical_allreduce_inter_nranks: 8\n",
            "init_checkpoint: /content/vilio/ernie-vil/output_hm/step_2500traindev\n",
            "is_distributed: False\n",
            "learning_rate: 0.0001\n",
            "lr_decay_dict_file: \n",
            "lr_decay_ratio: 0.1\n",
            "lr_scheduler: linear_warmup_decay\n",
            "max_img_len: 100\n",
            "max_seq_len: 128\n",
            "nccl_comm_num: 1\n",
            "num_features: 50\n",
            "num_train_steps: 1000000\n",
            "output_file: \n",
            "result_file: /content/vilio/ernie-vil/data/log\n",
            "save_steps: 100\n",
            "skip_steps: 10\n",
            "split: test_unseen\n",
            "stop_steps: 5000\n",
            "subtrain: False\n",
            "task_group_json: /content/vilio/ernie-vil/conf/hm/task_hm.json\n",
            "task_name: hm\n",
            "test_filelist: \n",
            "test_split: val\n",
            "train_filelist: \n",
            "use_cuda: True\n",
            "use_fast_executor: True\n",
            "use_fuse: False\n",
            "use_gpu: True\n",
            "use_hierarchical_allreduce: False\n",
            "valid_filelist: \n",
            "validation_steps: 6000\n",
            "verbose: False\n",
            "vocab_path: /content/vilio/ernie-vil/data/erniesmall/vocab.txt\n",
            "warmup_steps: 0\n",
            "weight_decay: 0.01\n",
            "------------------------------------------------\n",
            "finetuning tasks start\n",
            "attention_probs_dropout_prob: 0.1\n",
            "class_attr_size: 401\n",
            "class_size: 1601\n",
            "co_hidden_size: 1024\n",
            "co_intermediate_size: 1024\n",
            "co_num_attention_heads: 8\n",
            "hidden_act: gelu\n",
            "hidden_dropout_prob: 0.1\n",
            "hidden_size: 768\n",
            "initializer_range: 0.02\n",
            "max_position_embeddings: 512\n",
            "num_attention_heads: 12\n",
            "num_hidden_layers: 12\n",
            "sent_type_vocab_size: 4\n",
            "t_biattention_id: [6, 7, 8, 9, 10, 11]\n",
            "task_type_vocab_size: 16\n",
            "type_vocab_size: 2\n",
            "v_biattention_id: [0, 1, 2, 3, 4, 5]\n",
            "v_hidden_size: 1024\n",
            "v_intermediate_size: 1024\n",
            "v_num_attention_heads: 8\n",
            "vocab_size: 30522\n",
            "------------------------------------------------\n",
            "task:  [{'task': 'HM', 'num_choice': 1, 'annotations_jsonpath_train': '/content/vilio/ernie-vil/data/hm/train.jsonl', 'annotations_jsonpath_dev_seen': '/content/vilio/ernie-vil/data/hm/dev_seenlong.jsonl', 'annotations_jsonpath_traindev': '/content/vilio/ernie-vil/data/hm/traindev.jsonl', 'annotations_jsonpath_test_unseen': '/content/vilio/ernie-vil/data/hm/test_unseenlong.jsonl', 'annotations_jsonpath_test_seen': '/content/vilio/ernie-vil/data/hm/test_seenlong.jsonl', 'feature_lmdb_path': '/content/vilio/ernie-vil/data/hm/HM_img.tsv', 'gt_feature_lmdb_path': '/content/vilio/ernie-vil/data/hm/HM_gt_img.tsv', 'unisex_names_table': '/content/vilio/ernie-vil/data/vcr/unisex_names_table.csv', 'Proprocessor': 'PreprocessorBasic', 'tokenizer_name': 'FullTokenizer', 'fusion_method': 'mul', 'dropout_rate': 0.1, 'max_seq_len': 128, 'use_gt_fea': True, 'shufflekeep_across_task': True, 'shuffle_every_epoch': True, 'task_weight': 1.0, 'task_prefix': 'hm'}]\n",
            "2022-05-31 11:53:19,225-WARNING: paddle.fluid.layers.py_reader() may be deprecated in the near future. Please use paddle.fluid.io.DataLoader.from_generator() instead.\n",
            "theoretical memory usage: \n",
            "(3678.2632896423343, 3853.418684387207, 'MB')\n",
            "args.is_distributed: False\n",
            "W0531 11:53:20.460925  1243 device_context.cc:252] Please NOTE: device: 0, CUDA Capability: 60, Driver API Version: 11.2, Runtime API Version: 9.0\n",
            "W0531 11:53:20.477720  1243 device_context.cc:260] device: 0, cuDNN Version: 7.6.\n",
            "SPLIT: test_unseen\n",
            "Start to load Faster-RCNN detected objects from /content/vilio/ernie-vil/data/hm/HM_img.tsv\n",
            "Loaded 2000 images in file /content/vilio/ernie-vil/data/hm/HM_img.tsv in 84 seconds.\n",
            "Start to load Faster-RCNN detected objects from /content/vilio/ernie-vil/data/hm/HM_gt_img.tsv\n",
            "Loaded 2000 images in file /content/vilio/ernie-vil/data/hm/HM_gt_img.tsv in 58 seconds.\n",
            "Load 2600 data from split(s) /content/vilio/ernie-vil/data/hm/test_unseenlong.jsonl.\n",
            "use gt featurre\n",
            "LEN:  2600\n",
            "Load pretraining parameters from /content/vilio/ernie-vil/output_hm/step_2500traindev.\n",
            "testing on hm val split\n",
            "task name list :  ['mean_0.tmp_0', 'accuracy_0.tmp_0', 'arg_max_0.tmp_0', 'read_file_0.tmp_9', 'read_file_0.tmp_8', 'reshape2_120.tmp_0']\n",
            "cur_step: 10 cur_acc: 0.9875\n",
            "cur_step: 20 cur_acc: 0.99375\n",
            "cur_step: 30 cur_acc: 0.9958333333333333\n",
            "cur_step: 40 cur_acc: 0.996875\n",
            "cur_step: 50 cur_acc: 0.9975\n",
            "cur_step: 60 cur_acc: 0.9979166666666667\n",
            "cur_step: 70 cur_acc: 0.9982142857142857\n",
            "cur_step: 80 cur_acc: 0.9984375\n",
            "cur_step: 90 cur_acc: 0.9986111111111111\n",
            "cur_step: 100 cur_acc: 0.99875\n",
            "cur_step: 110 cur_acc: 0.9988636363636364\n",
            "cur_step: 120 cur_acc: 0.9989583333333333\n",
            "cur_step: 130 cur_acc: 0.9990384615384615\n",
            "cur_step: 140 cur_acc: 0.9991071428571429\n",
            "cur_step: 150 cur_acc: 0.9991666666666666\n",
            "cur_step: 160 cur_acc: 0.99921875\n",
            "cur_step: 170 cur_acc: 0.9992647058823529\n",
            "cur_step: 180 cur_acc: 0.9993055555555556\n",
            "cur_step: 190 cur_acc: 0.9993421052631579\n",
            "cur_step: 200 cur_acc: 0.999375\n",
            "cur_step: 210 cur_acc: 0.9994047619047619\n",
            "cur_step: 220 cur_acc: 0.9994318181818181\n",
            "cur_step: 230 cur_acc: 0.9994565217391305\n",
            "cur_step: 240 cur_acc: 0.9994791666666667\n",
            "cur_step: 250 cur_acc: 0.9995\n",
            "cur_step: 260 cur_acc: 0.9990384615384615\n",
            "cur_step: 270 cur_acc: 0.9990740740740741\n",
            "cur_step: 280 cur_acc: 0.9991071428571429\n",
            "cur_step: 290 cur_acc: 0.9991379310344828\n",
            "cur_step: 300 cur_acc: 0.9991666666666666\n",
            "cur_step: 310 cur_acc: 0.9991935483870967\n",
            "cur_step: 320 cur_acc: 0.99921875\n",
            "EXCEPTING\n",
            "LEN: 2000 2000\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2000 entries, 0 to 1999\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   id      2000 non-null   int64  \n",
            " 1   proba   2000 non-null   float32\n",
            " 2   label   2000 non-null   int64  \n",
            "dtypes: float32(1), int64(2)\n",
            "memory usage: 39.2 KB\n",
            "None\n",
            "average_acc: 0.99921875\n",
            "rocauc: 0.3831118060985145\n",
            "CPU times: user 15.3 s, sys: 2.32 s, total: 17.6 s\n",
            "Wall time: 33min 39s\n"
          ]
        }
      ],
      "source": [
        "# second round\n",
        "\n",
        "%%time\n",
        "!bash /content/vilio/ernie-vil/bash/training/ES/hm_ES36.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results record\n",
        "* The results should be stored in `/content/vilio/ernie-vil/data/hm` as `.csv` file."
      ],
      "metadata": {
        "id": "CDu9x_tvia6F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!bash /content/vilio/ernie-vil/bash/training/ES/hm_ES.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPPXt4rQiQU1",
        "outputId": "69504ef2-9a15-429f-8c09-e44294e9f2fe"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mSe han truncado las últimas 5000 líneas del flujo de salida.\u001b[0m\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 950, loss: 0.931593, acc: 0.250000\n",
            "steps: 950\n",
            "save_steps: 1250\n",
            "20220531 14:58:23 current learning_rate:0.00001000\n",
            "used_time: 0.20546722412109375\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 960, loss: 0.311602, acc: 0.625000\n",
            "steps: 960\n",
            "save_steps: 1250\n",
            "20220531 14:58:25 current learning_rate:0.00001000\n",
            "used_time: 0.2059006690979004\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 970, loss: 0.785169, acc: 0.875000\n",
            "steps: 970\n",
            "save_steps: 1250\n",
            "20220531 14:58:28 current learning_rate:0.00001000\n",
            "used_time: 0.2615816593170166\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 980, loss: 0.350206, acc: 0.625000\n",
            "steps: 980\n",
            "save_steps: 1250\n",
            "20220531 14:58:30 current learning_rate:0.00001000\n",
            "used_time: 0.2339005470275879\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 990, loss: 0.299601, acc: 0.625000\n",
            "steps: 990\n",
            "save_steps: 1250\n",
            "20220531 14:58:32 current learning_rate:0.00001000\n",
            "used_time: 0.2653834819793701\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1000, loss: 0.479480, acc: 0.625000\n",
            "steps: 1000\n",
            "save_steps: 1250\n",
            "Train-RCAC 0.8381410256410255\n",
            "20220531 14:58:34 current learning_rate:0.00001000\n",
            "used_time: 0.22706055641174316\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1010, loss: 0.554391, acc: 0.625000\n",
            "steps: 1010\n",
            "save_steps: 1250\n",
            "20220531 14:58:36 current learning_rate:0.00001000\n",
            "used_time: 0.2586183547973633\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1020, loss: 0.852745, acc: 0.500000\n",
            "steps: 1020\n",
            "save_steps: 1250\n",
            "20220531 14:58:39 current learning_rate:0.00001000\n",
            "used_time: 0.20362186431884766\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1030, loss: 0.474054, acc: 0.250000\n",
            "steps: 1030\n",
            "save_steps: 1250\n",
            "20220531 14:58:41 current learning_rate:0.00001000\n",
            "used_time: 0.21155524253845215\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1040, loss: 0.135241, acc: 0.875000\n",
            "steps: 1040\n",
            "save_steps: 1250\n",
            "20220531 14:58:43 current learning_rate:0.00001000\n",
            "used_time: 0.2363126277923584\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1050, loss: 0.548537, acc: 0.500000\n",
            "steps: 1050\n",
            "save_steps: 1250\n",
            "20220531 14:58:45 current learning_rate:0.00001000\n",
            "used_time: 0.25122690200805664\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1060, loss: 0.634030, acc: 0.625000\n",
            "steps: 1060\n",
            "save_steps: 1250\n",
            "20220531 14:58:47 current learning_rate:0.00001000\n",
            "used_time: 0.20757818222045898\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1070, loss: 0.240998, acc: 1.000000\n",
            "steps: 1070\n",
            "save_steps: 1250\n",
            "20220531 14:58:50 current learning_rate:0.00001000\n",
            "used_time: 0.23417091369628906\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1080, loss: 0.280500, acc: 0.750000\n",
            "steps: 1080\n",
            "save_steps: 1250\n",
            "20220531 14:58:52 current learning_rate:0.00001000\n",
            "used_time: 0.21040081977844238\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1090, loss: 0.953590, acc: 0.250000\n",
            "steps: 1090\n",
            "save_steps: 1250\n",
            "20220531 14:58:54 current learning_rate:0.00001000\n",
            "used_time: 0.25455451011657715\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1100, loss: 0.455743, acc: 0.625000\n",
            "steps: 1100\n",
            "save_steps: 1250\n",
            "20220531 14:58:56 current learning_rate:0.00001000\n",
            "used_time: 0.24465036392211914\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1110, loss: 0.803627, acc: 0.500000\n",
            "steps: 1110\n",
            "save_steps: 1250\n",
            "20220531 14:58:59 current learning_rate:0.00001000\n",
            "used_time: 0.2202472686767578\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1120, loss: 0.336353, acc: 0.375000\n",
            "steps: 1120\n",
            "save_steps: 1250\n",
            "20220531 14:59:01 current learning_rate:0.00001000\n",
            "used_time: 0.20367026329040527\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1130, loss: 0.662261, acc: 0.750000\n",
            "steps: 1130\n",
            "save_steps: 1250\n",
            "20220531 14:59:03 current learning_rate:0.00001000\n",
            "used_time: 0.23287034034729004\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1140, loss: 0.381918, acc: 0.500000\n",
            "steps: 1140\n",
            "save_steps: 1250\n",
            "20220531 14:59:05 current learning_rate:0.00001000\n",
            "used_time: 0.20416784286499023\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1150, loss: 0.455310, acc: 0.750000\n",
            "steps: 1150\n",
            "save_steps: 1250\n",
            "20220531 14:59:07 current learning_rate:0.00001000\n",
            "used_time: 0.2278456687927246\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1160, loss: 0.234407, acc: 0.375000\n",
            "steps: 1160\n",
            "save_steps: 1250\n",
            "20220531 14:59:10 current learning_rate:0.00001000\n",
            "used_time: 0.20940876007080078\n",
            "shuffle epoch 1\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1170, loss: 0.392700, acc: 0.625000\n",
            "steps: 1170\n",
            "save_steps: 1250\n",
            "20220531 14:59:12 current learning_rate:0.00001000\n",
            "used_time: 0.24007678031921387\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1180, loss: 0.680509, acc: 0.625000\n",
            "steps: 1180\n",
            "save_steps: 1250\n",
            "20220531 14:59:14 current learning_rate:0.00001000\n",
            "used_time: 0.20729827880859375\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1190, loss: 1.149479, acc: 0.375000\n",
            "steps: 1190\n",
            "save_steps: 1250\n",
            "20220531 14:59:16 current learning_rate:0.00001000\n",
            "used_time: 0.21769928932189941\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1200, loss: 0.205276, acc: 0.833333\n",
            "steps: 1200\n",
            "save_steps: 1250\n",
            "20220531 14:59:18 current learning_rate:0.00001000\n",
            "used_time: 0.18233275413513184\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1210, loss: 0.114305, acc: 0.500000\n",
            "steps: 1210\n",
            "save_steps: 1250\n",
            "20220531 14:59:20 current learning_rate:0.00001000\n",
            "used_time: 0.24057435989379883\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1220, loss: 0.770137, acc: 1.000000\n",
            "steps: 1220\n",
            "save_steps: 1250\n",
            "20220531 14:59:23 current learning_rate:0.00001000\n",
            "used_time: 0.20623421669006348\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1230, loss: 0.090450, acc: 0.375000\n",
            "steps: 1230\n",
            "save_steps: 1250\n",
            "20220531 14:59:25 current learning_rate:0.00001000\n",
            "used_time: 0.20885419845581055\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1240, loss: 0.182285, acc: 0.750000\n",
            "steps: 1240\n",
            "save_steps: 1250\n",
            "20220531 14:59:27 current learning_rate:0.00001000\n",
            "used_time: 0.21997356414794922\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1250, loss: 0.199277, acc: 0.625000\n",
            "steps: 1250\n",
            "save_steps: 1250\n",
            "20220531 14:59:29 current learning_rate:0.00001000\n",
            "save_path: output_hm/step_1250traindev\n",
            "used_time: 12.090893507003784\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1260, loss: 0.511118, acc: 0.750000\n",
            "steps: 1260\n",
            "save_steps: 1250\n",
            "20220531 14:59:43 current learning_rate:0.00001000\n",
            "used_time: 0.23229289054870605\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1270, loss: 0.145424, acc: 0.875000\n",
            "steps: 1270\n",
            "save_steps: 1250\n",
            "20220531 14:59:46 current learning_rate:0.00001000\n",
            "used_time: 0.2277686595916748\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1280, loss: 0.424958, acc: 0.625000\n",
            "steps: 1280\n",
            "save_steps: 1250\n",
            "20220531 14:59:48 current learning_rate:0.00001000\n",
            "used_time: 0.21938800811767578\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1290, loss: 0.210807, acc: 0.750000\n",
            "steps: 1290\n",
            "save_steps: 1250\n",
            "20220531 14:59:50 current learning_rate:0.00001000\n",
            "used_time: 0.2699699401855469\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1300, loss: 0.192696, acc: 0.500000\n",
            "steps: 1300\n",
            "save_steps: 1250\n",
            "20220531 14:59:52 current learning_rate:0.00001000\n",
            "used_time: 0.20608139038085938\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1310, loss: 0.201681, acc: 0.875000\n",
            "steps: 1310\n",
            "save_steps: 1250\n",
            "20220531 14:59:55 current learning_rate:0.00001000\n",
            "used_time: 0.2971150875091553\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1320, loss: 0.128034, acc: 0.625000\n",
            "steps: 1320\n",
            "save_steps: 1250\n",
            "20220531 14:59:57 current learning_rate:0.00001000\n",
            "used_time: 0.22493577003479004\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1330, loss: 0.295391, acc: 0.625000\n",
            "steps: 1330\n",
            "save_steps: 1250\n",
            "20220531 14:59:59 current learning_rate:0.00001000\n",
            "used_time: 0.24676036834716797\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1340, loss: 0.295429, acc: 0.500000\n",
            "steps: 1340\n",
            "save_steps: 1250\n",
            "20220531 15:00:01 current learning_rate:0.00001000\n",
            "used_time: 0.22099781036376953\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1350, loss: 0.457293, acc: 0.750000\n",
            "steps: 1350\n",
            "save_steps: 1250\n",
            "20220531 15:00:04 current learning_rate:0.00001000\n",
            "used_time: 0.22279620170593262\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1360, loss: 0.552906, acc: 0.625000\n",
            "steps: 1360\n",
            "save_steps: 1250\n",
            "20220531 15:00:06 current learning_rate:0.00001000\n",
            "used_time: 0.21096348762512207\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1370, loss: 0.417100, acc: 0.500000\n",
            "steps: 1370\n",
            "save_steps: 1250\n",
            "20220531 15:00:08 current learning_rate:0.00001000\n",
            "used_time: 0.2310335636138916\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1380, loss: 0.658520, acc: 0.500000\n",
            "steps: 1380\n",
            "save_steps: 1250\n",
            "20220531 15:00:10 current learning_rate:0.00001000\n",
            "used_time: 0.21078848838806152\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1390, loss: 0.497399, acc: 0.500000\n",
            "steps: 1390\n",
            "save_steps: 1250\n",
            "20220531 15:00:12 current learning_rate:0.00001000\n",
            "used_time: 0.23232531547546387\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1400, loss: 0.471747, acc: 0.625000\n",
            "steps: 1400\n",
            "save_steps: 1250\n",
            "20220531 15:00:14 current learning_rate:0.00001000\n",
            "used_time: 0.21455073356628418\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1410, loss: 0.689248, acc: 0.375000\n",
            "steps: 1410\n",
            "save_steps: 1250\n",
            "20220531 15:00:17 current learning_rate:0.00001000\n",
            "used_time: 0.2489452362060547\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1420, loss: 0.152417, acc: 0.875000\n",
            "steps: 1420\n",
            "save_steps: 1250\n",
            "20220531 15:00:19 current learning_rate:0.00001000\n",
            "used_time: 0.2305305004119873\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1430, loss: 0.191916, acc: 1.000000\n",
            "steps: 1430\n",
            "save_steps: 1250\n",
            "20220531 15:00:21 current learning_rate:0.00001000\n",
            "used_time: 0.2111814022064209\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1440, loss: 0.573586, acc: 0.500000\n",
            "steps: 1440\n",
            "save_steps: 1250\n",
            "20220531 15:00:23 current learning_rate:0.00001000\n",
            "used_time: 0.21825337409973145\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1450, loss: 0.297527, acc: 0.500000\n",
            "steps: 1450\n",
            "save_steps: 1250\n",
            "20220531 15:00:26 current learning_rate:0.00001000\n",
            "used_time: 0.251986026763916\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1460, loss: 0.075142, acc: 0.375000\n",
            "steps: 1460\n",
            "save_steps: 1250\n",
            "20220531 15:00:28 current learning_rate:0.00001000\n",
            "used_time: 0.24215412139892578\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1470, loss: 0.123592, acc: 0.750000\n",
            "steps: 1470\n",
            "save_steps: 1250\n",
            "20220531 15:00:30 current learning_rate:0.00001000\n",
            "used_time: 0.20465469360351562\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1480, loss: 0.072380, acc: 0.625000\n",
            "steps: 1480\n",
            "save_steps: 1250\n",
            "20220531 15:00:32 current learning_rate:0.00001000\n",
            "used_time: 0.21751785278320312\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1490, loss: 0.138959, acc: 0.750000\n",
            "steps: 1490\n",
            "save_steps: 1250\n",
            "20220531 15:00:35 current learning_rate:0.00001000\n",
            "used_time: 0.2423419952392578\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1500, loss: 1.151499, acc: 0.500000\n",
            "steps: 1500\n",
            "save_steps: 1250\n",
            "Train-RCAC 0.8472222222222222\n",
            "20220531 15:00:37 current learning_rate:0.00001000\n",
            "used_time: 0.23118996620178223\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1510, loss: 0.343242, acc: 0.625000\n",
            "steps: 1510\n",
            "save_steps: 1250\n",
            "20220531 15:00:39 current learning_rate:0.00001000\n",
            "used_time: 0.2183845043182373\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1520, loss: 0.575605, acc: 0.750000\n",
            "steps: 1520\n",
            "save_steps: 1250\n",
            "20220531 15:00:41 current learning_rate:0.00001000\n",
            "used_time: 0.21200799942016602\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1530, loss: 0.726647, acc: 0.500000\n",
            "steps: 1530\n",
            "save_steps: 1250\n",
            "20220531 15:00:44 current learning_rate:0.00001000\n",
            "used_time: 0.2574162483215332\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1540, loss: 0.596194, acc: 0.500000\n",
            "steps: 1540\n",
            "save_steps: 1250\n",
            "20220531 15:00:46 current learning_rate:0.00001000\n",
            "used_time: 0.23018407821655273\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1550, loss: 0.550895, acc: 0.500000\n",
            "steps: 1550\n",
            "save_steps: 1250\n",
            "20220531 15:00:48 current learning_rate:0.00001000\n",
            "used_time: 0.24494552612304688\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1560, loss: 0.129703, acc: 0.875000\n",
            "steps: 1560\n",
            "save_steps: 1250\n",
            "20220531 15:00:50 current learning_rate:0.00001000\n",
            "used_time: 0.21028351783752441\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1570, loss: 0.654101, acc: 0.125000\n",
            "steps: 1570\n",
            "save_steps: 1250\n",
            "20220531 15:00:53 current learning_rate:0.00001000\n",
            "used_time: 0.25089311599731445\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1580, loss: 0.565692, acc: 0.750000\n",
            "steps: 1580\n",
            "save_steps: 1250\n",
            "20220531 15:00:55 current learning_rate:0.00001000\n",
            "used_time: 0.2067856788635254\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1590, loss: 0.033262, acc: 0.750000\n",
            "steps: 1590\n",
            "save_steps: 1250\n",
            "20220531 15:00:57 current learning_rate:0.00001000\n",
            "used_time: 0.22981810569763184\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1600, loss: 0.344378, acc: 0.750000\n",
            "steps: 1600\n",
            "save_steps: 1250\n",
            "20220531 15:00:59 current learning_rate:0.00001000\n",
            "used_time: 0.21216487884521484\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1610, loss: 0.226295, acc: 0.500000\n",
            "steps: 1610\n",
            "save_steps: 1250\n",
            "20220531 15:01:01 current learning_rate:0.00001000\n",
            "used_time: 0.2653944492340088\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1620, loss: 0.038599, acc: 0.625000\n",
            "steps: 1620\n",
            "save_steps: 1250\n",
            "20220531 15:01:04 current learning_rate:0.00001000\n",
            "used_time: 0.21543002128601074\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1630, loss: 0.614410, acc: 0.625000\n",
            "steps: 1630\n",
            "save_steps: 1250\n",
            "20220531 15:01:06 current learning_rate:0.00001000\n",
            "used_time: 0.21837878227233887\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1640, loss: 0.110994, acc: 0.625000\n",
            "steps: 1640\n",
            "save_steps: 1250\n",
            "20220531 15:01:08 current learning_rate:0.00001000\n",
            "used_time: 0.21958184242248535\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1650, loss: 0.262172, acc: 0.750000\n",
            "steps: 1650\n",
            "save_steps: 1250\n",
            "20220531 15:01:10 current learning_rate:0.00001000\n",
            "used_time: 0.25481200218200684\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1660, loss: 0.661669, acc: 0.500000\n",
            "steps: 1660\n",
            "save_steps: 1250\n",
            "20220531 15:01:13 current learning_rate:0.00001000\n",
            "used_time: 0.2273881435394287\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1670, loss: 0.543039, acc: 0.875000\n",
            "steps: 1670\n",
            "save_steps: 1250\n",
            "20220531 15:01:15 current learning_rate:0.00001000\n",
            "used_time: 0.20828700065612793\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1680, loss: 0.659437, acc: 0.875000\n",
            "steps: 1680\n",
            "save_steps: 1250\n",
            "20220531 15:01:17 current learning_rate:0.00001000\n",
            "used_time: 0.20583581924438477\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1690, loss: 0.541720, acc: 0.625000\n",
            "steps: 1690\n",
            "save_steps: 1250\n",
            "20220531 15:01:19 current learning_rate:0.00001000\n",
            "used_time: 0.24611568450927734\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1700, loss: 0.155059, acc: 0.625000\n",
            "steps: 1700\n",
            "save_steps: 1250\n",
            "20220531 15:01:21 current learning_rate:0.00001000\n",
            "used_time: 0.21623897552490234\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1710, loss: 0.187257, acc: 0.500000\n",
            "steps: 1710\n",
            "save_steps: 1250\n",
            "20220531 15:01:23 current learning_rate:0.00001000\n",
            "used_time: 0.20588970184326172\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1720, loss: 0.509052, acc: 1.000000\n",
            "steps: 1720\n",
            "save_steps: 1250\n",
            "20220531 15:01:26 current learning_rate:0.00001000\n",
            "used_time: 0.21677017211914062\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1730, loss: 0.544956, acc: 0.625000\n",
            "steps: 1730\n",
            "save_steps: 1250\n",
            "20220531 15:01:28 current learning_rate:0.00001000\n",
            "used_time: 0.2453765869140625\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1740, loss: 0.406583, acc: 1.000000\n",
            "steps: 1740\n",
            "save_steps: 1250\n",
            "20220531 15:01:30 current learning_rate:0.00001000\n",
            "used_time: 0.20817351341247559\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1750, loss: 0.068125, acc: 0.625000\n",
            "steps: 1750\n",
            "save_steps: 1250\n",
            "20220531 15:01:32 current learning_rate:0.00001000\n",
            "used_time: 0.23348402976989746\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1760, loss: 0.575117, acc: 0.625000\n",
            "steps: 1760\n",
            "save_steps: 1250\n",
            "20220531 15:01:35 current learning_rate:0.00001000\n",
            "used_time: 0.21235442161560059\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1770, loss: 0.843427, acc: 0.625000\n",
            "steps: 1770\n",
            "save_steps: 1250\n",
            "20220531 15:01:37 current learning_rate:0.00001000\n",
            "used_time: 0.24639439582824707\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1780, loss: 0.571445, acc: 0.375000\n",
            "steps: 1780\n",
            "save_steps: 1250\n",
            "20220531 15:01:39 current learning_rate:0.00001000\n",
            "used_time: 0.22458887100219727\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1790, loss: 0.510078, acc: 0.750000\n",
            "steps: 1790\n",
            "save_steps: 1250\n",
            "20220531 15:01:41 current learning_rate:0.00001000\n",
            "used_time: 0.2101895809173584\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1800, loss: 0.030287, acc: 0.875000\n",
            "steps: 1800\n",
            "save_steps: 1250\n",
            "20220531 15:01:43 current learning_rate:0.00001000\n",
            "used_time: 0.23821353912353516\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1810, loss: 0.128683, acc: 0.625000\n",
            "steps: 1810\n",
            "save_steps: 1250\n",
            "20220531 15:01:45 current learning_rate:0.00001000\n",
            "used_time: 0.2541646957397461\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1820, loss: 0.810703, acc: 0.500000\n",
            "steps: 1820\n",
            "save_steps: 1250\n",
            "20220531 15:01:48 current learning_rate:0.00001000\n",
            "used_time: 0.20825743675231934\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1830, loss: 0.009070, acc: 0.750000\n",
            "steps: 1830\n",
            "save_steps: 1250\n",
            "20220531 15:01:50 current learning_rate:0.00001000\n",
            "used_time: 0.2673375606536865\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1840, loss: 0.018927, acc: 0.500000\n",
            "steps: 1840\n",
            "save_steps: 1250\n",
            "20220531 15:01:52 current learning_rate:0.00001000\n",
            "used_time: 0.20404887199401855\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1850, loss: 1.240197, acc: 0.750000\n",
            "steps: 1850\n",
            "save_steps: 1250\n",
            "20220531 15:01:54 current learning_rate:0.00001000\n",
            "used_time: 0.22018122673034668\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1860, loss: 1.285587, acc: 0.375000\n",
            "steps: 1860\n",
            "save_steps: 1250\n",
            "20220531 15:01:57 current learning_rate:0.00001000\n",
            "used_time: 0.22520685195922852\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1870, loss: 0.011416, acc: 0.750000\n",
            "steps: 1870\n",
            "save_steps: 1250\n",
            "20220531 15:01:59 current learning_rate:0.00001000\n",
            "used_time: 0.22296476364135742\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1880, loss: 0.454810, acc: 0.625000\n",
            "steps: 1880\n",
            "save_steps: 1250\n",
            "20220531 15:02:01 current learning_rate:0.00001000\n",
            "used_time: 0.23678255081176758\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1890, loss: 0.686423, acc: 0.750000\n",
            "steps: 1890\n",
            "save_steps: 1250\n",
            "20220531 15:02:03 current learning_rate:0.00001000\n",
            "used_time: 0.23930931091308594\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1900, loss: 0.033205, acc: 0.750000\n",
            "steps: 1900\n",
            "save_steps: 1250\n",
            "20220531 15:02:06 current learning_rate:0.00001000\n",
            "used_time: 0.20482826232910156\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1910, loss: 0.519519, acc: 0.750000\n",
            "steps: 1910\n",
            "save_steps: 1250\n",
            "20220531 15:02:08 current learning_rate:0.00001000\n",
            "used_time: 0.22860360145568848\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1920, loss: 0.346716, acc: 0.500000\n",
            "steps: 1920\n",
            "save_steps: 1250\n",
            "20220531 15:02:10 current learning_rate:0.00001000\n",
            "used_time: 0.2054762840270996\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1930, loss: 0.063743, acc: 0.750000\n",
            "steps: 1930\n",
            "save_steps: 1250\n",
            "20220531 15:02:12 current learning_rate:0.00001000\n",
            "used_time: 0.22891712188720703\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1940, loss: 0.162883, acc: 0.875000\n",
            "steps: 1940\n",
            "save_steps: 1250\n",
            "20220531 15:02:15 current learning_rate:0.00001000\n",
            "used_time: 0.21186351776123047\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1950, loss: 0.289452, acc: 1.000000\n",
            "steps: 1950\n",
            "save_steps: 1250\n",
            "20220531 15:02:17 current learning_rate:0.00001000\n",
            "used_time: 0.2160942554473877\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1960, loss: 0.350428, acc: 0.625000\n",
            "steps: 1960\n",
            "save_steps: 1250\n",
            "20220531 15:02:19 current learning_rate:0.00001000\n",
            "used_time: 0.20768523216247559\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1970, loss: 0.769692, acc: 0.625000\n",
            "steps: 1970\n",
            "save_steps: 1250\n",
            "20220531 15:02:21 current learning_rate:0.00001000\n",
            "used_time: 0.24505066871643066\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1980, loss: 0.128838, acc: 1.000000\n",
            "steps: 1980\n",
            "save_steps: 1250\n",
            "20220531 15:02:23 current learning_rate:0.00001000\n",
            "used_time: 0.2040998935699463\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1990, loss: 0.740267, acc: 1.000000\n",
            "steps: 1990\n",
            "save_steps: 1250\n",
            "20220531 15:02:26 current learning_rate:0.00001000\n",
            "used_time: 0.2688772678375244\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2000, loss: 0.181883, acc: 0.750000\n",
            "steps: 2000\n",
            "save_steps: 1250\n",
            "Train-RCAC 0.8161764705882354\n",
            "20220531 15:02:28 current learning_rate:0.00001000\n",
            "used_time: 0.21912932395935059\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2010, loss: 0.182589, acc: 0.875000\n",
            "steps: 2010\n",
            "save_steps: 1250\n",
            "20220531 15:02:30 current learning_rate:0.00001000\n",
            "used_time: 0.2618708610534668\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2020, loss: 0.193718, acc: 0.875000\n",
            "steps: 2020\n",
            "save_steps: 1250\n",
            "20220531 15:02:32 current learning_rate:0.00001000\n",
            "used_time: 0.20456600189208984\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2030, loss: 0.476050, acc: 0.375000\n",
            "steps: 2030\n",
            "save_steps: 1250\n",
            "20220531 15:02:35 current learning_rate:0.00001000\n",
            "used_time: 0.24068474769592285\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2040, loss: 0.231393, acc: 0.500000\n",
            "steps: 2040\n",
            "save_steps: 1250\n",
            "20220531 15:02:37 current learning_rate:0.00001000\n",
            "used_time: 0.22461605072021484\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2050, loss: 0.062981, acc: 0.750000\n",
            "steps: 2050\n",
            "save_steps: 1250\n",
            "20220531 15:02:39 current learning_rate:0.00001000\n",
            "used_time: 0.26005005836486816\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2060, loss: 1.673112, acc: 0.500000\n",
            "steps: 2060\n",
            "save_steps: 1250\n",
            "20220531 15:02:41 current learning_rate:0.00001000\n",
            "used_time: 0.20556068420410156\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2070, loss: 0.183657, acc: 0.625000\n",
            "steps: 2070\n",
            "save_steps: 1250\n",
            "20220531 15:02:44 current learning_rate:0.00001000\n",
            "used_time: 0.21282291412353516\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2080, loss: 0.710501, acc: 0.500000\n",
            "steps: 2080\n",
            "save_steps: 1250\n",
            "20220531 15:02:46 current learning_rate:0.00001000\n",
            "used_time: 0.22194910049438477\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2090, loss: 0.267143, acc: 0.750000\n",
            "steps: 2090\n",
            "save_steps: 1250\n",
            "20220531 15:02:48 current learning_rate:0.00001000\n",
            "used_time: 0.25058913230895996\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2100, loss: 0.099085, acc: 0.625000\n",
            "steps: 2100\n",
            "save_steps: 1250\n",
            "20220531 15:02:50 current learning_rate:0.00001000\n",
            "used_time: 0.22019457817077637\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2110, loss: 0.654202, acc: 0.625000\n",
            "steps: 2110\n",
            "save_steps: 1250\n",
            "20220531 15:02:52 current learning_rate:0.00001000\n",
            "used_time: 0.2126786708831787\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2120, loss: 0.131291, acc: 1.000000\n",
            "steps: 2120\n",
            "save_steps: 1250\n",
            "20220531 15:02:55 current learning_rate:0.00001000\n",
            "used_time: 0.21905112266540527\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2130, loss: 0.064420, acc: 0.750000\n",
            "steps: 2130\n",
            "save_steps: 1250\n",
            "20220531 15:02:57 current learning_rate:0.00001000\n",
            "used_time: 0.2228555679321289\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2140, loss: 0.320427, acc: 0.875000\n",
            "steps: 2140\n",
            "save_steps: 1250\n",
            "20220531 15:02:59 current learning_rate:0.00001000\n",
            "used_time: 0.21944284439086914\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2150, loss: 0.014971, acc: 0.750000\n",
            "steps: 2150\n",
            "save_steps: 1250\n",
            "20220531 15:03:01 current learning_rate:0.00001000\n",
            "used_time: 0.2122049331665039\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2160, loss: 0.018355, acc: 0.375000\n",
            "steps: 2160\n",
            "save_steps: 1250\n",
            "20220531 15:03:03 current learning_rate:0.00001000\n",
            "used_time: 0.2478477954864502\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2170, loss: 0.136409, acc: 0.375000\n",
            "steps: 2170\n",
            "save_steps: 1250\n",
            "20220531 15:03:06 current learning_rate:0.00001000\n",
            "used_time: 0.2561075687408447\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2180, loss: 1.079070, acc: 0.250000\n",
            "steps: 2180\n",
            "save_steps: 1250\n",
            "20220531 15:03:08 current learning_rate:0.00001000\n",
            "used_time: 0.22051358222961426\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2190, loss: 1.305250, acc: 0.625000\n",
            "steps: 2190\n",
            "save_steps: 1250\n",
            "20220531 15:03:10 current learning_rate:0.00001000\n",
            "used_time: 0.20821332931518555\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2200, loss: 0.765344, acc: 0.750000\n",
            "steps: 2200\n",
            "save_steps: 1250\n",
            "20220531 15:03:12 current learning_rate:0.00001000\n",
            "used_time: 0.23348045349121094\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2210, loss: 0.503002, acc: 0.500000\n",
            "steps: 2210\n",
            "save_steps: 1250\n",
            "20220531 15:03:15 current learning_rate:0.00001000\n",
            "used_time: 0.26072168350219727\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2220, loss: 0.363680, acc: 0.500000\n",
            "steps: 2220\n",
            "save_steps: 1250\n",
            "20220531 15:03:17 current learning_rate:0.00001000\n",
            "used_time: 0.22826933860778809\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2230, loss: 0.566466, acc: 0.500000\n",
            "steps: 2230\n",
            "save_steps: 1250\n",
            "20220531 15:03:19 current learning_rate:0.00001000\n",
            "used_time: 0.22777223587036133\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2240, loss: 0.170541, acc: 0.875000\n",
            "steps: 2240\n",
            "save_steps: 1250\n",
            "20220531 15:03:21 current learning_rate:0.00001000\n",
            "used_time: 0.2304065227508545\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2250, loss: 0.374089, acc: 0.500000\n",
            "steps: 2250\n",
            "save_steps: 1250\n",
            "20220531 15:03:23 current learning_rate:0.00001000\n",
            "used_time: 0.23851442337036133\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2260, loss: 0.321273, acc: 0.625000\n",
            "steps: 2260\n",
            "save_steps: 1250\n",
            "20220531 15:03:26 current learning_rate:0.00001000\n",
            "used_time: 0.20676016807556152\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2270, loss: 0.037185, acc: 0.875000\n",
            "steps: 2270\n",
            "save_steps: 1250\n",
            "20220531 15:03:28 current learning_rate:0.00001000\n",
            "used_time: 0.21064972877502441\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2280, loss: 0.276725, acc: 0.875000\n",
            "steps: 2280\n",
            "save_steps: 1250\n",
            "20220531 15:03:30 current learning_rate:0.00001000\n",
            "used_time: 0.19435358047485352\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2290, loss: 0.024609, acc: 0.875000\n",
            "steps: 2290\n",
            "save_steps: 1250\n",
            "20220531 15:03:32 current learning_rate:0.00001000\n",
            "used_time: 0.2446901798248291\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2300, loss: 0.207872, acc: 0.625000\n",
            "steps: 2300\n",
            "save_steps: 1250\n",
            "20220531 15:03:34 current learning_rate:0.00001000\n",
            "used_time: 0.2730429172515869\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2310, loss: 0.452731, acc: 0.625000\n",
            "steps: 2310\n",
            "save_steps: 1250\n",
            "20220531 15:03:37 current learning_rate:0.00001000\n",
            "used_time: 0.2080986499786377\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2320, loss: 0.171801, acc: 0.750000\n",
            "steps: 2320\n",
            "save_steps: 1250\n",
            "20220531 15:03:39 current learning_rate:0.00001000\n",
            "used_time: 0.2062528133392334\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2330, loss: 0.578679, acc: 0.625000\n",
            "steps: 2330\n",
            "save_steps: 1250\n",
            "20220531 15:03:41 current learning_rate:0.00001000\n",
            "used_time: 0.24888825416564941\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2340, loss: 0.009043, acc: 0.875000\n",
            "steps: 2340\n",
            "save_steps: 1250\n",
            "20220531 15:03:43 current learning_rate:0.00001000\n",
            "used_time: 0.22157859802246094\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2350, loss: 1.129668, acc: 0.875000\n",
            "steps: 2350\n",
            "save_steps: 1250\n",
            "20220531 15:03:46 current learning_rate:0.00001000\n",
            "used_time: 0.22932982444763184\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2360, loss: 0.278181, acc: 0.750000\n",
            "steps: 2360\n",
            "save_steps: 1250\n",
            "20220531 15:03:48 current learning_rate:0.00001000\n",
            "used_time: 0.2444627285003662\n",
            "shuffle epoch 2\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2370, loss: 0.274226, acc: 0.625000\n",
            "steps: 2370\n",
            "save_steps: 1250\n",
            "20220531 15:03:50 current learning_rate:0.00001000\n",
            "used_time: 0.260936975479126\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2380, loss: 0.380888, acc: 0.875000\n",
            "steps: 2380\n",
            "save_steps: 1250\n",
            "20220531 15:03:52 current learning_rate:0.00001000\n",
            "used_time: 0.21175646781921387\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2390, loss: 0.021344, acc: 0.750000\n",
            "steps: 2390\n",
            "save_steps: 1250\n",
            "20220531 15:03:54 current learning_rate:0.00001000\n",
            "used_time: 0.2415621280670166\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2400, loss: 0.077092, acc: 0.833333\n",
            "steps: 2400\n",
            "save_steps: 1250\n",
            "20220531 15:03:57 current learning_rate:0.00001000\n",
            "used_time: 0.18767666816711426\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2410, loss: 0.058906, acc: 0.375000\n",
            "steps: 2410\n",
            "save_steps: 1250\n",
            "20220531 15:03:59 current learning_rate:0.00001000\n",
            "used_time: 0.2606825828552246\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2420, loss: 0.580901, acc: 0.875000\n",
            "steps: 2420\n",
            "save_steps: 1250\n",
            "20220531 15:04:01 current learning_rate:0.00001000\n",
            "used_time: 0.2186870574951172\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2430, loss: 0.015167, acc: 0.625000\n",
            "steps: 2430\n",
            "save_steps: 1250\n",
            "20220531 15:04:03 current learning_rate:0.00001000\n",
            "used_time: 0.20720458030700684\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2440, loss: 0.003429, acc: 0.750000\n",
            "steps: 2440\n",
            "save_steps: 1250\n",
            "20220531 15:04:06 current learning_rate:0.00001000\n",
            "used_time: 0.20678949356079102\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2450, loss: 0.017065, acc: 0.625000\n",
            "steps: 2450\n",
            "save_steps: 1250\n",
            "20220531 15:04:08 current learning_rate:0.00001000\n",
            "used_time: 0.24210453033447266\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2460, loss: 0.001812, acc: 0.625000\n",
            "steps: 2460\n",
            "save_steps: 1250\n",
            "20220531 15:04:10 current learning_rate:0.00001000\n",
            "used_time: 0.19374561309814453\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2470, loss: 0.512919, acc: 0.500000\n",
            "steps: 2470\n",
            "save_steps: 1250\n",
            "20220531 15:04:12 current learning_rate:0.00001000\n",
            "used_time: 0.2250065803527832\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2480, loss: 1.127302, acc: 0.750000\n",
            "steps: 2480\n",
            "save_steps: 1250\n",
            "20220531 15:04:14 current learning_rate:0.00001000\n",
            "used_time: 0.21617579460144043\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2490, loss: 0.819145, acc: 0.500000\n",
            "steps: 2490\n",
            "save_steps: 1250\n",
            "20220531 15:04:17 current learning_rate:0.00001000\n",
            "used_time: 0.25067782402038574\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2500, loss: 0.003917, acc: 0.500000\n",
            "steps: 2500\n",
            "save_steps: 1250\n",
            "Train-RCAC 0.9883333333333334\n",
            "20220531 15:04:19 current learning_rate:0.00001000\n",
            "save_path: output_hm/step_2500traindev\n",
            "used_time: 12.03463101387024\n",
            "############################WARNING################################### using init_pretraining_params, not init_checkpoint ###### meaning hyper param e.g. lr won't inherit from checkpoint#################################################################terminate called without an active exception\n",
            "W0531 15:04:31.751502  2577 init.cc:216] Warning: PaddlePaddle catches a failure signal, it may not work properly\n",
            "W0531 15:04:31.751581  2577 init.cc:218] You could check whether you killed PaddlePaddle thread/process accidentally or report the case to PaddlePaddle\n",
            "W0531 15:04:31.751597  2577 init.cc:221] The detail failure signal is:\n",
            "\n",
            "W0531 15:04:31.751613  2577 init.cc:224] *** Aborted at 1654009471 (unix time) try \"date -d @1654009471\" if you are using GNU date ***\n",
            "W0531 15:04:31.753896  2577 init.cc:224] PC: @                0x0 (unknown)\n",
            "W0531 15:04:31.754194  2577 init.cc:224] *** SIGABRT (@0x9e5) received by PID 2533 (TID 0x7f40b67ab700) from PID 2533; stack trace: ***\n",
            "W0531 15:04:31.755724  2577 init.cc:224]     @     0x7f427646bf10 (unknown)\n",
            "W0531 15:04:31.757251  2577 init.cc:224]     @     0x7f427646be87 gsignal\n",
            "W0531 15:04:31.758798  2577 init.cc:224]     @     0x7f427646d7f1 abort\n",
            "W0531 15:04:31.760483  2577 init.cc:224]     @     0x7f4275102957 (unknown)\n",
            "W0531 15:04:31.762183  2577 init.cc:224]     @     0x7f4275108ae6 (unknown)\n",
            "W0531 15:04:31.763787  2577 init.cc:224]     @     0x7f4275108b21 std::terminate()\n",
            "W0531 15:04:31.765856  2577 init.cc:224]     @     0x7f42751084ea __gxx_personality_v0\n",
            "W0531 15:04:31.767745  2577 init.cc:224]     @     0x7f4274c48668 (unknown)\n",
            "W0531 15:04:31.769495  2577 init.cc:224]     @     0x7f4274c48c5c _Unwind_ForcedUnwind\n",
            "W0531 15:04:31.771064  2577 init.cc:224]     @     0x7f427621f000 __GI___pthread_unwind\n",
            "W0531 15:04:31.772579  2577 init.cc:224]     @     0x7f4276216ae5 __pthread_exit\n",
            "W0531 15:04:31.774291  2577 init.cc:224]     @     0x7f427655d364 pthread_exit\n",
            "W0531 15:04:31.774513  2577 init.cc:224]     @           0x5e37d8 PyThread_exit_thread\n",
            "W0531 15:04:31.774685  2577 init.cc:224]     @           0x47028a (unknown)\n",
            "W0531 15:04:31.783838  2577 init.cc:224]     @     0x7f4223211019 pybind11::gil_scoped_release::~gil_scoped_release()\n",
            "W0531 15:04:31.785629  2577 init.cc:224]     @     0x7f42232f93b6 _ZZN8pybind1112cpp_function10initializeIZN6paddle6pybind10BindReaderEPNS_6moduleEEUlRNS2_9operators6reader22LoDTensorBlockingQueueERKSt6vectorINS2_9framework9LoDTensorESaISC_EEE1_bIS9_SG_EINS_4nameENS_9is_methodENS_7siblingENS_10call_guardIINS_18gil_scoped_releaseEEEEEEEvOT_PFT0_DpT1_EDpRKT2_ENUlRNS_6detail13function_callEE1_4_FUNES11_\n",
            "W0531 15:04:31.793502  2577 init.cc:224]     @     0x7f422322e829 pybind11::cpp_function::dispatcher()\n",
            "W0531 15:04:31.793707  2577 init.cc:224]     @           0x593784 _PyMethodDef_RawFastCallKeywords\n",
            "W0531 15:04:31.793848  2577 init.cc:224]     @           0x594731 _PyObject_FastCallKeywords\n",
            "W0531 15:04:31.794067  2577 init.cc:224]     @           0x548cc1 (unknown)\n",
            "W0531 15:04:31.794261  2577 init.cc:224]     @           0x51566f _PyEval_EvalFrameDefault\n",
            "W0531 15:04:31.794412  2577 init.cc:224]     @           0x549e0e _PyEval_EvalCodeWithName\n",
            "W0531 15:04:31.794561  2577 init.cc:224]     @           0x4bcb19 _PyFunction_FastCallDict\n",
            "W0531 15:04:31.794670  2577 init.cc:224]     @           0x5134a6 _PyEval_EvalFrameDefault\n",
            "W0531 15:04:31.794813  2577 init.cc:224]     @           0x593dd7 _PyFunction_FastCallKeywords\n",
            "W0531 15:04:31.794904  2577 init.cc:224]     @           0x511e2c _PyEval_EvalFrameDefault\n",
            "W0531 15:04:31.795080  2577 init.cc:224]     @           0x593dd7 _PyFunction_FastCallKeywords\n",
            "W0531 15:04:31.795198  2577 init.cc:224]     @           0x511e2c _PyEval_EvalFrameDefault\n",
            "W0531 15:04:31.795290  2577 init.cc:224]     @           0x4bc98a _PyFunction_FastCallDict\n",
            "W0531 15:04:31.795464  2577 init.cc:224]     @           0x59c019 (unknown)\n",
            "W0531 15:04:31.795744  2577 init.cc:224]     @           0x595ef6 PyObject_Call\n",
            "W0531 15:04:31.795943  2577 init.cc:224]     @           0x5d5393 (unknown)\n",
            "run_finetuning.sh: line 64:  2533 Aborted                 (core dumped) python /content/vilio/ernie-vil/finetune.py --use_cuda \"True\" --is_distributed \"False\" --use_fast_executor ${e_executor-\"True\"} --nccl_comm_num ${nccl_comm_num:-\"1\"} --batch_size $((BATCH_SIZE/gpu_cnt)) --do_train \"True\" --do_test \"False\" --task_name ${TASK_NAME} --vocab_path ${VOCAB_PATH} --task_group_json ${TASK_GROUP_JSON} --lr_scheduler ${lr_scheduler} --decay_steps ${decay_steps-\"\"} --lr_decay_ratio ${lr_decay_ratio-0.1} --num_train_steps ${num_train_steps} --checkpoints $output_model_path --save_steps ${SAVE_STEPS} --init_checkpoint ${PRETRAIN_MODELS} --ernie_config_path ${ERNIE_VIL_CONFIG} --learning_rate ${LR_RATE} --warmup_steps ${WARMUP_STEPS} --weight_decay ${WEIGHT_DECAY:-0} --max_seq_len ${MAX_LEN} --validation_steps ${VALID_STEPS} --skip_steps 10 --split ${SPLIT} --stop_steps ${STOP}\n",
            "-----------  Configuration Arguments -----------\n",
            "batch_size: 8\n",
            "checkpoints: checkpoints\n",
            "combine: False\n",
            "decay_steps: \n",
            "do_test: True\n",
            "do_train: False\n",
            "do_val: False\n",
            "epoch: 100\n",
            "ernie_config_path: /content/vilio/ernie-vil/data/erniesmall/ernie_vil_config.base.json\n",
            "exp: ES72\n",
            "feature_size: 2048\n",
            "fusion_method: sum\n",
            "hierarchical_allreduce_inter_nranks: 8\n",
            "init_checkpoint: /content/vilio/ernie-vil/output_hm/step_2500traindev\n",
            "is_distributed: False\n",
            "learning_rate: 0.0001\n",
            "lr_decay_dict_file: \n",
            "lr_decay_ratio: 0.1\n",
            "lr_scheduler: linear_warmup_decay\n",
            "max_img_len: 100\n",
            "max_seq_len: 128\n",
            "nccl_comm_num: 1\n",
            "num_features: 50\n",
            "num_train_steps: 1000000\n",
            "output_file: \n",
            "result_file: /content/vilio/ernie-vil/data/log\n",
            "save_steps: 100\n",
            "skip_steps: 10\n",
            "split: test_seen\n",
            "stop_steps: 5000\n",
            "subtrain: False\n",
            "task_group_json: /content/vilio/ernie-vil/conf/hm/task_hm.json\n",
            "task_name: hm\n",
            "test_filelist: \n",
            "test_split: val\n",
            "train_filelist: \n",
            "use_cuda: True\n",
            "use_fast_executor: True\n",
            "use_fuse: False\n",
            "use_gpu: True\n",
            "use_hierarchical_allreduce: False\n",
            "valid_filelist: \n",
            "validation_steps: 6000\n",
            "verbose: False\n",
            "vocab_path: /content/vilio/ernie-vil/data/erniesmall/vocab.txt\n",
            "warmup_steps: 0\n",
            "weight_decay: 0.01\n",
            "------------------------------------------------\n",
            "finetuning tasks start\n",
            "attention_probs_dropout_prob: 0.1\n",
            "class_attr_size: 401\n",
            "class_size: 1601\n",
            "co_hidden_size: 1024\n",
            "co_intermediate_size: 1024\n",
            "co_num_attention_heads: 8\n",
            "hidden_act: gelu\n",
            "hidden_dropout_prob: 0.1\n",
            "hidden_size: 768\n",
            "initializer_range: 0.02\n",
            "max_position_embeddings: 512\n",
            "num_attention_heads: 12\n",
            "num_hidden_layers: 12\n",
            "sent_type_vocab_size: 4\n",
            "t_biattention_id: [6, 7, 8, 9, 10, 11]\n",
            "task_type_vocab_size: 16\n",
            "type_vocab_size: 2\n",
            "v_biattention_id: [0, 1, 2, 3, 4, 5]\n",
            "v_hidden_size: 1024\n",
            "v_intermediate_size: 1024\n",
            "v_num_attention_heads: 8\n",
            "vocab_size: 30522\n",
            "------------------------------------------------\n",
            "task:  [{'task': 'HM', 'num_choice': 1, 'annotations_jsonpath_train': '/content/vilio/ernie-vil/data/hm/train.jsonl', 'annotations_jsonpath_dev_seen': '/content/vilio/ernie-vil/data/hm/dev_seenlong.jsonl', 'annotations_jsonpath_traindev': '/content/vilio/ernie-vil/data/hm/traindev.jsonl', 'annotations_jsonpath_test_unseen': '/content/vilio/ernie-vil/data/hm/test_unseenlong.jsonl', 'annotations_jsonpath_test_seen': '/content/vilio/ernie-vil/data/hm/test_seenlong.jsonl', 'feature_lmdb_path': '/content/vilio/ernie-vil/data/hm/HM_img.tsv', 'gt_feature_lmdb_path': '/content/vilio/ernie-vil/data/hm/HM_gt_img.tsv', 'unisex_names_table': '/content/vilio/ernie-vil/data/vcr/unisex_names_table.csv', 'Proprocessor': 'PreprocessorBasic', 'tokenizer_name': 'FullTokenizer', 'fusion_method': 'mul', 'dropout_rate': 0.1, 'max_seq_len': 128, 'use_gt_fea': True, 'shufflekeep_across_task': True, 'shuffle_every_epoch': True, 'task_weight': 1.0, 'task_prefix': 'hm'}]\n",
            "2022-05-31 15:04:36,373-WARNING: paddle.fluid.layers.py_reader() may be deprecated in the near future. Please use paddle.fluid.io.DataLoader.from_generator() instead.\n",
            "theoretical memory usage: \n",
            "(3678.2632896423343, 3853.418684387207, 'MB')\n",
            "args.is_distributed: False\n",
            "W0531 15:04:37.511584  2609 device_context.cc:252] Please NOTE: device: 0, CUDA Capability: 60, Driver API Version: 11.2, Runtime API Version: 9.0\n",
            "W0531 15:04:37.531750  2609 device_context.cc:260] device: 0, cuDNN Version: 7.6.\n",
            "SPLIT: test_seen\n",
            "Start to load Faster-RCNN detected objects from /content/vilio/ernie-vil/data/hm/HM_img.tsv\n",
            "Loaded 1000 images in file /content/vilio/ernie-vil/data/hm/HM_img.tsv in 169 seconds.\n",
            "Start to load Faster-RCNN detected objects from /content/vilio/ernie-vil/data/hm/HM_gt_img.tsv\n",
            "Loaded 1000 images in file /content/vilio/ernie-vil/data/hm/HM_gt_img.tsv in 55 seconds.\n",
            "Load 1300 data from split(s) /content/vilio/ernie-vil/data/hm/test_seenlong.jsonl.\n",
            "use gt featurre\n",
            "LEN:  1300\n",
            "Load pretraining parameters from /content/vilio/ernie-vil/output_hm/step_2500traindev.\n",
            "testing on hm val split\n",
            "task name list :  ['mean_0.tmp_0', 'accuracy_0.tmp_0', 'arg_max_0.tmp_0', 'read_file_0.tmp_9', 'read_file_0.tmp_8', 'reshape2_120.tmp_0']\n",
            "cur_step: 10 cur_acc: 0.9875\n",
            "cur_step: 20 cur_acc: 0.99375\n",
            "cur_step: 30 cur_acc: 0.9958333333333333\n",
            "cur_step: 40 cur_acc: 0.996875\n",
            "cur_step: 50 cur_acc: 0.9975\n",
            "cur_step: 60 cur_acc: 0.9979166666666667\n",
            "cur_step: 70 cur_acc: 0.9982142857142857\n",
            "cur_step: 80 cur_acc: 0.9984375\n",
            "cur_step: 90 cur_acc: 0.9986111111111111\n",
            "cur_step: 100 cur_acc: 0.99875\n",
            "cur_step: 110 cur_acc: 0.9988636363636364\n",
            "cur_step: 120 cur_acc: 0.9989583333333333\n",
            "cur_step: 130 cur_acc: 0.9980769230769231\n",
            "cur_step: 140 cur_acc: 0.9982142857142857\n",
            "cur_step: 150 cur_acc: 0.9983333333333333\n",
            "cur_step: 160 cur_acc: 0.9984375\n",
            "EXCEPTING\n",
            "LEN: 1000 1000\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   id      1000 non-null   int64  \n",
            " 1   proba   1000 non-null   float32\n",
            " 2   label   1000 non-null   int64  \n",
            "dtypes: float32(1), int64(2)\n",
            "memory usage: 19.7 KB\n",
            "None\n",
            "average_acc: 0.9984375\n",
            "rocauc: 0.8841940532081377\n",
            "-----------  Configuration Arguments -----------\n",
            "batch_size: 8\n",
            "checkpoints: checkpoints\n",
            "combine: False\n",
            "decay_steps: \n",
            "do_test: True\n",
            "do_train: False\n",
            "do_val: False\n",
            "epoch: 100\n",
            "ernie_config_path: /content/vilio/ernie-vil/data/erniesmall/ernie_vil_config.base.json\n",
            "exp: ES72\n",
            "feature_size: 2048\n",
            "fusion_method: sum\n",
            "hierarchical_allreduce_inter_nranks: 8\n",
            "init_checkpoint: /content/vilio/ernie-vil/output_hm/step_2500traindev\n",
            "is_distributed: False\n",
            "learning_rate: 0.0001\n",
            "lr_decay_dict_file: \n",
            "lr_decay_ratio: 0.1\n",
            "lr_scheduler: linear_warmup_decay\n",
            "max_img_len: 100\n",
            "max_seq_len: 128\n",
            "nccl_comm_num: 1\n",
            "num_features: 50\n",
            "num_train_steps: 1000000\n",
            "output_file: \n",
            "result_file: /content/vilio/ernie-vil/data/log\n",
            "save_steps: 100\n",
            "skip_steps: 10\n",
            "split: test_unseen\n",
            "stop_steps: 5000\n",
            "subtrain: False\n",
            "task_group_json: /content/vilio/ernie-vil/conf/hm/task_hm.json\n",
            "task_name: hm\n",
            "test_filelist: \n",
            "test_split: val\n",
            "train_filelist: \n",
            "use_cuda: True\n",
            "use_fast_executor: True\n",
            "use_fuse: False\n",
            "use_gpu: True\n",
            "use_hierarchical_allreduce: False\n",
            "valid_filelist: \n",
            "validation_steps: 6000\n",
            "verbose: False\n",
            "vocab_path: /content/vilio/ernie-vil/data/erniesmall/vocab.txt\n",
            "warmup_steps: 0\n",
            "weight_decay: 0.01\n",
            "------------------------------------------------\n",
            "finetuning tasks start\n",
            "attention_probs_dropout_prob: 0.1\n",
            "class_attr_size: 401\n",
            "class_size: 1601\n",
            "co_hidden_size: 1024\n",
            "co_intermediate_size: 1024\n",
            "co_num_attention_heads: 8\n",
            "hidden_act: gelu\n",
            "hidden_dropout_prob: 0.1\n",
            "hidden_size: 768\n",
            "initializer_range: 0.02\n",
            "max_position_embeddings: 512\n",
            "num_attention_heads: 12\n",
            "num_hidden_layers: 12\n",
            "sent_type_vocab_size: 4\n",
            "t_biattention_id: [6, 7, 8, 9, 10, 11]\n",
            "task_type_vocab_size: 16\n",
            "type_vocab_size: 2\n",
            "v_biattention_id: [0, 1, 2, 3, 4, 5]\n",
            "v_hidden_size: 1024\n",
            "v_intermediate_size: 1024\n",
            "v_num_attention_heads: 8\n",
            "vocab_size: 30522\n",
            "------------------------------------------------\n",
            "task:  [{'task': 'HM', 'num_choice': 1, 'annotations_jsonpath_train': '/content/vilio/ernie-vil/data/hm/train.jsonl', 'annotations_jsonpath_dev_seen': '/content/vilio/ernie-vil/data/hm/dev_seenlong.jsonl', 'annotations_jsonpath_traindev': '/content/vilio/ernie-vil/data/hm/traindev.jsonl', 'annotations_jsonpath_test_unseen': '/content/vilio/ernie-vil/data/hm/test_unseenlong.jsonl', 'annotations_jsonpath_test_seen': '/content/vilio/ernie-vil/data/hm/test_seenlong.jsonl', 'feature_lmdb_path': '/content/vilio/ernie-vil/data/hm/HM_img.tsv', 'gt_feature_lmdb_path': '/content/vilio/ernie-vil/data/hm/HM_gt_img.tsv', 'unisex_names_table': '/content/vilio/ernie-vil/data/vcr/unisex_names_table.csv', 'Proprocessor': 'PreprocessorBasic', 'tokenizer_name': 'FullTokenizer', 'fusion_method': 'mul', 'dropout_rate': 0.1, 'max_seq_len': 128, 'use_gt_fea': True, 'shufflekeep_across_task': True, 'shuffle_every_epoch': True, 'task_weight': 1.0, 'task_prefix': 'hm'}]\n",
            "2022-05-31 15:08:57,056-WARNING: paddle.fluid.layers.py_reader() may be deprecated in the near future. Please use paddle.fluid.io.DataLoader.from_generator() instead.\n",
            "theoretical memory usage: \n",
            "(3678.2632896423343, 3853.418684387207, 'MB')\n",
            "args.is_distributed: False\n",
            "W0531 15:08:58.164213  2657 device_context.cc:252] Please NOTE: device: 0, CUDA Capability: 60, Driver API Version: 11.2, Runtime API Version: 9.0\n",
            "W0531 15:08:58.181370  2657 device_context.cc:260] device: 0, cuDNN Version: 7.6.\n",
            "SPLIT: test_unseen\n",
            "Start to load Faster-RCNN detected objects from /content/vilio/ernie-vil/data/hm/HM_img.tsv\n",
            "Loaded 2000 images in file /content/vilio/ernie-vil/data/hm/HM_img.tsv in 175 seconds.\n",
            "Start to load Faster-RCNN detected objects from /content/vilio/ernie-vil/data/hm/HM_gt_img.tsv\n",
            "Loaded 2000 images in file /content/vilio/ernie-vil/data/hm/HM_gt_img.tsv in 56 seconds.\n",
            "Load 2600 data from split(s) /content/vilio/ernie-vil/data/hm/test_unseenlong.jsonl.\n",
            "use gt featurre\n",
            "LEN:  2600\n",
            "Load pretraining parameters from /content/vilio/ernie-vil/output_hm/step_2500traindev.\n",
            "testing on hm val split\n",
            "task name list :  ['mean_0.tmp_0', 'accuracy_0.tmp_0', 'arg_max_0.tmp_0', 'read_file_0.tmp_9', 'read_file_0.tmp_8', 'reshape2_120.tmp_0']\n",
            "cur_step: 10 cur_acc: 0.9875\n",
            "cur_step: 20 cur_acc: 0.99375\n",
            "cur_step: 30 cur_acc: 0.9958333333333333\n",
            "cur_step: 40 cur_acc: 0.996875\n",
            "cur_step: 50 cur_acc: 0.9975\n",
            "cur_step: 60 cur_acc: 0.9979166666666667\n",
            "cur_step: 70 cur_acc: 0.9982142857142857\n",
            "cur_step: 80 cur_acc: 0.9984375\n",
            "cur_step: 90 cur_acc: 0.9986111111111111\n",
            "cur_step: 100 cur_acc: 0.99875\n",
            "cur_step: 110 cur_acc: 0.9988636363636364\n",
            "cur_step: 120 cur_acc: 0.9989583333333333\n",
            "cur_step: 130 cur_acc: 0.9990384615384615\n",
            "cur_step: 140 cur_acc: 0.9991071428571429\n",
            "cur_step: 150 cur_acc: 0.9991666666666666\n",
            "cur_step: 160 cur_acc: 0.99921875\n",
            "cur_step: 170 cur_acc: 0.9992647058823529\n",
            "cur_step: 180 cur_acc: 0.9993055555555556\n",
            "cur_step: 190 cur_acc: 0.9993421052631579\n",
            "cur_step: 200 cur_acc: 0.999375\n",
            "cur_step: 210 cur_acc: 0.9994047619047619\n",
            "cur_step: 220 cur_acc: 0.9994318181818181\n",
            "cur_step: 230 cur_acc: 0.9994565217391305\n",
            "cur_step: 240 cur_acc: 0.9994791666666667\n",
            "cur_step: 250 cur_acc: 0.9995\n",
            "cur_step: 260 cur_acc: 0.9990384615384615\n",
            "cur_step: 270 cur_acc: 0.9990740740740741\n",
            "cur_step: 280 cur_acc: 0.9991071428571429\n",
            "cur_step: 290 cur_acc: 0.9991379310344828\n",
            "cur_step: 300 cur_acc: 0.9991666666666666\n",
            "cur_step: 310 cur_acc: 0.9991935483870967\n",
            "cur_step: 320 cur_acc: 0.99921875\n",
            "EXCEPTING\n",
            "LEN: 2000 2000\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2000 entries, 0 to 1999\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   id      2000 non-null   int64  \n",
            " 1   proba   2000 non-null   float32\n",
            " 2   label   2000 non-null   int64  \n",
            "dtypes: float32(1), int64(2)\n",
            "memory usage: 39.2 KB\n",
            "None\n",
            "average_acc: 0.99921875\n",
            "rocauc: 0.5586395621579359\n",
            "mv: cannot stat '/content/vilio/ernie-vil/data/hm/hm_vgattr10100.tsv': No such file or directory\n",
            "mv: cannot stat '/content/vilio/ernie-vil/data/hm/hm_vgattr7272.tsv': No such file or directory\n",
            "+ TASK_NAME=hm\n",
            "+ CONF_FILE=conf/hm/model_conf_hm\n",
            "+ VOCAB_PATH=/content/vilio/ernie-vil/data/erniesmallvcr/vocab.txt\n",
            "+ ERNIE_VIL_CONFIG=/content/vilio/ernie-vil/data/erniesmallvcr/ernie_vil_config.base.json\n",
            "+ PRETRAIN_MODELS=/content/vilio/ernie-vil/data/erniesmallvcr/params\n",
            "+ SPLIT=train\n",
            "+ STOP=2500\n",
            "+ source conf/hm/model_conf_hm\n",
            "++ output_model_path=output_hm\n",
            "++ lr_scheduler=manual_warmup_decay\n",
            "++ decay_steps='13308;19962'\n",
            "++ lr_decay_ratio=0.1\n",
            "++ num_train_steps=5000\n",
            "++ SAVE_STEPS=1250\n",
            "++ WARMUP_STEPS=500\n",
            "++ BATCH_SIZE=8\n",
            "++ VALID_STEPS=20000\n",
            "++ LR_RATE=1e-5\n",
            "++ WEIGHT_DECAY=0.01\n",
            "++ MAX_LEN=128\n",
            "+ CUDA_VISIBLE_DEVICES=1\n",
            "+ export FLAGS_fast_eager_deletion_mode=1\n",
            "+ FLAGS_fast_eager_deletion_mode=1\n",
            "+ export FLAGS_eager_delete_tensor_gb=0.0\n",
            "+ FLAGS_eager_delete_tensor_gb=0.0\n",
            "+ export FLAGS_fraction_of_gpu_memory_to_use=0.98\n",
            "+ FLAGS_fraction_of_gpu_memory_to_use=0.98\n",
            "++ echo True\n",
            "++ tr '[A-Z]' '[a-z]'\n",
            "+ e_executor=true\n",
            "++ echo False\n",
            "++ tr '[A-Z]' '[a-z]'\n",
            "+ use_fuse=false\n",
            "+ [[ false == \\t\\r\\u\\e ]]\n",
            "+ TASK_GROUP_JSON=/content/vilio/ernie-vil/conf/hm/task_hm.json\n",
            "++ echo 1\n",
            "++ awk '-F\\t' '{len=split($0,vec,\",\");print len}'\n",
            "+ gpu_cnt=1\n",
            "+ echo gpu_cnt, 1\n",
            "gpu_cnt, 1\n",
            "+ python /content/vilio/ernie-vil/finetune.py --use_cuda True --is_distributed False --use_fast_executor true --nccl_comm_num 1 --batch_size 8 --do_train True --do_test False --task_name hm --vocab_path /content/vilio/ernie-vil/data/erniesmallvcr/vocab.txt --task_group_json /content/vilio/ernie-vil/conf/hm/task_hm.json --lr_scheduler manual_warmup_decay --decay_steps '13308;19962' --lr_decay_ratio 0.1 --num_train_steps 5000 --checkpoints output_hm --save_steps 1250 --init_checkpoint /content/vilio/ernie-vil/data/erniesmallvcr/params --ernie_config_path /content/vilio/ernie-vil/data/erniesmallvcr/ernie_vil_config.base.json --learning_rate 1e-5 --warmup_steps 500 --weight_decay 0.01 --max_seq_len 128 --validation_steps 20000 --skip_steps 10 --split train --stop_steps 2500\n",
            "-----------  Configuration Arguments -----------\n",
            "batch_size: 8\n",
            "checkpoints: output_hm\n",
            "combine: False\n",
            "decay_steps: 13308;19962\n",
            "do_test: False\n",
            "do_train: True\n",
            "do_val: False\n",
            "epoch: 100\n",
            "ernie_config_path: /content/vilio/ernie-vil/data/erniesmallvcr/ernie_vil_config.base.json\n",
            "exp: experiment\n",
            "feature_size: 2048\n",
            "fusion_method: sum\n",
            "hierarchical_allreduce_inter_nranks: 8\n",
            "init_checkpoint: /content/vilio/ernie-vil/data/erniesmallvcr/params\n",
            "is_distributed: False\n",
            "learning_rate: 1e-05\n",
            "lr_decay_dict_file: \n",
            "lr_decay_ratio: 0.1\n",
            "lr_scheduler: manual_warmup_decay\n",
            "max_img_len: 100\n",
            "max_seq_len: 128\n",
            "nccl_comm_num: 1\n",
            "num_features: 50\n",
            "num_train_steps: 5000\n",
            "output_file: \n",
            "result_file: ./res_tmp\n",
            "save_steps: 1250\n",
            "skip_steps: 10\n",
            "split: train\n",
            "stop_steps: 2500\n",
            "subtrain: False\n",
            "task_group_json: /content/vilio/ernie-vil/conf/hm/task_hm.json\n",
            "task_name: hm\n",
            "test_filelist: \n",
            "test_split: test\n",
            "train_filelist: \n",
            "use_cuda: True\n",
            "use_fast_executor: True\n",
            "use_fuse: False\n",
            "use_gpu: True\n",
            "use_hierarchical_allreduce: False\n",
            "valid_filelist: \n",
            "validation_steps: 20000\n",
            "verbose: False\n",
            "vocab_path: /content/vilio/ernie-vil/data/erniesmallvcr/vocab.txt\n",
            "warmup_steps: 500\n",
            "weight_decay: 0.01\n",
            "------------------------------------------------\n",
            "finetuning tasks start\n",
            "attention_probs_dropout_prob: 0.1\n",
            "class_attr_size: 401\n",
            "class_size: 1601\n",
            "co_hidden_size: 1024\n",
            "co_intermediate_size: 1024\n",
            "co_num_attention_heads: 8\n",
            "hidden_act: gelu\n",
            "hidden_dropout_prob: 0.1\n",
            "hidden_size: 768\n",
            "initializer_range: 0.02\n",
            "max_position_embeddings: 512\n",
            "num_attention_heads: 12\n",
            "num_hidden_layers: 12\n",
            "sent_type_vocab_size: 4\n",
            "t_biattention_id: [6, 7, 8, 9, 10, 11]\n",
            "task_type_vocab_size: 16\n",
            "type_vocab_size: 2\n",
            "v_biattention_id: [0, 1, 2, 3, 4, 5]\n",
            "v_hidden_size: 1024\n",
            "v_intermediate_size: 1024\n",
            "v_num_attention_heads: 8\n",
            "vocab_size: 30522\n",
            "------------------------------------------------\n",
            "task:  [{'task': 'HM', 'num_choice': 1, 'annotations_jsonpath_train': '/content/vilio/ernie-vil/data/hm/train.jsonl', 'annotations_jsonpath_dev_seen': '/content/vilio/ernie-vil/data/hm/dev_seenlong.jsonl', 'annotations_jsonpath_traindev': '/content/vilio/ernie-vil/data/hm/traindev.jsonl', 'annotations_jsonpath_test_unseen': '/content/vilio/ernie-vil/data/hm/test_unseenlong.jsonl', 'annotations_jsonpath_test_seen': '/content/vilio/ernie-vil/data/hm/test_seenlong.jsonl', 'feature_lmdb_path': '/content/vilio/ernie-vil/data/hm/HM_img.tsv', 'gt_feature_lmdb_path': '/content/vilio/ernie-vil/data/hm/HM_gt_img.tsv', 'unisex_names_table': '/content/vilio/ernie-vil/data/vcr/unisex_names_table.csv', 'Proprocessor': 'PreprocessorBasic', 'tokenizer_name': 'FullTokenizer', 'fusion_method': 'mul', 'dropout_rate': 0.1, 'max_seq_len': 128, 'use_gt_fea': True, 'shufflekeep_across_task': True, 'shuffle_every_epoch': True, 'task_weight': 1.0, 'task_prefix': 'hm'}]\n",
            "2022-05-31 15:13:48,341-WARNING: paddle.fluid.layers.py_reader() may be deprecated in the near future. Please use paddle.fluid.io.DataLoader.from_generator() instead.\n",
            "/usr/local/lib/python3.7/dist-packages/paddle/fluid/clip.py:779: UserWarning: Caution! 'set_gradient_clip' is not recommended and may be deprecated in future! We recommend a new strategy: set 'grad_clip' when initializing the 'optimizer'. This method can reduce the mistakes, please refer to documention of 'optimizer'.\n",
            "  warnings.warn(\"Caution! 'set_gradient_clip' is not recommended \"\n",
            "theoretical memory usage: \n",
            "(18209.21138906479, 19076.31669330597, 'MB')\n",
            "args.is_distributed: False\n",
            "W0531 15:13:53.897352  2715 device_context.cc:252] Please NOTE: device: 0, CUDA Capability: 60, Driver API Version: 11.2, Runtime API Version: 9.0\n",
            "W0531 15:13:53.913276  2715 device_context.cc:260] device: 0, cuDNN Version: 7.6.\n",
            "Load pretraining parameters from /content/vilio/ernie-vil/data/erniesmallvcr/params.\n",
            "SPLIT: train\n",
            "Start to load Faster-RCNN detected objects from /content/vilio/ernie-vil/data/hm/HM_img.tsv\n",
            "Loaded 8598 images in file /content/vilio/ernie-vil/data/hm/HM_img.tsv in 194 seconds.\n",
            "Start to load Faster-RCNN detected objects from /content/vilio/ernie-vil/data/hm/HM_gt_img.tsv\n",
            "Loaded 8598 images in file /content/vilio/ernie-vil/data/hm/HM_gt_img.tsv in 63 seconds.\n",
            "Load 8598 data from split(s) /content/vilio/ernie-vil/data/hm/train.jsonl.\n",
            "use gt featurre\n",
            "LEN:  8598\n",
            "shuffle epoch 0\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 10, loss: 0.737756, acc: 0.375000\n",
            "steps: 10\n",
            "save_steps: 1250\n",
            "20220531 15:18:27 current learning_rate:0.00000018\n",
            "used_time: 0.253082275390625\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 20, loss: 0.705736, acc: 0.500000\n",
            "steps: 20\n",
            "save_steps: 1250\n",
            "20220531 15:18:29 current learning_rate:0.00000038\n",
            "used_time: 0.1995091438293457\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 30, loss: 0.591657, acc: 0.875000\n",
            "steps: 30\n",
            "save_steps: 1250\n",
            "20220531 15:18:31 current learning_rate:0.00000058\n",
            "used_time: 0.20008277893066406\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 40, loss: 0.735187, acc: 0.500000\n",
            "steps: 40\n",
            "save_steps: 1250\n",
            "20220531 15:18:34 current learning_rate:0.00000078\n",
            "used_time: 0.21847224235534668\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 50, loss: 0.679898, acc: 0.500000\n",
            "steps: 50\n",
            "save_steps: 1250\n",
            "20220531 15:18:36 current learning_rate:0.00000098\n",
            "used_time: 0.22461938858032227\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 60, loss: 0.551047, acc: 0.875000\n",
            "steps: 60\n",
            "save_steps: 1250\n",
            "20220531 15:18:38 current learning_rate:0.00000118\n",
            "used_time: 0.24668240547180176\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 70, loss: 0.590047, acc: 0.750000\n",
            "steps: 70\n",
            "save_steps: 1250\n",
            "20220531 15:18:40 current learning_rate:0.00000138\n",
            "used_time: 0.20752620697021484\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 80, loss: 0.764730, acc: 0.375000\n",
            "steps: 80\n",
            "save_steps: 1250\n",
            "20220531 15:18:42 current learning_rate:0.00000158\n",
            "used_time: 0.207474946975708\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 90, loss: 0.667941, acc: 0.625000\n",
            "steps: 90\n",
            "save_steps: 1250\n",
            "20220531 15:18:45 current learning_rate:0.00000178\n",
            "used_time: 0.25855374336242676\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 100, loss: 0.610424, acc: 0.750000\n",
            "steps: 100\n",
            "save_steps: 1250\n",
            "20220531 15:18:47 current learning_rate:0.00000198\n",
            "used_time: 0.2178807258605957\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 110, loss: 0.741373, acc: 0.500000\n",
            "steps: 110\n",
            "save_steps: 1250\n",
            "20220531 15:18:49 current learning_rate:0.00000218\n",
            "used_time: 0.21739721298217773\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 120, loss: 0.587059, acc: 0.750000\n",
            "steps: 120\n",
            "save_steps: 1250\n",
            "20220531 15:18:51 current learning_rate:0.00000238\n",
            "used_time: 0.22219228744506836\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 130, loss: 0.561623, acc: 0.750000\n",
            "steps: 130\n",
            "save_steps: 1250\n",
            "20220531 15:18:53 current learning_rate:0.00000258\n",
            "used_time: 0.22613239288330078\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 140, loss: 0.604349, acc: 0.750000\n",
            "steps: 140\n",
            "save_steps: 1250\n",
            "20220531 15:18:56 current learning_rate:0.00000278\n",
            "used_time: 0.21294856071472168\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 150, loss: 0.853251, acc: 0.375000\n",
            "steps: 150\n",
            "save_steps: 1250\n",
            "20220531 15:18:58 current learning_rate:0.00000298\n",
            "used_time: 0.2275989055633545\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 160, loss: 0.701095, acc: 0.500000\n",
            "steps: 160\n",
            "save_steps: 1250\n",
            "20220531 15:19:00 current learning_rate:0.00000318\n",
            "used_time: 0.20185422897338867\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 170, loss: 0.654704, acc: 0.625000\n",
            "steps: 170\n",
            "save_steps: 1250\n",
            "20220531 15:19:02 current learning_rate:0.00000338\n",
            "used_time: 0.2565600872039795\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 180, loss: 0.705462, acc: 0.625000\n",
            "steps: 180\n",
            "save_steps: 1250\n",
            "20220531 15:19:04 current learning_rate:0.00000358\n",
            "used_time: 0.23041915893554688\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 190, loss: 0.432566, acc: 1.000000\n",
            "steps: 190\n",
            "save_steps: 1250\n",
            "20220531 15:19:07 current learning_rate:0.00000378\n",
            "used_time: 0.20427703857421875\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 200, loss: 0.719574, acc: 0.500000\n",
            "steps: 200\n",
            "save_steps: 1250\n",
            "20220531 15:19:09 current learning_rate:0.00000398\n",
            "used_time: 0.21124792098999023\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 210, loss: 0.646482, acc: 0.375000\n",
            "steps: 210\n",
            "save_steps: 1250\n",
            "20220531 15:19:11 current learning_rate:0.00000418\n",
            "used_time: 0.316831111907959\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 220, loss: 0.599361, acc: 0.625000\n",
            "steps: 220\n",
            "save_steps: 1250\n",
            "20220531 15:19:13 current learning_rate:0.00000438\n",
            "used_time: 0.20924878120422363\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 230, loss: 0.662125, acc: 0.750000\n",
            "steps: 230\n",
            "save_steps: 1250\n",
            "20220531 15:19:15 current learning_rate:0.00000458\n",
            "used_time: 0.19123387336730957\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 240, loss: 0.475968, acc: 0.875000\n",
            "steps: 240\n",
            "save_steps: 1250\n",
            "20220531 15:19:17 current learning_rate:0.00000478\n",
            "used_time: 0.20554709434509277\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 250, loss: 0.776729, acc: 0.500000\n",
            "steps: 250\n",
            "save_steps: 1250\n",
            "20220531 15:19:20 current learning_rate:0.00000498\n",
            "used_time: 0.2474977970123291\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 260, loss: 0.659439, acc: 0.500000\n",
            "steps: 260\n",
            "save_steps: 1250\n",
            "20220531 15:19:22 current learning_rate:0.00000518\n",
            "used_time: 0.21126389503479004\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 270, loss: 0.554308, acc: 0.375000\n",
            "steps: 270\n",
            "save_steps: 1250\n",
            "20220531 15:19:24 current learning_rate:0.00000538\n",
            "used_time: 0.2079925537109375\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 280, loss: 0.464410, acc: 0.750000\n",
            "steps: 280\n",
            "save_steps: 1250\n",
            "20220531 15:19:26 current learning_rate:0.00000558\n",
            "used_time: 0.20136594772338867\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 290, loss: 0.561069, acc: 0.750000\n",
            "steps: 290\n",
            "save_steps: 1250\n",
            "20220531 15:19:29 current learning_rate:0.00000578\n",
            "used_time: 0.2547924518585205\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 300, loss: 0.591111, acc: 0.625000\n",
            "steps: 300\n",
            "save_steps: 1250\n",
            "20220531 15:19:31 current learning_rate:0.00000598\n",
            "used_time: 0.1958482265472412\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 310, loss: 0.747883, acc: 0.625000\n",
            "steps: 310\n",
            "save_steps: 1250\n",
            "20220531 15:19:33 current learning_rate:0.00000618\n",
            "used_time: 0.2319645881652832\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 320, loss: 0.423571, acc: 0.750000\n",
            "steps: 320\n",
            "save_steps: 1250\n",
            "20220531 15:19:35 current learning_rate:0.00000638\n",
            "used_time: 0.2275097370147705\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 330, loss: 0.874581, acc: 0.500000\n",
            "steps: 330\n",
            "save_steps: 1250\n",
            "20220531 15:19:38 current learning_rate:0.00000658\n",
            "used_time: 0.290294885635376\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 340, loss: 0.836108, acc: 0.625000\n",
            "steps: 340\n",
            "save_steps: 1250\n",
            "20220531 15:19:40 current learning_rate:0.00000678\n",
            "used_time: 0.22374320030212402\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 350, loss: 0.398428, acc: 0.750000\n",
            "steps: 350\n",
            "save_steps: 1250\n",
            "20220531 15:19:42 current learning_rate:0.00000698\n",
            "used_time: 0.2097775936126709\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 360, loss: 0.769540, acc: 0.500000\n",
            "steps: 360\n",
            "save_steps: 1250\n",
            "20220531 15:19:44 current learning_rate:0.00000718\n",
            "used_time: 0.22417664527893066\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 370, loss: 0.672558, acc: 0.750000\n",
            "steps: 370\n",
            "save_steps: 1250\n",
            "20220531 15:19:46 current learning_rate:0.00000738\n",
            "used_time: 0.2575538158416748\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 380, loss: 0.575636, acc: 0.875000\n",
            "steps: 380\n",
            "save_steps: 1250\n",
            "20220531 15:19:49 current learning_rate:0.00000758\n",
            "used_time: 0.19950580596923828\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 390, loss: 0.214078, acc: 0.750000\n",
            "steps: 390\n",
            "save_steps: 1250\n",
            "20220531 15:19:51 current learning_rate:0.00000778\n",
            "used_time: 0.23177528381347656\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 400, loss: 0.513934, acc: 0.750000\n",
            "steps: 400\n",
            "save_steps: 1250\n",
            "20220531 15:19:53 current learning_rate:0.00000798\n",
            "used_time: 0.21507954597473145\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 410, loss: 0.467121, acc: 0.750000\n",
            "steps: 410\n",
            "save_steps: 1250\n",
            "20220531 15:19:55 current learning_rate:0.00000818\n",
            "used_time: 0.2613866329193115\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 420, loss: 0.537592, acc: 0.625000\n",
            "steps: 420\n",
            "save_steps: 1250\n",
            "20220531 15:19:57 current learning_rate:0.00000838\n",
            "used_time: 0.20605206489562988\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 430, loss: 0.356850, acc: 0.875000\n",
            "steps: 430\n",
            "save_steps: 1250\n",
            "20220531 15:20:00 current learning_rate:0.00000858\n",
            "used_time: 0.25006985664367676\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 440, loss: 0.692033, acc: 0.625000\n",
            "steps: 440\n",
            "save_steps: 1250\n",
            "20220531 15:20:02 current learning_rate:0.00000878\n",
            "used_time: 0.28554368019104004\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 450, loss: 0.564815, acc: 0.750000\n",
            "steps: 450\n",
            "save_steps: 1250\n",
            "20220531 15:20:04 current learning_rate:0.00000898\n",
            "used_time: 0.2463228702545166\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 460, loss: 0.886878, acc: 0.875000\n",
            "steps: 460\n",
            "save_steps: 1250\n",
            "20220531 15:20:06 current learning_rate:0.00000918\n",
            "used_time: 0.23588871955871582\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 470, loss: 0.757792, acc: 0.625000\n",
            "steps: 470\n",
            "save_steps: 1250\n",
            "20220531 15:20:08 current learning_rate:0.00000938\n",
            "used_time: 0.19817543029785156\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 480, loss: 0.388702, acc: 0.875000\n",
            "steps: 480\n",
            "save_steps: 1250\n",
            "20220531 15:20:11 current learning_rate:0.00000958\n",
            "used_time: 0.223585844039917\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 490, loss: 0.734731, acc: 0.625000\n",
            "steps: 490\n",
            "save_steps: 1250\n",
            "20220531 15:20:13 current learning_rate:0.00000978\n",
            "used_time: 0.26603102684020996\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 500, loss: 0.630085, acc: 0.875000\n",
            "steps: 500\n",
            "save_steps: 1250\n",
            "Train-RCAC 0.7123809523809523\n",
            "20220531 15:20:15 current learning_rate:0.00000998\n",
            "used_time: 0.19972538948059082\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 510, loss: 0.262033, acc: 0.750000\n",
            "steps: 510\n",
            "save_steps: 1250\n",
            "20220531 15:20:17 current learning_rate:0.00001000\n",
            "used_time: 0.22596406936645508\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 520, loss: 0.572278, acc: 0.500000\n",
            "steps: 520\n",
            "save_steps: 1250\n",
            "20220531 15:20:19 current learning_rate:0.00001000\n",
            "used_time: 0.2231597900390625\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 530, loss: 0.640272, acc: 0.750000\n",
            "steps: 530\n",
            "save_steps: 1250\n",
            "20220531 15:20:22 current learning_rate:0.00001000\n",
            "used_time: 0.262676477432251\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 540, loss: 0.090201, acc: 1.000000\n",
            "steps: 540\n",
            "save_steps: 1250\n",
            "20220531 15:20:24 current learning_rate:0.00001000\n",
            "used_time: 0.20796799659729004\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 550, loss: 0.240113, acc: 0.750000\n",
            "steps: 550\n",
            "save_steps: 1250\n",
            "20220531 15:20:26 current learning_rate:0.00001000\n",
            "used_time: 0.246657133102417\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 560, loss: 0.558824, acc: 0.750000\n",
            "steps: 560\n",
            "save_steps: 1250\n",
            "20220531 15:20:28 current learning_rate:0.00001000\n",
            "used_time: 0.22536182403564453\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 570, loss: 0.700342, acc: 0.375000\n",
            "steps: 570\n",
            "save_steps: 1250\n",
            "20220531 15:20:31 current learning_rate:0.00001000\n",
            "used_time: 0.24990630149841309\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 580, loss: 0.470473, acc: 0.625000\n",
            "steps: 580\n",
            "save_steps: 1250\n",
            "20220531 15:20:33 current learning_rate:0.00001000\n",
            "used_time: 0.22028183937072754\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 590, loss: 0.511223, acc: 0.375000\n",
            "steps: 590\n",
            "save_steps: 1250\n",
            "20220531 15:20:35 current learning_rate:0.00001000\n",
            "used_time: 0.20390033721923828\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 600, loss: 0.254277, acc: 0.500000\n",
            "steps: 600\n",
            "save_steps: 1250\n",
            "20220531 15:20:37 current learning_rate:0.00001000\n",
            "used_time: 0.21284985542297363\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 610, loss: 0.630227, acc: 0.375000\n",
            "steps: 610\n",
            "save_steps: 1250\n",
            "20220531 15:20:39 current learning_rate:0.00001000\n",
            "used_time: 0.25893402099609375\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 620, loss: 0.287668, acc: 0.750000\n",
            "steps: 620\n",
            "save_steps: 1250\n",
            "20220531 15:20:42 current learning_rate:0.00001000\n",
            "used_time: 0.23122334480285645\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 630, loss: 0.558733, acc: 0.625000\n",
            "steps: 630\n",
            "save_steps: 1250\n",
            "20220531 15:20:44 current learning_rate:0.00001000\n",
            "used_time: 0.2169322967529297\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 640, loss: 0.269234, acc: 0.750000\n",
            "steps: 640\n",
            "save_steps: 1250\n",
            "20220531 15:20:46 current learning_rate:0.00001000\n",
            "used_time: 0.21135163307189941\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 650, loss: 0.210359, acc: 0.625000\n",
            "steps: 650\n",
            "save_steps: 1250\n",
            "20220531 15:20:48 current learning_rate:0.00001000\n",
            "used_time: 0.2314162254333496\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 660, loss: 0.379120, acc: 0.500000\n",
            "steps: 660\n",
            "save_steps: 1250\n",
            "20220531 15:20:50 current learning_rate:0.00001000\n",
            "used_time: 0.22245478630065918\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 670, loss: 0.413807, acc: 0.750000\n",
            "steps: 670\n",
            "save_steps: 1250\n",
            "20220531 15:20:53 current learning_rate:0.00001000\n",
            "used_time: 0.20877408981323242\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 680, loss: 0.478595, acc: 0.625000\n",
            "steps: 680\n",
            "save_steps: 1250\n",
            "20220531 15:20:55 current learning_rate:0.00001000\n",
            "used_time: 0.22804760932922363\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 690, loss: 0.178410, acc: 0.875000\n",
            "steps: 690\n",
            "save_steps: 1250\n",
            "20220531 15:20:57 current learning_rate:0.00001000\n",
            "used_time: 0.24634647369384766\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 700, loss: 0.543421, acc: 0.750000\n",
            "steps: 700\n",
            "save_steps: 1250\n",
            "20220531 15:20:59 current learning_rate:0.00001000\n",
            "used_time: 0.2175920009613037\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 710, loss: 0.323533, acc: 0.625000\n",
            "steps: 710\n",
            "save_steps: 1250\n",
            "20220531 15:21:02 current learning_rate:0.00001000\n",
            "used_time: 0.24641871452331543\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 720, loss: 0.891257, acc: 0.500000\n",
            "steps: 720\n",
            "save_steps: 1250\n",
            "20220531 15:21:04 current learning_rate:0.00001000\n",
            "used_time: 0.2240757942199707\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 730, loss: 0.215551, acc: 0.625000\n",
            "steps: 730\n",
            "save_steps: 1250\n",
            "20220531 15:21:06 current learning_rate:0.00001000\n",
            "used_time: 0.23641562461853027\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 740, loss: 0.678545, acc: 1.000000\n",
            "steps: 740\n",
            "save_steps: 1250\n",
            "20220531 15:21:08 current learning_rate:0.00001000\n",
            "used_time: 0.20570588111877441\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 750, loss: 0.375329, acc: 0.750000\n",
            "steps: 750\n",
            "save_steps: 1250\n",
            "20220531 15:21:10 current learning_rate:0.00001000\n",
            "used_time: 0.22858071327209473\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 760, loss: 0.312101, acc: 0.750000\n",
            "steps: 760\n",
            "save_steps: 1250\n",
            "20220531 15:21:13 current learning_rate:0.00001000\n",
            "used_time: 0.2082688808441162\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 770, loss: 0.512891, acc: 0.750000\n",
            "steps: 770\n",
            "save_steps: 1250\n",
            "20220531 15:21:15 current learning_rate:0.00001000\n",
            "used_time: 0.24866843223571777\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 780, loss: 0.463485, acc: 0.875000\n",
            "steps: 780\n",
            "save_steps: 1250\n",
            "20220531 15:21:17 current learning_rate:0.00001000\n",
            "used_time: 0.22928881645202637\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 790, loss: 0.422073, acc: 0.625000\n",
            "steps: 790\n",
            "save_steps: 1250\n",
            "20220531 15:21:19 current learning_rate:0.00001000\n",
            "used_time: 0.2150561809539795\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 800, loss: 0.710616, acc: 0.625000\n",
            "steps: 800\n",
            "save_steps: 1250\n",
            "20220531 15:21:21 current learning_rate:0.00001000\n",
            "used_time: 0.22182369232177734\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 810, loss: 0.372270, acc: 0.750000\n",
            "steps: 810\n",
            "save_steps: 1250\n",
            "20220531 15:21:24 current learning_rate:0.00001000\n",
            "used_time: 0.247267484664917\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 820, loss: 0.499898, acc: 0.500000\n",
            "steps: 820\n",
            "save_steps: 1250\n",
            "20220531 15:21:26 current learning_rate:0.00001000\n",
            "used_time: 0.23909997940063477\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 830, loss: 0.472172, acc: 0.375000\n",
            "steps: 830\n",
            "save_steps: 1250\n",
            "20220531 15:21:28 current learning_rate:0.00001000\n",
            "used_time: 0.20541858673095703\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 840, loss: 0.338315, acc: 0.625000\n",
            "steps: 840\n",
            "save_steps: 1250\n",
            "20220531 15:21:30 current learning_rate:0.00001000\n",
            "used_time: 0.23211002349853516\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 850, loss: 0.363229, acc: 0.625000\n",
            "steps: 850\n",
            "save_steps: 1250\n",
            "20220531 15:21:32 current learning_rate:0.00001000\n",
            "used_time: 0.2531166076660156\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 860, loss: 0.533955, acc: 0.875000\n",
            "steps: 860\n",
            "save_steps: 1250\n",
            "20220531 15:21:34 current learning_rate:0.00001000\n",
            "used_time: 0.20587754249572754\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 870, loss: 0.884220, acc: 0.250000\n",
            "steps: 870\n",
            "save_steps: 1250\n",
            "20220531 15:21:37 current learning_rate:0.00001000\n",
            "used_time: 0.2176070213317871\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 880, loss: 1.047940, acc: 0.500000\n",
            "steps: 880\n",
            "save_steps: 1250\n",
            "20220531 15:21:39 current learning_rate:0.00001000\n",
            "used_time: 0.22089719772338867\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 890, loss: 0.484218, acc: 0.625000\n",
            "steps: 890\n",
            "save_steps: 1250\n",
            "20220531 15:21:41 current learning_rate:0.00001000\n",
            "used_time: 0.24314355850219727\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 900, loss: 0.803430, acc: 0.500000\n",
            "steps: 900\n",
            "save_steps: 1250\n",
            "20220531 15:21:43 current learning_rate:0.00001000\n",
            "used_time: 0.20060300827026367\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 910, loss: 0.834322, acc: 0.750000\n",
            "steps: 910\n",
            "save_steps: 1250\n",
            "20220531 15:21:46 current learning_rate:0.00001000\n",
            "used_time: 0.21970438957214355\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 920, loss: 0.429545, acc: 0.625000\n",
            "steps: 920\n",
            "save_steps: 1250\n",
            "20220531 15:21:48 current learning_rate:0.00001000\n",
            "used_time: 0.22270894050598145\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 930, loss: 0.640752, acc: 0.875000\n",
            "steps: 930\n",
            "save_steps: 1250\n",
            "20220531 15:21:50 current learning_rate:0.00001000\n",
            "used_time: 0.24752402305603027\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 940, loss: 0.254034, acc: 0.625000\n",
            "steps: 940\n",
            "save_steps: 1250\n",
            "20220531 15:21:52 current learning_rate:0.00001000\n",
            "used_time: 0.2090141773223877\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 950, loss: 0.489381, acc: 0.500000\n",
            "steps: 950\n",
            "save_steps: 1250\n",
            "20220531 15:21:54 current learning_rate:0.00001000\n",
            "used_time: 0.24324631690979004\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 960, loss: 0.108462, acc: 0.875000\n",
            "steps: 960\n",
            "save_steps: 1250\n",
            "20220531 15:21:57 current learning_rate:0.00001000\n",
            "used_time: 0.2182469367980957\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 970, loss: 0.363551, acc: 0.375000\n",
            "steps: 970\n",
            "save_steps: 1250\n",
            "20220531 15:21:59 current learning_rate:0.00001000\n",
            "used_time: 0.241499662399292\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 980, loss: 0.388300, acc: 0.750000\n",
            "steps: 980\n",
            "save_steps: 1250\n",
            "20220531 15:22:01 current learning_rate:0.00001000\n",
            "used_time: 0.21326231956481934\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 990, loss: 0.822412, acc: 0.375000\n",
            "steps: 990\n",
            "save_steps: 1250\n",
            "20220531 15:22:03 current learning_rate:0.00001000\n",
            "used_time: 0.20917344093322754\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1000, loss: 0.541542, acc: 0.625000\n",
            "steps: 1000\n",
            "save_steps: 1250\n",
            "Train-RCAC 0.77\n",
            "20220531 15:22:05 current learning_rate:0.00001000\n",
            "used_time: 0.22040295600891113\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1010, loss: 0.335396, acc: 0.500000\n",
            "steps: 1010\n",
            "save_steps: 1250\n",
            "20220531 15:22:08 current learning_rate:0.00001000\n",
            "used_time: 0.25327181816101074\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1020, loss: 0.148328, acc: 0.875000\n",
            "steps: 1020\n",
            "save_steps: 1250\n",
            "20220531 15:22:10 current learning_rate:0.00001000\n",
            "used_time: 0.19993877410888672\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1030, loss: 0.780544, acc: 0.500000\n",
            "steps: 1030\n",
            "save_steps: 1250\n",
            "20220531 15:22:12 current learning_rate:0.00001000\n",
            "used_time: 0.21587753295898438\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1040, loss: 0.498274, acc: 0.375000\n",
            "steps: 1040\n",
            "save_steps: 1250\n",
            "20220531 15:22:14 current learning_rate:0.00001000\n",
            "used_time: 0.22652673721313477\n",
            "shuffle epoch 1\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1050, loss: 0.509397, acc: 0.750000\n",
            "steps: 1050\n",
            "save_steps: 1250\n",
            "20220531 15:22:16 current learning_rate:0.00001000\n",
            "used_time: 0.24262690544128418\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1060, loss: 0.580605, acc: 0.750000\n",
            "steps: 1060\n",
            "save_steps: 1250\n",
            "20220531 15:22:18 current learning_rate:0.00001000\n",
            "used_time: 0.19312548637390137\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1070, loss: 0.461423, acc: 0.375000\n",
            "steps: 1070\n",
            "save_steps: 1250\n",
            "20220531 15:22:21 current learning_rate:0.00001000\n",
            "used_time: 0.23860669136047363\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1080, loss: 0.100663, acc: 0.750000\n",
            "steps: 1080\n",
            "save_steps: 1250\n",
            "20220531 15:22:23 current learning_rate:0.00001000\n",
            "used_time: 0.21758508682250977\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1090, loss: 0.664306, acc: 0.250000\n",
            "steps: 1090\n",
            "save_steps: 1250\n",
            "20220531 15:22:25 current learning_rate:0.00001000\n",
            "used_time: 0.2297191619873047\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1100, loss: 0.110958, acc: 0.875000\n",
            "steps: 1100\n",
            "save_steps: 1250\n",
            "20220531 15:22:27 current learning_rate:0.00001000\n",
            "used_time: 0.22100114822387695\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1110, loss: 0.194119, acc: 0.750000\n",
            "steps: 1110\n",
            "save_steps: 1250\n",
            "20220531 15:22:29 current learning_rate:0.00001000\n",
            "used_time: 0.20046401023864746\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1120, loss: 0.356024, acc: 0.625000\n",
            "steps: 1120\n",
            "save_steps: 1250\n",
            "20220531 15:22:32 current learning_rate:0.00001000\n",
            "used_time: 0.22695207595825195\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1130, loss: 0.332858, acc: 0.625000\n",
            "steps: 1130\n",
            "save_steps: 1250\n",
            "20220531 15:22:34 current learning_rate:0.00001000\n",
            "used_time: 0.2598147392272949\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1140, loss: 0.471048, acc: 0.500000\n",
            "steps: 1140\n",
            "save_steps: 1250\n",
            "20220531 15:22:36 current learning_rate:0.00001000\n",
            "used_time: 0.2084503173828125\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1150, loss: 0.485922, acc: 0.500000\n",
            "steps: 1150\n",
            "save_steps: 1250\n",
            "20220531 15:22:38 current learning_rate:0.00001000\n",
            "used_time: 0.19935107231140137\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1160, loss: 0.469046, acc: 0.250000\n",
            "steps: 1160\n",
            "save_steps: 1250\n",
            "20220531 15:22:41 current learning_rate:0.00001000\n",
            "used_time: 0.2831847667694092\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1170, loss: 0.071751, acc: 0.500000\n",
            "steps: 1170\n",
            "save_steps: 1250\n",
            "20220531 15:22:43 current learning_rate:0.00001000\n",
            "used_time: 0.23866558074951172\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1180, loss: 0.260864, acc: 0.500000\n",
            "steps: 1180\n",
            "save_steps: 1250\n",
            "20220531 15:22:45 current learning_rate:0.00001000\n",
            "used_time: 0.22568178176879883\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1190, loss: 0.781819, acc: 0.500000\n",
            "steps: 1190\n",
            "save_steps: 1250\n",
            "20220531 15:22:47 current learning_rate:0.00001000\n",
            "used_time: 0.22259855270385742\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1200, loss: 0.820109, acc: 0.625000\n",
            "steps: 1200\n",
            "save_steps: 1250\n",
            "20220531 15:22:49 current learning_rate:0.00001000\n",
            "used_time: 0.22364282608032227\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1210, loss: 0.374971, acc: 0.750000\n",
            "steps: 1210\n",
            "save_steps: 1250\n",
            "20220531 15:22:52 current learning_rate:0.00001000\n",
            "used_time: 0.2596001625061035\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1220, loss: 0.741664, acc: 0.375000\n",
            "steps: 1220\n",
            "save_steps: 1250\n",
            "20220531 15:22:54 current learning_rate:0.00001000\n",
            "used_time: 0.1993720531463623\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1230, loss: 0.276448, acc: 0.750000\n",
            "steps: 1230\n",
            "save_steps: 1250\n",
            "20220531 15:22:56 current learning_rate:0.00001000\n",
            "used_time: 0.20551037788391113\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1240, loss: 0.632579, acc: 0.625000\n",
            "steps: 1240\n",
            "save_steps: 1250\n",
            "20220531 15:22:58 current learning_rate:0.00001000\n",
            "used_time: 0.21661710739135742\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1250, loss: 0.102307, acc: 0.750000\n",
            "steps: 1250\n",
            "save_steps: 1250\n",
            "20220531 15:23:00 current learning_rate:0.00001000\n",
            "save_path: output_hm/step_1250train\n",
            "used_time: 12.094056606292725\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1260, loss: 0.060207, acc: 0.750000\n",
            "steps: 1260\n",
            "save_steps: 1250\n",
            "20220531 15:23:14 current learning_rate:0.00001000\n",
            "used_time: 0.2266216278076172\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1270, loss: 0.060667, acc: 0.625000\n",
            "steps: 1270\n",
            "save_steps: 1250\n",
            "20220531 15:23:17 current learning_rate:0.00001000\n",
            "used_time: 0.22084259986877441\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1280, loss: 0.358783, acc: 0.500000\n",
            "steps: 1280\n",
            "save_steps: 1250\n",
            "20220531 15:23:19 current learning_rate:0.00001000\n",
            "used_time: 0.2184455394744873\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1290, loss: 0.243299, acc: 1.000000\n",
            "steps: 1290\n",
            "save_steps: 1250\n",
            "20220531 15:23:21 current learning_rate:0.00001000\n",
            "used_time: 0.2342369556427002\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1300, loss: 0.622012, acc: 0.625000\n",
            "steps: 1300\n",
            "save_steps: 1250\n",
            "20220531 15:23:23 current learning_rate:0.00001000\n",
            "used_time: 0.22548246383666992\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1310, loss: 0.255557, acc: 0.375000\n",
            "steps: 1310\n",
            "save_steps: 1250\n",
            "20220531 15:23:26 current learning_rate:0.00001000\n",
            "used_time: 0.22580170631408691\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1320, loss: 0.297046, acc: 0.250000\n",
            "steps: 1320\n",
            "save_steps: 1250\n",
            "20220531 15:23:28 current learning_rate:0.00001000\n",
            "used_time: 0.25867629051208496\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1330, loss: 0.493380, acc: 0.500000\n",
            "steps: 1330\n",
            "save_steps: 1250\n",
            "20220531 15:23:30 current learning_rate:0.00001000\n",
            "used_time: 0.24437761306762695\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1340, loss: 0.504094, acc: 0.875000\n",
            "steps: 1340\n",
            "save_steps: 1250\n",
            "20220531 15:23:32 current learning_rate:0.00001000\n",
            "used_time: 0.21062469482421875\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1350, loss: 0.338965, acc: 0.750000\n",
            "steps: 1350\n",
            "save_steps: 1250\n",
            "20220531 15:23:34 current learning_rate:0.00001000\n",
            "used_time: 0.21938276290893555\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1360, loss: 0.110753, acc: 0.875000\n",
            "steps: 1360\n",
            "save_steps: 1250\n",
            "20220531 15:23:37 current learning_rate:0.00001000\n",
            "used_time: 0.20192813873291016\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1370, loss: 0.584541, acc: 0.625000\n",
            "steps: 1370\n",
            "save_steps: 1250\n",
            "20220531 15:23:39 current learning_rate:0.00001000\n",
            "used_time: 0.2461566925048828\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1380, loss: 1.490524, acc: 0.500000\n",
            "steps: 1380\n",
            "save_steps: 1250\n",
            "20220531 15:23:41 current learning_rate:0.00001000\n",
            "used_time: 0.21990966796875\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1390, loss: 0.496343, acc: 0.625000\n",
            "steps: 1390\n",
            "save_steps: 1250\n",
            "20220531 15:23:43 current learning_rate:0.00001000\n",
            "used_time: 0.21467351913452148\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1400, loss: 0.063928, acc: 0.750000\n",
            "steps: 1400\n",
            "save_steps: 1250\n",
            "20220531 15:23:45 current learning_rate:0.00001000\n",
            "used_time: 0.2281947135925293\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1410, loss: 0.240752, acc: 0.750000\n",
            "steps: 1410\n",
            "save_steps: 1250\n",
            "20220531 15:23:48 current learning_rate:0.00001000\n",
            "used_time: 0.22933149337768555\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1420, loss: 0.607968, acc: 0.625000\n",
            "steps: 1420\n",
            "save_steps: 1250\n",
            "20220531 15:23:50 current learning_rate:0.00001000\n",
            "used_time: 0.2247459888458252\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1430, loss: 0.110515, acc: 0.750000\n",
            "steps: 1430\n",
            "save_steps: 1250\n",
            "20220531 15:23:52 current learning_rate:0.00001000\n",
            "used_time: 0.23445606231689453\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1440, loss: 0.094647, acc: 0.750000\n",
            "steps: 1440\n",
            "save_steps: 1250\n",
            "20220531 15:23:54 current learning_rate:0.00001000\n",
            "used_time: 0.19834089279174805\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1450, loss: 0.052541, acc: 0.750000\n",
            "steps: 1450\n",
            "save_steps: 1250\n",
            "20220531 15:23:56 current learning_rate:0.00001000\n",
            "used_time: 0.2516813278198242\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1460, loss: 0.431851, acc: 0.625000\n",
            "steps: 1460\n",
            "save_steps: 1250\n",
            "20220531 15:23:59 current learning_rate:0.00001000\n",
            "used_time: 0.20784425735473633\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1470, loss: 0.342341, acc: 0.375000\n",
            "steps: 1470\n",
            "save_steps: 1250\n",
            "20220531 15:24:01 current learning_rate:0.00001000\n",
            "used_time: 0.22152400016784668\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1480, loss: 0.078176, acc: 0.750000\n",
            "steps: 1480\n",
            "save_steps: 1250\n",
            "20220531 15:24:03 current learning_rate:0.00001000\n",
            "used_time: 0.22372984886169434\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1490, loss: 0.310696, acc: 0.500000\n",
            "steps: 1490\n",
            "save_steps: 1250\n",
            "20220531 15:24:05 current learning_rate:0.00001000\n",
            "used_time: 0.22976183891296387\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1500, loss: 0.633262, acc: 0.750000\n",
            "steps: 1500\n",
            "save_steps: 1250\n",
            "Train-RCAC 0.8730158730158731\n",
            "20220531 15:24:07 current learning_rate:0.00001000\n",
            "used_time: 0.21314525604248047\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1510, loss: 0.276749, acc: 0.625000\n",
            "steps: 1510\n",
            "save_steps: 1250\n",
            "20220531 15:24:10 current learning_rate:0.00001000\n",
            "used_time: 0.23456263542175293\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1520, loss: 0.182764, acc: 0.625000\n",
            "steps: 1520\n",
            "save_steps: 1250\n",
            "20220531 15:24:12 current learning_rate:0.00001000\n",
            "used_time: 0.2265458106994629\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1530, loss: 0.034491, acc: 0.750000\n",
            "steps: 1530\n",
            "save_steps: 1250\n",
            "20220531 15:24:14 current learning_rate:0.00001000\n",
            "used_time: 0.2463972568511963\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1540, loss: 0.074966, acc: 0.625000\n",
            "steps: 1540\n",
            "save_steps: 1250\n",
            "20220531 15:24:16 current learning_rate:0.00001000\n",
            "used_time: 0.20733213424682617\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1550, loss: 0.010418, acc: 0.500000\n",
            "steps: 1550\n",
            "save_steps: 1250\n",
            "20220531 15:24:19 current learning_rate:0.00001000\n",
            "used_time: 0.2065296173095703\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1560, loss: 0.179812, acc: 0.500000\n",
            "steps: 1560\n",
            "save_steps: 1250\n",
            "20220531 15:24:21 current learning_rate:0.00001000\n",
            "used_time: 0.21620869636535645\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1570, loss: 0.625303, acc: 0.625000\n",
            "steps: 1570\n",
            "save_steps: 1250\n",
            "20220531 15:24:23 current learning_rate:0.00001000\n",
            "used_time: 0.2699413299560547\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1580, loss: 0.077200, acc: 0.500000\n",
            "steps: 1580\n",
            "save_steps: 1250\n",
            "20220531 15:24:25 current learning_rate:0.00001000\n",
            "used_time: 0.22223567962646484\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1590, loss: 0.766205, acc: 0.625000\n",
            "steps: 1590\n",
            "save_steps: 1250\n",
            "20220531 15:24:27 current learning_rate:0.00001000\n",
            "used_time: 0.22563648223876953\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1600, loss: 0.045118, acc: 0.625000\n",
            "steps: 1600\n",
            "save_steps: 1250\n",
            "20220531 15:24:30 current learning_rate:0.00001000\n",
            "used_time: 0.2087867259979248\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1610, loss: 0.043730, acc: 0.625000\n",
            "steps: 1610\n",
            "save_steps: 1250\n",
            "20220531 15:24:32 current learning_rate:0.00001000\n",
            "used_time: 0.22494983673095703\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1620, loss: 0.089204, acc: 0.625000\n",
            "steps: 1620\n",
            "save_steps: 1250\n",
            "20220531 15:24:34 current learning_rate:0.00001000\n",
            "used_time: 0.21610713005065918\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1630, loss: 0.030017, acc: 0.625000\n",
            "steps: 1630\n",
            "save_steps: 1250\n",
            "20220531 15:24:36 current learning_rate:0.00001000\n",
            "used_time: 0.2005162239074707\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1640, loss: 0.188925, acc: 0.875000\n",
            "steps: 1640\n",
            "save_steps: 1250\n",
            "20220531 15:24:38 current learning_rate:0.00001000\n",
            "used_time: 0.2115771770477295\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1650, loss: 0.472378, acc: 0.500000\n",
            "steps: 1650\n",
            "save_steps: 1250\n",
            "20220531 15:24:40 current learning_rate:0.00001000\n",
            "used_time: 0.2509613037109375\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1660, loss: 0.250924, acc: 0.625000\n",
            "steps: 1660\n",
            "save_steps: 1250\n",
            "20220531 15:24:43 current learning_rate:0.00001000\n",
            "used_time: 0.22371983528137207\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1670, loss: 0.397743, acc: 0.750000\n",
            "steps: 1670\n",
            "save_steps: 1250\n",
            "20220531 15:24:45 current learning_rate:0.00001000\n",
            "used_time: 0.20528793334960938\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1680, loss: 0.421673, acc: 0.750000\n",
            "steps: 1680\n",
            "save_steps: 1250\n",
            "20220531 15:24:47 current learning_rate:0.00001000\n",
            "used_time: 0.21745061874389648\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1690, loss: 0.276886, acc: 0.750000\n",
            "steps: 1690\n",
            "save_steps: 1250\n",
            "20220531 15:24:49 current learning_rate:0.00001000\n",
            "used_time: 0.2526683807373047\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1700, loss: 0.200103, acc: 0.500000\n",
            "steps: 1700\n",
            "save_steps: 1250\n",
            "20220531 15:24:51 current learning_rate:0.00001000\n",
            "used_time: 0.20049071311950684\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1710, loss: 0.122019, acc: 1.000000\n",
            "steps: 1710\n",
            "save_steps: 1250\n",
            "20220531 15:24:53 current learning_rate:0.00001000\n",
            "used_time: 0.20514822006225586\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1720, loss: 0.134418, acc: 0.875000\n",
            "steps: 1720\n",
            "save_steps: 1250\n",
            "20220531 15:24:56 current learning_rate:0.00001000\n",
            "used_time: 0.22286272048950195\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1730, loss: 0.104981, acc: 0.625000\n",
            "steps: 1730\n",
            "save_steps: 1250\n",
            "20220531 15:24:58 current learning_rate:0.00001000\n",
            "used_time: 0.2505645751953125\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1740, loss: 0.193911, acc: 0.750000\n",
            "steps: 1740\n",
            "save_steps: 1250\n",
            "20220531 15:25:00 current learning_rate:0.00001000\n",
            "used_time: 0.22458243370056152\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1750, loss: 0.060821, acc: 0.875000\n",
            "steps: 1750\n",
            "save_steps: 1250\n",
            "20220531 15:25:02 current learning_rate:0.00001000\n",
            "used_time: 0.21950268745422363\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1760, loss: 0.827355, acc: 0.625000\n",
            "steps: 1760\n",
            "save_steps: 1250\n",
            "20220531 15:25:05 current learning_rate:0.00001000\n",
            "used_time: 0.21370482444763184\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1770, loss: 0.597808, acc: 0.625000\n",
            "steps: 1770\n",
            "save_steps: 1250\n",
            "20220531 15:25:07 current learning_rate:0.00001000\n",
            "used_time: 0.24092888832092285\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1780, loss: 0.081458, acc: 0.750000\n",
            "steps: 1780\n",
            "save_steps: 1250\n",
            "20220531 15:25:09 current learning_rate:0.00001000\n",
            "used_time: 0.20444536209106445\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1790, loss: 0.586483, acc: 0.625000\n",
            "steps: 1790\n",
            "save_steps: 1250\n",
            "20220531 15:25:11 current learning_rate:0.00001000\n",
            "used_time: 0.20731019973754883\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1800, loss: 0.124722, acc: 0.500000\n",
            "steps: 1800\n",
            "save_steps: 1250\n",
            "20220531 15:25:13 current learning_rate:0.00001000\n",
            "used_time: 0.2258157730102539\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1810, loss: 0.645102, acc: 0.625000\n",
            "steps: 1810\n",
            "save_steps: 1250\n",
            "20220531 15:25:16 current learning_rate:0.00001000\n",
            "used_time: 0.255523681640625\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1820, loss: 0.112739, acc: 0.750000\n",
            "steps: 1820\n",
            "save_steps: 1250\n",
            "20220531 15:25:18 current learning_rate:0.00001000\n",
            "used_time: 0.2110457420349121\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1830, loss: 0.464038, acc: 0.875000\n",
            "steps: 1830\n",
            "save_steps: 1250\n",
            "20220531 15:25:20 current learning_rate:0.00001000\n",
            "used_time: 0.20604181289672852\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1840, loss: 1.190659, acc: 0.500000\n",
            "steps: 1840\n",
            "save_steps: 1250\n",
            "20220531 15:25:22 current learning_rate:0.00001000\n",
            "used_time: 0.20222997665405273\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1850, loss: 0.452690, acc: 0.375000\n",
            "steps: 1850\n",
            "save_steps: 1250\n",
            "20220531 15:25:24 current learning_rate:0.00001000\n",
            "used_time: 0.26517176628112793\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1860, loss: 0.062042, acc: 0.625000\n",
            "steps: 1860\n",
            "save_steps: 1250\n",
            "20220531 15:25:27 current learning_rate:0.00001000\n",
            "used_time: 0.1966257095336914\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1870, loss: 2.261827, acc: 0.500000\n",
            "steps: 1870\n",
            "save_steps: 1250\n",
            "20220531 15:25:29 current learning_rate:0.00001000\n",
            "used_time: 0.21436119079589844\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1880, loss: 0.022002, acc: 0.750000\n",
            "steps: 1880\n",
            "save_steps: 1250\n",
            "20220531 15:25:31 current learning_rate:0.00001000\n",
            "used_time: 0.2124168872833252\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1890, loss: 0.284095, acc: 0.625000\n",
            "steps: 1890\n",
            "save_steps: 1250\n",
            "20220531 15:25:33 current learning_rate:0.00001000\n",
            "used_time: 0.25450825691223145\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1900, loss: 0.463243, acc: 0.875000\n",
            "steps: 1900\n",
            "save_steps: 1250\n",
            "20220531 15:25:35 current learning_rate:0.00001000\n",
            "used_time: 0.20872092247009277\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1910, loss: 0.125068, acc: 0.625000\n",
            "steps: 1910\n",
            "save_steps: 1250\n",
            "20220531 15:25:38 current learning_rate:0.00001000\n",
            "used_time: 0.20487737655639648\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1920, loss: 0.395217, acc: 0.500000\n",
            "steps: 1920\n",
            "save_steps: 1250\n",
            "20220531 15:25:40 current learning_rate:0.00001000\n",
            "used_time: 0.2038288116455078\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1930, loss: 0.714747, acc: 0.750000\n",
            "steps: 1930\n",
            "save_steps: 1250\n",
            "20220531 15:25:42 current learning_rate:0.00001000\n",
            "used_time: 0.24152493476867676\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1940, loss: 0.432419, acc: 0.750000\n",
            "steps: 1940\n",
            "save_steps: 1250\n",
            "20220531 15:25:44 current learning_rate:0.00001000\n",
            "used_time: 0.2092130184173584\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1950, loss: 1.345167, acc: 0.250000\n",
            "steps: 1950\n",
            "save_steps: 1250\n",
            "20220531 15:25:46 current learning_rate:0.00001000\n",
            "used_time: 0.22701168060302734\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1960, loss: 0.243078, acc: 0.750000\n",
            "steps: 1960\n",
            "save_steps: 1250\n",
            "20220531 15:25:49 current learning_rate:0.00001000\n",
            "used_time: 0.2112133502960205\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1970, loss: 0.232562, acc: 0.750000\n",
            "steps: 1970\n",
            "save_steps: 1250\n",
            "20220531 15:25:51 current learning_rate:0.00001000\n",
            "used_time: 0.24649786949157715\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1980, loss: 0.232922, acc: 0.625000\n",
            "steps: 1980\n",
            "save_steps: 1250\n",
            "20220531 15:25:53 current learning_rate:0.00001000\n",
            "used_time: 0.2277050018310547\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1990, loss: 1.050082, acc: 0.625000\n",
            "steps: 1990\n",
            "save_steps: 1250\n",
            "20220531 15:25:55 current learning_rate:0.00001000\n",
            "used_time: 0.21376419067382812\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 2000, loss: 0.346014, acc: 0.750000\n",
            "steps: 2000\n",
            "save_steps: 1250\n",
            "Train-RCAC 0.9366666666666666\n",
            "20220531 15:25:57 current learning_rate:0.00001000\n",
            "used_time: 0.2027113437652588\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 2010, loss: 0.148870, acc: 0.625000\n",
            "steps: 2010\n",
            "save_steps: 1250\n",
            "20220531 15:26:00 current learning_rate:0.00001000\n",
            "used_time: 0.22064924240112305\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 2020, loss: 0.187789, acc: 0.750000\n",
            "steps: 2020\n",
            "save_steps: 1250\n",
            "20220531 15:26:02 current learning_rate:0.00001000\n",
            "used_time: 0.22987771034240723\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 2030, loss: 0.023640, acc: 0.875000\n",
            "steps: 2030\n",
            "save_steps: 1250\n",
            "20220531 15:26:04 current learning_rate:0.00001000\n",
            "used_time: 0.22272181510925293\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 2040, loss: 0.248302, acc: 0.625000\n",
            "steps: 2040\n",
            "save_steps: 1250\n",
            "20220531 15:26:06 current learning_rate:0.00001000\n",
            "used_time: 0.2253861427307129\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 2050, loss: 0.517355, acc: 0.625000\n",
            "steps: 2050\n",
            "save_steps: 1250\n",
            "20220531 15:26:09 current learning_rate:0.00001000\n",
            "used_time: 0.2685251235961914\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 2060, loss: 1.114482, acc: 0.500000\n",
            "steps: 2060\n",
            "save_steps: 1250\n",
            "20220531 15:26:11 current learning_rate:0.00001000\n",
            "used_time: 0.21695995330810547\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 2070, loss: 0.075790, acc: 0.750000\n",
            "steps: 2070\n",
            "save_steps: 1250\n",
            "20220531 15:26:13 current learning_rate:0.00001000\n",
            "used_time: 0.22615599632263184\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 2080, loss: 0.453849, acc: 0.625000\n",
            "steps: 2080\n",
            "save_steps: 1250\n",
            "20220531 15:26:15 current learning_rate:0.00001000\n",
            "used_time: 0.2246558666229248\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 2090, loss: 0.284074, acc: 0.625000\n",
            "steps: 2090\n",
            "save_steps: 1250\n",
            "20220531 15:26:17 current learning_rate:0.00001000\n",
            "used_time: 0.2599928379058838\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 2100, loss: 0.213293, acc: 1.000000\n",
            "steps: 2100\n",
            "save_steps: 1250\n",
            "20220531 15:26:19 current learning_rate:0.00001000\n",
            "used_time: 0.20206737518310547\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 2110, loss: 0.239515, acc: 0.375000\n",
            "steps: 2110\n",
            "save_steps: 1250\n",
            "20220531 15:26:22 current learning_rate:0.00001000\n",
            "used_time: 0.20832419395446777\n",
            "shuffle epoch 2\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2120, loss: 0.442005, acc: 0.750000\n",
            "steps: 2120\n",
            "save_steps: 1250\n",
            "20220531 15:26:24 current learning_rate:0.00001000\n",
            "used_time: 0.20061612129211426\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2130, loss: 0.037284, acc: 0.875000\n",
            "steps: 2130\n",
            "save_steps: 1250\n",
            "20220531 15:26:26 current learning_rate:0.00001000\n",
            "used_time: 0.2435150146484375\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2140, loss: 0.079990, acc: 0.875000\n",
            "steps: 2140\n",
            "save_steps: 1250\n",
            "20220531 15:26:28 current learning_rate:0.00001000\n",
            "used_time: 0.28476738929748535\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2150, loss: 0.249245, acc: 1.000000\n",
            "steps: 2150\n",
            "save_steps: 1250\n",
            "20220531 15:26:30 current learning_rate:0.00001000\n",
            "used_time: 0.20403313636779785\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2160, loss: 0.092969, acc: 0.375000\n",
            "steps: 2160\n",
            "save_steps: 1250\n",
            "20220531 15:26:33 current learning_rate:0.00001000\n",
            "used_time: 0.2251434326171875\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2170, loss: 0.237030, acc: 0.750000\n",
            "steps: 2170\n",
            "save_steps: 1250\n",
            "20220531 15:26:35 current learning_rate:0.00001000\n",
            "used_time: 0.27864718437194824\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2180, loss: 0.025365, acc: 0.750000\n",
            "steps: 2180\n",
            "save_steps: 1250\n",
            "20220531 15:26:37 current learning_rate:0.00001000\n",
            "used_time: 0.2232813835144043\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2190, loss: 0.003362, acc: 0.625000\n",
            "steps: 2190\n",
            "save_steps: 1250\n",
            "20220531 15:26:39 current learning_rate:0.00001000\n",
            "used_time: 0.21863913536071777\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2200, loss: 0.006024, acc: 0.250000\n",
            "steps: 2200\n",
            "save_steps: 1250\n",
            "20220531 15:26:42 current learning_rate:0.00001000\n",
            "used_time: 0.21532297134399414\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2210, loss: 0.001911, acc: 0.625000\n",
            "steps: 2210\n",
            "save_steps: 1250\n",
            "20220531 15:26:44 current learning_rate:0.00001000\n",
            "used_time: 0.26989150047302246\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2220, loss: 0.011194, acc: 0.875000\n",
            "steps: 2220\n",
            "save_steps: 1250\n",
            "20220531 15:26:46 current learning_rate:0.00001000\n",
            "used_time: 0.2394089698791504\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2230, loss: 0.837906, acc: 0.625000\n",
            "steps: 2230\n",
            "save_steps: 1250\n",
            "20220531 15:26:48 current learning_rate:0.00001000\n",
            "used_time: 0.20676612854003906\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2240, loss: 0.701214, acc: 0.375000\n",
            "steps: 2240\n",
            "save_steps: 1250\n",
            "20220531 15:26:50 current learning_rate:0.00001000\n",
            "used_time: 0.20920491218566895\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2250, loss: 0.029013, acc: 0.500000\n",
            "steps: 2250\n",
            "save_steps: 1250\n",
            "20220531 15:26:53 current learning_rate:0.00001000\n",
            "used_time: 0.24582433700561523\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2260, loss: 0.172534, acc: 0.500000\n",
            "steps: 2260\n",
            "save_steps: 1250\n",
            "20220531 15:26:55 current learning_rate:0.00001000\n",
            "used_time: 0.2239055633544922\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2270, loss: 0.044934, acc: 0.500000\n",
            "steps: 2270\n",
            "save_steps: 1250\n",
            "20220531 15:26:57 current learning_rate:0.00001000\n",
            "used_time: 0.21982693672180176\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2280, loss: 0.012554, acc: 0.500000\n",
            "steps: 2280\n",
            "save_steps: 1250\n",
            "20220531 15:26:59 current learning_rate:0.00001000\n",
            "used_time: 0.2132425308227539\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2290, loss: 0.065589, acc: 0.750000\n",
            "steps: 2290\n",
            "save_steps: 1250\n",
            "20220531 15:27:02 current learning_rate:0.00001000\n",
            "used_time: 0.2443990707397461\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2300, loss: 0.085349, acc: 0.625000\n",
            "steps: 2300\n",
            "save_steps: 1250\n",
            "20220531 15:27:04 current learning_rate:0.00001000\n",
            "used_time: 0.24438762664794922\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2310, loss: 0.002106, acc: 0.875000\n",
            "steps: 2310\n",
            "save_steps: 1250\n",
            "20220531 15:27:06 current learning_rate:0.00001000\n",
            "used_time: 0.20255279541015625\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2320, loss: 0.004004, acc: 0.250000\n",
            "steps: 2320\n",
            "save_steps: 1250\n",
            "20220531 15:27:08 current learning_rate:0.00001000\n",
            "used_time: 0.22886323928833008\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2330, loss: 0.000832, acc: 0.625000\n",
            "steps: 2330\n",
            "save_steps: 1250\n",
            "20220531 15:27:10 current learning_rate:0.00001000\n",
            "used_time: 0.2431628704071045\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2340, loss: 0.000754, acc: 0.750000\n",
            "steps: 2340\n",
            "save_steps: 1250\n",
            "20220531 15:27:13 current learning_rate:0.00001000\n",
            "used_time: 0.2111070156097412\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2350, loss: 0.045610, acc: 0.875000\n",
            "steps: 2350\n",
            "save_steps: 1250\n",
            "20220531 15:27:15 current learning_rate:0.00001000\n",
            "used_time: 0.21578478813171387\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2360, loss: 0.003050, acc: 0.875000\n",
            "steps: 2360\n",
            "save_steps: 1250\n",
            "20220531 15:27:17 current learning_rate:0.00001000\n",
            "used_time: 0.22478055953979492\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2370, loss: 0.026968, acc: 0.250000\n",
            "steps: 2370\n",
            "save_steps: 1250\n",
            "20220531 15:27:19 current learning_rate:0.00001000\n",
            "used_time: 0.25189924240112305\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2380, loss: 0.005170, acc: 0.625000\n",
            "steps: 2380\n",
            "save_steps: 1250\n",
            "20220531 15:27:22 current learning_rate:0.00001000\n",
            "used_time: 0.22171640396118164\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2390, loss: 0.014537, acc: 0.750000\n",
            "steps: 2390\n",
            "save_steps: 1250\n",
            "20220531 15:27:24 current learning_rate:0.00001000\n",
            "used_time: 0.2116374969482422\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2400, loss: 0.351222, acc: 0.625000\n",
            "steps: 2400\n",
            "save_steps: 1250\n",
            "20220531 15:27:26 current learning_rate:0.00001000\n",
            "used_time: 0.21784090995788574\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2410, loss: 0.019611, acc: 0.625000\n",
            "steps: 2410\n",
            "save_steps: 1250\n",
            "20220531 15:27:28 current learning_rate:0.00001000\n",
            "used_time: 0.2351222038269043\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2420, loss: 0.611892, acc: 0.625000\n",
            "steps: 2420\n",
            "save_steps: 1250\n",
            "20220531 15:27:30 current learning_rate:0.00001000\n",
            "used_time: 0.2169339656829834\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2430, loss: 0.002125, acc: 0.750000\n",
            "steps: 2430\n",
            "save_steps: 1250\n",
            "20220531 15:27:32 current learning_rate:0.00001000\n",
            "used_time: 0.2069408893585205\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2440, loss: 0.034062, acc: 0.625000\n",
            "steps: 2440\n",
            "save_steps: 1250\n",
            "20220531 15:27:35 current learning_rate:0.00001000\n",
            "used_time: 0.21335434913635254\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2450, loss: 0.227557, acc: 0.750000\n",
            "steps: 2450\n",
            "save_steps: 1250\n",
            "20220531 15:27:37 current learning_rate:0.00001000\n",
            "used_time: 0.24830102920532227\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2460, loss: 1.184020, acc: 0.750000\n",
            "steps: 2460\n",
            "save_steps: 1250\n",
            "20220531 15:27:39 current learning_rate:0.00001000\n",
            "used_time: 0.22904133796691895\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2470, loss: 0.004602, acc: 0.750000\n",
            "steps: 2470\n",
            "save_steps: 1250\n",
            "20220531 15:27:41 current learning_rate:0.00001000\n",
            "used_time: 0.2324230670928955\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2480, loss: 0.199942, acc: 0.875000\n",
            "steps: 2480\n",
            "save_steps: 1250\n",
            "20220531 15:27:43 current learning_rate:0.00001000\n",
            "used_time: 0.20552611351013184\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2490, loss: 0.002576, acc: 0.625000\n",
            "steps: 2490\n",
            "save_steps: 1250\n",
            "20220531 15:27:45 current learning_rate:0.00001000\n",
            "used_time: 0.2719244956970215\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2500, loss: 0.001956, acc: 0.625000\n",
            "steps: 2500\n",
            "save_steps: 1250\n",
            "Train-RCAC 0.9783333333333333\n",
            "20220531 15:27:48 current learning_rate:0.00001000\n",
            "save_path: output_hm/step_2500train\n",
            "used_time: 12.01874589920044\n",
            "############################WARNING################################### using init_pretraining_params, not init_checkpoint ###### meaning hyper param e.g. lr won't inherit from checkpoint#################################################################W0531 15:28:00.557768  2759 init.cc:216] Warning: PaddlePaddle catches a failure signal, it may not work properly\n",
            "W0531 15:28:00.557853  2759 init.cc:218] You could check whether you killed PaddlePaddle thread/process accidentally or report the case to PaddlePaddle\n",
            "W0531 15:28:00.557873  2759 init.cc:221] The detail failure signal is:\n",
            "\n",
            "W0531 15:28:00.557888  2759 init.cc:224] *** Aborted at 1654010880 (unix time) try \"date -d @1654010880\" if you are using GNU date ***\n",
            "W0531 15:28:00.560298  2759 init.cc:224] PC: @                0x0 (unknown)\n",
            "W0531 15:28:00.560631  2759 init.cc:224] *** SIGABRT (@0xa9b) received by PID 2715 (TID 0x7ff37f17f700) from PID 2715; stack trace: ***\n",
            "W0531 15:28:00.562539  2759 init.cc:224]     @     0x7ff526b30f10 (unknown)\n",
            "W0531 15:28:00.564208  2759 init.cc:224]     @     0x7ff526b30e87 gsignal\n",
            "W0531 15:28:00.565917  2759 init.cc:224]     @     0x7ff526b327f1 abort\n",
            "W0531 15:28:00.567751  2759 init.cc:224]     @     0x7ff5257cd10e (unknown)\n",
            "W0531 15:28:00.569279  2759 init.cc:224]     @     0x7ff5257cd356 __gxx_personality_v0\n",
            "W0531 15:28:00.571087  2759 init.cc:224]     @     0x7ff52530d668 (unknown)\n",
            "W0531 15:28:00.573071  2759 init.cc:224]     @     0x7ff52530dc5c _Unwind_ForcedUnwind\n",
            "W0531 15:28:00.574851  2759 init.cc:224]     @     0x7ff5268e4000 __GI___pthread_unwind\n",
            "W0531 15:28:00.576411  2759 init.cc:224]     @     0x7ff5268dbae5 __pthread_exit\n",
            "W0531 15:28:00.578140  2759 init.cc:224]     @     0x7ff526c22364 pthread_exit\n",
            "W0531 15:28:00.578317  2759 init.cc:224]     @           0x5e37d8 PyThread_exit_thread\n",
            "W0531 15:28:00.578491  2759 init.cc:224]     @           0x47028a (unknown)\n",
            "W0531 15:28:00.586272  2759 init.cc:224]     @     0x7ff4d38d6019 pybind11::gil_scoped_release::~gil_scoped_release()\n",
            "W0531 15:28:00.587653  2759 init.cc:224]     @     0x7ff4d39be3b6 _ZZN8pybind1112cpp_function10initializeIZN6paddle6pybind10BindReaderEPNS_6moduleEEUlRNS2_9operators6reader22LoDTensorBlockingQueueERKSt6vectorINS2_9framework9LoDTensorESaISC_EEE1_bIS9_SG_EINS_4nameENS_9is_methodENS_7siblingENS_10call_guardIINS_18gil_scoped_releaseEEEEEEEvOT_PFT0_DpT1_EDpRKT2_ENUlRNS_6detail13function_callEE1_4_FUNES11_\n",
            "W0531 15:28:00.590867  2759 init.cc:224]     @     0x7ff4d38f3829 pybind11::cpp_function::dispatcher()\n",
            "W0531 15:28:00.591058  2759 init.cc:224]     @           0x593784 _PyMethodDef_RawFastCallKeywords\n",
            "W0531 15:28:00.591187  2759 init.cc:224]     @           0x594731 _PyObject_FastCallKeywords\n",
            "W0531 15:28:00.591351  2759 init.cc:224]     @           0x548cc1 (unknown)\n",
            "W0531 15:28:00.591481  2759 init.cc:224]     @           0x51566f _PyEval_EvalFrameDefault\n",
            "W0531 15:28:00.591615  2759 init.cc:224]     @           0x549e0e _PyEval_EvalCodeWithName\n",
            "W0531 15:28:00.591727  2759 init.cc:224]     @           0x4bcb19 _PyFunction_FastCallDict\n",
            "W0531 15:28:00.591832  2759 init.cc:224]     @           0x5134a6 _PyEval_EvalFrameDefault\n",
            "W0531 15:28:00.592016  2759 init.cc:224]     @           0x593dd7 _PyFunction_FastCallKeywords\n",
            "W0531 15:28:00.592140  2759 init.cc:224]     @           0x511e2c _PyEval_EvalFrameDefault\n",
            "W0531 15:28:00.592260  2759 init.cc:224]     @           0x593dd7 _PyFunction_FastCallKeywords\n",
            "W0531 15:28:00.592347  2759 init.cc:224]     @           0x511e2c _PyEval_EvalFrameDefault\n",
            "W0531 15:28:00.592437  2759 init.cc:224]     @           0x4bc98a _PyFunction_FastCallDict\n",
            "W0531 15:28:00.592654  2759 init.cc:224]     @           0x59c019 (unknown)\n",
            "W0531 15:28:00.592875  2759 init.cc:224]     @           0x595ef6 PyObject_Call\n",
            "W0531 15:28:00.593048  2759 init.cc:224]     @           0x5d5393 (unknown)\n",
            "W0531 15:28:00.593216  2759 init.cc:224]     @           0x5e3137 (unknown)\n",
            "W0531 15:28:00.594898  2759 init.cc:224]     @     0x7ff5268da6db start_thread\n",
            "run_finetuning.sh: line 64:  2715 Aborted                 (core dumped) python /content/vilio/ernie-vil/finetune.py --use_cuda \"True\" --is_distributed \"False\" --use_fast_executor ${e_executor-\"True\"} --nccl_comm_num ${nccl_comm_num:-\"1\"} --batch_size $((BATCH_SIZE/gpu_cnt)) --do_train \"True\" --do_test \"False\" --task_name ${TASK_NAME} --vocab_path ${VOCAB_PATH} --task_group_json ${TASK_GROUP_JSON} --lr_scheduler ${lr_scheduler} --decay_steps ${decay_steps-\"\"} --lr_decay_ratio ${lr_decay_ratio-0.1} --num_train_steps ${num_train_steps} --checkpoints $output_model_path --save_steps ${SAVE_STEPS} --init_checkpoint ${PRETRAIN_MODELS} --ernie_config_path ${ERNIE_VIL_CONFIG} --learning_rate ${LR_RATE} --warmup_steps ${WARMUP_STEPS} --weight_decay ${WEIGHT_DECAY:-0} --max_seq_len ${MAX_LEN} --validation_steps ${VALID_STEPS} --skip_steps 10 --split ${SPLIT} --stop_steps ${STOP}\n",
            "-----------  Configuration Arguments -----------\n",
            "batch_size: 8\n",
            "checkpoints: checkpoints\n",
            "combine: False\n",
            "decay_steps: \n",
            "do_test: True\n",
            "do_train: False\n",
            "do_val: False\n",
            "epoch: 100\n",
            "ernie_config_path: /content/vilio/ernie-vil/data/erniesmallvcr/ernie_vil_config.base.json\n",
            "exp: ESVCR72\n",
            "feature_size: 2048\n",
            "fusion_method: sum\n",
            "hierarchical_allreduce_inter_nranks: 8\n",
            "init_checkpoint: /content/vilio/ernie-vil/output_hm/step_2500train\n",
            "is_distributed: False\n",
            "learning_rate: 0.0001\n",
            "lr_decay_dict_file: \n",
            "lr_decay_ratio: 0.1\n",
            "lr_scheduler: linear_warmup_decay\n",
            "max_img_len: 100\n",
            "max_seq_len: 128\n",
            "nccl_comm_num: 1\n",
            "num_features: 50\n",
            "num_train_steps: 1000000\n",
            "output_file: \n",
            "result_file: /content/vilio/ernie-vil/data/log\n",
            "save_steps: 100\n",
            "skip_steps: 10\n",
            "split: dev_seen\n",
            "stop_steps: 5000\n",
            "subtrain: False\n",
            "task_group_json: /content/vilio/ernie-vil/conf/hm/task_hm.json\n",
            "task_name: hm\n",
            "test_filelist: \n",
            "test_split: val\n",
            "train_filelist: \n",
            "use_cuda: True\n",
            "use_fast_executor: True\n",
            "use_fuse: False\n",
            "use_gpu: True\n",
            "use_hierarchical_allreduce: False\n",
            "valid_filelist: \n",
            "validation_steps: 6000\n",
            "verbose: False\n",
            "vocab_path: /content/vilio/ernie-vil/data/erniesmallvcr/vocab.txt\n",
            "warmup_steps: 0\n",
            "weight_decay: 0.01\n",
            "------------------------------------------------\n",
            "finetuning tasks start\n",
            "attention_probs_dropout_prob: 0.1\n",
            "class_attr_size: 401\n",
            "class_size: 1601\n",
            "co_hidden_size: 1024\n",
            "co_intermediate_size: 1024\n",
            "co_num_attention_heads: 8\n",
            "hidden_act: gelu\n",
            "hidden_dropout_prob: 0.1\n",
            "hidden_size: 768\n",
            "initializer_range: 0.02\n",
            "max_position_embeddings: 512\n",
            "num_attention_heads: 12\n",
            "num_hidden_layers: 12\n",
            "sent_type_vocab_size: 4\n",
            "t_biattention_id: [6, 7, 8, 9, 10, 11]\n",
            "task_type_vocab_size: 16\n",
            "type_vocab_size: 2\n",
            "v_biattention_id: [0, 1, 2, 3, 4, 5]\n",
            "v_hidden_size: 1024\n",
            "v_intermediate_size: 1024\n",
            "v_num_attention_heads: 8\n",
            "vocab_size: 30522\n",
            "------------------------------------------------\n",
            "task:  [{'task': 'HM', 'num_choice': 1, 'annotations_jsonpath_train': '/content/vilio/ernie-vil/data/hm/train.jsonl', 'annotations_jsonpath_dev_seen': '/content/vilio/ernie-vil/data/hm/dev_seenlong.jsonl', 'annotations_jsonpath_traindev': '/content/vilio/ernie-vil/data/hm/traindev.jsonl', 'annotations_jsonpath_test_unseen': '/content/vilio/ernie-vil/data/hm/test_unseenlong.jsonl', 'annotations_jsonpath_test_seen': '/content/vilio/ernie-vil/data/hm/test_seenlong.jsonl', 'feature_lmdb_path': '/content/vilio/ernie-vil/data/hm/HM_img.tsv', 'gt_feature_lmdb_path': '/content/vilio/ernie-vil/data/hm/HM_gt_img.tsv', 'unisex_names_table': '/content/vilio/ernie-vil/data/vcr/unisex_names_table.csv', 'Proprocessor': 'PreprocessorBasic', 'tokenizer_name': 'FullTokenizer', 'fusion_method': 'mul', 'dropout_rate': 0.1, 'max_seq_len': 128, 'use_gt_fea': True, 'shufflekeep_across_task': True, 'shuffle_every_epoch': True, 'task_weight': 1.0, 'task_prefix': 'hm'}]\n",
            "2022-05-31 15:28:04,996-WARNING: paddle.fluid.layers.py_reader() may be deprecated in the near future. Please use paddle.fluid.io.DataLoader.from_generator() instead.\n",
            "theoretical memory usage: \n",
            "(3678.2632896423343, 3853.418684387207, 'MB')\n",
            "args.is_distributed: False\n",
            "W0531 15:28:06.100405  2791 device_context.cc:252] Please NOTE: device: 0, CUDA Capability: 60, Driver API Version: 11.2, Runtime API Version: 9.0\n",
            "W0531 15:28:06.113504  2791 device_context.cc:260] device: 0, cuDNN Version: 7.6.\n",
            "SPLIT: dev_seen\n",
            "Start to load Faster-RCNN detected objects from /content/vilio/ernie-vil/data/hm/HM_img.tsv\n",
            "Loaded 500 images in file /content/vilio/ernie-vil/data/hm/HM_img.tsv in 171 seconds.\n",
            "Start to load Faster-RCNN detected objects from /content/vilio/ernie-vil/data/hm/HM_gt_img.tsv\n",
            "Loaded 500 images in file /content/vilio/ernie-vil/data/hm/HM_gt_img.tsv in 55 seconds.\n",
            "Load 650 data from split(s) /content/vilio/ernie-vil/data/hm/dev_seenlong.jsonl.\n",
            "use gt featurre\n",
            "LEN:  650\n",
            "Load pretraining parameters from /content/vilio/ernie-vil/output_hm/step_2500train.\n",
            "testing on hm val split\n",
            "task name list :  ['mean_0.tmp_0', 'accuracy_0.tmp_0', 'arg_max_0.tmp_0', 'read_file_0.tmp_9', 'read_file_0.tmp_8', 'reshape2_120.tmp_0']\n",
            "cur_step: 10 cur_acc: 0.1125\n",
            "cur_step: 20 cur_acc: 0.31875\n",
            "cur_step: 30 cur_acc: 0.35833333333333334\n",
            "cur_step: 40 cur_acc: 0.43125\n",
            "cur_step: 50 cur_acc: 0.4675\n",
            "cur_step: 60 cur_acc: 0.49583333333333335\n",
            "cur_step: 70 cur_acc: 0.45714285714285713\n",
            "cur_step: 80 cur_acc: 0.4609375\n",
            "EXCEPTING\n",
            "LEN: 500 500\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 500 entries, 0 to 499\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   id      500 non-null    int64  \n",
            " 1   proba   500 non-null    float32\n",
            " 2   label   500 non-null    int64  \n",
            "dtypes: float32(1), int64(2)\n",
            "memory usage: 9.9 KB\n",
            "None\n",
            "average_acc: 0.4609375\n",
            "rocauc: 0.7660132645541635\n",
            "+ TASK_NAME=hm\n",
            "+ CONF_FILE=conf/hm/model_conf_hm\n",
            "+ VOCAB_PATH=/content/vilio/ernie-vil/data/erniesmallvcr/vocab.txt\n",
            "+ ERNIE_VIL_CONFIG=/content/vilio/ernie-vil/data/erniesmallvcr/ernie_vil_config.base.json\n",
            "+ PRETRAIN_MODELS=/content/vilio/ernie-vil/data/erniesmallvcr/params\n",
            "+ SPLIT=traindev\n",
            "+ STOP=2500\n",
            "+ source conf/hm/model_conf_hm\n",
            "++ output_model_path=output_hm\n",
            "++ lr_scheduler=manual_warmup_decay\n",
            "++ decay_steps='13308;19962'\n",
            "++ lr_decay_ratio=0.1\n",
            "++ num_train_steps=5000\n",
            "++ SAVE_STEPS=1250\n",
            "++ WARMUP_STEPS=500\n",
            "++ BATCH_SIZE=8\n",
            "++ VALID_STEPS=20000\n",
            "++ LR_RATE=1e-5\n",
            "++ WEIGHT_DECAY=0.01\n",
            "++ MAX_LEN=128\n",
            "+ CUDA_VISIBLE_DEVICES=1\n",
            "+ export FLAGS_fast_eager_deletion_mode=1\n",
            "+ FLAGS_fast_eager_deletion_mode=1\n",
            "+ export FLAGS_eager_delete_tensor_gb=0.0\n",
            "+ FLAGS_eager_delete_tensor_gb=0.0\n",
            "+ export FLAGS_fraction_of_gpu_memory_to_use=0.98\n",
            "+ FLAGS_fraction_of_gpu_memory_to_use=0.98\n",
            "++ echo True\n",
            "++ tr '[A-Z]' '[a-z]'\n",
            "+ e_executor=true\n",
            "++ echo False\n",
            "++ tr '[A-Z]' '[a-z]'\n",
            "+ use_fuse=false\n",
            "+ [[ false == \\t\\r\\u\\e ]]\n",
            "+ TASK_GROUP_JSON=/content/vilio/ernie-vil/conf/hm/task_hm.json\n",
            "++ echo 1\n",
            "++ awk '-F\\t' '{len=split($0,vec,\",\");print len}'\n",
            "+ gpu_cnt=1\n",
            "+ echo gpu_cnt, 1\n",
            "gpu_cnt, 1\n",
            "+ python /content/vilio/ernie-vil/finetune.py --use_cuda True --is_distributed False --use_fast_executor true --nccl_comm_num 1 --batch_size 8 --do_train True --do_test False --task_name hm --vocab_path /content/vilio/ernie-vil/data/erniesmallvcr/vocab.txt --task_group_json /content/vilio/ernie-vil/conf/hm/task_hm.json --lr_scheduler manual_warmup_decay --decay_steps '13308;19962' --lr_decay_ratio 0.1 --num_train_steps 5000 --checkpoints output_hm --save_steps 1250 --init_checkpoint /content/vilio/ernie-vil/data/erniesmallvcr/params --ernie_config_path /content/vilio/ernie-vil/data/erniesmallvcr/ernie_vil_config.base.json --learning_rate 1e-5 --warmup_steps 500 --weight_decay 0.01 --max_seq_len 128 --validation_steps 20000 --skip_steps 10 --split traindev --stop_steps 2500\n",
            "-----------  Configuration Arguments -----------\n",
            "batch_size: 8\n",
            "checkpoints: output_hm\n",
            "combine: False\n",
            "decay_steps: 13308;19962\n",
            "do_test: False\n",
            "do_train: True\n",
            "do_val: False\n",
            "epoch: 100\n",
            "ernie_config_path: /content/vilio/ernie-vil/data/erniesmallvcr/ernie_vil_config.base.json\n",
            "exp: experiment\n",
            "feature_size: 2048\n",
            "fusion_method: sum\n",
            "hierarchical_allreduce_inter_nranks: 8\n",
            "init_checkpoint: /content/vilio/ernie-vil/data/erniesmallvcr/params\n",
            "is_distributed: False\n",
            "learning_rate: 1e-05\n",
            "lr_decay_dict_file: \n",
            "lr_decay_ratio: 0.1\n",
            "lr_scheduler: manual_warmup_decay\n",
            "max_img_len: 100\n",
            "max_seq_len: 128\n",
            "nccl_comm_num: 1\n",
            "num_features: 50\n",
            "num_train_steps: 5000\n",
            "output_file: \n",
            "result_file: ./res_tmp\n",
            "save_steps: 1250\n",
            "skip_steps: 10\n",
            "split: traindev\n",
            "stop_steps: 2500\n",
            "subtrain: False\n",
            "task_group_json: /content/vilio/ernie-vil/conf/hm/task_hm.json\n",
            "task_name: hm\n",
            "test_filelist: \n",
            "test_split: test\n",
            "train_filelist: \n",
            "use_cuda: True\n",
            "use_fast_executor: True\n",
            "use_fuse: False\n",
            "use_gpu: True\n",
            "use_hierarchical_allreduce: False\n",
            "valid_filelist: \n",
            "validation_steps: 20000\n",
            "verbose: False\n",
            "vocab_path: /content/vilio/ernie-vil/data/erniesmallvcr/vocab.txt\n",
            "warmup_steps: 500\n",
            "weight_decay: 0.01\n",
            "------------------------------------------------\n",
            "finetuning tasks start\n",
            "attention_probs_dropout_prob: 0.1\n",
            "class_attr_size: 401\n",
            "class_size: 1601\n",
            "co_hidden_size: 1024\n",
            "co_intermediate_size: 1024\n",
            "co_num_attention_heads: 8\n",
            "hidden_act: gelu\n",
            "hidden_dropout_prob: 0.1\n",
            "hidden_size: 768\n",
            "initializer_range: 0.02\n",
            "max_position_embeddings: 512\n",
            "num_attention_heads: 12\n",
            "num_hidden_layers: 12\n",
            "sent_type_vocab_size: 4\n",
            "t_biattention_id: [6, 7, 8, 9, 10, 11]\n",
            "task_type_vocab_size: 16\n",
            "type_vocab_size: 2\n",
            "v_biattention_id: [0, 1, 2, 3, 4, 5]\n",
            "v_hidden_size: 1024\n",
            "v_intermediate_size: 1024\n",
            "v_num_attention_heads: 8\n",
            "vocab_size: 30522\n",
            "------------------------------------------------\n",
            "task:  [{'task': 'HM', 'num_choice': 1, 'annotations_jsonpath_train': '/content/vilio/ernie-vil/data/hm/train.jsonl', 'annotations_jsonpath_dev_seen': '/content/vilio/ernie-vil/data/hm/dev_seenlong.jsonl', 'annotations_jsonpath_traindev': '/content/vilio/ernie-vil/data/hm/traindev.jsonl', 'annotations_jsonpath_test_unseen': '/content/vilio/ernie-vil/data/hm/test_unseenlong.jsonl', 'annotations_jsonpath_test_seen': '/content/vilio/ernie-vil/data/hm/test_seenlong.jsonl', 'feature_lmdb_path': '/content/vilio/ernie-vil/data/hm/HM_img.tsv', 'gt_feature_lmdb_path': '/content/vilio/ernie-vil/data/hm/HM_gt_img.tsv', 'unisex_names_table': '/content/vilio/ernie-vil/data/vcr/unisex_names_table.csv', 'Proprocessor': 'PreprocessorBasic', 'tokenizer_name': 'FullTokenizer', 'fusion_method': 'mul', 'dropout_rate': 0.1, 'max_seq_len': 128, 'use_gt_fea': True, 'shufflekeep_across_task': True, 'shuffle_every_epoch': True, 'task_weight': 1.0, 'task_prefix': 'hm'}]\n",
            "2022-05-31 15:32:17,975-WARNING: paddle.fluid.layers.py_reader() may be deprecated in the near future. Please use paddle.fluid.io.DataLoader.from_generator() instead.\n",
            "/usr/local/lib/python3.7/dist-packages/paddle/fluid/clip.py:779: UserWarning: Caution! 'set_gradient_clip' is not recommended and may be deprecated in future! We recommend a new strategy: set 'grad_clip' when initializing the 'optimizer'. This method can reduce the mistakes, please refer to documention of 'optimizer'.\n",
            "  warnings.warn(\"Caution! 'set_gradient_clip' is not recommended \"\n",
            "theoretical memory usage: \n",
            "(18209.21138906479, 19076.31669330597, 'MB')\n",
            "args.is_distributed: False\n",
            "W0531 15:32:23.511617  2844 device_context.cc:252] Please NOTE: device: 0, CUDA Capability: 60, Driver API Version: 11.2, Runtime API Version: 9.0\n",
            "W0531 15:32:23.526623  2844 device_context.cc:260] device: 0, cuDNN Version: 7.6.\n",
            "Load pretraining parameters from /content/vilio/ernie-vil/data/erniesmallvcr/params.\n",
            "SPLIT: traindev\n",
            "Start to load Faster-RCNN detected objects from /content/vilio/ernie-vil/data/hm/HM_img.tsv\n",
            "Loaded 9098 images in file /content/vilio/ernie-vil/data/hm/HM_img.tsv in 193 seconds.\n",
            "Start to load Faster-RCNN detected objects from /content/vilio/ernie-vil/data/hm/HM_gt_img.tsv\n",
            "Loaded 9098 images in file /content/vilio/ernie-vil/data/hm/HM_gt_img.tsv in 63 seconds.\n",
            "Load 9598 data from split(s) /content/vilio/ernie-vil/data/hm/traindev.jsonl.\n",
            "use gt featurre\n",
            "LEN:  9598\n",
            "shuffle epoch 0\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 10, loss: 0.712804, acc: 0.500000\n",
            "steps: 10\n",
            "save_steps: 1250\n",
            "20220531 15:36:56 current learning_rate:0.00000018\n",
            "used_time: 0.24788570404052734\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 20, loss: 0.692635, acc: 0.625000\n",
            "steps: 20\n",
            "save_steps: 1250\n",
            "20220531 15:36:58 current learning_rate:0.00000038\n",
            "used_time: 0.2318878173828125\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 30, loss: 0.694141, acc: 0.625000\n",
            "steps: 30\n",
            "save_steps: 1250\n",
            "20220531 15:37:00 current learning_rate:0.00000058\n",
            "used_time: 0.2468864917755127\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 40, loss: 0.673253, acc: 0.500000\n",
            "steps: 40\n",
            "save_steps: 1250\n",
            "20220531 15:37:03 current learning_rate:0.00000078\n",
            "used_time: 0.2715475559234619\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 50, loss: 0.695490, acc: 0.750000\n",
            "steps: 50\n",
            "save_steps: 1250\n",
            "20220531 15:37:05 current learning_rate:0.00000098\n",
            "used_time: 0.2511756420135498\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 60, loss: 0.710473, acc: 0.250000\n",
            "steps: 60\n",
            "save_steps: 1250\n",
            "20220531 15:37:07 current learning_rate:0.00000118\n",
            "used_time: 0.21439194679260254\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 70, loss: 0.736189, acc: 0.500000\n",
            "steps: 70\n",
            "save_steps: 1250\n",
            "20220531 15:37:09 current learning_rate:0.00000138\n",
            "used_time: 0.20524072647094727\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 80, loss: 0.642257, acc: 0.875000\n",
            "steps: 80\n",
            "save_steps: 1250\n",
            "20220531 15:37:11 current learning_rate:0.00000158\n",
            "used_time: 0.20775079727172852\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 90, loss: 0.621938, acc: 0.750000\n",
            "steps: 90\n",
            "save_steps: 1250\n",
            "20220531 15:37:13 current learning_rate:0.00000178\n",
            "used_time: 0.2345414161682129\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 100, loss: 0.732719, acc: 0.500000\n",
            "steps: 100\n",
            "save_steps: 1250\n",
            "20220531 15:37:16 current learning_rate:0.00000198\n",
            "used_time: 0.20952558517456055\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 110, loss: 0.777938, acc: 0.125000\n",
            "steps: 110\n",
            "save_steps: 1250\n",
            "20220531 15:37:18 current learning_rate:0.00000218\n",
            "used_time: 0.2256159782409668\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 120, loss: 0.669712, acc: 0.625000\n",
            "steps: 120\n",
            "save_steps: 1250\n",
            "20220531 15:37:20 current learning_rate:0.00000238\n",
            "used_time: 0.20727014541625977\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 130, loss: 0.631315, acc: 0.750000\n",
            "steps: 130\n",
            "save_steps: 1250\n",
            "20220531 15:37:22 current learning_rate:0.00000258\n",
            "used_time: 0.23685097694396973\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 140, loss: 0.711495, acc: 0.500000\n",
            "steps: 140\n",
            "save_steps: 1250\n",
            "20220531 15:37:25 current learning_rate:0.00000278\n",
            "used_time: 0.20843791961669922\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 150, loss: 0.769370, acc: 0.375000\n",
            "steps: 150\n",
            "save_steps: 1250\n",
            "20220531 15:37:27 current learning_rate:0.00000298\n",
            "used_time: 0.20434117317199707\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 160, loss: 0.708479, acc: 0.500000\n",
            "steps: 160\n",
            "save_steps: 1250\n",
            "20220531 15:37:29 current learning_rate:0.00000318\n",
            "used_time: 0.21947193145751953\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 170, loss: 0.711884, acc: 0.500000\n",
            "steps: 170\n",
            "save_steps: 1250\n",
            "20220531 15:37:31 current learning_rate:0.00000338\n",
            "used_time: 0.2393038272857666\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 180, loss: 0.483652, acc: 1.000000\n",
            "steps: 180\n",
            "save_steps: 1250\n",
            "20220531 15:37:33 current learning_rate:0.00000358\n",
            "used_time: 0.21761441230773926\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 190, loss: 0.624999, acc: 0.625000\n",
            "steps: 190\n",
            "save_steps: 1250\n",
            "20220531 15:37:35 current learning_rate:0.00000378\n",
            "used_time: 0.20687127113342285\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 200, loss: 0.583263, acc: 0.875000\n",
            "steps: 200\n",
            "save_steps: 1250\n",
            "20220531 15:37:38 current learning_rate:0.00000398\n",
            "used_time: 0.23314452171325684\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 210, loss: 0.620169, acc: 0.750000\n",
            "steps: 210\n",
            "save_steps: 1250\n",
            "20220531 15:37:40 current learning_rate:0.00000418\n",
            "used_time: 0.2638282775878906\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 220, loss: 0.602033, acc: 0.750000\n",
            "steps: 220\n",
            "save_steps: 1250\n",
            "20220531 15:37:42 current learning_rate:0.00000438\n",
            "used_time: 0.20894670486450195\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 230, loss: 0.673011, acc: 0.625000\n",
            "steps: 230\n",
            "save_steps: 1250\n",
            "20220531 15:37:44 current learning_rate:0.00000458\n",
            "used_time: 0.2190871238708496\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 240, loss: 0.615215, acc: 0.750000\n",
            "steps: 240\n",
            "save_steps: 1250\n",
            "20220531 15:37:46 current learning_rate:0.00000478\n",
            "used_time: 0.22335290908813477\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 250, loss: 0.530812, acc: 0.875000\n",
            "steps: 250\n",
            "save_steps: 1250\n",
            "20220531 15:37:49 current learning_rate:0.00000498\n",
            "used_time: 0.25450658798217773\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 260, loss: 0.574353, acc: 0.750000\n",
            "steps: 260\n",
            "save_steps: 1250\n",
            "20220531 15:37:51 current learning_rate:0.00000518\n",
            "used_time: 0.2037973403930664\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 270, loss: 0.489535, acc: 0.750000\n",
            "steps: 270\n",
            "save_steps: 1250\n",
            "20220531 15:37:53 current learning_rate:0.00000538\n",
            "used_time: 0.20881915092468262\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 280, loss: 0.628688, acc: 0.625000\n",
            "steps: 280\n",
            "save_steps: 1250\n",
            "20220531 15:37:55 current learning_rate:0.00000558\n",
            "used_time: 0.2222118377685547\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 290, loss: 0.676362, acc: 0.625000\n",
            "steps: 290\n",
            "save_steps: 1250\n",
            "20220531 15:37:57 current learning_rate:0.00000578\n",
            "used_time: 0.2485666275024414\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 300, loss: 0.620583, acc: 0.625000\n",
            "steps: 300\n",
            "save_steps: 1250\n",
            "20220531 15:37:59 current learning_rate:0.00000598\n",
            "used_time: 0.20847749710083008\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 310, loss: 0.590166, acc: 0.625000\n",
            "steps: 310\n",
            "save_steps: 1250\n",
            "20220531 15:38:02 current learning_rate:0.00000618\n",
            "used_time: 0.20088768005371094\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 320, loss: 0.835506, acc: 0.250000\n",
            "steps: 320\n",
            "save_steps: 1250\n",
            "20220531 15:38:04 current learning_rate:0.00000638\n",
            "used_time: 0.22258949279785156\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 330, loss: 0.467182, acc: 0.750000\n",
            "steps: 330\n",
            "save_steps: 1250\n",
            "20220531 15:38:06 current learning_rate:0.00000658\n",
            "used_time: 0.24150466918945312\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 340, loss: 0.645822, acc: 0.625000\n",
            "steps: 340\n",
            "save_steps: 1250\n",
            "20220531 15:38:08 current learning_rate:0.00000678\n",
            "used_time: 0.2223803997039795\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 350, loss: 0.394908, acc: 0.625000\n",
            "steps: 350\n",
            "save_steps: 1250\n",
            "20220531 15:38:10 current learning_rate:0.00000698\n",
            "used_time: 0.20573115348815918\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 360, loss: 0.542462, acc: 0.500000\n",
            "steps: 360\n",
            "save_steps: 1250\n",
            "20220531 15:38:13 current learning_rate:0.00000718\n",
            "used_time: 0.2084965705871582\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 370, loss: 0.434052, acc: 0.750000\n",
            "steps: 370\n",
            "save_steps: 1250\n",
            "20220531 15:38:15 current learning_rate:0.00000738\n",
            "used_time: 0.24597454071044922\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 380, loss: 0.777117, acc: 0.500000\n",
            "steps: 380\n",
            "save_steps: 1250\n",
            "20220531 15:38:17 current learning_rate:0.00000758\n",
            "used_time: 0.20705437660217285\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 390, loss: 0.577809, acc: 0.375000\n",
            "steps: 390\n",
            "save_steps: 1250\n",
            "20220531 15:38:19 current learning_rate:0.00000778\n",
            "used_time: 0.2204911708831787\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 400, loss: 0.351170, acc: 0.625000\n",
            "steps: 400\n",
            "save_steps: 1250\n",
            "20220531 15:38:21 current learning_rate:0.00000798\n",
            "used_time: 0.22140288352966309\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 410, loss: 0.617777, acc: 0.875000\n",
            "steps: 410\n",
            "save_steps: 1250\n",
            "20220531 15:38:24 current learning_rate:0.00000818\n",
            "used_time: 0.26439523696899414\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 420, loss: 0.662443, acc: 0.500000\n",
            "steps: 420\n",
            "save_steps: 1250\n",
            "20220531 15:38:26 current learning_rate:0.00000838\n",
            "used_time: 0.23481178283691406\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 430, loss: 0.747133, acc: 0.625000\n",
            "steps: 430\n",
            "save_steps: 1250\n",
            "20220531 15:38:28 current learning_rate:0.00000858\n",
            "used_time: 0.21605515480041504\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 440, loss: 0.786505, acc: 0.625000\n",
            "steps: 440\n",
            "save_steps: 1250\n",
            "20220531 15:38:30 current learning_rate:0.00000878\n",
            "used_time: 0.22209692001342773\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 450, loss: 0.397768, acc: 0.875000\n",
            "steps: 450\n",
            "save_steps: 1250\n",
            "20220531 15:38:32 current learning_rate:0.00000898\n",
            "used_time: 0.24766278266906738\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 460, loss: 1.081681, acc: 0.250000\n",
            "steps: 460\n",
            "save_steps: 1250\n",
            "20220531 15:38:35 current learning_rate:0.00000918\n",
            "used_time: 0.27564144134521484\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 470, loss: 0.868614, acc: 0.125000\n",
            "steps: 470\n",
            "save_steps: 1250\n",
            "20220531 15:38:37 current learning_rate:0.00000938\n",
            "used_time: 0.24578118324279785\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 480, loss: 0.591623, acc: 0.625000\n",
            "steps: 480\n",
            "save_steps: 1250\n",
            "20220531 15:38:40 current learning_rate:0.00000958\n",
            "used_time: 0.22664904594421387\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 490, loss: 0.769851, acc: 0.625000\n",
            "steps: 490\n",
            "save_steps: 1250\n",
            "20220531 15:38:42 current learning_rate:0.00000978\n",
            "used_time: 0.24077200889587402\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 500, loss: 0.462094, acc: 1.000000\n",
            "steps: 500\n",
            "save_steps: 1250\n",
            "Train-RCAC 0.6239737274220033\n",
            "20220531 15:38:44 current learning_rate:0.00000998\n",
            "used_time: 0.2106153964996338\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 510, loss: 0.480331, acc: 0.750000\n",
            "steps: 510\n",
            "save_steps: 1250\n",
            "20220531 15:38:46 current learning_rate:0.00001000\n",
            "used_time: 0.22157669067382812\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 520, loss: 0.347291, acc: 0.625000\n",
            "steps: 520\n",
            "save_steps: 1250\n",
            "20220531 15:38:49 current learning_rate:0.00001000\n",
            "used_time: 0.1904306411743164\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 530, loss: 0.337456, acc: 0.500000\n",
            "steps: 530\n",
            "save_steps: 1250\n",
            "20220531 15:38:51 current learning_rate:0.00001000\n",
            "used_time: 0.2647888660430908\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 540, loss: 0.617074, acc: 0.625000\n",
            "steps: 540\n",
            "save_steps: 1250\n",
            "20220531 15:38:53 current learning_rate:0.00001000\n",
            "used_time: 0.21765518188476562\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 550, loss: 0.326176, acc: 0.875000\n",
            "steps: 550\n",
            "save_steps: 1250\n",
            "20220531 15:38:55 current learning_rate:0.00001000\n",
            "used_time: 0.20843863487243652\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 560, loss: 0.525393, acc: 0.625000\n",
            "steps: 560\n",
            "save_steps: 1250\n",
            "20220531 15:38:58 current learning_rate:0.00001000\n",
            "used_time: 0.208967924118042\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 570, loss: 0.244131, acc: 0.875000\n",
            "steps: 570\n",
            "save_steps: 1250\n",
            "20220531 15:39:00 current learning_rate:0.00001000\n",
            "used_time: 0.2374427318572998\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 580, loss: 0.856908, acc: 0.500000\n",
            "steps: 580\n",
            "save_steps: 1250\n",
            "20220531 15:39:02 current learning_rate:0.00001000\n",
            "used_time: 0.23985028266906738\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 590, loss: 1.005512, acc: 0.625000\n",
            "steps: 590\n",
            "save_steps: 1250\n",
            "20220531 15:39:04 current learning_rate:0.00001000\n",
            "used_time: 0.20337247848510742\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 600, loss: 0.739357, acc: 0.750000\n",
            "steps: 600\n",
            "save_steps: 1250\n",
            "20220531 15:39:06 current learning_rate:0.00001000\n",
            "used_time: 0.19946050643920898\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 610, loss: 0.471004, acc: 0.875000\n",
            "steps: 610\n",
            "save_steps: 1250\n",
            "20220531 15:39:09 current learning_rate:0.00001000\n",
            "used_time: 0.2505009174346924\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 620, loss: 0.330913, acc: 0.750000\n",
            "steps: 620\n",
            "save_steps: 1250\n",
            "20220531 15:39:11 current learning_rate:0.00001000\n",
            "used_time: 0.22410106658935547\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 630, loss: 0.400335, acc: 0.750000\n",
            "steps: 630\n",
            "save_steps: 1250\n",
            "20220531 15:39:13 current learning_rate:0.00001000\n",
            "used_time: 0.20269107818603516\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 640, loss: 0.400591, acc: 0.875000\n",
            "steps: 640\n",
            "save_steps: 1250\n",
            "20220531 15:39:15 current learning_rate:0.00001000\n",
            "used_time: 0.25891566276550293\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 650, loss: 0.434490, acc: 0.625000\n",
            "steps: 650\n",
            "save_steps: 1250\n",
            "20220531 15:39:17 current learning_rate:0.00001000\n",
            "used_time: 0.22333312034606934\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 660, loss: 0.587339, acc: 0.625000\n",
            "steps: 660\n",
            "save_steps: 1250\n",
            "20220531 15:39:19 current learning_rate:0.00001000\n",
            "used_time: 0.22062897682189941\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 670, loss: 0.346849, acc: 0.750000\n",
            "steps: 670\n",
            "save_steps: 1250\n",
            "20220531 15:39:22 current learning_rate:0.00001000\n",
            "used_time: 0.2208573818206787\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 680, loss: 0.486227, acc: 0.625000\n",
            "steps: 680\n",
            "save_steps: 1250\n",
            "20220531 15:39:24 current learning_rate:0.00001000\n",
            "used_time: 0.20582270622253418\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 690, loss: 0.496198, acc: 0.750000\n",
            "steps: 690\n",
            "save_steps: 1250\n",
            "20220531 15:39:26 current learning_rate:0.00001000\n",
            "used_time: 0.24879169464111328\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 700, loss: 0.985808, acc: 0.625000\n",
            "steps: 700\n",
            "save_steps: 1250\n",
            "20220531 15:39:28 current learning_rate:0.00001000\n",
            "used_time: 0.20028281211853027\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 710, loss: 0.627376, acc: 0.625000\n",
            "steps: 710\n",
            "save_steps: 1250\n",
            "20220531 15:39:30 current learning_rate:0.00001000\n",
            "used_time: 0.2060539722442627\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 720, loss: 0.473643, acc: 0.625000\n",
            "steps: 720\n",
            "save_steps: 1250\n",
            "20220531 15:39:33 current learning_rate:0.00001000\n",
            "used_time: 0.207489013671875\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 730, loss: 0.416395, acc: 0.375000\n",
            "steps: 730\n",
            "save_steps: 1250\n",
            "20220531 15:39:35 current learning_rate:0.00001000\n",
            "used_time: 0.27191948890686035\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 740, loss: 0.213866, acc: 0.625000\n",
            "steps: 740\n",
            "save_steps: 1250\n",
            "20220531 15:39:37 current learning_rate:0.00001000\n",
            "used_time: 0.2044532299041748\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 750, loss: 0.133485, acc: 0.875000\n",
            "steps: 750\n",
            "save_steps: 1250\n",
            "20220531 15:39:39 current learning_rate:0.00001000\n",
            "used_time: 0.22301292419433594\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 760, loss: 0.359318, acc: 0.750000\n",
            "steps: 760\n",
            "save_steps: 1250\n",
            "20220531 15:39:42 current learning_rate:0.00001000\n",
            "used_time: 0.22825050354003906\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 770, loss: 0.512863, acc: 0.500000\n",
            "steps: 770\n",
            "save_steps: 1250\n",
            "20220531 15:39:44 current learning_rate:0.00001000\n",
            "used_time: 0.24802446365356445\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 780, loss: 0.789998, acc: 0.500000\n",
            "steps: 780\n",
            "save_steps: 1250\n",
            "20220531 15:39:46 current learning_rate:0.00001000\n",
            "used_time: 0.21546506881713867\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 790, loss: 0.396529, acc: 0.750000\n",
            "steps: 790\n",
            "save_steps: 1250\n",
            "20220531 15:39:48 current learning_rate:0.00001000\n",
            "used_time: 0.19621729850769043\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 800, loss: 0.341851, acc: 0.750000\n",
            "steps: 800\n",
            "save_steps: 1250\n",
            "20220531 15:39:50 current learning_rate:0.00001000\n",
            "used_time: 0.20473361015319824\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 810, loss: 0.165735, acc: 0.875000\n",
            "steps: 810\n",
            "save_steps: 1250\n",
            "20220531 15:39:53 current learning_rate:0.00001000\n",
            "used_time: 0.22973346710205078\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 820, loss: 1.187591, acc: 0.500000\n",
            "steps: 820\n",
            "save_steps: 1250\n",
            "20220531 15:39:55 current learning_rate:0.00001000\n",
            "used_time: 0.20776605606079102\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 830, loss: 0.335089, acc: 0.875000\n",
            "steps: 830\n",
            "save_steps: 1250\n",
            "20220531 15:39:57 current learning_rate:0.00001000\n",
            "used_time: 0.2031404972076416\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 840, loss: 0.690696, acc: 0.750000\n",
            "steps: 840\n",
            "save_steps: 1250\n",
            "20220531 15:39:59 current learning_rate:0.00001000\n",
            "used_time: 0.2041301727294922\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 850, loss: 0.392719, acc: 0.875000\n",
            "steps: 850\n",
            "save_steps: 1250\n",
            "20220531 15:40:01 current learning_rate:0.00001000\n",
            "used_time: 0.23224282264709473\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 860, loss: 0.408716, acc: 0.875000\n",
            "steps: 860\n",
            "save_steps: 1250\n",
            "20220531 15:40:04 current learning_rate:0.00001000\n",
            "used_time: 0.21515440940856934\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 870, loss: 0.299859, acc: 0.625000\n",
            "steps: 870\n",
            "save_steps: 1250\n",
            "20220531 15:40:06 current learning_rate:0.00001000\n",
            "used_time: 0.24771666526794434\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 880, loss: 0.865119, acc: 0.500000\n",
            "steps: 880\n",
            "save_steps: 1250\n",
            "20220531 15:40:08 current learning_rate:0.00001000\n",
            "used_time: 0.22832655906677246\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 890, loss: 0.443097, acc: 0.625000\n",
            "steps: 890\n",
            "save_steps: 1250\n",
            "20220531 15:40:10 current learning_rate:0.00001000\n",
            "used_time: 0.22350120544433594\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 900, loss: 0.745927, acc: 0.750000\n",
            "steps: 900\n",
            "save_steps: 1250\n",
            "20220531 15:40:12 current learning_rate:0.00001000\n",
            "used_time: 0.19851064682006836\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 910, loss: 0.496687, acc: 0.125000\n",
            "steps: 910\n",
            "save_steps: 1250\n",
            "20220531 15:40:15 current learning_rate:0.00001000\n",
            "used_time: 0.22250723838806152\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 920, loss: 0.726401, acc: 0.750000\n",
            "steps: 920\n",
            "save_steps: 1250\n",
            "20220531 15:40:17 current learning_rate:0.00001000\n",
            "used_time: 0.20866179466247559\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 930, loss: 0.418642, acc: 0.750000\n",
            "steps: 930\n",
            "save_steps: 1250\n",
            "20220531 15:40:19 current learning_rate:0.00001000\n",
            "used_time: 0.25904393196105957\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 940, loss: 0.510398, acc: 0.500000\n",
            "steps: 940\n",
            "save_steps: 1250\n",
            "20220531 15:40:21 current learning_rate:0.00001000\n",
            "used_time: 0.25565099716186523\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 950, loss: 0.474684, acc: 0.625000\n",
            "steps: 950\n",
            "save_steps: 1250\n",
            "20220531 15:40:24 current learning_rate:0.00001000\n",
            "used_time: 0.21851110458374023\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 960, loss: 0.691842, acc: 0.625000\n",
            "steps: 960\n",
            "save_steps: 1250\n",
            "20220531 15:40:26 current learning_rate:0.00001000\n",
            "used_time: 0.20851635932922363\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 970, loss: 0.214100, acc: 0.625000\n",
            "steps: 970\n",
            "save_steps: 1250\n",
            "20220531 15:40:28 current learning_rate:0.00001000\n",
            "used_time: 0.2617945671081543\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 980, loss: 0.833002, acc: 0.250000\n",
            "steps: 980\n",
            "save_steps: 1250\n",
            "20220531 15:40:30 current learning_rate:0.00001000\n",
            "used_time: 0.2254009246826172\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 990, loss: 0.352389, acc: 0.500000\n",
            "steps: 990\n",
            "save_steps: 1250\n",
            "20220531 15:40:33 current learning_rate:0.00001000\n",
            "used_time: 0.2070789337158203\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1000, loss: 0.714521, acc: 0.750000\n",
            "steps: 1000\n",
            "save_steps: 1250\n",
            "Train-RCAC 0.7224264705882353\n",
            "20220531 15:40:35 current learning_rate:0.00001000\n",
            "used_time: 0.252246618270874\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1010, loss: 0.624343, acc: 0.875000\n",
            "steps: 1010\n",
            "save_steps: 1250\n",
            "20220531 15:40:37 current learning_rate:0.00001000\n",
            "used_time: 0.2655620574951172\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1020, loss: 0.426874, acc: 1.000000\n",
            "steps: 1020\n",
            "save_steps: 1250\n",
            "20220531 15:40:39 current learning_rate:0.00001000\n",
            "used_time: 0.20872926712036133\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1030, loss: 0.667731, acc: 0.875000\n",
            "steps: 1030\n",
            "save_steps: 1250\n",
            "20220531 15:40:42 current learning_rate:0.00001000\n",
            "used_time: 0.24378585815429688\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1040, loss: 1.181699, acc: 0.250000\n",
            "steps: 1040\n",
            "save_steps: 1250\n",
            "20220531 15:40:44 current learning_rate:0.00001000\n",
            "used_time: 0.21157598495483398\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1050, loss: 0.897455, acc: 0.625000\n",
            "steps: 1050\n",
            "save_steps: 1250\n",
            "20220531 15:40:46 current learning_rate:0.00001000\n",
            "used_time: 0.2776639461517334\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1060, loss: 0.598421, acc: 0.750000\n",
            "steps: 1060\n",
            "save_steps: 1250\n",
            "20220531 15:40:48 current learning_rate:0.00001000\n",
            "used_time: 0.20430254936218262\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1070, loss: 0.517124, acc: 0.625000\n",
            "steps: 1070\n",
            "save_steps: 1250\n",
            "20220531 15:40:50 current learning_rate:0.00001000\n",
            "used_time: 0.21007156372070312\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1080, loss: 0.366513, acc: 0.750000\n",
            "steps: 1080\n",
            "save_steps: 1250\n",
            "20220531 15:40:53 current learning_rate:0.00001000\n",
            "used_time: 0.22474431991577148\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1090, loss: 0.440849, acc: 0.625000\n",
            "steps: 1090\n",
            "save_steps: 1250\n",
            "20220531 15:40:55 current learning_rate:0.00001000\n",
            "used_time: 0.2388322353363037\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1100, loss: 0.874777, acc: 0.500000\n",
            "steps: 1100\n",
            "save_steps: 1250\n",
            "20220531 15:40:57 current learning_rate:0.00001000\n",
            "used_time: 0.23106646537780762\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1110, loss: 0.433881, acc: 0.375000\n",
            "steps: 1110\n",
            "save_steps: 1250\n",
            "20220531 15:40:59 current learning_rate:0.00001000\n",
            "used_time: 0.20711660385131836\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1120, loss: 0.627481, acc: 0.375000\n",
            "steps: 1120\n",
            "save_steps: 1250\n",
            "20220531 15:41:02 current learning_rate:0.00001000\n",
            "used_time: 0.2199077606201172\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1130, loss: 0.609011, acc: 0.750000\n",
            "steps: 1130\n",
            "save_steps: 1250\n",
            "20220531 15:41:04 current learning_rate:0.00001000\n",
            "used_time: 0.3088400363922119\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1140, loss: 0.285771, acc: 0.625000\n",
            "steps: 1140\n",
            "save_steps: 1250\n",
            "20220531 15:41:06 current learning_rate:0.00001000\n",
            "used_time: 0.20067620277404785\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1150, loss: 1.079846, acc: 0.500000\n",
            "steps: 1150\n",
            "save_steps: 1250\n",
            "20220531 15:41:08 current learning_rate:0.00001000\n",
            "used_time: 0.1993091106414795\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1160, loss: 0.351019, acc: 0.375000\n",
            "steps: 1160\n",
            "save_steps: 1250\n",
            "20220531 15:41:10 current learning_rate:0.00001000\n",
            "used_time: 0.19939231872558594\n",
            "shuffle epoch 1\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1170, loss: 0.680013, acc: 0.375000\n",
            "steps: 1170\n",
            "save_steps: 1250\n",
            "20220531 15:41:13 current learning_rate:0.00001000\n",
            "used_time: 0.24663853645324707\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1180, loss: 0.237798, acc: 0.750000\n",
            "steps: 1180\n",
            "save_steps: 1250\n",
            "20220531 15:41:15 current learning_rate:0.00001000\n",
            "used_time: 0.21611571311950684\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1190, loss: 0.428234, acc: 0.500000\n",
            "steps: 1190\n",
            "save_steps: 1250\n",
            "20220531 15:41:17 current learning_rate:0.00001000\n",
            "used_time: 0.2026076316833496\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1200, loss: 0.399072, acc: 0.500000\n",
            "steps: 1200\n",
            "save_steps: 1250\n",
            "20220531 15:41:19 current learning_rate:0.00001000\n",
            "used_time: 0.19156312942504883\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1210, loss: 0.447174, acc: 0.750000\n",
            "steps: 1210\n",
            "save_steps: 1250\n",
            "20220531 15:41:22 current learning_rate:0.00001000\n",
            "used_time: 0.2255105972290039\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1220, loss: 0.097465, acc: 0.750000\n",
            "steps: 1220\n",
            "save_steps: 1250\n",
            "20220531 15:41:24 current learning_rate:0.00001000\n",
            "used_time: 0.20740222930908203\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1230, loss: 0.178428, acc: 0.625000\n",
            "steps: 1230\n",
            "save_steps: 1250\n",
            "20220531 15:41:26 current learning_rate:0.00001000\n",
            "used_time: 0.21149301528930664\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1240, loss: 0.300919, acc: 0.625000\n",
            "steps: 1240\n",
            "save_steps: 1250\n",
            "20220531 15:41:28 current learning_rate:0.00001000\n",
            "used_time: 0.23818612098693848\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1250, loss: 0.084170, acc: 0.750000\n",
            "steps: 1250\n",
            "save_steps: 1250\n",
            "20220531 15:41:30 current learning_rate:0.00001000\n",
            "save_path: output_hm/step_1250traindev\n",
            "used_time: 12.002792596817017\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1260, loss: 0.507670, acc: 0.625000\n",
            "steps: 1260\n",
            "save_steps: 1250\n",
            "20220531 15:41:44 current learning_rate:0.00001000\n",
            "used_time: 0.21490740776062012\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1270, loss: 0.107490, acc: 0.750000\n",
            "steps: 1270\n",
            "save_steps: 1250\n",
            "20220531 15:41:47 current learning_rate:0.00001000\n",
            "used_time: 0.20438289642333984\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1280, loss: 0.477981, acc: 0.375000\n",
            "steps: 1280\n",
            "save_steps: 1250\n",
            "20220531 15:41:49 current learning_rate:0.00001000\n",
            "used_time: 0.23124957084655762\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1290, loss: 0.382816, acc: 0.750000\n",
            "steps: 1290\n",
            "save_steps: 1250\n",
            "20220531 15:41:51 current learning_rate:0.00001000\n",
            "used_time: 0.2520942687988281\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1300, loss: 0.088583, acc: 0.500000\n",
            "steps: 1300\n",
            "save_steps: 1250\n",
            "20220531 15:41:53 current learning_rate:0.00001000\n",
            "used_time: 0.22132086753845215\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1310, loss: 0.345006, acc: 0.875000\n",
            "steps: 1310\n",
            "save_steps: 1250\n",
            "20220531 15:41:55 current learning_rate:0.00001000\n",
            "used_time: 0.21619439125061035\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1320, loss: 0.291517, acc: 0.875000\n",
            "steps: 1320\n",
            "save_steps: 1250\n",
            "20220531 15:41:58 current learning_rate:0.00001000\n",
            "used_time: 0.2270057201385498\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1330, loss: 0.042231, acc: 1.000000\n",
            "steps: 1330\n",
            "save_steps: 1250\n",
            "20220531 15:42:00 current learning_rate:0.00001000\n",
            "used_time: 0.25841188430786133\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1340, loss: 0.076394, acc: 0.750000\n",
            "steps: 1340\n",
            "save_steps: 1250\n",
            "20220531 15:42:02 current learning_rate:0.00001000\n",
            "used_time: 0.22303509712219238\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1350, loss: 0.035760, acc: 0.875000\n",
            "steps: 1350\n",
            "save_steps: 1250\n",
            "20220531 15:42:04 current learning_rate:0.00001000\n",
            "used_time: 0.20783066749572754\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1360, loss: 0.386135, acc: 0.750000\n",
            "steps: 1360\n",
            "save_steps: 1250\n",
            "20220531 15:42:06 current learning_rate:0.00001000\n",
            "used_time: 0.2224714756011963\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1370, loss: 0.234093, acc: 0.625000\n",
            "steps: 1370\n",
            "save_steps: 1250\n",
            "20220531 15:42:09 current learning_rate:0.00001000\n",
            "used_time: 0.24265265464782715\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1380, loss: 0.062518, acc: 0.625000\n",
            "steps: 1380\n",
            "save_steps: 1250\n",
            "20220531 15:42:11 current learning_rate:0.00001000\n",
            "used_time: 0.20738482475280762\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1390, loss: 0.310144, acc: 0.625000\n",
            "steps: 1390\n",
            "save_steps: 1250\n",
            "20220531 15:42:13 current learning_rate:0.00001000\n",
            "used_time: 0.23239946365356445\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1400, loss: 0.045676, acc: 0.750000\n",
            "steps: 1400\n",
            "save_steps: 1250\n",
            "20220531 15:42:15 current learning_rate:0.00001000\n",
            "used_time: 0.24064874649047852\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1410, loss: 0.681188, acc: 0.625000\n",
            "steps: 1410\n",
            "save_steps: 1250\n",
            "20220531 15:42:18 current learning_rate:0.00001000\n",
            "used_time: 0.24572086334228516\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1420, loss: 0.580402, acc: 0.625000\n",
            "steps: 1420\n",
            "save_steps: 1250\n",
            "20220531 15:42:20 current learning_rate:0.00001000\n",
            "used_time: 0.22426056861877441\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1430, loss: 0.253093, acc: 0.625000\n",
            "steps: 1430\n",
            "save_steps: 1250\n",
            "20220531 15:42:22 current learning_rate:0.00001000\n",
            "used_time: 0.2028055191040039\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1440, loss: 0.387861, acc: 0.625000\n",
            "steps: 1440\n",
            "save_steps: 1250\n",
            "20220531 15:42:24 current learning_rate:0.00001000\n",
            "used_time: 0.21921753883361816\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1450, loss: 0.029005, acc: 0.500000\n",
            "steps: 1450\n",
            "save_steps: 1250\n",
            "20220531 15:42:26 current learning_rate:0.00001000\n",
            "used_time: 0.23994874954223633\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1460, loss: 0.054183, acc: 0.375000\n",
            "steps: 1460\n",
            "save_steps: 1250\n",
            "20220531 15:42:29 current learning_rate:0.00001000\n",
            "used_time: 0.26079511642456055\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1470, loss: 1.583092, acc: 0.500000\n",
            "steps: 1470\n",
            "save_steps: 1250\n",
            "20220531 15:42:31 current learning_rate:0.00001000\n",
            "used_time: 0.23162126541137695\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1480, loss: 0.023401, acc: 0.500000\n",
            "steps: 1480\n",
            "save_steps: 1250\n",
            "20220531 15:42:33 current learning_rate:0.00001000\n",
            "used_time: 0.2097768783569336\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1490, loss: 0.059930, acc: 0.500000\n",
            "steps: 1490\n",
            "save_steps: 1250\n",
            "20220531 15:42:35 current learning_rate:0.00001000\n",
            "used_time: 0.24581432342529297\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1500, loss: 0.395173, acc: 0.625000\n",
            "steps: 1500\n",
            "save_steps: 1250\n",
            "Train-RCAC 0.875\n",
            "20220531 15:42:37 current learning_rate:0.00001000\n",
            "used_time: 0.2154076099395752\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1510, loss: 0.683355, acc: 0.500000\n",
            "steps: 1510\n",
            "save_steps: 1250\n",
            "20220531 15:42:40 current learning_rate:0.00001000\n",
            "used_time: 0.2222135066986084\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1520, loss: 0.199895, acc: 0.625000\n",
            "steps: 1520\n",
            "save_steps: 1250\n",
            "20220531 15:42:42 current learning_rate:0.00001000\n",
            "used_time: 0.22943568229675293\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1530, loss: 0.713281, acc: 0.750000\n",
            "steps: 1530\n",
            "save_steps: 1250\n",
            "20220531 15:42:44 current learning_rate:0.00001000\n",
            "used_time: 0.23956036567687988\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1540, loss: 0.912790, acc: 0.500000\n",
            "steps: 1540\n",
            "save_steps: 1250\n",
            "20220531 15:42:46 current learning_rate:0.00001000\n",
            "used_time: 0.20690155029296875\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1550, loss: 0.423035, acc: 0.500000\n",
            "steps: 1550\n",
            "save_steps: 1250\n",
            "20220531 15:42:48 current learning_rate:0.00001000\n",
            "used_time: 0.2221212387084961\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1560, loss: 0.134267, acc: 0.625000\n",
            "steps: 1560\n",
            "save_steps: 1250\n",
            "20220531 15:42:51 current learning_rate:0.00001000\n",
            "used_time: 0.21926617622375488\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1570, loss: 0.236951, acc: 0.750000\n",
            "steps: 1570\n",
            "save_steps: 1250\n",
            "20220531 15:42:53 current learning_rate:0.00001000\n",
            "used_time: 0.2450428009033203\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1580, loss: 0.275479, acc: 0.750000\n",
            "steps: 1580\n",
            "save_steps: 1250\n",
            "20220531 15:42:55 current learning_rate:0.00001000\n",
            "used_time: 0.2480607032775879\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1590, loss: 0.352104, acc: 0.750000\n",
            "steps: 1590\n",
            "save_steps: 1250\n",
            "20220531 15:42:57 current learning_rate:0.00001000\n",
            "used_time: 0.2041473388671875\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1600, loss: 0.634802, acc: 0.750000\n",
            "steps: 1600\n",
            "save_steps: 1250\n",
            "20220531 15:43:00 current learning_rate:0.00001000\n",
            "used_time: 0.22230291366577148\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1610, loss: 0.132178, acc: 0.750000\n",
            "steps: 1610\n",
            "save_steps: 1250\n",
            "20220531 15:43:02 current learning_rate:0.00001000\n",
            "used_time: 0.2546536922454834\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1620, loss: 0.219507, acc: 0.375000\n",
            "steps: 1620\n",
            "save_steps: 1250\n",
            "20220531 15:43:04 current learning_rate:0.00001000\n",
            "used_time: 0.21230387687683105\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1630, loss: 0.205481, acc: 0.500000\n",
            "steps: 1630\n",
            "save_steps: 1250\n",
            "20220531 15:43:06 current learning_rate:0.00001000\n",
            "used_time: 0.2268228530883789\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1640, loss: 0.416904, acc: 0.750000\n",
            "steps: 1640\n",
            "save_steps: 1250\n",
            "20220531 15:43:09 current learning_rate:0.00001000\n",
            "used_time: 0.22725796699523926\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1650, loss: 0.181569, acc: 0.750000\n",
            "steps: 1650\n",
            "save_steps: 1250\n",
            "20220531 15:43:11 current learning_rate:0.00001000\n",
            "used_time: 0.24536824226379395\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1660, loss: 0.787644, acc: 0.625000\n",
            "steps: 1660\n",
            "save_steps: 1250\n",
            "20220531 15:43:13 current learning_rate:0.00001000\n",
            "used_time: 0.21089935302734375\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1670, loss: 0.439928, acc: 0.625000\n",
            "steps: 1670\n",
            "save_steps: 1250\n",
            "20220531 15:43:15 current learning_rate:0.00001000\n",
            "used_time: 0.22223305702209473\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1680, loss: 0.133774, acc: 0.750000\n",
            "steps: 1680\n",
            "save_steps: 1250\n",
            "20220531 15:43:17 current learning_rate:0.00001000\n",
            "used_time: 0.2180476188659668\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1690, loss: 0.267957, acc: 0.625000\n",
            "steps: 1690\n",
            "save_steps: 1250\n",
            "20220531 15:43:20 current learning_rate:0.00001000\n",
            "used_time: 0.23726701736450195\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1700, loss: 0.106234, acc: 0.750000\n",
            "steps: 1700\n",
            "save_steps: 1250\n",
            "20220531 15:43:22 current learning_rate:0.00001000\n",
            "used_time: 0.21985387802124023\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1710, loss: 0.643362, acc: 0.750000\n",
            "steps: 1710\n",
            "save_steps: 1250\n",
            "20220531 15:43:24 current learning_rate:0.00001000\n",
            "used_time: 0.21959304809570312\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1720, loss: 0.420784, acc: 0.500000\n",
            "steps: 1720\n",
            "save_steps: 1250\n",
            "20220531 15:43:26 current learning_rate:0.00001000\n",
            "used_time: 0.24021363258361816\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1730, loss: 0.954292, acc: 0.375000\n",
            "steps: 1730\n",
            "save_steps: 1250\n",
            "20220531 15:43:29 current learning_rate:0.00001000\n",
            "used_time: 0.25392723083496094\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1740, loss: 0.847453, acc: 0.750000\n",
            "steps: 1740\n",
            "save_steps: 1250\n",
            "20220531 15:43:31 current learning_rate:0.00001000\n",
            "used_time: 0.22328901290893555\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1750, loss: 0.434659, acc: 0.625000\n",
            "steps: 1750\n",
            "save_steps: 1250\n",
            "20220531 15:43:33 current learning_rate:0.00001000\n",
            "used_time: 0.21123099327087402\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1760, loss: 0.233032, acc: 1.000000\n",
            "steps: 1760\n",
            "save_steps: 1250\n",
            "20220531 15:43:35 current learning_rate:0.00001000\n",
            "used_time: 0.19655394554138184\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1770, loss: 0.259355, acc: 0.750000\n",
            "steps: 1770\n",
            "save_steps: 1250\n",
            "20220531 15:43:37 current learning_rate:0.00001000\n",
            "used_time: 0.23600101470947266\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1780, loss: 0.821896, acc: 0.500000\n",
            "steps: 1780\n",
            "save_steps: 1250\n",
            "20220531 15:43:40 current learning_rate:0.00001000\n",
            "used_time: 0.20813250541687012\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1790, loss: 0.398900, acc: 0.250000\n",
            "steps: 1790\n",
            "save_steps: 1250\n",
            "20220531 15:43:42 current learning_rate:0.00001000\n",
            "used_time: 0.2212686538696289\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1800, loss: 0.079754, acc: 0.500000\n",
            "steps: 1800\n",
            "save_steps: 1250\n",
            "20220531 15:43:44 current learning_rate:0.00001000\n",
            "used_time: 0.2194831371307373\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1810, loss: 0.020670, acc: 0.750000\n",
            "steps: 1810\n",
            "save_steps: 1250\n",
            "20220531 15:43:46 current learning_rate:0.00001000\n",
            "used_time: 0.23731207847595215\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1820, loss: 0.284160, acc: 0.625000\n",
            "steps: 1820\n",
            "save_steps: 1250\n",
            "20220531 15:43:49 current learning_rate:0.00001000\n",
            "used_time: 0.2895512580871582\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1830, loss: 0.316225, acc: 0.875000\n",
            "steps: 1830\n",
            "save_steps: 1250\n",
            "20220531 15:43:51 current learning_rate:0.00001000\n",
            "used_time: 0.21622729301452637\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1840, loss: 0.387954, acc: 0.500000\n",
            "steps: 1840\n",
            "save_steps: 1250\n",
            "20220531 15:43:53 current learning_rate:0.00001000\n",
            "used_time: 0.20617055892944336\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1850, loss: 0.301725, acc: 0.625000\n",
            "steps: 1850\n",
            "save_steps: 1250\n",
            "20220531 15:43:55 current learning_rate:0.00001000\n",
            "used_time: 0.23647308349609375\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1860, loss: 0.733737, acc: 0.875000\n",
            "steps: 1860\n",
            "save_steps: 1250\n",
            "20220531 15:43:57 current learning_rate:0.00001000\n",
            "used_time: 0.20480608940124512\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1870, loss: 0.439730, acc: 0.625000\n",
            "steps: 1870\n",
            "save_steps: 1250\n",
            "20220531 15:44:00 current learning_rate:0.00001000\n",
            "used_time: 0.204850435256958\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1880, loss: 0.098150, acc: 0.375000\n",
            "steps: 1880\n",
            "save_steps: 1250\n",
            "20220531 15:44:02 current learning_rate:0.00001000\n",
            "used_time: 0.21150684356689453\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1890, loss: 0.836824, acc: 0.500000\n",
            "steps: 1890\n",
            "save_steps: 1250\n",
            "20220531 15:44:04 current learning_rate:0.00001000\n",
            "used_time: 0.2696094512939453\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1900, loss: 0.709619, acc: 0.500000\n",
            "steps: 1900\n",
            "save_steps: 1250\n",
            "20220531 15:44:06 current learning_rate:0.00001000\n",
            "used_time: 0.20770525932312012\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1910, loss: 0.467586, acc: 0.500000\n",
            "steps: 1910\n",
            "save_steps: 1250\n",
            "20220531 15:44:09 current learning_rate:0.00001000\n",
            "used_time: 0.23938775062561035\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1920, loss: 0.311031, acc: 0.750000\n",
            "steps: 1920\n",
            "save_steps: 1250\n",
            "20220531 15:44:11 current learning_rate:0.00001000\n",
            "used_time: 0.19791769981384277\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1930, loss: 0.405322, acc: 0.750000\n",
            "steps: 1930\n",
            "save_steps: 1250\n",
            "20220531 15:44:13 current learning_rate:0.00001000\n",
            "used_time: 0.2593388557434082\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1940, loss: 0.490740, acc: 0.250000\n",
            "steps: 1940\n",
            "save_steps: 1250\n",
            "20220531 15:44:15 current learning_rate:0.00001000\n",
            "used_time: 0.21417713165283203\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1950, loss: 0.449925, acc: 0.875000\n",
            "steps: 1950\n",
            "save_steps: 1250\n",
            "20220531 15:44:17 current learning_rate:0.00001000\n",
            "used_time: 0.25866031646728516\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1960, loss: 0.086297, acc: 0.500000\n",
            "steps: 1960\n",
            "save_steps: 1250\n",
            "20220531 15:44:20 current learning_rate:0.00001000\n",
            "used_time: 0.23220133781433105\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1970, loss: 0.189716, acc: 0.625000\n",
            "steps: 1970\n",
            "save_steps: 1250\n",
            "20220531 15:44:22 current learning_rate:0.00001000\n",
            "used_time: 0.260725736618042\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1980, loss: 0.214224, acc: 0.500000\n",
            "steps: 1980\n",
            "save_steps: 1250\n",
            "20220531 15:44:24 current learning_rate:0.00001000\n",
            "used_time: 0.23280858993530273\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1990, loss: 0.197876, acc: 0.625000\n",
            "steps: 1990\n",
            "save_steps: 1250\n",
            "20220531 15:44:26 current learning_rate:0.00001000\n",
            "used_time: 0.20540642738342285\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2000, loss: 0.556035, acc: 0.625000\n",
            "steps: 2000\n",
            "save_steps: 1250\n",
            "Train-RCAC 0.890625\n",
            "20220531 15:44:29 current learning_rate:0.00001000\n",
            "used_time: 0.22377777099609375\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2010, loss: 0.751176, acc: 0.750000\n",
            "steps: 2010\n",
            "save_steps: 1250\n",
            "20220531 15:44:31 current learning_rate:0.00001000\n",
            "used_time: 0.25832056999206543\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2020, loss: 0.419613, acc: 0.625000\n",
            "steps: 2020\n",
            "save_steps: 1250\n",
            "20220531 15:44:33 current learning_rate:0.00001000\n",
            "used_time: 0.2098371982574463\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2030, loss: 0.393427, acc: 0.625000\n",
            "steps: 2030\n",
            "save_steps: 1250\n",
            "20220531 15:44:35 current learning_rate:0.00001000\n",
            "used_time: 0.2189624309539795\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2040, loss: 0.507016, acc: 0.625000\n",
            "steps: 2040\n",
            "save_steps: 1250\n",
            "20220531 15:44:37 current learning_rate:0.00001000\n",
            "used_time: 0.21805953979492188\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2050, loss: 0.352295, acc: 0.625000\n",
            "steps: 2050\n",
            "save_steps: 1250\n",
            "20220531 15:44:40 current learning_rate:0.00001000\n",
            "used_time: 0.25336790084838867\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2060, loss: 0.168906, acc: 0.625000\n",
            "steps: 2060\n",
            "save_steps: 1250\n",
            "20220531 15:44:42 current learning_rate:0.00001000\n",
            "used_time: 0.2070467472076416\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2070, loss: 0.362220, acc: 0.625000\n",
            "steps: 2070\n",
            "save_steps: 1250\n",
            "20220531 15:44:44 current learning_rate:0.00001000\n",
            "used_time: 0.20694875717163086\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2080, loss: 1.030484, acc: 0.500000\n",
            "steps: 2080\n",
            "save_steps: 1250\n",
            "20220531 15:44:46 current learning_rate:0.00001000\n",
            "used_time: 0.23024249076843262\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2090, loss: 0.084541, acc: 0.875000\n",
            "steps: 2090\n",
            "save_steps: 1250\n",
            "20220531 15:44:48 current learning_rate:0.00001000\n",
            "used_time: 0.25266098976135254\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2100, loss: 0.985264, acc: 0.500000\n",
            "steps: 2100\n",
            "save_steps: 1250\n",
            "20220531 15:44:51 current learning_rate:0.00001000\n",
            "used_time: 0.20670652389526367\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2110, loss: 0.489841, acc: 0.750000\n",
            "steps: 2110\n",
            "save_steps: 1250\n",
            "20220531 15:44:53 current learning_rate:0.00001000\n",
            "used_time: 0.21651196479797363\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2120, loss: 0.337634, acc: 0.500000\n",
            "steps: 2120\n",
            "save_steps: 1250\n",
            "20220531 15:44:55 current learning_rate:0.00001000\n",
            "used_time: 0.2318742275238037\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2130, loss: 0.158863, acc: 0.500000\n",
            "steps: 2130\n",
            "save_steps: 1250\n",
            "20220531 15:44:57 current learning_rate:0.00001000\n",
            "used_time: 0.23646998405456543\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2140, loss: 0.096914, acc: 0.375000\n",
            "steps: 2140\n",
            "save_steps: 1250\n",
            "20220531 15:45:00 current learning_rate:0.00001000\n",
            "used_time: 0.2545661926269531\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2150, loss: 0.853068, acc: 0.500000\n",
            "steps: 2150\n",
            "save_steps: 1250\n",
            "20220531 15:45:02 current learning_rate:0.00001000\n",
            "used_time: 0.25949740409851074\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2160, loss: 0.493087, acc: 0.625000\n",
            "steps: 2160\n",
            "save_steps: 1250\n",
            "20220531 15:45:05 current learning_rate:0.00001000\n",
            "used_time: 0.2310929298400879\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2170, loss: 0.355368, acc: 0.625000\n",
            "steps: 2170\n",
            "save_steps: 1250\n",
            "20220531 15:45:07 current learning_rate:0.00001000\n",
            "used_time: 0.27301692962646484\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2180, loss: 1.288919, acc: 0.500000\n",
            "steps: 2180\n",
            "save_steps: 1250\n",
            "20220531 15:45:09 current learning_rate:0.00001000\n",
            "used_time: 0.20764684677124023\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2190, loss: 0.687735, acc: 0.625000\n",
            "steps: 2190\n",
            "save_steps: 1250\n",
            "20220531 15:45:11 current learning_rate:0.00001000\n",
            "used_time: 0.23166871070861816\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2200, loss: 0.584393, acc: 0.375000\n",
            "steps: 2200\n",
            "save_steps: 1250\n",
            "20220531 15:45:13 current learning_rate:0.00001000\n",
            "used_time: 0.2035367488861084\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2210, loss: 0.100662, acc: 0.750000\n",
            "steps: 2210\n",
            "save_steps: 1250\n",
            "20220531 15:45:16 current learning_rate:0.00001000\n",
            "used_time: 0.24707245826721191\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2220, loss: 0.146433, acc: 0.750000\n",
            "steps: 2220\n",
            "save_steps: 1250\n",
            "20220531 15:45:18 current learning_rate:0.00001000\n",
            "used_time: 0.21235299110412598\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2230, loss: 0.292059, acc: 0.625000\n",
            "steps: 2230\n",
            "save_steps: 1250\n",
            "20220531 15:45:20 current learning_rate:0.00001000\n",
            "used_time: 0.2286522388458252\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2240, loss: 0.066673, acc: 0.875000\n",
            "steps: 2240\n",
            "save_steps: 1250\n",
            "20220531 15:45:22 current learning_rate:0.00001000\n",
            "used_time: 0.2162938117980957\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2250, loss: 0.029755, acc: 0.625000\n",
            "steps: 2250\n",
            "save_steps: 1250\n",
            "20220531 15:45:25 current learning_rate:0.00001000\n",
            "used_time: 0.25340747833251953\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2260, loss: 0.037317, acc: 0.500000\n",
            "steps: 2260\n",
            "save_steps: 1250\n",
            "20220531 15:45:27 current learning_rate:0.00001000\n",
            "used_time: 0.21013760566711426\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2270, loss: 0.045222, acc: 0.875000\n",
            "steps: 2270\n",
            "save_steps: 1250\n",
            "20220531 15:45:29 current learning_rate:0.00001000\n",
            "used_time: 0.20418787002563477\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2280, loss: 0.036033, acc: 0.875000\n",
            "steps: 2280\n",
            "save_steps: 1250\n",
            "20220531 15:45:31 current learning_rate:0.00001000\n",
            "used_time: 0.20427513122558594\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2290, loss: 0.074077, acc: 0.625000\n",
            "steps: 2290\n",
            "save_steps: 1250\n",
            "20220531 15:45:33 current learning_rate:0.00001000\n",
            "used_time: 0.25145864486694336\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2300, loss: 0.909574, acc: 0.875000\n",
            "steps: 2300\n",
            "save_steps: 1250\n",
            "20220531 15:45:36 current learning_rate:0.00001000\n",
            "used_time: 0.22989726066589355\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2310, loss: 0.370179, acc: 0.750000\n",
            "steps: 2310\n",
            "save_steps: 1250\n",
            "20220531 15:45:38 current learning_rate:0.00001000\n",
            "used_time: 0.22183012962341309\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2320, loss: 0.592576, acc: 0.500000\n",
            "steps: 2320\n",
            "save_steps: 1250\n",
            "20220531 15:45:40 current learning_rate:0.00001000\n",
            "used_time: 0.2291123867034912\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2330, loss: 0.181091, acc: 0.750000\n",
            "steps: 2330\n",
            "save_steps: 1250\n",
            "20220531 15:45:42 current learning_rate:0.00001000\n",
            "used_time: 0.3302001953125\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2340, loss: 0.057060, acc: 0.625000\n",
            "steps: 2340\n",
            "save_steps: 1250\n",
            "20220531 15:45:45 current learning_rate:0.00001000\n",
            "used_time: 0.20110630989074707\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2350, loss: 0.108576, acc: 0.750000\n",
            "steps: 2350\n",
            "save_steps: 1250\n",
            "20220531 15:45:47 current learning_rate:0.00001000\n",
            "used_time: 0.21859335899353027\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2360, loss: 0.017336, acc: 0.500000\n",
            "steps: 2360\n",
            "save_steps: 1250\n",
            "20220531 15:45:49 current learning_rate:0.00001000\n",
            "used_time: 0.20901226997375488\n",
            "shuffle epoch 2\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2370, loss: 1.129077, acc: 0.625000\n",
            "steps: 2370\n",
            "save_steps: 1250\n",
            "20220531 15:45:51 current learning_rate:0.00001000\n",
            "used_time: 0.25699830055236816\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2380, loss: 0.544600, acc: 0.875000\n",
            "steps: 2380\n",
            "save_steps: 1250\n",
            "20220531 15:45:54 current learning_rate:0.00001000\n",
            "used_time: 0.24009943008422852\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2390, loss: 0.132813, acc: 0.500000\n",
            "steps: 2390\n",
            "save_steps: 1250\n",
            "20220531 15:45:56 current learning_rate:0.00001000\n",
            "used_time: 0.20710539817810059\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2400, loss: 0.592599, acc: 0.500000\n",
            "steps: 2400\n",
            "save_steps: 1250\n",
            "20220531 15:45:58 current learning_rate:0.00001000\n",
            "used_time: 0.18638849258422852\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2410, loss: 0.206831, acc: 0.375000\n",
            "steps: 2410\n",
            "save_steps: 1250\n",
            "20220531 15:46:00 current learning_rate:0.00001000\n",
            "used_time: 0.26018857955932617\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2420, loss: 0.013256, acc: 0.750000\n",
            "steps: 2420\n",
            "save_steps: 1250\n",
            "20220531 15:46:03 current learning_rate:0.00001000\n",
            "used_time: 0.22723793983459473\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2430, loss: 0.009824, acc: 0.500000\n",
            "steps: 2430\n",
            "save_steps: 1250\n",
            "20220531 15:46:05 current learning_rate:0.00001000\n",
            "used_time: 0.21877694129943848\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2440, loss: 0.708681, acc: 0.750000\n",
            "steps: 2440\n",
            "save_steps: 1250\n",
            "20220531 15:46:07 current learning_rate:0.00001000\n",
            "used_time: 0.2065122127532959\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2450, loss: 2.234875, acc: 0.500000\n",
            "steps: 2450\n",
            "save_steps: 1250\n",
            "20220531 15:46:09 current learning_rate:0.00001000\n",
            "used_time: 0.26726770401000977\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2460, loss: 0.058750, acc: 0.625000\n",
            "steps: 2460\n",
            "save_steps: 1250\n",
            "20220531 15:46:11 current learning_rate:0.00001000\n",
            "used_time: 0.21254658699035645\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2470, loss: 0.618335, acc: 0.625000\n",
            "steps: 2470\n",
            "save_steps: 1250\n",
            "20220531 15:46:13 current learning_rate:0.00001000\n",
            "used_time: 0.209381103515625\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2480, loss: 0.252186, acc: 0.750000\n",
            "steps: 2480\n",
            "save_steps: 1250\n",
            "20220531 15:46:16 current learning_rate:0.00001000\n",
            "used_time: 0.20580434799194336\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2490, loss: 0.007268, acc: 0.500000\n",
            "steps: 2490\n",
            "save_steps: 1250\n",
            "20220531 15:46:18 current learning_rate:0.00001000\n",
            "used_time: 0.25174498558044434\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2500, loss: 0.012100, acc: 0.750000\n",
            "steps: 2500\n",
            "save_steps: 1250\n",
            "Train-RCAC 0.96875\n",
            "20220531 15:46:20 current learning_rate:0.00001000\n",
            "save_path: output_hm/step_2500traindev\n",
            "used_time: 12.094560146331787\n",
            "############################WARNING################################### using init_pretraining_params, not init_checkpoint ###### meaning hyper param e.g. lr won't inherit from checkpoint#################################################################W0531 15:46:33.066848  2884 init.cc:216] Warning: PaddlePaddle catches a failure signal, it may not work properly\n",
            "W0531 15:46:33.066916  2884 init.cc:218] You could check whether you killed PaddlePaddle thread/process accidentally or report the case to PaddlePaddle\n",
            "W0531 15:46:33.066931  2884 init.cc:221] The detail failure signal is:\n",
            "\n",
            "W0531 15:46:33.066944  2884 init.cc:224] *** Aborted at 1654011993 (unix time) try \"date -d @1654011993\" if you are using GNU date ***\n",
            "W0531 15:46:33.069990  2884 init.cc:224] PC: @                0x0 (unknown)\n",
            "W0531 15:46:33.070320  2884 init.cc:224] *** SIGABRT (@0xb1c) received by PID 2844 (TID 0x7f2dcbdeb700) from PID 2844; stack trace: ***\n",
            "W0531 15:46:33.073415  2884 init.cc:224]     @     0x7f2f8c80af10 (unknown)\n",
            "W0531 15:46:33.074888  2884 init.cc:224]     @     0x7f2f8c80ae87 gsignal\n",
            "W0531 15:46:33.076277  2884 init.cc:224]     @     0x7f2f8c80c7f1 abort\n",
            "W0531 15:46:33.077845  2884 init.cc:224]     @     0x7f2f8b4a710e (unknown)\n",
            "W0531 15:46:33.079267  2884 init.cc:224]     @     0x7f2f8b4a7356 __gxx_personality_v0\n",
            "W0531 15:46:33.080854  2884 init.cc:224]     @     0x7f2f8afe7668 (unknown)\n",
            "W0531 15:46:33.082677  2884 init.cc:224]     @     0x7f2f8afe7c5c _Unwind_ForcedUnwind\n",
            "W0531 15:46:33.084270  2884 init.cc:224]     @     0x7f2f8c5be000 __GI___pthread_unwind\n",
            "W0531 15:46:33.085970  2884 init.cc:224]     @     0x7f2f8c5b5ae5 __pthread_exit\n",
            "W0531 15:46:33.087944  2884 init.cc:224]     @     0x7f2f8c8fc364 pthread_exit\n",
            "W0531 15:46:33.088222  2884 init.cc:224]     @           0x5e37d8 PyThread_exit_thread\n",
            "W0531 15:46:33.088414  2884 init.cc:224]     @           0x47028a (unknown)\n",
            "W0531 15:46:33.094090  2884 init.cc:224]     @     0x7f2f395b0019 pybind11::gil_scoped_release::~gil_scoped_release()\n",
            "W0531 15:46:33.095232  2884 init.cc:224]     @     0x7f2f396983b6 _ZZN8pybind1112cpp_function10initializeIZN6paddle6pybind10BindReaderEPNS_6moduleEEUlRNS2_9operators6reader22LoDTensorBlockingQueueERKSt6vectorINS2_9framework9LoDTensorESaISC_EEE1_bIS9_SG_EINS_4nameENS_9is_methodENS_7siblingENS_10call_guardIINS_18gil_scoped_releaseEEEEEEEvOT_PFT0_DpT1_EDpRKT2_ENUlRNS_6detail13function_callEE1_4_FUNES11_\n",
            "W0531 15:46:33.100106  2884 init.cc:224]     @     0x7f2f395cd829 pybind11::cpp_function::dispatcher()\n",
            "W0531 15:46:33.100281  2884 init.cc:224]     @           0x593784 _PyMethodDef_RawFastCallKeywords\n",
            "W0531 15:46:33.100405  2884 init.cc:224]     @           0x594731 _PyObject_FastCallKeywords\n",
            "W0531 15:46:33.100579  2884 init.cc:224]     @           0x548cc1 (unknown)\n",
            "W0531 15:46:33.100684  2884 init.cc:224]     @           0x51566f _PyEval_EvalFrameDefault\n",
            "W0531 15:46:33.100818  2884 init.cc:224]     @           0x549e0e _PyEval_EvalCodeWithName\n",
            "W0531 15:46:33.100908  2884 init.cc:224]     @           0x4bcb19 _PyFunction_FastCallDict\n",
            "W0531 15:46:33.101045  2884 init.cc:224]     @           0x5134a6 _PyEval_EvalFrameDefault\n",
            "W0531 15:46:33.101167  2884 init.cc:224]     @           0x593dd7 _PyFunction_FastCallKeywords\n",
            "W0531 15:46:33.101251  2884 init.cc:224]     @           0x511e2c _PyEval_EvalFrameDefault\n",
            "W0531 15:46:33.101363  2884 init.cc:224]     @           0x593dd7 _PyFunction_FastCallKeywords\n",
            "W0531 15:46:33.101464  2884 init.cc:224]     @           0x511e2c _PyEval_EvalFrameDefault\n",
            "W0531 15:46:33.101583  2884 init.cc:224]     @           0x4bc98a _PyFunction_FastCallDict\n",
            "W0531 15:46:33.101799  2884 init.cc:224]     @           0x59c019 (unknown)\n",
            "W0531 15:46:33.101994  2884 init.cc:224]     @           0x595ef6 PyObject_Call\n",
            "W0531 15:46:33.102174  2884 init.cc:224]     @           0x5d5393 (unknown)\n",
            "W0531 15:46:33.102353  2884 init.cc:224]     @           0x5e3137 (unknown)\n",
            "W0531 15:46:33.106333  2884 init.cc:224]     @     0x7f2f8c5b46db start_thread\n",
            "run_finetuning.sh: line 64:  2844 Aborted                 (core dumped) python /content/vilio/ernie-vil/finetune.py --use_cuda \"True\" --is_distributed \"False\" --use_fast_executor ${e_executor-\"True\"} --nccl_comm_num ${nccl_comm_num:-\"1\"} --batch_size $((BATCH_SIZE/gpu_cnt)) --do_train \"True\" --do_test \"False\" --task_name ${TASK_NAME} --vocab_path ${VOCAB_PATH} --task_group_json ${TASK_GROUP_JSON} --lr_scheduler ${lr_scheduler} --decay_steps ${decay_steps-\"\"} --lr_decay_ratio ${lr_decay_ratio-0.1} --num_train_steps ${num_train_steps} --checkpoints $output_model_path --save_steps ${SAVE_STEPS} --init_checkpoint ${PRETRAIN_MODELS} --ernie_config_path ${ERNIE_VIL_CONFIG} --learning_rate ${LR_RATE} --warmup_steps ${WARMUP_STEPS} --weight_decay ${WEIGHT_DECAY:-0} --max_seq_len ${MAX_LEN} --validation_steps ${VALID_STEPS} --skip_steps 10 --split ${SPLIT} --stop_steps ${STOP}\n",
            "-----------  Configuration Arguments -----------\n",
            "batch_size: 8\n",
            "checkpoints: checkpoints\n",
            "combine: False\n",
            "decay_steps: \n",
            "do_test: True\n",
            "do_train: False\n",
            "do_val: False\n",
            "epoch: 100\n",
            "ernie_config_path: /content/vilio/ernie-vil/data/erniesmallvcr/ernie_vil_config.base.json\n",
            "exp: ESVCR72\n",
            "feature_size: 2048\n",
            "fusion_method: sum\n",
            "hierarchical_allreduce_inter_nranks: 8\n",
            "init_checkpoint: /content/vilio/ernie-vil/output_hm/step_2500traindev\n",
            "is_distributed: False\n",
            "learning_rate: 0.0001\n",
            "lr_decay_dict_file: \n",
            "lr_decay_ratio: 0.1\n",
            "lr_scheduler: linear_warmup_decay\n",
            "max_img_len: 100\n",
            "max_seq_len: 128\n",
            "nccl_comm_num: 1\n",
            "num_features: 50\n",
            "num_train_steps: 1000000\n",
            "output_file: \n",
            "result_file: /content/vilio/ernie-vil/data/log\n",
            "save_steps: 100\n",
            "skip_steps: 10\n",
            "split: test_seen\n",
            "stop_steps: 5000\n",
            "subtrain: False\n",
            "task_group_json: /content/vilio/ernie-vil/conf/hm/task_hm.json\n",
            "task_name: hm\n",
            "test_filelist: \n",
            "test_split: val\n",
            "train_filelist: \n",
            "use_cuda: True\n",
            "use_fast_executor: True\n",
            "use_fuse: False\n",
            "use_gpu: True\n",
            "use_hierarchical_allreduce: False\n",
            "valid_filelist: \n",
            "validation_steps: 6000\n",
            "verbose: False\n",
            "vocab_path: /content/vilio/ernie-vil/data/erniesmallvcr/vocab.txt\n",
            "warmup_steps: 0\n",
            "weight_decay: 0.01\n",
            "------------------------------------------------\n",
            "finetuning tasks start\n",
            "attention_probs_dropout_prob: 0.1\n",
            "class_attr_size: 401\n",
            "class_size: 1601\n",
            "co_hidden_size: 1024\n",
            "co_intermediate_size: 1024\n",
            "co_num_attention_heads: 8\n",
            "hidden_act: gelu\n",
            "hidden_dropout_prob: 0.1\n",
            "hidden_size: 768\n",
            "initializer_range: 0.02\n",
            "max_position_embeddings: 512\n",
            "num_attention_heads: 12\n",
            "num_hidden_layers: 12\n",
            "sent_type_vocab_size: 4\n",
            "t_biattention_id: [6, 7, 8, 9, 10, 11]\n",
            "task_type_vocab_size: 16\n",
            "type_vocab_size: 2\n",
            "v_biattention_id: [0, 1, 2, 3, 4, 5]\n",
            "v_hidden_size: 1024\n",
            "v_intermediate_size: 1024\n",
            "v_num_attention_heads: 8\n",
            "vocab_size: 30522\n",
            "------------------------------------------------\n",
            "task:  [{'task': 'HM', 'num_choice': 1, 'annotations_jsonpath_train': '/content/vilio/ernie-vil/data/hm/train.jsonl', 'annotations_jsonpath_dev_seen': '/content/vilio/ernie-vil/data/hm/dev_seenlong.jsonl', 'annotations_jsonpath_traindev': '/content/vilio/ernie-vil/data/hm/traindev.jsonl', 'annotations_jsonpath_test_unseen': '/content/vilio/ernie-vil/data/hm/test_unseenlong.jsonl', 'annotations_jsonpath_test_seen': '/content/vilio/ernie-vil/data/hm/test_seenlong.jsonl', 'feature_lmdb_path': '/content/vilio/ernie-vil/data/hm/HM_img.tsv', 'gt_feature_lmdb_path': '/content/vilio/ernie-vil/data/hm/HM_gt_img.tsv', 'unisex_names_table': '/content/vilio/ernie-vil/data/vcr/unisex_names_table.csv', 'Proprocessor': 'PreprocessorBasic', 'tokenizer_name': 'FullTokenizer', 'fusion_method': 'mul', 'dropout_rate': 0.1, 'max_seq_len': 128, 'use_gt_fea': True, 'shufflekeep_across_task': True, 'shuffle_every_epoch': True, 'task_weight': 1.0, 'task_prefix': 'hm'}]\n",
            "2022-05-31 15:46:37,393-WARNING: paddle.fluid.layers.py_reader() may be deprecated in the near future. Please use paddle.fluid.io.DataLoader.from_generator() instead.\n",
            "theoretical memory usage: \n",
            "(3678.2632896423343, 3853.418684387207, 'MB')\n",
            "args.is_distributed: False\n",
            "W0531 15:46:38.524256  2920 device_context.cc:252] Please NOTE: device: 0, CUDA Capability: 60, Driver API Version: 11.2, Runtime API Version: 9.0\n",
            "W0531 15:46:38.539482  2920 device_context.cc:260] device: 0, cuDNN Version: 7.6.\n",
            "SPLIT: test_seen\n",
            "Start to load Faster-RCNN detected objects from /content/vilio/ernie-vil/data/hm/HM_img.tsv\n",
            "Loaded 1000 images in file /content/vilio/ernie-vil/data/hm/HM_img.tsv in 169 seconds.\n",
            "Start to load Faster-RCNN detected objects from /content/vilio/ernie-vil/data/hm/HM_gt_img.tsv\n",
            "Loaded 1000 images in file /content/vilio/ernie-vil/data/hm/HM_gt_img.tsv in 55 seconds.\n",
            "Load 1300 data from split(s) /content/vilio/ernie-vil/data/hm/test_seenlong.jsonl.\n",
            "use gt featurre\n",
            "LEN:  1300\n",
            "Load pretraining parameters from /content/vilio/ernie-vil/output_hm/step_2500traindev.\n",
            "testing on hm val split\n",
            "task name list :  ['mean_0.tmp_0', 'accuracy_0.tmp_0', 'arg_max_0.tmp_0', 'read_file_0.tmp_9', 'read_file_0.tmp_8', 'reshape2_120.tmp_0']\n",
            "cur_step: 10 cur_acc: 0.9875\n",
            "cur_step: 20 cur_acc: 0.99375\n",
            "cur_step: 30 cur_acc: 0.9958333333333333\n",
            "cur_step: 40 cur_acc: 0.996875\n",
            "cur_step: 50 cur_acc: 0.9975\n",
            "cur_step: 60 cur_acc: 0.9979166666666667\n",
            "cur_step: 70 cur_acc: 0.9982142857142857\n",
            "cur_step: 80 cur_acc: 0.9984375\n",
            "cur_step: 90 cur_acc: 0.9986111111111111\n",
            "cur_step: 100 cur_acc: 0.99875\n",
            "cur_step: 110 cur_acc: 0.9988636363636364\n",
            "cur_step: 120 cur_acc: 0.9989583333333333\n",
            "cur_step: 130 cur_acc: 0.9980769230769231\n",
            "cur_step: 140 cur_acc: 0.9982142857142857\n",
            "cur_step: 150 cur_acc: 0.9983333333333333\n",
            "cur_step: 160 cur_acc: 0.9984375\n",
            "EXCEPTING\n",
            "LEN: 1000 1000\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   id      1000 non-null   int64  \n",
            " 1   proba   1000 non-null   float32\n",
            " 2   label   1000 non-null   int64  \n",
            "dtypes: float32(1), int64(2)\n",
            "memory usage: 19.7 KB\n",
            "None\n",
            "average_acc: 0.9984375\n",
            "rocauc: 0.6932707355242567\n",
            "-----------  Configuration Arguments -----------\n",
            "batch_size: 8\n",
            "checkpoints: checkpoints\n",
            "combine: False\n",
            "decay_steps: \n",
            "do_test: True\n",
            "do_train: False\n",
            "do_val: False\n",
            "epoch: 100\n",
            "ernie_config_path: /content/vilio/ernie-vil/data/erniesmallvcr/ernie_vil_config.base.json\n",
            "exp: ESVCR72\n",
            "feature_size: 2048\n",
            "fusion_method: sum\n",
            "hierarchical_allreduce_inter_nranks: 8\n",
            "init_checkpoint: /content/vilio/ernie-vil/output_hm/step_2500traindev\n",
            "is_distributed: False\n",
            "learning_rate: 0.0001\n",
            "lr_decay_dict_file: \n",
            "lr_decay_ratio: 0.1\n",
            "lr_scheduler: linear_warmup_decay\n",
            "max_img_len: 100\n",
            "max_seq_len: 128\n",
            "nccl_comm_num: 1\n",
            "num_features: 50\n",
            "num_train_steps: 1000000\n",
            "output_file: \n",
            "result_file: /content/vilio/ernie-vil/data/log\n",
            "save_steps: 100\n",
            "skip_steps: 10\n",
            "split: test_unseen\n",
            "stop_steps: 5000\n",
            "subtrain: False\n",
            "task_group_json: /content/vilio/ernie-vil/conf/hm/task_hm.json\n",
            "task_name: hm\n",
            "test_filelist: \n",
            "test_split: val\n",
            "train_filelist: \n",
            "use_cuda: True\n",
            "use_fast_executor: True\n",
            "use_fuse: False\n",
            "use_gpu: True\n",
            "use_hierarchical_allreduce: False\n",
            "valid_filelist: \n",
            "validation_steps: 6000\n",
            "verbose: False\n",
            "vocab_path: /content/vilio/ernie-vil/data/erniesmallvcr/vocab.txt\n",
            "warmup_steps: 0\n",
            "weight_decay: 0.01\n",
            "------------------------------------------------\n",
            "finetuning tasks start\n",
            "attention_probs_dropout_prob: 0.1\n",
            "class_attr_size: 401\n",
            "class_size: 1601\n",
            "co_hidden_size: 1024\n",
            "co_intermediate_size: 1024\n",
            "co_num_attention_heads: 8\n",
            "hidden_act: gelu\n",
            "hidden_dropout_prob: 0.1\n",
            "hidden_size: 768\n",
            "initializer_range: 0.02\n",
            "max_position_embeddings: 512\n",
            "num_attention_heads: 12\n",
            "num_hidden_layers: 12\n",
            "sent_type_vocab_size: 4\n",
            "t_biattention_id: [6, 7, 8, 9, 10, 11]\n",
            "task_type_vocab_size: 16\n",
            "type_vocab_size: 2\n",
            "v_biattention_id: [0, 1, 2, 3, 4, 5]\n",
            "v_hidden_size: 1024\n",
            "v_intermediate_size: 1024\n",
            "v_num_attention_heads: 8\n",
            "vocab_size: 30522\n",
            "------------------------------------------------\n",
            "task:  [{'task': 'HM', 'num_choice': 1, 'annotations_jsonpath_train': '/content/vilio/ernie-vil/data/hm/train.jsonl', 'annotations_jsonpath_dev_seen': '/content/vilio/ernie-vil/data/hm/dev_seenlong.jsonl', 'annotations_jsonpath_traindev': '/content/vilio/ernie-vil/data/hm/traindev.jsonl', 'annotations_jsonpath_test_unseen': '/content/vilio/ernie-vil/data/hm/test_unseenlong.jsonl', 'annotations_jsonpath_test_seen': '/content/vilio/ernie-vil/data/hm/test_seenlong.jsonl', 'feature_lmdb_path': '/content/vilio/ernie-vil/data/hm/HM_img.tsv', 'gt_feature_lmdb_path': '/content/vilio/ernie-vil/data/hm/HM_gt_img.tsv', 'unisex_names_table': '/content/vilio/ernie-vil/data/vcr/unisex_names_table.csv', 'Proprocessor': 'PreprocessorBasic', 'tokenizer_name': 'FullTokenizer', 'fusion_method': 'mul', 'dropout_rate': 0.1, 'max_seq_len': 128, 'use_gt_fea': True, 'shufflekeep_across_task': True, 'shuffle_every_epoch': True, 'task_weight': 1.0, 'task_prefix': 'hm'}]\n",
            "2022-05-31 15:50:59,900-WARNING: paddle.fluid.layers.py_reader() may be deprecated in the near future. Please use paddle.fluid.io.DataLoader.from_generator() instead.\n",
            "theoretical memory usage: \n",
            "(3678.2632896423343, 3853.418684387207, 'MB')\n",
            "args.is_distributed: False\n",
            "W0531 15:51:01.013104  2970 device_context.cc:252] Please NOTE: device: 0, CUDA Capability: 60, Driver API Version: 11.2, Runtime API Version: 9.0\n",
            "W0531 15:51:01.028839  2970 device_context.cc:260] device: 0, cuDNN Version: 7.6.\n",
            "SPLIT: test_unseen\n",
            "Start to load Faster-RCNN detected objects from /content/vilio/ernie-vil/data/hm/HM_img.tsv\n",
            "Loaded 2000 images in file /content/vilio/ernie-vil/data/hm/HM_img.tsv in 175 seconds.\n",
            "Start to load Faster-RCNN detected objects from /content/vilio/ernie-vil/data/hm/HM_gt_img.tsv\n",
            "Loaded 2000 images in file /content/vilio/ernie-vil/data/hm/HM_gt_img.tsv in 56 seconds.\n",
            "Load 2600 data from split(s) /content/vilio/ernie-vil/data/hm/test_unseenlong.jsonl.\n",
            "use gt featurre\n",
            "LEN:  2600\n",
            "Load pretraining parameters from /content/vilio/ernie-vil/output_hm/step_2500traindev.\n",
            "testing on hm val split\n",
            "task name list :  ['mean_0.tmp_0', 'accuracy_0.tmp_0', 'arg_max_0.tmp_0', 'read_file_0.tmp_9', 'read_file_0.tmp_8', 'reshape2_120.tmp_0']\n",
            "cur_step: 10 cur_acc: 0.9875\n",
            "cur_step: 20 cur_acc: 0.99375\n",
            "cur_step: 30 cur_acc: 0.9958333333333333\n",
            "cur_step: 40 cur_acc: 0.996875\n",
            "cur_step: 50 cur_acc: 0.9975\n",
            "cur_step: 60 cur_acc: 0.9979166666666667\n",
            "cur_step: 70 cur_acc: 0.9982142857142857\n",
            "cur_step: 80 cur_acc: 0.9984375\n",
            "cur_step: 90 cur_acc: 0.9986111111111111\n",
            "cur_step: 100 cur_acc: 0.99875\n",
            "cur_step: 110 cur_acc: 0.9988636363636364\n",
            "cur_step: 120 cur_acc: 0.9989583333333333\n",
            "cur_step: 130 cur_acc: 0.9990384615384615\n",
            "cur_step: 140 cur_acc: 0.9991071428571429\n",
            "cur_step: 150 cur_acc: 0.9991666666666666\n",
            "cur_step: 160 cur_acc: 0.99921875\n",
            "cur_step: 170 cur_acc: 0.9992647058823529\n",
            "cur_step: 180 cur_acc: 0.9993055555555556\n",
            "cur_step: 190 cur_acc: 0.9993421052631579\n",
            "cur_step: 200 cur_acc: 0.999375\n",
            "cur_step: 210 cur_acc: 0.9994047619047619\n",
            "cur_step: 220 cur_acc: 0.9994318181818181\n",
            "cur_step: 230 cur_acc: 0.9994565217391305\n",
            "cur_step: 240 cur_acc: 0.9994791666666667\n",
            "cur_step: 250 cur_acc: 0.9995\n",
            "cur_step: 260 cur_acc: 0.9990384615384615\n",
            "cur_step: 270 cur_acc: 0.9990740740740741\n",
            "cur_step: 280 cur_acc: 0.9991071428571429\n",
            "cur_step: 290 cur_acc: 0.9991379310344828\n",
            "cur_step: 300 cur_acc: 0.9991666666666666\n",
            "cur_step: 310 cur_acc: 0.9991935483870967\n",
            "cur_step: 320 cur_acc: 0.99921875\n",
            "EXCEPTING\n",
            "LEN: 2000 2000\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2000 entries, 0 to 1999\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   id      2000 non-null   int64  \n",
            " 1   proba   2000 non-null   float32\n",
            " 2   label   2000 non-null   int64  \n",
            "dtypes: float32(1), int64(2)\n",
            "memory usage: 39.2 KB\n",
            "None\n",
            "average_acc: 0.99921875\n",
            "rocauc: 0.6462079749804535\n",
            "Included in Simple Average:  dev_seenES36.csv\n",
            "Included in Simple Average:  dev_seenES72.csv\n",
            "Included in Simple Average:  dev_seenESV50.csv\n",
            "Included in Simple Average:  dev_seenESVCR36.csv\n",
            "Included in Simple Average:  dev_seenESVCR72.csv\n",
            "Included in Simple Average:  test_seenES36.csv\n",
            "Included in Simple Average:  test_seenES72.csv\n",
            "Included in Simple Average:  test_seenESV50.csv\n",
            "Included in Simple Average:  test_seenESVCR36.csv\n",
            "Included in Simple Average:  test_seenESVCR72.csv\n",
            "Included in Simple Average:  test_unseenES36.csv\n",
            "Included in Simple Average:  test_unseenES72.csv\n",
            "Included in Simple Average:  test_unseenESV50.csv\n",
            "Included in Simple Average:  test_unseenESVCR36.csv\n",
            "Included in Simple Average:  test_unseenESVCR72.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 3 h 6 min 49 s execution"
      ],
      "metadata": {
        "id": "By1MYO_21YAA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(\"/content/vilio/ernie-vil/data/hm\")"
      ],
      "metadata": {
        "id": "rtTPALTGA2fh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/vilio/ernie-vil/data/hm/ES365072/* /content/drive/MyDrive/2505Models/ernie-vil"
      ],
      "metadata": {
        "id": "OcGRPYvuBFZ6"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/vilio/ernie-vil/data/hm/ES365072/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSrSCrlqCAox",
        "outputId": "2508a740-a9b5-402c-aa2c-5983dc601a13"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ES365072_dev_seen_SA.csv   ES365072_test_unseen_SA.csv\n",
            "ES365072_test_seen_SA.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "ES365072_dev_seen_SA = pd.read_csv(\"/content/vilio/ernie-vil/data/hm/ES365072/ES365072_dev_seen_SA.csv\")\n",
        "ES365072_test_unseen_SA = pd.read_csv(\"/content/vilio/ernie-vil/data/hm/ES365072/ES365072_test_unseen_SA.csv\")\n",
        "ES365072_test_seen_SA = pd.read_csv(\"/content/vilio/ernie-vil/data/hm/ES365072/ES365072_test_seen_SA.csv\")"
      ],
      "metadata": {
        "id": "_LtJv9FlBwgi"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dev_seen = pd.read_json(\"/content/vilio/ernie-vil/data/hm/dev_seen.jsonl\", lines = True)\n",
        "test_seen = pd.read_json(\"/content/vilio/ernie-vil/data/hm/test_seen.jsonl\", lines = True)\n",
        "test_unseen = pd.read_json(\"/content/vilio/ernie-vil/data/hm/test_unseen.jsonl\", lines = True)"
      ],
      "metadata": {
        "id": "c6XAqeH1CM1K"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dev_seen.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKH90cfUCv4p",
        "outputId": "a79e3766-899b-4d90-c409-b9718f1d4ec6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(500, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ES365072_dev_seen_SA.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5i2ojWEPCxTA",
        "outputId": "8d133ef4-61e6-44a4-ee23-89a3b9ff75c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(500, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ES365072_dev_seen_SA"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "ZeKkvqI8DD-D",
        "outputId": "7f4c716d-ff10-4f69-d2b1-fc174fa2a448"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id     proba  label\n",
              "0     8291 -6.674554      0\n",
              "1    46971 -5.701749      0\n",
              "2     3745 -4.890941      0\n",
              "3    83745 -6.876825      0\n",
              "4    80243  3.244227      0\n",
              "..     ...       ...    ...\n",
              "495  83675 -6.290062      0\n",
              "496  37198 -8.780319      0\n",
              "497  48670 -7.524425      0\n",
              "498   9863 -7.005279      0\n",
              "499  97320 -7.885709      0\n",
              "\n",
              "[500 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c1ef13ef-8408-4088-b9a9-d2dd440418c9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>proba</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8291</td>\n",
              "      <td>-6.674554</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>46971</td>\n",
              "      <td>-5.701749</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3745</td>\n",
              "      <td>-4.890941</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>83745</td>\n",
              "      <td>-6.876825</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>80243</td>\n",
              "      <td>3.244227</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>83675</td>\n",
              "      <td>-6.290062</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>37198</td>\n",
              "      <td>-8.780319</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>48670</td>\n",
              "      <td>-7.524425</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>9863</td>\n",
              "      <td>-7.005279</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>97320</td>\n",
              "      <td>-7.885709</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c1ef13ef-8408-4088-b9a9-d2dd440418c9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c1ef13ef-8408-4088-b9a9-d2dd440418c9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c1ef13ef-8408-4088-b9a9-d2dd440418c9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dev_seen"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "YIaIc5OwDE_g",
        "outputId": "13d0554a-b71b-492d-ad3a-2f4165dfa32a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id            img  label  \\\n",
              "0     8291  img/08291.png      1   \n",
              "1    46971  img/46971.png      1   \n",
              "2     3745  img/03745.png      1   \n",
              "3    83745  img/83745.png      1   \n",
              "4    80243  img/80243.png      1   \n",
              "..     ...            ...    ...   \n",
              "495  83675  img/83675.png      0   \n",
              "496  37198  img/37198.png      0   \n",
              "497  48670  img/48670.png      0   \n",
              "498   9863  img/09863.png      0   \n",
              "499  97320  img/97320.png      0   \n",
              "\n",
              "                                                  text  \n",
              "0                white people is this a shooting range  \n",
              "1                                bravery at its finest  \n",
              "2    your order comes to $37.50 and your white priv...  \n",
              "3    it is time.. to send these parasites back to t...  \n",
              "4                               mississippi wind chime  \n",
              "..                                                 ...  \n",
              "495                   i'm gonna be like phelps one day  \n",
              "496  when you're so relaxed you can feel yourself g...  \n",
              "497  look at this sandwich maker club i found on wi...  \n",
              "498                             diverse group of women  \n",
              "499  \"when your dishwasher is broken so you take it...  \n",
              "\n",
              "[500 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3fe1e551-dfc2-44bd-87f7-45d6993ec769\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>img</th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8291</td>\n",
              "      <td>img/08291.png</td>\n",
              "      <td>1</td>\n",
              "      <td>white people is this a shooting range</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>46971</td>\n",
              "      <td>img/46971.png</td>\n",
              "      <td>1</td>\n",
              "      <td>bravery at its finest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3745</td>\n",
              "      <td>img/03745.png</td>\n",
              "      <td>1</td>\n",
              "      <td>your order comes to $37.50 and your white priv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>83745</td>\n",
              "      <td>img/83745.png</td>\n",
              "      <td>1</td>\n",
              "      <td>it is time.. to send these parasites back to t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>80243</td>\n",
              "      <td>img/80243.png</td>\n",
              "      <td>1</td>\n",
              "      <td>mississippi wind chime</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>83675</td>\n",
              "      <td>img/83675.png</td>\n",
              "      <td>0</td>\n",
              "      <td>i'm gonna be like phelps one day</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>37198</td>\n",
              "      <td>img/37198.png</td>\n",
              "      <td>0</td>\n",
              "      <td>when you're so relaxed you can feel yourself g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>48670</td>\n",
              "      <td>img/48670.png</td>\n",
              "      <td>0</td>\n",
              "      <td>look at this sandwich maker club i found on wi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>9863</td>\n",
              "      <td>img/09863.png</td>\n",
              "      <td>0</td>\n",
              "      <td>diverse group of women</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>97320</td>\n",
              "      <td>img/97320.png</td>\n",
              "      <td>0</td>\n",
              "      <td>\"when your dishwasher is broken so you take it...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3fe1e551-dfc2-44bd-87f7-45d6993ec769')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3fe1e551-dfc2-44bd-87f7-45d6993ec769 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3fe1e551-dfc2-44bd-87f7-45d6993ec769');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(ES365072_dev_seen_SA['label'] == dev_seen['label']).sum()/500"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rZEwjTXC1aR",
        "outputId": "a8ebf535-e9b5-4a0b-c80d-439d3fc3d3a2"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.506"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(ES365072_test_unseen_SA['label'] == test_unseen['label']).sum()/2000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhXbbsqzElQh",
        "outputId": "11b52722-9269-4a7f-a285-f74a294a620d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.625"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(ES365072_test_seen_SA['label'] == test_seen['label']).sum()/1000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLopqZikEl0P",
        "outputId": "cecd11a3-84bb-4c93-c7a3-cb91669b01e5"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.51"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "d6b_VyL_2TaX",
        "ioROtCsx2dxM",
        "ESIwA-mEx7Rv",
        "udCFF9nsxx-O",
        "CVClNfTN2n4t",
        "dp2fgvy2-IWd",
        "jbgyMPys-j8W",
        "_-9Q3p3H0VSx"
      ],
      "name": "Vilio-ERNIE-Vil.ipynb",
      "provenance": [],
      "mount_file_id": "1zrFLBwAjiqTESsglTg4fj8Ad9L31szJ4",
      "authorship_tag": "ABX9TyPeWf3yBKBhZmXjpmfAc93+",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}