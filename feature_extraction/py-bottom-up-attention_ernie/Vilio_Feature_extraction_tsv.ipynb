{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JanLeyva/approach_TFM/blob/master/Vilio_Feature_extraction_tsv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65KBwK5txKiZ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxg1188lxQ_U"
      },
      "source": [
        "#  <font color='#A8EB15'> <b> Vilio-Feature extrction tsv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6b_VyL_2TaX"
      },
      "source": [
        "### <font color='#A8EB15'> Environment characteristics and `Conda env`  if need"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9Hop6LvxPIO",
        "outputId": "8c5fa763-4bd5-40b6-f8d3-d1422798b868"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.7.13\n"
          ]
        }
      ],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!free -m"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yl1ve62oULxy",
        "outputId": "b71a7aaf-aa0f-4e9c-91b0-838374e6c894"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              total        used        free      shared  buff/cache   available\n",
            "Mem:          12986         602       10257           1        2126       12147\n",
            "Swap:             0           0           0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXJTAraH2NUB",
        "outputId": "554457b2-f703-48ae-852f-86e300fb75ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Mon_Oct_12_20:09:46_PDT_2020\n",
            "Cuda compilation tools, release 11.1, V11.1.105\n",
            "Build cuda_11.1.TC455_06.29190527_0\n",
            "Tue May 10 13:40:23 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!/usr/local/cuda/bin/nvcc --version\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "#MINICONDA_INSTALLER_SCRIPT=Miniconda3-4.5.4-Linux-x86_64.sh\n",
        "#MINICONDA_PREFIX=/usr/local\n",
        "#wget https://repo.continuum.io/miniconda/$MINICONDA_INSTALLER_SCRIPT\n",
        "#chmod +x $MINICONDA_INSTALLER_SCRIPT\n",
        "#./$MINICONDA_INSTALLER_SCRIPT -b -f -p $MINICONDA_PREFIX     "
      ],
      "metadata": {
        "id": "0Tcdwr-MRySL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import sys\n",
        "#_ = (sys.path.append(\"/usr/local/lib/python3.6/site-packages\"))"
      ],
      "metadata": {
        "id": "ZMmMQ7EzR9Fy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhKFK3RESIOS",
        "outputId": "5f73ba07-9cc1-4aed-d1a6-1c231edf32b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.7.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioROtCsx2dxM"
      },
      "source": [
        "### <font color='#A8EB15'> Clone repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVEo0-IGxVcs",
        "outputId": "5aceddcf-5cd2-461e-a665-b9ce14a2dd72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'vilio'...\n",
            "remote: Enumerating objects: 2956, done.\u001b[K\n",
            "remote: Counting objects: 100% (33/33), done.\u001b[K\n",
            "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
            "remote: Total 2956 (delta 13), reused 21 (delta 9), pack-reused 2923\u001b[K\n",
            "Receiving objects: 100% (2956/2956), 10.65 MiB | 29.57 MiB/s, done.\n",
            "Resolving deltas: 100% (1569/1569), done.\n"
          ]
        }
      ],
      "source": [
        "# clone original repo\n",
        "!git clone https://github.com/JanLeyva/vilio.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "e1KxhxFDxhMZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir(\"/content/vilio/py-bottom-up-attention\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhPhwAq-xliz",
        "outputId": "2c833a47-e45b-453f-f921-30098d14fcba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/facebookresearch/fvcore.git (from -r requirements.txt (line 1))\n",
            "  Cloning https://github.com/facebookresearch/fvcore.git to /tmp/pip-req-build-bhrhc4nd\n",
            "  Running command git clone -q https://github.com/facebookresearch/fvcore.git /tmp/pip-req-build-bhrhc4nd\n",
            "Collecting torch==1.4.0\n",
            "  Downloading torch-1.4.0-cp37-cp37m-manylinux1_x86_64.whl (753.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 753.4 MB 7.2 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.5.0\n",
            "  Downloading torchvision-0.5.0-cp37-cp37m-manylinux1_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 50.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (1.21.6)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (0.29.30)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (4.1.2.30)\n",
            "Collecting yacs>=0.1.6\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 65.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fvcore==0.1.5->-r requirements.txt (line 1)) (4.64.0)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from fvcore==0.1.5->-r requirements.txt (line 1)) (1.1.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from fvcore==0.1.5->-r requirements.txt (line 1)) (7.1.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from fvcore==0.1.5->-r requirements.txt (line 1)) (0.8.9)\n",
            "Collecting iopath>=0.1.7\n",
            "  Downloading iopath-0.1.9-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchvision==0.5.0->-r requirements.txt (line 3)) (1.15.0)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Building wheels for collected packages: fvcore\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5-py3-none-any.whl size=65176 sha256=e9a2f3f60a14fb9b7805fa48ecb221d8d3f1cd0f53db43ed18d1f65f9a7cadd1\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ym61f4si/wheels/24/1d/09/8167de727fe5b74f832b6fcb5d9069d8f03ca29f337bfe484d\n",
            "Successfully built fvcore\n",
            "Installing collected packages: pyyaml, portalocker, yacs, torch, iopath, torchvision, fvcore\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.11.0+cu113\n",
            "    Uninstalling torch-1.11.0+cu113:\n",
            "      Successfully uninstalled torch-1.11.0+cu113\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.12.0+cu113\n",
            "    Uninstalling torchvision-0.12.0+cu113:\n",
            "      Successfully uninstalled torchvision-0.12.0+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.4.0 which is incompatible.\n",
            "torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.4.0 which is incompatible.\u001b[0m\n",
            "Successfully installed fvcore-0.1.5 iopath-0.1.9 portalocker-2.4.0 pyyaml-6.0 torch-1.4.0 torchvision-0.5.0 yacs-0.1.8\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "vXAvUoNOxpZ4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0393c0fb-ffbd-45c8-84bf-e6dbc9255c68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI\n",
            "  Cloning https://github.com/cocodataset/cocoapi.git to /tmp/pip-req-build-f3qof5um\n",
            "  Running command git clone -q https://github.com/cocodataset/cocoapi.git /tmp/pip-req-build-f3qof5um\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools==2.0) (57.4.0)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.7/dist-packages (from pycocotools==2.0) (0.29.30)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools==2.0) (3.2.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.21.6)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=2.1.0->pycocotools==2.0) (4.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=2.1.0->pycocotools==2.0) (1.15.0)\n",
            "Building wheels for collected packages: pycocotools\n",
            "  Building wheel for pycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycocotools: filename=pycocotools-2.0-cp37-cp37m-linux_x86_64.whl size=265166 sha256=2715dd26d12da341d9637ac8abfbf8b9c4485720623dd020b6fef9bbd8442d6f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ggjqby9t/wheels/e2/6b/1d/344ac773c7495ea0b85eb228bc66daec7400a143a92d36b7b1\n",
            "Successfully built pycocotools\n",
            "Installing collected packages: pycocotools\n",
            "  Attempting uninstall: pycocotools\n",
            "    Found existing installation: pycocotools 2.0.4\n",
            "    Uninstalling pycocotools-2.0.4:\n",
            "      Successfully uninstalled pycocotools-2.0.4\n",
            "Successfully installed pycocotools-2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4WS12CmuxuEm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77eada3a-3f11-4e79-f1cd-5e639c355848"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running build\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib.linux-x86_64-3.7\n",
            "creating build/lib.linux-x86_64-3.7/detectron2\n",
            "copying detectron2/__init__.py -> build/lib.linux-x86_64-3.7/detectron2\n",
            "creating build/lib.linux-x86_64-3.7/detectron2/solver\n",
            "copying detectron2/solver/build.py -> build/lib.linux-x86_64-3.7/detectron2/solver\n",
            "copying detectron2/solver/lr_scheduler.py -> build/lib.linux-x86_64-3.7/detectron2/solver\n",
            "copying detectron2/solver/__init__.py -> build/lib.linux-x86_64-3.7/detectron2/solver\n",
            "creating build/lib.linux-x86_64-3.7/detectron2/engine\n",
            "copying detectron2/engine/launch.py -> build/lib.linux-x86_64-3.7/detectron2/engine\n",
            "copying detectron2/engine/defaults.py -> build/lib.linux-x86_64-3.7/detectron2/engine\n",
            "copying detectron2/engine/hooks.py -> build/lib.linux-x86_64-3.7/detectron2/engine\n",
            "copying detectron2/engine/train_loop.py -> build/lib.linux-x86_64-3.7/detectron2/engine\n",
            "copying detectron2/engine/__init__.py -> build/lib.linux-x86_64-3.7/detectron2/engine\n",
            "creating build/lib.linux-x86_64-3.7/detectron2/modeling\n",
            "copying detectron2/modeling/box_regression.py -> build/lib.linux-x86_64-3.7/detectron2/modeling\n",
            "copying detectron2/modeling/anchor_generator.py -> build/lib.linux-x86_64-3.7/detectron2/modeling\n",
            "copying detectron2/modeling/sampling.py -> build/lib.linux-x86_64-3.7/detectron2/modeling\n",
            "copying detectron2/modeling/__init__.py -> build/lib.linux-x86_64-3.7/detectron2/modeling\n",
            "copying detectron2/modeling/postprocessing.py -> build/lib.linux-x86_64-3.7/detectron2/modeling\n",
            "copying detectron2/modeling/matcher.py -> build/lib.linux-x86_64-3.7/detectron2/modeling\n",
            "copying detectron2/modeling/poolers.py -> build/lib.linux-x86_64-3.7/detectron2/modeling\n",
            "copying detectron2/modeling/test_time_augmentation.py -> build/lib.linux-x86_64-3.7/detectron2/modeling\n",
            "creating build/lib.linux-x86_64-3.7/detectron2/data\n",
            "copying detectron2/data/common.py -> build/lib.linux-x86_64-3.7/detectron2/data\n",
            "copying detectron2/data/build.py -> build/lib.linux-x86_64-3.7/detectron2/data\n",
            "copying detectron2/data/dataset_mapper.py -> build/lib.linux-x86_64-3.7/detectron2/data\n",
            "copying detectron2/data/detection_utils.py -> build/lib.linux-x86_64-3.7/detectron2/data\n",
            "copying detectron2/data/__init__.py -> build/lib.linux-x86_64-3.7/detectron2/data\n",
            "copying detectron2/data/catalog.py -> build/lib.linux-x86_64-3.7/detectron2/data\n",
            "creating build/lib.linux-x86_64-3.7/detectron2/evaluation\n",
            "copying detectron2/evaluation/sem_seg_evaluation.py -> build/lib.linux-x86_64-3.7/detectron2/evaluation\n",
            "copying detectron2/evaluation/pascal_voc_evaluation.py -> build/lib.linux-x86_64-3.7/detectron2/evaluation\n",
            "copying detectron2/evaluation/coco_evaluation.py -> build/lib.linux-x86_64-3.7/detectron2/evaluation\n",
            "copying detectron2/evaluation/cityscapes_evaluation.py -> build/lib.linux-x86_64-3.7/detectron2/evaluation\n",
            "copying detectron2/evaluation/evaluator.py -> build/lib.linux-x86_64-3.7/detectron2/evaluation\n",
            "copying detectron2/evaluation/lvis_evaluation.py -> build/lib.linux-x86_64-3.7/detectron2/evaluation\n",
            "copying detectron2/evaluation/testing.py -> build/lib.linux-x86_64-3.7/detectron2/evaluation\n",
            "copying detectron2/evaluation/__init__.py -> build/lib.linux-x86_64-3.7/detectron2/evaluation\n",
            "copying detectron2/evaluation/panoptic_evaluation.py -> build/lib.linux-x86_64-3.7/detectron2/evaluation\n",
            "creating build/lib.linux-x86_64-3.7/detectron2/checkpoint\n",
            "copying detectron2/checkpoint/detection_checkpoint.py -> build/lib.linux-x86_64-3.7/detectron2/checkpoint\n",
            "copying detectron2/checkpoint/__init__.py -> build/lib.linux-x86_64-3.7/detectron2/checkpoint\n",
            "copying detectron2/checkpoint/c2_model_loading.py -> build/lib.linux-x86_64-3.7/detectron2/checkpoint\n",
            "copying detectron2/checkpoint/catalog.py -> build/lib.linux-x86_64-3.7/detectron2/checkpoint\n",
            "creating build/lib.linux-x86_64-3.7/detectron2/model_zoo\n",
            "copying detectron2/model_zoo/model_zoo.py -> build/lib.linux-x86_64-3.7/detectron2/model_zoo\n",
            "copying detectron2/model_zoo/__init__.py -> build/lib.linux-x86_64-3.7/detectron2/model_zoo\n",
            "creating build/lib.linux-x86_64-3.7/detectron2/utils\n",
            "copying detectron2/utils/serialize.py -> build/lib.linux-x86_64-3.7/detectron2/utils\n",
            "copying detectron2/utils/events.py -> build/lib.linux-x86_64-3.7/detectron2/utils\n",
            "copying detectron2/utils/logger.py -> build/lib.linux-x86_64-3.7/detectron2/utils\n",
            "copying detectron2/utils/comm.py -> build/lib.linux-x86_64-3.7/detectron2/utils\n",
            "copying detectron2/utils/video_visualizer.py -> build/lib.linux-x86_64-3.7/detectron2/utils\n",
            "copying detectron2/utils/__init__.py -> build/lib.linux-x86_64-3.7/detectron2/utils\n",
            "copying detectron2/utils/memory.py -> build/lib.linux-x86_64-3.7/detectron2/utils\n",
            "copying detectron2/utils/colormap.py -> build/lib.linux-x86_64-3.7/detectron2/utils\n",
            "copying detectron2/utils/env.py -> build/lib.linux-x86_64-3.7/detectron2/utils\n",
            "copying detectron2/utils/registry.py -> build/lib.linux-x86_64-3.7/detectron2/utils\n",
            "copying detectron2/utils/collect_env.py -> build/lib.linux-x86_64-3.7/detectron2/utils\n",
            "copying detectron2/utils/visualizer.py -> build/lib.linux-x86_64-3.7/detectron2/utils\n",
            "creating build/lib.linux-x86_64-3.7/detectron2/structures\n",
            "copying detectron2/structures/keypoints.py -> build/lib.linux-x86_64-3.7/detectron2/structures\n",
            "copying detectron2/structures/masks.py -> build/lib.linux-x86_64-3.7/detectron2/structures\n",
            "copying detectron2/structures/boxes.py -> build/lib.linux-x86_64-3.7/detectron2/structures\n",
            "copying detectron2/structures/rotated_boxes.py -> build/lib.linux-x86_64-3.7/detectron2/structures\n",
            "copying detectron2/structures/__init__.py -> build/lib.linux-x86_64-3.7/detectron2/structures\n",
            "copying detectron2/structures/image_list.py -> build/lib.linux-x86_64-3.7/detectron2/structures\n",
            "copying detectron2/structures/instances.py -> build/lib.linux-x86_64-3.7/detectron2/structures\n",
            "creating build/lib.linux-x86_64-3.7/detectron2/config\n",
            "copying detectron2/config/config.py -> build/lib.linux-x86_64-3.7/detectron2/config\n",
            "copying detectron2/config/defaults.py -> build/lib.linux-x86_64-3.7/detectron2/config\n",
            "copying detectron2/config/compat.py -> build/lib.linux-x86_64-3.7/detectron2/config\n",
            "copying detectron2/config/__init__.py -> build/lib.linux-x86_64-3.7/detectron2/config\n",
            "creating build/lib.linux-x86_64-3.7/detectron2/layers\n",
            "copying detectron2/layers/deform_conv.py -> build/lib.linux-x86_64-3.7/detectron2/layers\n",
            "copying detectron2/layers/rotated_boxes.py -> build/lib.linux-x86_64-3.7/detectron2/layers\n",
            "copying detectron2/layers/__init__.py -> build/lib.linux-x86_64-3.7/detectron2/layers\n",
            "copying detectron2/layers/shape_spec.py -> build/lib.linux-x86_64-3.7/detectron2/layers\n",
            "copying detectron2/layers/mask_ops.py -> build/lib.linux-x86_64-3.7/detectron2/layers\n",
            "copying detectron2/layers/batch_norm.py -> build/lib.linux-x86_64-3.7/detectron2/layers\n",
            "copying detectron2/layers/roi_align.py -> build/lib.linux-x86_64-3.7/detectron2/layers\n",
            "copying detectron2/layers/roi_align_rotated.py -> build/lib.linux-x86_64-3.7/detectron2/layers\n",
            "copying detectron2/layers/nms.py -> build/lib.linux-x86_64-3.7/detectron2/layers\n",
            "copying detectron2/layers/wrappers.py -> build/lib.linux-x86_64-3.7/detectron2/layers\n",
            "creating build/lib.linux-x86_64-3.7/detectron2/modeling/proposal_generator\n",
            "copying detectron2/modeling/proposal_generator/rpn_outputs.py -> build/lib.linux-x86_64-3.7/detectron2/modeling/proposal_generator\n",
            "copying detectron2/modeling/proposal_generator/build.py -> build/lib.linux-x86_64-3.7/detectron2/modeling/proposal_generator\n",
            "copying detectron2/modeling/proposal_generator/proposal_utils.py -> build/lib.linux-x86_64-3.7/detectron2/modeling/proposal_generator\n",
            "copying detectron2/modeling/proposal_generator/rrpn.py -> build/lib.linux-x86_64-3.7/detectron2/modeling/proposal_generator\n",
            "copying detectron2/modeling/proposal_generator/__init__.py -> build/lib.linux-x86_64-3.7/detectron2/modeling/proposal_generator\n",
            "copying detectron2/modeling/proposal_generator/rrpn_outputs.py -> build/lib.linux-x86_64-3.7/detectron2/modeling/proposal_generator\n",
            "copying detectron2/modeling/proposal_generator/rpn.py -> build/lib.linux-x86_64-3.7/detectron2/modeling/proposal_generator\n",
            "creating build/lib.linux-x86_64-3.7/detectron2/modeling/meta_arch\n",
            "copying detectron2/modeling/meta_arch/semantic_seg.py -> build/lib.linux-x86_64-3.7/detectron2/modeling/meta_arch\n",
            "copying detectron2/modeling/meta_arch/build.py -> build/lib.linux-x86_64-3.7/detectron2/modeling/meta_arch\n",
            "copying detectron2/modeling/meta_arch/panoptic_fpn.py -> build/lib.linux-x86_64-3.7/detectron2/modeling/meta_arch\n",
            "copying detectron2/modeling/meta_arch/retinanet.py -> build/lib.linux-x86_64-3.7/detectron2/modeling/meta_arch\n",
            "copying detectron2/modeling/meta_arch/rcnn.py -> build/lib.linux-x86_64-3.7/detectron2/modeling/meta_arch\n",
            "copying detectron2/modeling/meta_arch/__init__.py -> build/lib.linux-x86_64-3.7/detectron2/modeling/meta_arch\n",
            "creating build/lib.linux-x86_64-3.7/detectron2/modeling/roi_heads\n",
            "copying detectron2/modeling/roi_heads/roi_heads.py -> build/lib.linux-x86_64-3.7/detectron2/modeling/roi_heads\n",
            "copying detectron2/modeling/roi_heads/mask_head.py -> build/lib.linux-x86_64-3.7/detectron2/modeling/roi_heads\n",
            "copying detectron2/modeling/roi_heads/cascade_rcnn.py -> build/lib.linux-x86_64-3.7/detectron2/modeling/roi_heads\n",
            "copying detectron2/modeling/roi_heads/box_head.py -> build/lib.linux-x86_64-3.7/detectron2/modeling/roi_heads\n",
            "copying detectron2/modeling/roi_heads/keypoint_head.py -> build/lib.linux-x86_64-3.7/detectron2/modeling/roi_heads\n",
            "copying detectron2/modeling/roi_heads/rotated_fast_rcnn.py -> build/lib.linux-x86_64-3.7/detectron2/modeling/roi_heads\n",
            "copying detectron2/modeling/roi_heads/__init__.py -> build/lib.linux-x86_64-3.7/detectron2/modeling/roi_heads\n",
            "copying detectron2/modeling/roi_heads/fast_rcnn.py -> build/lib.linux-x86_64-3.7/detectron2/modeling/roi_heads\n",
            "creating build/lib.linux-x86_64-3.7/detectron2/modeling/backbone\n",
            "copying detectron2/modeling/backbone/resnet.py -> build/lib.linux-x86_64-3.7/detectron2/modeling/backbone\n",
            "copying detectron2/modeling/backbone/backbone.py -> build/lib.linux-x86_64-3.7/detectron2/modeling/backbone\n",
            "copying detectron2/modeling/backbone/build.py -> build/lib.linux-x86_64-3.7/detectron2/modeling/backbone\n",
            "copying detectron2/modeling/backbone/fpn.py -> build/lib.linux-x86_64-3.7/detectron2/modeling/backbone\n",
            "copying detectron2/modeling/backbone/__init__.py -> build/lib.linux-x86_64-3.7/detectron2/modeling/backbone\n",
            "creating build/lib.linux-x86_64-3.7/detectron2/data/samplers\n",
            "copying detectron2/data/samplers/distributed_sampler.py -> build/lib.linux-x86_64-3.7/detectron2/data/samplers\n",
            "copying detectron2/data/samplers/grouped_batch_sampler.py -> build/lib.linux-x86_64-3.7/detectron2/data/samplers\n",
            "copying detectron2/data/samplers/__init__.py -> build/lib.linux-x86_64-3.7/detectron2/data/samplers\n",
            "creating build/lib.linux-x86_64-3.7/detectron2/data/datasets\n",
            "copying detectron2/data/datasets/lvis_v0_5_categories.py -> build/lib.linux-x86_64-3.7/detectron2/data/datasets\n",
            "copying detectron2/data/datasets/pascal_voc.py -> build/lib.linux-x86_64-3.7/detectron2/data/datasets\n",
            "copying detectron2/data/datasets/coco.py -> build/lib.linux-x86_64-3.7/detectron2/data/datasets\n",
            "copying detectron2/data/datasets/cityscapes.py -> build/lib.linux-x86_64-3.7/detectron2/data/datasets\n",
            "copying detectron2/data/datasets/lvis.py -> build/lib.linux-x86_64-3.7/detectron2/data/datasets\n",
            "copying detectron2/data/datasets/__init__.py -> build/lib.linux-x86_64-3.7/detectron2/data/datasets\n",
            "copying detectron2/data/datasets/builtin_meta.py -> build/lib.linux-x86_64-3.7/detectron2/data/datasets\n",
            "copying detectron2/data/datasets/builtin.py -> build/lib.linux-x86_64-3.7/detectron2/data/datasets\n",
            "copying detectron2/data/datasets/register_coco.py -> build/lib.linux-x86_64-3.7/detectron2/data/datasets\n",
            "creating build/lib.linux-x86_64-3.7/detectron2/data/transforms\n",
            "copying detectron2/data/transforms/transform.py -> build/lib.linux-x86_64-3.7/detectron2/data/transforms\n",
            "copying detectron2/data/transforms/__init__.py -> build/lib.linux-x86_64-3.7/detectron2/data/transforms\n",
            "copying detectron2/data/transforms/transform_gen.py -> build/lib.linux-x86_64-3.7/detectron2/data/transforms\n",
            "creating build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs\n",
            "copying detectron2/model_zoo/configs/Base-RCNN-FPN.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs\n",
            "copying detectron2/model_zoo/configs/Base-RCNN-C4.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs\n",
            "copying detectron2/model_zoo/configs/Base-RCNN-DilatedC5.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs\n",
            "copying detectron2/model_zoo/configs/Base-RetinaNet.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs\n",
            "creating build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/LVIS-InstanceSegmentation\n",
            "copying detectron2/model_zoo/configs/LVIS-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_1x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/LVIS-InstanceSegmentation\n",
            "copying detectron2/model_zoo/configs/LVIS-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/LVIS-InstanceSegmentation\n",
            "copying detectron2/model_zoo/configs/LVIS-InstanceSegmentation/mask_rcnn_R_101_FPN_1x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/LVIS-InstanceSegmentation\n",
            "creating build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/Detectron1-Comparisons\n",
            "copying detectron2/model_zoo/configs/Detectron1-Comparisons/keypoint_rcnn_R_50_FPN_1x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/Detectron1-Comparisons\n",
            "copying detectron2/model_zoo/configs/Detectron1-Comparisons/faster_rcnn_R_50_FPN_noaug_1x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/Detectron1-Comparisons\n",
            "copying detectron2/model_zoo/configs/Detectron1-Comparisons/mask_rcnn_R_50_FPN_noaug_1x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/Detectron1-Comparisons\n",
            "creating build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-Keypoints\n",
            "copying detectron2/model_zoo/configs/COCO-Keypoints/keypoint_rcnn_X_101_32x8d_FPN_3x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-Keypoints\n",
            "copying detectron2/model_zoo/configs/COCO-Keypoints/keypoint_rcnn_R_50_FPN_1x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-Keypoints\n",
            "copying detectron2/model_zoo/configs/COCO-Keypoints/keypoint_rcnn_R_101_FPN_3x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-Keypoints\n",
            "copying detectron2/model_zoo/configs/COCO-Keypoints/keypoint_rcnn_R_50_FPN_3x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-Keypoints\n",
            "copying detectron2/model_zoo/configs/COCO-Keypoints/Base-Keypoint-RCNN-FPN.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-Keypoints\n",
            "creating build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/Cityscapes\n",
            "copying detectron2/model_zoo/configs/Cityscapes/mask_rcnn_R_50_FPN.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/Cityscapes\n",
            "creating build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/PascalVOC-Detection\n",
            "copying detectron2/model_zoo/configs/PascalVOC-Detection/faster_rcnn_R_50_C4.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/PascalVOC-Detection\n",
            "copying detectron2/model_zoo/configs/PascalVOC-Detection/faster_rcnn_R_50_FPN.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/PascalVOC-Detection\n",
            "creating build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/VG-Detection\n",
            "copying detectron2/model_zoo/configs/VG-Detection/faster_rcnn_R_101_C4_caffe.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/VG-Detection\n",
            "copying detectron2/model_zoo/configs/VG-Detection/faster_rcnn_R_101_C4_caffemaxpool.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/VG-Detection\n",
            "copying detectron2/model_zoo/configs/VG-Detection/faster_rcnn_R_101_C4_attr_caffemaxpool.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/VG-Detection\n",
            "creating build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/quick_schedules\n",
            "copying detectron2/model_zoo/configs/quick_schedules/retinanet_R_50_FPN_inference_acc_test.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/quick_schedules\n",
            "copying detectron2/model_zoo/configs/quick_schedules/fast_rcnn_R_50_FPN_instant_test.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/quick_schedules\n",
            "copying detectron2/model_zoo/configs/quick_schedules/mask_rcnn_R_50_DC5_inference_acc_test.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/quick_schedules\n",
            "copying detectron2/model_zoo/configs/quick_schedules/rpn_R_50_FPN_instant_test.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/quick_schedules\n",
            "copying detectron2/model_zoo/configs/quick_schedules/panoptic_fpn_R_50_inference_acc_test.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/quick_schedules\n",
            "copying detectron2/model_zoo/configs/quick_schedules/semantic_R_50_FPN_inference_acc_test.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/quick_schedules\n",
            "copying detectron2/model_zoo/configs/quick_schedules/fast_rcnn_R_50_FPN_inference_acc_test.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/quick_schedules\n",
            "copying detectron2/model_zoo/configs/quick_schedules/mask_rcnn_R_50_FPN_instant_test.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/quick_schedules\n",
            "copying detectron2/model_zoo/configs/quick_schedules/panoptic_fpn_R_50_instant_test.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/quick_schedules\n",
            "copying detectron2/model_zoo/configs/quick_schedules/mask_rcnn_R_50_FPN_training_acc_test.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/quick_schedules\n",
            "copying detectron2/model_zoo/configs/quick_schedules/keypoint_rcnn_R_50_FPN_training_acc_test.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/quick_schedules\n",
            "copying detectron2/model_zoo/configs/quick_schedules/keypoint_rcnn_R_50_FPN_inference_acc_test.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/quick_schedules\n",
            "copying detectron2/model_zoo/configs/quick_schedules/mask_rcnn_R_50_C4_training_acc_test.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/quick_schedules\n",
            "copying detectron2/model_zoo/configs/quick_schedules/keypoint_rcnn_R_50_FPN_normalized_training_acc_test.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/quick_schedules\n",
            "copying detectron2/model_zoo/configs/quick_schedules/semantic_R_50_FPN_training_acc_test.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/quick_schedules\n",
            "copying detectron2/model_zoo/configs/quick_schedules/retinanet_R_50_FPN_instant_test.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/quick_schedules\n",
            "copying detectron2/model_zoo/configs/quick_schedules/panoptic_fpn_R_50_training_acc_test.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/quick_schedules\n",
            "copying detectron2/model_zoo/configs/quick_schedules/mask_rcnn_R_50_FPN_inference_acc_test.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/quick_schedules\n",
            "copying detectron2/model_zoo/configs/quick_schedules/rpn_R_50_FPN_inference_acc_test.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/quick_schedules\n",
            "copying detectron2/model_zoo/configs/quick_schedules/semantic_R_50_FPN_instant_test.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/quick_schedules\n",
            "copying detectron2/model_zoo/configs/quick_schedules/mask_rcnn_R_50_C4_instant_test.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/quick_schedules\n",
            "copying detectron2/model_zoo/configs/quick_schedules/keypoint_rcnn_R_50_FPN_instant_test.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/quick_schedules\n",
            "copying detectron2/model_zoo/configs/quick_schedules/mask_rcnn_R_50_C4_inference_acc_test.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/quick_schedules\n",
            "creating build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-Detection\n",
            "copying detectron2/model_zoo/configs/COCO-Detection/faster_rcnn_R_101_DC5_3x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-Detection\n",
            "copying detectron2/model_zoo/configs/COCO-Detection/faster_rcnn_R_50_C4_1x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-Detection\n",
            "copying detectron2/model_zoo/configs/COCO-Detection/retinanet_R_101_FPN_3x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-Detection\n",
            "copying detectron2/model_zoo/configs/COCO-Detection/retinanet_R_50_FPN_1x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-Detection\n",
            "copying detectron2/model_zoo/configs/COCO-Detection/rpn_R_50_FPN_1x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-Detection\n",
            "copying detectron2/model_zoo/configs/COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-Detection\n",
            "copying detectron2/model_zoo/configs/COCO-Detection/faster_rcnn_R_50_DC5_1x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-Detection\n",
            "copying detectron2/model_zoo/configs/COCO-Detection/rpn_R_50_C4_1x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-Detection\n",
            "copying detectron2/model_zoo/configs/COCO-Detection/faster_rcnn_R_50_DC5_3x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-Detection\n",
            "copying detectron2/model_zoo/configs/COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-Detection\n",
            "copying detectron2/model_zoo/configs/COCO-Detection/faster_rcnn_R_101_C4_3x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-Detection\n",
            "copying detectron2/model_zoo/configs/COCO-Detection/faster_rcnn_R_50_C4_3x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-Detection\n",
            "copying detectron2/model_zoo/configs/COCO-Detection/faster_rcnn_R_50_FPN_1x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-Detection\n",
            "copying detectron2/model_zoo/configs/COCO-Detection/fast_rcnn_R_50_FPN_1x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-Detection\n",
            "copying detectron2/model_zoo/configs/COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-Detection\n",
            "copying detectron2/model_zoo/configs/COCO-Detection/retinanet_R_50_FPN_3x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-Detection\n",
            "creating build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-InstanceSegmentation\n",
            "copying detectron2/model_zoo/configs/COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-InstanceSegmentation\n",
            "copying detectron2/model_zoo/configs/COCO-InstanceSegmentation/mask_rcnn_R_101_C4_3x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-InstanceSegmentation\n",
            "copying detectron2/model_zoo/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-InstanceSegmentation\n",
            "copying detectron2/model_zoo/configs/COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-InstanceSegmentation\n",
            "copying detectron2/model_zoo/configs/COCO-InstanceSegmentation/mask_rcnn_R_101_DC5_3x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-InstanceSegmentation\n",
            "copying detectron2/model_zoo/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-InstanceSegmentation\n",
            "copying detectron2/model_zoo/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_DC5_3x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-InstanceSegmentation\n",
            "copying detectron2/model_zoo/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_C4_3x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-InstanceSegmentation\n",
            "copying detectron2/model_zoo/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_DC5_1x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-InstanceSegmentation\n",
            "copying detectron2/model_zoo/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_C4_1x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-InstanceSegmentation\n",
            "creating build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-PanopticSegmentation\n",
            "copying detectron2/model_zoo/configs/COCO-PanopticSegmentation/panoptic_fpn_R_50_1x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-PanopticSegmentation\n",
            "copying detectron2/model_zoo/configs/COCO-PanopticSegmentation/panoptic_fpn_R_50_3x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-PanopticSegmentation\n",
            "copying detectron2/model_zoo/configs/COCO-PanopticSegmentation/panoptic_fpn_R_101_3x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-PanopticSegmentation\n",
            "copying detectron2/model_zoo/configs/COCO-PanopticSegmentation/Base-Panoptic-FPN.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/COCO-PanopticSegmentation\n",
            "creating build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/Misc\n",
            "copying detectron2/model_zoo/configs/Misc/panoptic_fpn_R_101_dconv_cascade_gn_3x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/Misc\n",
            "copying detectron2/model_zoo/configs/Misc/mask_rcnn_R_50_FPN_1x_dconv_c3-c5.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/Misc\n",
            "copying detectron2/model_zoo/configs/Misc/cascade_mask_rcnn_R_50_FPN_3x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/Misc\n",
            "copying detectron2/model_zoo/configs/Misc/mask_rcnn_R_50_FPN_3x_dconv_c3-c5.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/Misc\n",
            "copying detectron2/model_zoo/configs/Misc/mask_rcnn_R_50_FPN_1x_cls_agnostic.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/Misc\n",
            "copying detectron2/model_zoo/configs/Misc/cascade_mask_rcnn_R_50_FPN_1x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/Misc\n",
            "copying detectron2/model_zoo/configs/Misc/scratch_mask_rcnn_R_50_FPN_3x_gn.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/Misc\n",
            "copying detectron2/model_zoo/configs/Misc/cascade_mask_rcnn_X_152_32x8d_FPN_IN5k_gn_dconv.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/Misc\n",
            "copying detectron2/model_zoo/configs/Misc/mask_rcnn_R_50_FPN_3x_syncbn.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/Misc\n",
            "copying detectron2/model_zoo/configs/Misc/semantic_R_50_FPN_1x.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/Misc\n",
            "copying detectron2/model_zoo/configs/Misc/mask_rcnn_R_50_FPN_3x_gn.yaml -> build/lib.linux-x86_64-3.7/detectron2/model_zoo/configs/Misc\n",
            "running build_ext\n",
            "building 'detectron2._C' extension\n",
            "creating build/temp.linux-x86_64-3.7\n",
            "creating build/temp.linux-x86_64-3.7/content\n",
            "creating build/temp.linux-x86_64-3.7/content/vilio\n",
            "creating build/temp.linux-x86_64-3.7/content/vilio/py-bottom-up-attention\n",
            "creating build/temp.linux-x86_64-3.7/content/vilio/py-bottom-up-attention/detectron2\n",
            "creating build/temp.linux-x86_64-3.7/content/vilio/py-bottom-up-attention/detectron2/layers\n",
            "creating build/temp.linux-x86_64-3.7/content/vilio/py-bottom-up-attention/detectron2/layers/csrc\n",
            "creating build/temp.linux-x86_64-3.7/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlign\n",
            "creating build/temp.linux-x86_64-3.7/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlignRotated\n",
            "creating build/temp.linux-x86_64-3.7/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/nms_rotated\n",
            "creating build/temp.linux-x86_64-3.7/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/box_iou_rotated\n",
            "creating build/temp.linux-x86_64-3.7/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_CUDA -I/content/vilio/py-bottom-up-attention/detectron2/layers/csrc -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp -o build/temp.linux-x86_64-3.7/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kint detectron2::deform_conv_forward(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, int, int, int, int, int, int, int, int, int, int, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::\u001b[01;35m\u001b[Kd\u001b[m\u001b[Keprecated_AT_CHECK();                 \\\n",
            "                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:136:5:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "     \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(weight.type().is_cuda(), \"weight tensor is not on GPU!\");\n",
            "     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::deprecated_AT_CHECK(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                 \\\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:136:5:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "     \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(weight.type().is_cuda(), \"weight tensor is not on GPU!\");\n",
            "     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::\u001b[01;35m\u001b[Kd\u001b[m\u001b[Keprecated_AT_CHECK();                 \\\n",
            "                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:137:5:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "     \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(offset.type().is_cuda(), \"offset tensor is not on GPU!\");\n",
            "     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::deprecated_AT_CHECK(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                 \\\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:137:5:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "     \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(offset.type().is_cuda(), \"offset tensor is not on GPU!\");\n",
            "     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kint detectron2::deform_conv_backward_input(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, int, int, int, int, int, int, int, int, int, int, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::\u001b[01;35m\u001b[Kd\u001b[m\u001b[Keprecated_AT_CHECK();                 \\\n",
            "                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:184:5:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "     \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(input.type().is_cuda(), \"input tensor is not on GPU!\");\n",
            "     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::deprecated_AT_CHECK(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                 \\\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:184:5:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "     \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(input.type().is_cuda(), \"input tensor is not on GPU!\");\n",
            "     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::\u001b[01;35m\u001b[Kd\u001b[m\u001b[Keprecated_AT_CHECK();                 \\\n",
            "                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:185:5:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "     \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(weight.type().is_cuda(), \"weight tensor is not on GPU!\");\n",
            "     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::deprecated_AT_CHECK(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                 \\\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:185:5:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "     \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(weight.type().is_cuda(), \"weight tensor is not on GPU!\");\n",
            "     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::\u001b[01;35m\u001b[Kd\u001b[m\u001b[Keprecated_AT_CHECK();                 \\\n",
            "                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:186:5:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "     \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(offset.type().is_cuda(), \"offset tensor is not on GPU!\");\n",
            "     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::deprecated_AT_CHECK(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                 \\\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:186:5:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "     \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(offset.type().is_cuda(), \"offset tensor is not on GPU!\");\n",
            "     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kint detectron2::deform_conv_backward_filter(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, int, int, int, int, int, int, int, int, int, int, float, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::\u001b[01;35m\u001b[Kd\u001b[m\u001b[Keprecated_AT_CHECK();                 \\\n",
            "                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:234:5:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "     \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(input.type().is_cuda(), \"input tensor is not on GPU!\");\n",
            "     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::deprecated_AT_CHECK(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                 \\\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:234:5:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "     \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(input.type().is_cuda(), \"input tensor is not on GPU!\");\n",
            "     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::\u001b[01;35m\u001b[Kd\u001b[m\u001b[Keprecated_AT_CHECK();                 \\\n",
            "                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:235:5:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "     \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(offset.type().is_cuda(), \"offset tensor is not on GPU!\");\n",
            "     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::deprecated_AT_CHECK(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                 \\\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:235:5:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "     \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(offset.type().is_cuda(), \"offset tensor is not on GPU!\");\n",
            "     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid detectron2::modulated_deform_conv_forward(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, int, int, int, int, int, int, int, int, int, int, bool)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::\u001b[01;35m\u001b[Kd\u001b[m\u001b[Keprecated_AT_CHECK();                 \\\n",
            "                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:284:5:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "     \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(weight.type().is_cuda(), \"weight tensor is not on GPU!\");\n",
            "     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::deprecated_AT_CHECK(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                 \\\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:284:5:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "     \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(weight.type().is_cuda(), \"weight tensor is not on GPU!\");\n",
            "     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::\u001b[01;35m\u001b[Kd\u001b[m\u001b[Keprecated_AT_CHECK();                 \\\n",
            "                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:285:5:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "     \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(bias.type().is_cuda(), \"bias tensor is not on GPU!\");\n",
            "     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::deprecated_AT_CHECK(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                 \\\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:285:5:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "     \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(bias.type().is_cuda(), \"bias tensor is not on GPU!\");\n",
            "     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::\u001b[01;35m\u001b[Kd\u001b[m\u001b[Keprecated_AT_CHECK();                 \\\n",
            "                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:286:5:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "     \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(offset.type().is_cuda(), \"offset tensor is not on GPU!\");\n",
            "     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::deprecated_AT_CHECK(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                 \\\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:286:5:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "     \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(offset.type().is_cuda(), \"offset tensor is not on GPU!\");\n",
            "     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid detectron2::modulated_deform_conv_backward(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, int, int, int, int, int, int, int, int, int, int, bool)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::\u001b[01;35m\u001b[Kd\u001b[m\u001b[Keprecated_AT_CHECK();                 \\\n",
            "                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:341:5:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "     \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(input.type().is_cuda(), \"input tensor is not on GPU!\");\n",
            "     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::deprecated_AT_CHECK(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                 \\\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:341:5:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "     \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(input.type().is_cuda(), \"input tensor is not on GPU!\");\n",
            "     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::\u001b[01;35m\u001b[Kd\u001b[m\u001b[Keprecated_AT_CHECK();                 \\\n",
            "                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:342:5:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "     \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(weight.type().is_cuda(), \"weight tensor is not on GPU!\");\n",
            "     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::deprecated_AT_CHECK(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                 \\\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:342:5:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "     \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(weight.type().is_cuda(), \"weight tensor is not on GPU!\");\n",
            "     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::\u001b[01;35m\u001b[Kd\u001b[m\u001b[Keprecated_AT_CHECK();                 \\\n",
            "                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:343:5:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "     \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(bias.type().is_cuda(), \"bias tensor is not on GPU!\");\n",
            "     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::deprecated_AT_CHECK(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                 \\\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:343:5:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "     \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(bias.type().is_cuda(), \"bias tensor is not on GPU!\");\n",
            "     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::\u001b[01;35m\u001b[Kd\u001b[m\u001b[Keprecated_AT_CHECK();                 \\\n",
            "                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:344:5:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "     \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(offset.type().is_cuda(), \"offset tensor is not on GPU!\");\n",
            "     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:355:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     ::c10::detail::deprecated_AT_CHECK(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                 \\\n",
            "                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:344:5:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_CHECK\u001b[m\u001b[K’\n",
            "     \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_CHECK(offset.type().is_cuda(), \"offset tensor is not on GPU!\");\n",
            "     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline void \u001b[01;36m\u001b[Kdeprecated_AT_CHECK\u001b[m\u001b[K() {}\n",
            "             \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_CUDA -I/content/vilio/py-bottom-up-attention/detectron2/layers/csrc -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlign/ROIAlign_cpu.cpp -o build/temp.linux-x86_64-3.7/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlign/ROIAlign_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlign/ROIAlign.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlign/ROIAlign_cpu.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlign/ROIAlign_cpu.cpp:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:116:56:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     at::ScalarType _st = ::detail::scalar_type(the_type\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                    \\\n",
            "                                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlign/ROIAlign_cpu.cpp:429:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_DISPATCH_FLOATING_TYPES_AND_HALF\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"ROIAlign_forward\", [&] {\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:31:23:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline at::ScalarType \u001b[01;36m\u001b[Kscalar_type\u001b[m\u001b[K(const at::DeprecatedTypeProperties &t) {\n",
            "                       \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlign/ROIAlign_cpu.cpp:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:116:56:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     at::ScalarType _st = ::detail::scalar_type(the_type\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                    \\\n",
            "                                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlign/ROIAlign_cpu.cpp:481:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_DISPATCH_FLOATING_TYPES_AND_HALF\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_DISPATCH_FLOATING_TYPES_AND_HALF(grad.type(), \"ROIAlign_forward\", [&] {\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:31:23:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline at::ScalarType \u001b[01;36m\u001b[Kscalar_type\u001b[m\u001b[K(const at::DeprecatedTypeProperties &t) {\n",
            "                       \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_CUDA -I/content/vilio/py-bottom-up-attention/detectron2/layers/csrc -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.cpp -o build/temp.linux-x86_64-3.7/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.cpp:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:116:56:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     at::ScalarType _st = ::detail::scalar_type(the_type\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                    \\\n",
            "                                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.cpp:446:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_DISPATCH_FLOATING_TYPES_AND_HALF\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:31:23:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline at::ScalarType \u001b[01;36m\u001b[Kscalar_type\u001b[m\u001b[K(const at::DeprecatedTypeProperties &t) {\n",
            "                       \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.cpp:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:116:56:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     at::ScalarType _st = ::detail::scalar_type(the_type\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                    \\\n",
            "                                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.cpp:497:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_DISPATCH_FLOATING_TYPES_AND_HALF\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:31:23:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline at::ScalarType \u001b[01;36m\u001b[Kscalar_type\u001b[m\u001b[K(const at::DeprecatedTypeProperties &t) {\n",
            "                       \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_CUDA -I/content/vilio/py-bottom-up-attention/detectron2/layers/csrc -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/vilio/py-bottom-up-attention/detectron2/layers/csrc/nms_rotated/nms_rotated_cpu.cpp -o build/temp.linux-x86_64-3.7/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/nms_rotated/nms_rotated_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/nms_rotated/nms_rotated.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/nms_rotated/nms_rotated_cpu.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/nms_rotated/nms_rotated_cpu.cpp:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:103:56:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     at::ScalarType _st = ::detail::scalar_type(the_type\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                    \\\n",
            "                                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/nms_rotated/nms_rotated_cpu.cpp:67:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_DISPATCH_FLOATING_TYPES\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KAT_DISPATCH_FLOATING_TYPES\u001b[m\u001b[K(dets.type(), \"nms_rotated\", [&] {\n",
            "   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:31:23:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline at::ScalarType \u001b[01;36m\u001b[Kscalar_type\u001b[m\u001b[K(const at::DeprecatedTypeProperties &t) {\n",
            "                       \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_CUDA -I/content/vilio/py-bottom-up-attention/detectron2/layers/csrc -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/vilio/py-bottom-up-attention/detectron2/layers/csrc/box_iou_rotated/box_iou_rotated_cpu.cpp -o build/temp.linux-x86_64-3.7/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/box_iou_rotated/box_iou_rotated_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/vilio/py-bottom-up-attention/detectron2/layers/csrc -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlign/ROIAlign_cuda.cu -o build/temp.linux-x86_64-3.7/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlign/ROIAlign_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++11\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/vilio/py-bottom-up-attention/detectron2/layers/csrc -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cuda.cu -o build/temp.linux-x86_64-3.7/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++11\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/vilio/py-bottom-up-attention/detectron2/layers/csrc -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda_kernel.cu -o build/temp.linux-x86_64-3.7/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++11\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda_kernel.cu:486:100:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:31:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline at::\u001b[m\u001b[KScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda_kernel.cu:555:101:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                     \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:31:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline at::\u001b[m\u001b[KScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda_kernel.cu:625:101:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                     \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:31:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline at::\u001b[m\u001b[KScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda_kernel.cu:1098:100:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:31:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline at::\u001b[m\u001b[KScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda_kernel.cu:1168:101:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                     \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:31:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline at::\u001b[m\u001b[KScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda_kernel.cu:1241:101:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                     \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:31:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline at::\u001b[m\u001b[KScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/vilio/py-bottom-up-attention/detectron2/layers/csrc -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu -o build/temp.linux-x86_64-3.7/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++11\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kint detectron2::deform_conv_forward(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, int, int, int, int, int, int, int, int, int, int, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:136:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_CHECK(weight.\u001b[01;35m\u001b[Ktype().is_cuda(), \"\u001b[m\u001b[Kweight tensor is not on GPU!\");\n",
            "                     \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:136:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_CHECK(weight.type().is_cuda(), \"w\u001b[01;35m\u001b[Ke\u001b[m\u001b[Kight tensor is not on GPU!\");\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:137:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_CHECK(offset.\u001b[01;35m\u001b[Ktype().is_cuda(), \"\u001b[m\u001b[Koffset tensor is not on GPU!\");\n",
            "                     \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:137:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_CHECK(offset.type().is_cuda(), \"o\u001b[01;35m\u001b[Kf\u001b[m\u001b[Kfset tensor is not on GPU!\");\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kint detectron2::deform_conv_backward_input(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, int, int, int, int, int, int, int, int, int, int, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:184:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_CHECK(input.t\u001b[01;35m\u001b[Kype().is_cuda(), \"i\u001b[m\u001b[Knput tensor is not on GPU!\");\n",
            "                     \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:184:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_CHECK(input.type().is_cuda(), \"in\u001b[01;35m\u001b[Kp\u001b[m\u001b[Kut tensor is not on GPU!\");\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:185:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_CHECK(weight.\u001b[01;35m\u001b[Ktype().is_cuda(), \"\u001b[m\u001b[Kweight tensor is not on GPU!\");\n",
            "                     \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:185:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_CHECK(weight.type().is_cuda(), \"w\u001b[01;35m\u001b[Ke\u001b[m\u001b[Kight tensor is not on GPU!\");\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:186:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_CHECK(offset.\u001b[01;35m\u001b[Ktype().is_cuda(), \"\u001b[m\u001b[Koffset tensor is not on GPU!\");\n",
            "                     \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:186:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_CHECK(offset.type().is_cuda(), \"o\u001b[01;35m\u001b[Kf\u001b[m\u001b[Kfset tensor is not on GPU!\");\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kint detectron2::deform_conv_backward_filter(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, int, int, int, int, int, int, int, int, int, int, float, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:234:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_CHECK(input.t\u001b[01;35m\u001b[Kype().is_cuda(), \"i\u001b[m\u001b[Knput tensor is not on GPU!\");\n",
            "                     \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:234:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_CHECK(input.type().is_cuda(), \"in\u001b[01;35m\u001b[Kp\u001b[m\u001b[Kut tensor is not on GPU!\");\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:235:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_CHECK(offset.\u001b[01;35m\u001b[Ktype().is_cuda(), \"\u001b[m\u001b[Koffset tensor is not on GPU!\");\n",
            "                     \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:235:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_CHECK(offset.type().is_cuda(), \"o\u001b[01;35m\u001b[Kf\u001b[m\u001b[Kfset tensor is not on GPU!\");\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid detectron2::modulated_deform_conv_forward(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, int, int, int, int, int, int, int, int, int, int, bool)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:284:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_CHECK(weight.\u001b[01;35m\u001b[Ktype().is_cuda(), \"\u001b[m\u001b[Kweight tensor is not on GPU!\");\n",
            "                     \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:284:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_CHECK(weight.type().is_cuda(), \"w\u001b[01;35m\u001b[Ke\u001b[m\u001b[Kight tensor is not on GPU!\");\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:285:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_CHECK(bias.ty\u001b[01;35m\u001b[Kpe().is_cuda(), \"bi\u001b[m\u001b[Kas tensor is not on GPU!\");\n",
            "                     \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:285:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_CHECK(bias.type().is_cuda(), \"bia\u001b[01;35m\u001b[Ks\u001b[m\u001b[K tensor is not on GPU!\");\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:286:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_CHECK(offset.\u001b[01;35m\u001b[Ktype().is_cuda(), \"\u001b[m\u001b[Koffset tensor is not on GPU!\");\n",
            "                     \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:286:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_CHECK(offset.type().is_cuda(), \"o\u001b[01;35m\u001b[Kf\u001b[m\u001b[Kfset tensor is not on GPU!\");\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid detectron2::modulated_deform_conv_backward(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, int, int, int, int, int, int, int, int, int, int, bool)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:341:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_CHECK(input.t\u001b[01;35m\u001b[Kype().is_cuda(), \"i\u001b[m\u001b[Knput tensor is not on GPU!\");\n",
            "                     \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:341:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_CHECK(input.type().is_cuda(), \"in\u001b[01;35m\u001b[Kp\u001b[m\u001b[Kut tensor is not on GPU!\");\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:342:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_CHECK(weight.\u001b[01;35m\u001b[Ktype().is_cuda(), \"\u001b[m\u001b[Kweight tensor is not on GPU!\");\n",
            "                     \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:342:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_CHECK(weight.type().is_cuda(), \"w\u001b[01;35m\u001b[Ke\u001b[m\u001b[Kight tensor is not on GPU!\");\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:343:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_CHECK(bias.ty\u001b[01;35m\u001b[Kpe().is_cuda(), \"bi\u001b[m\u001b[Kas tensor is not on GPU!\");\n",
            "                     \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:343:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_CHECK(bias.type().is_cuda(), \"bia\u001b[01;35m\u001b[Ks\u001b[m\u001b[K tensor is not on GPU!\");\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:344:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_CHECK(offset.\u001b[01;35m\u001b[Ktype().is_cuda(), \"\u001b[m\u001b[Koffset tensor is not on GPU!\");\n",
            "                     \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv.h:344:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_CHECK(offset.type().is_cuda(), \"o\u001b[01;35m\u001b[Kf\u001b[m\u001b[Kfset tensor is not on GPU!\");\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid detectron2::shape_check(at::Tensor, at::Tensor, at::Tensor*, at::Tensor, int, int, int, int, int, int, int, int, int, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:155:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK(\n",
            "                     \u001b[01;35m\u001b[K^\u001b[m\u001b[K                  \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:155:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK(\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:161:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK(weight.is\u001b[01;35m\u001b[K_contiguous(), \"wei\u001b[m\u001b[Kght tensor has to be contiguous\");\n",
            "                     \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:161:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK(weight.is_contiguous(), \"weig\u001b[01;35m\u001b[Kh\u001b[m\u001b[Kt tensor has to be contiguous\");\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:163:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK(\n",
            "                     \u001b[01;35m\u001b[K^\u001b[m\u001b[K                  \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:163:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK(\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:169:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK(\n",
            "                     \u001b[01;35m\u001b[K^\u001b[m\u001b[K                  \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:169:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK(\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:178:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK(\n",
            "                     \u001b[01;35m\u001b[K^\u001b[m\u001b[K                  \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:178:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK(\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:184:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK(\n",
            "                     \u001b[01;35m\u001b[K^\u001b[m\u001b[K                  \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:184:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK(\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:201:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK(\n",
            "                     \u001b[01;35m\u001b[K^\u001b[m\u001b[K                  \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:201:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK(\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:215:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK(\n",
            "                     \u001b[01;35m\u001b[K^\u001b[m\u001b[K                  \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:215:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK(\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:230:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK(\n",
            "                     \u001b[01;35m\u001b[K^\u001b[m\u001b[K                  \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:230:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK(\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:236:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK(\n",
            "                     \u001b[01;35m\u001b[K^\u001b[m\u001b[K                  \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:236:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK(\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:240:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK(\n",
            "                     \u001b[01;35m\u001b[K^\u001b[m\u001b[K                  \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:240:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK(\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:249:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK(\n",
            "                     \u001b[01;35m\u001b[K^\u001b[m\u001b[K                  \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:249:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK(\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:254:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_CHECK(\n",
            "                     \u001b[01;35m\u001b[K^\u001b[m\u001b[K                  \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:254:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_CHECK(\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:260:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_CHECK(\n",
            "                     \u001b[01;35m\u001b[K^\u001b[m\u001b[K                  \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:260:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     AT_CHECK(\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kint detectron2::deform_conv_forward_cuda(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, int, int, int, int, int, int, int, int, int, int, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:338:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK((offset.s\u001b[01;35m\u001b[Kize(0) == batchSize\u001b[m\u001b[K), \"invalid batch size of offset\");\n",
            "                     \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:338:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK((offset.size(0) == batchSize)\u001b[01;35m\u001b[K,\u001b[m\u001b[K \"invalid batch size of offset\");\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kint detectron2::deform_conv_backward_input_cuda(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, int, int, int, int, int, int, int, int, int, int, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:503:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK((offset.s\u001b[01;35m\u001b[Kize(0) == batchSize\u001b[m\u001b[K), 3, \"invalid batch size of offset\");\n",
            "                     \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:503:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK((offset.size(0) == batchSize)\u001b[01;35m\u001b[K,\u001b[m\u001b[K 3, \"invalid batch size of offset\");\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kint detectron2::deform_conv_backward_parameters_cuda(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, int, int, int, int, int, int, int, int, int, int, float, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:696:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK((offset.s\u001b[01;35m\u001b[Kize(0) == batchSize\u001b[m\u001b[K), \"invalid batch size of offset\");\n",
            "                     \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:696:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK((offset.size(0) == batchSize)\u001b[01;35m\u001b[K,\u001b[m\u001b[K \"invalid batch size of offset\");\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid detectron2::modulated_deform_conv_cuda_forward(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, int, int, int, int, int, int, int, int, int, int, bool)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:823:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK(input.is_\u001b[01;35m\u001b[Kcontiguous(), \"inpu\u001b[m\u001b[Kt tensor has to be contiguous\");\n",
            "                     \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:823:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK(input.is_contiguous(), \"input\u001b[01;35m\u001b[K \u001b[m\u001b[Ktensor has to be contiguous\");\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:824:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK(weight.is\u001b[01;35m\u001b[K_contiguous(), \"wei\u001b[m\u001b[Kght tensor has to be contiguous\");\n",
            "                     \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:824:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK(weight.is_contiguous(), \"weig\u001b[01;35m\u001b[Kh\u001b[m\u001b[Kt tensor has to be contiguous\");\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid detectron2::modulated_deform_conv_cuda_backward(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, int, int, int, int, int, int, int, int, int, int, bool)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:953:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK(input.is_\u001b[01;35m\u001b[Kcontiguous(), \"inpu\u001b[m\u001b[Kt tensor has to be contiguous\");\n",
            "                     \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:953:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK(input.is_contiguous(), \"input\u001b[01;35m\u001b[K \u001b[m\u001b[Ktensor has to be contiguous\");\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:954:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK(weight.is\u001b[01;35m\u001b[K_contiguous(), \"wei\u001b[m\u001b[Kght tensor has to be contiguous\");\n",
            "                     \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.cu:954:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid c10::detail::deprecated_AT_CHECK()\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_CHECK(weight.is_contiguous(), \"weig\u001b[01;35m\u001b[Kh\u001b[m\u001b[Kt tensor has to be contiguous\");\n",
            "                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:330:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline void depreca\u001b[m\u001b[Kted_AT_CHECK() {}\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/vilio/py-bottom-up-attention/detectron2/layers/csrc -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/vilio/py-bottom-up-attention/detectron2/layers/csrc/nms_rotated/nms_rotated_cuda.cu -o build/temp.linux-x86_64-3.7/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/nms_rotated/nms_rotated_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++11\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/nms_rotated/nms_rotated_cuda.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/nms_rotated/nms_rotated_cuda.cu:97:104:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:31:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline at::\u001b[m\u001b[KScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/nms_rotated/nms_rotated_cuda.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/nms_rotated/nms_rotated_cuda.cu:97:350:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                              \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/nms_rotated/nms_rotated_cuda.cu:97:402:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = long int]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                  \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/nms_rotated/nms_rotated_cuda.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/nms_rotated/nms_rotated_cuda.cu:97:639:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/nms_rotated/nms_rotated_cuda.cu:97:691:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = long int]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/nms_rotated/nms_rotated_cuda.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/nms_rotated/nms_rotated_cuda.cu:97:939:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = c10::Half]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/nms_rotated/nms_rotated_cuda.cu:97:991:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = long int]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/nms_rotated/nms_rotated_cuda.cu:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kat::Tensor detectron2::nms_rotated_cuda(const at::Tensor&, const at::Tensor&, float)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/nms_rotated/nms_rotated_cuda.cu:107:84:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = long int]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   unsigned long long* mask_host = (unsigned long long*)mask_cpu.data<int64_t>();\n",
            "                                                                                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/nms_rotated/nms_rotated_cuda.cu:114:46:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = long int]\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   int64_t* keep_out = keep.data<int64_t>();\n",
            "                                              \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:322:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            " \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/vilio/py-bottom-up-attention/detectron2/layers/csrc -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/vilio/py-bottom-up-attention/detectron2/layers/csrc/box_iou_rotated/box_iou_rotated_cuda.cu -o build/temp.linux-x86_64-3.7/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/box_iou_rotated/box_iou_rotated_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++11\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/vilio/py-bottom-up-attention/detectron2/layers/csrc -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/vilio/py-bottom-up-attention/detectron2/layers/csrc/cuda_version.cu -o build/temp.linux-x86_64-3.7/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/cuda_version.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++11\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 -Wl,-Bsymbolic-functions -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/vision.o build/temp.linux-x86_64-3.7/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlign/ROIAlign_cpu.o build/temp.linux-x86_64-3.7/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cpu.o build/temp.linux-x86_64-3.7/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/nms_rotated/nms_rotated_cpu.o build/temp.linux-x86_64-3.7/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/box_iou_rotated/box_iou_rotated_cpu.o build/temp.linux-x86_64-3.7/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlign/ROIAlign_cuda.o build/temp.linux-x86_64-3.7/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/ROIAlignRotated/ROIAlignRotated_cuda.o build/temp.linux-x86_64-3.7/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda_kernel.o build/temp.linux-x86_64-3.7/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/deformable/deform_conv_cuda.o build/temp.linux-x86_64-3.7/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/nms_rotated/nms_rotated_cuda.o build/temp.linux-x86_64-3.7/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/box_iou_rotated/box_iou_rotated_cuda.o build/temp.linux-x86_64-3.7/content/vilio/py-bottom-up-attention/detectron2/layers/csrc/cuda_version.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.7/detectron2/_C.cpython-37m-x86_64-linux-gnu.so\n",
            "running develop\n",
            "running egg_info\n",
            "creating detectron2.egg-info\n",
            "writing detectron2.egg-info/PKG-INFO\n",
            "writing dependency_links to detectron2.egg-info/dependency_links.txt\n",
            "writing requirements to detectron2.egg-info/requires.txt\n",
            "writing top-level names to detectron2.egg-info/top_level.txt\n",
            "writing manifest file 'detectron2.egg-info/SOURCES.txt'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'detectron2.egg-info/SOURCES.txt'\n",
            "running build_ext\n",
            "copying build/lib.linux-x86_64-3.7/detectron2/_C.cpython-37m-x86_64-linux-gnu.so -> detectron2\n",
            "Creating /usr/local/lib/python3.7/dist-packages/detectron2.egg-link (link to .)\n",
            "Adding detectron2 0.1 to easy-install.pth file\n",
            "\n",
            "Installed /content/vilio/py-bottom-up-attention\n",
            "Processing dependencies for detectron2==0.1\n",
            "Searching for imagesize==1.3.0\n",
            "Best match: imagesize 1.3.0\n",
            "Adding imagesize 1.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for tensorboard==2.8.0\n",
            "Best match: tensorboard 2.8.0\n",
            "Adding tensorboard 2.8.0 to easy-install.pth file\n",
            "Installing tensorboard script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for tqdm==4.64.0\n",
            "Best match: tqdm 4.64.0\n",
            "Adding tqdm 4.64.0 to easy-install.pth file\n",
            "Installing tqdm script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for matplotlib==3.2.2\n",
            "Best match: matplotlib 3.2.2\n",
            "Adding matplotlib 3.2.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for cloudpickle==1.3.0\n",
            "Best match: cloudpickle 1.3.0\n",
            "Adding cloudpickle 1.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for tabulate==0.8.9\n",
            "Best match: tabulate 0.8.9\n",
            "Adding tabulate 0.8.9 to easy-install.pth file\n",
            "Installing tabulate script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for yacs==0.1.8\n",
            "Best match: yacs 0.1.8\n",
            "Adding yacs 0.1.8 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for Pillow==7.1.2\n",
            "Best match: Pillow 7.1.2\n",
            "Adding Pillow 7.1.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for termcolor==1.1.0\n",
            "Best match: termcolor 1.1.0\n",
            "Adding termcolor 1.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for Werkzeug==1.0.1\n",
            "Best match: Werkzeug 1.0.1\n",
            "Adding Werkzeug 1.0.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for setuptools==57.4.0\n",
            "Best match: setuptools 57.4.0\n",
            "Adding setuptools 57.4.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for tensorboard-plugin-wit==1.8.1\n",
            "Best match: tensorboard-plugin-wit 1.8.1\n",
            "Adding tensorboard-plugin-wit 1.8.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for absl-py==1.0.0\n",
            "Best match: absl-py 1.0.0\n",
            "Adding absl-py 1.0.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for wheel==0.37.1\n",
            "Best match: wheel 0.37.1\n",
            "Adding wheel 0.37.1 to easy-install.pth file\n",
            "Installing wheel script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for google-auth==1.35.0\n",
            "Best match: google-auth 1.35.0\n",
            "Adding google-auth 1.35.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for requests==2.23.0\n",
            "Best match: requests 2.23.0\n",
            "Adding requests 2.23.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for google-auth-oauthlib==0.4.6\n",
            "Best match: google-auth-oauthlib 0.4.6\n",
            "Adding google-auth-oauthlib 0.4.6 to easy-install.pth file\n",
            "Installing google-oauthlib-tool script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for grpcio==1.46.1\n",
            "Best match: grpcio 1.46.1\n",
            "Adding grpcio 1.46.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for protobuf==3.17.3\n",
            "Best match: protobuf 3.17.3\n",
            "Adding protobuf 3.17.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for numpy==1.21.6\n",
            "Best match: numpy 1.21.6\n",
            "Adding numpy 1.21.6 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.7 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for tensorboard-data-server==0.6.1\n",
            "Best match: tensorboard-data-server 0.6.1\n",
            "Adding tensorboard-data-server 0.6.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for Markdown==3.3.7\n",
            "Best match: Markdown 3.3.7\n",
            "Adding Markdown 3.3.7 to easy-install.pth file\n",
            "Installing markdown_py script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for cycler==0.11.0\n",
            "Best match: cycler 0.11.0\n",
            "Adding cycler 0.11.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for kiwisolver==1.4.2\n",
            "Best match: kiwisolver 1.4.2\n",
            "Adding kiwisolver 1.4.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for python-dateutil==2.8.2\n",
            "Best match: python-dateutil 2.8.2\n",
            "Adding python-dateutil 2.8.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for pyparsing==3.0.9\n",
            "Best match: pyparsing 3.0.9\n",
            "Adding pyparsing 3.0.9 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for PyYAML==6.0\n",
            "Best match: PyYAML 6.0\n",
            "Adding PyYAML 6.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for six==1.15.0\n",
            "Best match: six 1.15.0\n",
            "Adding six 1.15.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for rsa==4.8\n",
            "Best match: rsa 4.8\n",
            "Adding rsa 4.8 to easy-install.pth file\n",
            "Installing pyrsa-decrypt script to /usr/local/bin\n",
            "Installing pyrsa-encrypt script to /usr/local/bin\n",
            "Installing pyrsa-keygen script to /usr/local/bin\n",
            "Installing pyrsa-priv2pub script to /usr/local/bin\n",
            "Installing pyrsa-sign script to /usr/local/bin\n",
            "Installing pyrsa-verify script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for pyasn1-modules==0.2.8\n",
            "Best match: pyasn1-modules 0.2.8\n",
            "Adding pyasn1-modules 0.2.8 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for cachetools==4.2.4\n",
            "Best match: cachetools 4.2.4\n",
            "Adding cachetools 4.2.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for urllib3==1.24.3\n",
            "Best match: urllib3 1.24.3\n",
            "Adding urllib3 1.24.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for certifi==2022.5.18.1\n",
            "Best match: certifi 2022.5.18.1\n",
            "Adding certifi 2022.5.18.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for chardet==3.0.4\n",
            "Best match: chardet 3.0.4\n",
            "Adding chardet 3.0.4 to easy-install.pth file\n",
            "Installing chardetect script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for idna==2.10\n",
            "Best match: idna 2.10\n",
            "Adding idna 2.10 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for requests-oauthlib==1.3.1\n",
            "Best match: requests-oauthlib 1.3.1\n",
            "Adding requests-oauthlib 1.3.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for importlib-metadata==4.11.3\n",
            "Best match: importlib-metadata 4.11.3\n",
            "Adding importlib-metadata 4.11.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for typing-extensions==4.2.0\n",
            "Best match: typing-extensions 4.2.0\n",
            "Adding typing-extensions 4.2.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for pyasn1==0.4.8\n",
            "Best match: pyasn1 0.4.8\n",
            "Adding pyasn1 0.4.8 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for oauthlib==3.2.0\n",
            "Best match: oauthlib 3.2.0\n",
            "Adding oauthlib 3.2.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for zipp==3.8.0\n",
            "Best match: zipp 3.8.0\n",
            "Adding zipp 3.8.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Finished processing dependencies for detectron2==0.1\n"
          ]
        }
      ],
      "source": [
        "# used for py-bottom-up-attention\n",
        "!python setup.py build develop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESIwA-mEx7Rv"
      },
      "source": [
        "##  <font color='#A8EB15'> Data Download\n",
        "\n",
        "In order to use **ERNIE-Vil** we need:\n",
        "- Put in `/content/vilio/ernie-vil/data/hm`:\n",
        "  * images and .json files from HM "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "i81B_Lkzy2Ft"
      },
      "outputs": [],
      "source": [
        "# we will put the data in the ernie-vil folder\n",
        "os.chdir(\"/content/vilio/ernie-vil/data/hm\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://drive.google.com/file/d/1Dbl-CQI61U3kDzzttE37lgl22b0Ay_nD/view?usp=sharing"
      ],
      "metadata": {
        "id": "b3_qgXY4fN9c"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!cp /content/drive/MyDrive/dataset/hateful_memes.zip /content/vilio/ernie-vil/data/hm/"
      ],
      "metadata": {
        "id": "5dY-k8cNW4WO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time \n",
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1B5kwn6IW28M03tlOoUdJQ1jFRgSyK6Ya' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1B5kwn6IW28M03tlOoUdJQ1jFRgSyK6Ya\" -O hateful_memes.zip && rm -rf /tmp/cookies.txt"
      ],
      "metadata": {
        "id": "ra00lhIWfT-y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f5e6688-4f36-4bee-f951-375aebd20c50"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-25 07:59:41--  https://docs.google.com/uc?export=download&confirm=t&id=1B5kwn6IW28M03tlOoUdJQ1jFRgSyK6Ya\n",
            "Resolving docs.google.com (docs.google.com)... 173.194.218.100, 173.194.218.101, 173.194.218.139, ...\n",
            "Connecting to docs.google.com (docs.google.com)|173.194.218.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-0c-44-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/ofkmtin5f9ugmucingjbtpfrv7g7p7dt/1653465525000/01761641334275034120/*/1B5kwn6IW28M03tlOoUdJQ1jFRgSyK6Ya?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2022-05-25 07:59:41--  https://doc-0c-44-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/ofkmtin5f9ugmucingjbtpfrv7g7p7dt/1653465525000/01761641334275034120/*/1B5kwn6IW28M03tlOoUdJQ1jFRgSyK6Ya?e=download\n",
            "Resolving doc-0c-44-docs.googleusercontent.com (doc-0c-44-docs.googleusercontent.com)... 108.177.11.132, 2607:f8b0:400c:c01::84\n",
            "Connecting to doc-0c-44-docs.googleusercontent.com (doc-0c-44-docs.googleusercontent.com)|108.177.11.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5045032354 (4.7G) [application/x-zip-compressed]\n",
            "Saving to: ‘hateful_memes.zip’\n",
            "\n",
            "hateful_memes.zip   100%[===================>]   4.70G   132MB/s    in 37s     \n",
            "\n",
            "2022-05-25 08:00:19 (130 MB/s) - ‘hateful_memes.zip’ saved [5045032354/5045032354]\n",
            "\n",
            "CPU times: user 533 ms, sys: 152 ms, total: 685 ms\n",
            "Wall time: 37.9 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "KGqAg0fux89K"
      },
      "outputs": [],
      "source": [
        "#%%time \n",
        "#!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1XiwUjy9BSwKw2x3eDDOG7e8tHrntj1l3' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1XiwUjy9BSwKw2x3eDDOG7e8tHrntj1l3\" -O hateful_memes.zip && rm -rf /tmp/cookies.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TQ40VtyyuqL",
        "outputId": "fca86625-05ed-4e10-a39a-4c238525de13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mSe han truncado las últimas 5000 líneas del flujo de salida.\u001b[0m\n",
            "  inflating: hateful_memes/img/24570.png  \n",
            "  inflating: hateful_memes/img/50734.png  \n",
            "  inflating: hateful_memes/img/85073.png  \n",
            "  inflating: hateful_memes/img/65371.png  \n",
            "  inflating: hateful_memes/img/79305.png  \n",
            "  inflating: hateful_memes/img/56972.png  \n",
            "  inflating: hateful_memes/img/14329.png  \n",
            "  inflating: hateful_memes/img/07685.png  \n",
            "  inflating: hateful_memes/img/69823.png  \n",
            "  inflating: hateful_memes/img/37095.png  \n",
            "  inflating: hateful_memes/img/45201.png  \n",
            "  inflating: hateful_memes/img/96435.png  \n",
            "  inflating: hateful_memes/img/35701.png  \n",
            "  inflating: hateful_memes/img/48106.png  \n",
            "  inflating: hateful_memes/img/17963.png  \n",
            "  inflating: hateful_memes/img/72046.png  \n",
            "  inflating: hateful_memes/img/26983.png  \n",
            "  inflating: hateful_memes/img/27810.png  \n",
            "  inflating: hateful_memes/img/76045.png  \n",
            "  inflating: hateful_memes/img/07865.png  \n",
            "  inflating: hateful_memes/img/91072.png  \n",
            "  inflating: hateful_memes/img/72386.png  \n",
            "  inflating: hateful_memes/img/81079.png  \n",
            "  inflating: hateful_memes/img/64532.png  \n",
            "  inflating: hateful_memes/img/37024.png  \n",
            "  inflating: hateful_memes/img/09852.png  \n",
            "  inflating: hateful_memes/img/60234.png  \n",
            "  inflating: hateful_memes/img/27058.png  \n",
            "  inflating: hateful_memes/img/90378.png  \n",
            "  inflating: hateful_memes/img/21850.png  \n",
            "  inflating: hateful_memes/img/56872.png  \n",
            "  inflating: hateful_memes/img/21047.png  \n",
            "  inflating: hateful_memes/img/82076.png  \n",
            "  inflating: hateful_memes/img/59836.png  \n",
            "  inflating: hateful_memes/img/45891.png  \n",
            "  inflating: hateful_memes/img/42376.png  \n",
            "  inflating: hateful_memes/img/16720.png  \n",
            "  inflating: hateful_memes/img/07632.png  \n",
            "  inflating: hateful_memes/img/04973.png  \n",
            "  inflating: hateful_memes/img/08427.png  \n",
            "  inflating: hateful_memes/img/72504.png  \n",
            "  inflating: hateful_memes/img/28067.png  \n",
            "  inflating: hateful_memes/img/15308.png  \n",
            "  inflating: hateful_memes/img/84015.png  \n",
            "  inflating: hateful_memes/img/59731.png  \n",
            "  inflating: hateful_memes/img/27150.png  \n",
            "  inflating: hateful_memes/img/10438.png  \n",
            "  inflating: hateful_memes/img/72536.png  \n",
            "  inflating: hateful_memes/img/35972.png  \n",
            "  inflating: hateful_memes/img/49307.png  \n",
            "  inflating: hateful_memes/img/01598.png  \n",
            "  inflating: hateful_memes/img/49316.png  \n",
            "  inflating: hateful_memes/img/19526.png  \n",
            "  inflating: hateful_memes/img/75286.png  \n",
            "  inflating: hateful_memes/img/53806.png  \n",
            "  inflating: hateful_memes/img/56810.png  \n",
            "  inflating: hateful_memes/img/53914.png  \n",
            "  inflating: hateful_memes/img/97406.png  \n",
            "  inflating: hateful_memes/img/32896.png  \n",
            "  inflating: hateful_memes/img/89465.png  \n",
            "  inflating: hateful_memes/img/20931.png  \n",
            "  inflating: hateful_memes/img/01564.png  \n",
            "  inflating: hateful_memes/img/65140.png  \n",
            "  inflating: hateful_memes/img/30695.png  \n",
            "  inflating: hateful_memes/img/32570.png  \n",
            "  inflating: hateful_memes/img/78642.png  \n",
            "  inflating: hateful_memes/img/30941.png  \n",
            "  inflating: hateful_memes/img/75832.png  \n",
            "  inflating: hateful_memes/img/02735.png  \n",
            "  inflating: hateful_memes/img/45987.png  \n",
            "  inflating: hateful_memes/img/62458.png  \n",
            "  inflating: hateful_memes/img/98702.png  \n",
            "  inflating: hateful_memes/img/79504.png  \n",
            "  inflating: hateful_memes/img/65283.png  \n",
            "  inflating: hateful_memes/img/27905.png  \n",
            "  inflating: hateful_memes/img/95274.png  \n",
            "  inflating: hateful_memes/img/60538.png  \n",
            "  inflating: hateful_memes/img/85730.png  \n",
            "  inflating: hateful_memes/img/24958.png  \n",
            "  inflating: hateful_memes/img/80912.png  \n",
            "  inflating: hateful_memes/img/91547.png  \n",
            "  inflating: hateful_memes/img/79834.png  \n",
            "  inflating: hateful_memes/img/65274.png  \n",
            "  inflating: hateful_memes/img/14830.png  \n",
            "  inflating: hateful_memes/img/34925.png  \n",
            "  inflating: hateful_memes/img/32017.png  \n",
            "  inflating: hateful_memes/img/85426.png  \n",
            "  inflating: hateful_memes/img/26381.png  \n",
            "  inflating: hateful_memes/img/03861.png  \n",
            "  inflating: hateful_memes/img/37259.png  \n",
            "  inflating: hateful_memes/img/10843.png  \n",
            "  inflating: hateful_memes/img/09132.png  \n",
            "  inflating: hateful_memes/img/43279.png  \n",
            "  inflating: hateful_memes/img/27901.png  \n",
            "  inflating: hateful_memes/img/14632.png  \n",
            "  inflating: hateful_memes/img/14732.png  \n",
            "  inflating: hateful_memes/img/29073.png  \n",
            "  inflating: hateful_memes/img/27438.png  \n",
            "  inflating: hateful_memes/img/03981.png  \n",
            "  inflating: hateful_memes/img/16405.png  \n",
            "  inflating: hateful_memes/img/28406.png  \n",
            "  inflating: hateful_memes/img/69305.png  \n",
            "  inflating: hateful_memes/img/62907.png  \n",
            "  inflating: hateful_memes/img/06243.png  \n",
            "  inflating: hateful_memes/img/03178.png  \n",
            "  inflating: hateful_memes/img/14375.png  \n",
            "  inflating: hateful_memes/img/03528.png  \n",
            "  inflating: hateful_memes/img/45802.png  \n",
            "  inflating: hateful_memes/img/61450.png  \n",
            "  inflating: hateful_memes/img/59340.png  \n",
            "  inflating: hateful_memes/img/07523.png  \n",
            "  inflating: hateful_memes/img/52803.png  \n",
            "  inflating: hateful_memes/img/85716.png  \n",
            "  inflating: hateful_memes/img/18023.png  \n",
            "  inflating: hateful_memes/img/30816.png  \n",
            "  inflating: hateful_memes/img/36104.png  \n",
            "  inflating: hateful_memes/img/04157.png  \n",
            "  inflating: hateful_memes/img/92436.png  \n",
            "  inflating: hateful_memes/img/60729.png  \n",
            "  inflating: hateful_memes/img/40518.png  \n",
            "  inflating: hateful_memes/img/93820.png  \n",
            "  inflating: hateful_memes/img/90186.png  \n",
            "  inflating: hateful_memes/img/90463.png  \n",
            "  inflating: hateful_memes/img/75618.png  \n",
            "  inflating: hateful_memes/img/60134.png  \n",
            "  inflating: hateful_memes/img/94873.png  \n",
            "  inflating: hateful_memes/img/30648.png  \n",
            "  inflating: hateful_memes/img/24108.png  \n",
            "  inflating: hateful_memes/img/06213.png  \n",
            "  inflating: hateful_memes/img/68529.png  \n",
            "  inflating: hateful_memes/img/92874.png  \n",
            "  inflating: hateful_memes/img/20567.png  \n",
            "  inflating: hateful_memes/img/57046.png  \n",
            "  inflating: hateful_memes/img/89107.png  \n",
            "  inflating: hateful_memes/img/20978.png  \n",
            "  inflating: hateful_memes/img/62850.png  \n",
            "  inflating: hateful_memes/img/41298.png  \n",
            "  inflating: hateful_memes/img/94783.png  \n",
            "  inflating: hateful_memes/img/01247.png  \n",
            "  inflating: hateful_memes/img/45370.png  \n",
            "  inflating: hateful_memes/img/52349.png  \n",
            "  inflating: hateful_memes/img/41830.png  \n",
            "  inflating: hateful_memes/img/01892.png  \n",
            "  inflating: hateful_memes/img/62713.png  \n",
            "  inflating: hateful_memes/img/34092.png  \n",
            "  inflating: hateful_memes/img/87406.png  \n",
            "  inflating: hateful_memes/img/61802.png  \n",
            "  inflating: hateful_memes/img/51496.png  \n",
            "  inflating: hateful_memes/img/28401.png  \n",
            "  inflating: hateful_memes/img/26750.png  \n",
            "  inflating: hateful_memes/img/21075.png  \n",
            "  inflating: hateful_memes/img/04982.png  \n",
            "  inflating: hateful_memes/img/41385.png  \n",
            "  inflating: hateful_memes/img/31685.png  \n",
            "  inflating: hateful_memes/img/38794.png  \n",
            "  inflating: hateful_memes/img/46529.png  \n",
            "  inflating: hateful_memes/img/76341.png  \n",
            "  inflating: hateful_memes/img/03849.png  \n",
            "  inflating: hateful_memes/img/26980.png  \n",
            "  inflating: hateful_memes/img/47029.png  \n",
            "  inflating: hateful_memes/img/67234.png  \n",
            "  inflating: hateful_memes/img/43517.png  \n",
            "  inflating: hateful_memes/img/64280.png  \n",
            "  inflating: hateful_memes/img/12867.png  \n",
            "  inflating: hateful_memes/img/31560.png  \n",
            "  inflating: hateful_memes/img/28450.png  \n",
            "  inflating: hateful_memes/img/70164.png  \n",
            "  inflating: hateful_memes/img/31609.png  \n",
            "  inflating: hateful_memes/img/98514.png  \n",
            "  inflating: hateful_memes/img/43928.png  \n",
            "  inflating: hateful_memes/img/92187.png  \n",
            "  inflating: hateful_memes/img/53678.png  \n",
            "  inflating: hateful_memes/img/85679.png  \n",
            "  inflating: hateful_memes/img/24039.png  \n",
            "  inflating: hateful_memes/img/61349.png  \n",
            "  inflating: hateful_memes/img/05172.png  \n",
            "  inflating: hateful_memes/img/48251.png  \n",
            "  inflating: hateful_memes/img/92051.png  \n",
            "  inflating: hateful_memes/img/46509.png  \n",
            "  inflating: hateful_memes/img/75839.png  \n",
            "  inflating: hateful_memes/img/32049.png  \n",
            "  inflating: hateful_memes/img/50861.png  \n",
            "  inflating: hateful_memes/img/30157.png  \n",
            "  inflating: hateful_memes/img/36725.png  \n",
            "  inflating: hateful_memes/img/57162.png  \n",
            "  inflating: hateful_memes/img/36924.png  \n",
            "  inflating: hateful_memes/img/39421.png  \n",
            "  inflating: hateful_memes/img/30476.png  \n",
            "  inflating: hateful_memes/img/19637.png  \n",
            "  inflating: hateful_memes/img/80649.png  \n",
            "  inflating: hateful_memes/img/27639.png  \n",
            "  inflating: hateful_memes/img/86215.png  \n",
            "  inflating: hateful_memes/img/72580.png  \n",
            "  inflating: hateful_memes/img/79856.png  \n",
            "  inflating: hateful_memes/img/62840.png  \n",
            "  inflating: hateful_memes/img/31094.png  \n",
            "  inflating: hateful_memes/img/08531.png  \n",
            "  inflating: hateful_memes/img/61379.png  \n",
            "  inflating: hateful_memes/img/73501.png  \n",
            "  inflating: hateful_memes/img/21584.png  \n",
            "  inflating: hateful_memes/img/29714.png  \n",
            "  inflating: hateful_memes/img/21346.png  \n",
            "  inflating: hateful_memes/img/74326.png  \n",
            "  inflating: hateful_memes/img/83091.png  \n",
            "  inflating: hateful_memes/img/16039.png  \n",
            "  inflating: hateful_memes/img/01943.png  \n",
            "  inflating: hateful_memes/img/06945.png  \n",
            "  inflating: hateful_memes/img/08153.png  \n",
            "  inflating: hateful_memes/img/90583.png  \n",
            "  inflating: hateful_memes/img/76598.png  \n",
            "  inflating: hateful_memes/img/08539.png  \n",
            "  inflating: hateful_memes/img/31975.png  \n",
            "  inflating: hateful_memes/img/73690.png  \n",
            "  inflating: hateful_memes/img/86123.png  \n",
            "  inflating: hateful_memes/img/98716.png  \n",
            "  inflating: hateful_memes/img/97026.png  \n",
            "  inflating: hateful_memes/img/17659.png  \n",
            "  inflating: hateful_memes/img/13706.png  \n",
            "  inflating: hateful_memes/img/72680.png  \n",
            "  inflating: hateful_memes/img/91602.png  \n",
            "  inflating: hateful_memes/img/82647.png  \n",
            "  inflating: hateful_memes/img/21596.png  \n",
            "  inflating: hateful_memes/img/80453.png  \n",
            "  inflating: hateful_memes/img/28597.png  \n",
            "  inflating: hateful_memes/img/23175.png  \n",
            "  inflating: hateful_memes/img/72456.png  \n",
            "  inflating: hateful_memes/img/08612.png  \n",
            "  inflating: hateful_memes/img/36102.png  \n",
            "  inflating: hateful_memes/img/08375.png  \n",
            "  inflating: hateful_memes/img/08137.png  \n",
            "  inflating: hateful_memes/img/09267.png  \n",
            "  inflating: hateful_memes/img/32081.png  \n",
            "  inflating: hateful_memes/img/19345.png  \n",
            "  inflating: hateful_memes/img/43798.png  \n",
            "  inflating: hateful_memes/img/95317.png  \n",
            "  inflating: hateful_memes/img/43810.png  \n",
            "  inflating: hateful_memes/img/85967.png  \n",
            "  inflating: hateful_memes/img/24890.png  \n",
            "  inflating: hateful_memes/img/93261.png  \n",
            "  inflating: hateful_memes/img/49675.png  \n",
            "  inflating: hateful_memes/img/07836.png  \n",
            "  inflating: hateful_memes/img/09357.png  \n",
            "  inflating: hateful_memes/img/94360.png  \n",
            "  inflating: hateful_memes/img/49318.png  \n",
            "  inflating: hateful_memes/img/09624.png  \n",
            "  inflating: hateful_memes/img/82916.png  \n",
            "  inflating: hateful_memes/img/59376.png  \n",
            "  inflating: hateful_memes/img/54730.png  \n",
            "  inflating: hateful_memes/img/20685.png  \n",
            "  inflating: hateful_memes/img/59874.png  \n",
            "  inflating: hateful_memes/img/29385.png  \n",
            "  inflating: hateful_memes/img/61527.png  \n",
            "  inflating: hateful_memes/img/49261.png  \n",
            "  inflating: hateful_memes/img/40312.png  \n",
            "  inflating: hateful_memes/img/67205.png  \n",
            "  inflating: hateful_memes/img/17234.png  \n",
            "  inflating: hateful_memes/img/13906.png  \n",
            "  inflating: hateful_memes/img/46810.png  \n",
            "  inflating: hateful_memes/img/25768.png  \n",
            "  inflating: hateful_memes/img/04876.png  \n",
            "  inflating: hateful_memes/img/98504.png  \n",
            "  inflating: hateful_memes/img/62301.png  \n",
            "  inflating: hateful_memes/img/54912.png  \n",
            "  inflating: hateful_memes/img/01763.png  \n",
            "  inflating: hateful_memes/img/28134.png  \n",
            "  inflating: hateful_memes/img/60592.png  \n",
            "  inflating: hateful_memes/img/19308.png  \n",
            "  inflating: hateful_memes/img/78509.png  \n",
            "  inflating: hateful_memes/img/10583.png  \n",
            "  inflating: hateful_memes/img/86354.png  \n",
            "  inflating: hateful_memes/img/01634.png  \n",
            "  inflating: hateful_memes/img/32907.png  \n",
            "  inflating: hateful_memes/img/83064.png  \n",
            "  inflating: hateful_memes/img/08679.png  \n",
            "  inflating: hateful_memes/img/27946.png  \n",
            "  inflating: hateful_memes/img/90637.png  \n",
            "  inflating: hateful_memes/img/29164.png  \n",
            "  inflating: hateful_memes/img/03418.png  \n",
            "  inflating: hateful_memes/img/85291.png  \n",
            "  inflating: hateful_memes/img/52916.png  \n",
            "  inflating: hateful_memes/img/80321.png  \n",
            "  inflating: hateful_memes/img/70158.png  \n",
            "  inflating: hateful_memes/img/06791.png  \n",
            "  inflating: hateful_memes/img/70182.png  \n",
            "  inflating: hateful_memes/img/82169.png  \n",
            "  inflating: hateful_memes/img/37482.png  \n",
            "  inflating: hateful_memes/img/32106.png  \n",
            "  inflating: hateful_memes/img/71048.png  \n",
            "  inflating: hateful_memes/img/51460.png  \n",
            "  inflating: hateful_memes/img/08319.png  \n",
            "  inflating: hateful_memes/img/15236.png  \n",
            "  inflating: hateful_memes/img/80197.png  \n",
            "  inflating: hateful_memes/img/54018.png  \n",
            "  inflating: hateful_memes/img/26945.png  \n",
            "  inflating: hateful_memes/img/97021.png  \n",
            "  inflating: hateful_memes/img/93741.png  \n",
            "  inflating: hateful_memes/img/67823.png  \n",
            "  inflating: hateful_memes/img/28019.png  \n",
            "  inflating: hateful_memes/img/58419.png  \n",
            "  inflating: hateful_memes/img/74536.png  \n",
            "  inflating: hateful_memes/img/61028.png  \n",
            "  inflating: hateful_memes/img/38954.png  \n",
            "  inflating: hateful_memes/img/59041.png  \n",
            "  inflating: hateful_memes/img/07623.png  \n",
            "  inflating: hateful_memes/img/59342.png  \n",
            "  inflating: hateful_memes/img/68597.png  \n",
            "  inflating: hateful_memes/img/68749.png  \n",
            "  inflating: hateful_memes/img/38164.png  \n",
            "  inflating: hateful_memes/img/63710.png  \n",
            "  inflating: hateful_memes/img/89573.png  \n",
            "  inflating: hateful_memes/img/89571.png  \n",
            "  inflating: hateful_memes/img/94861.png  \n",
            "  inflating: hateful_memes/img/67342.png  \n",
            "  inflating: hateful_memes/img/67014.png  \n",
            "  inflating: hateful_memes/img/80392.png  \n",
            "  inflating: hateful_memes/img/89173.png  \n",
            "  inflating: hateful_memes/img/98537.png  \n",
            "  inflating: hateful_memes/img/87610.png  \n",
            "  inflating: hateful_memes/img/05798.png  \n",
            "  inflating: hateful_memes/img/90162.png  \n",
            "  inflating: hateful_memes/img/03254.png  \n",
            "  inflating: hateful_memes/img/69824.png  \n",
            "  inflating: hateful_memes/img/03571.png  \n",
            "  inflating: hateful_memes/img/70649.png  \n",
            "  inflating: hateful_memes/img/32709.png  \n",
            "  inflating: hateful_memes/img/73125.png  \n",
            "  inflating: hateful_memes/img/62504.png  \n",
            "  inflating: hateful_memes/img/13297.png  \n",
            "  inflating: hateful_memes/img/13724.png  \n",
            "  inflating: hateful_memes/img/58093.png  \n",
            "  inflating: hateful_memes/img/30782.png  \n",
            "  inflating: hateful_memes/img/37859.png  \n",
            "  inflating: hateful_memes/img/26903.png  \n",
            "  inflating: hateful_memes/img/40159.png  \n",
            "  inflating: hateful_memes/img/90342.png  \n",
            "  inflating: hateful_memes/img/53096.png  \n",
            "  inflating: hateful_memes/img/47531.png  \n",
            "  inflating: hateful_memes/img/23645.png  \n",
            "  inflating: hateful_memes/img/02984.png  \n",
            "  inflating: hateful_memes/img/09781.png  \n",
            "  inflating: hateful_memes/img/03275.png  \n",
            "  inflating: hateful_memes/img/59678.png  \n",
            "  inflating: hateful_memes/img/86031.png  \n",
            "  inflating: hateful_memes/img/73254.png  \n",
            "  inflating: hateful_memes/img/45829.png  \n",
            "  inflating: hateful_memes/img/91034.png  \n",
            "  inflating: hateful_memes/img/89517.png  \n",
            "  inflating: hateful_memes/img/40136.png  \n",
            "  inflating: hateful_memes/img/48513.png  \n",
            "  inflating: hateful_memes/img/67831.png  \n",
            "  inflating: hateful_memes/img/83946.png  \n",
            "  inflating: hateful_memes/img/59341.png  \n",
            "  inflating: hateful_memes/img/15269.png  \n",
            "  inflating: hateful_memes/img/38754.png  \n",
            "  inflating: hateful_memes/img/08476.png  \n",
            "  inflating: hateful_memes/img/58176.png  \n",
            "  inflating: hateful_memes/img/48012.png  \n",
            "  inflating: hateful_memes/img/94062.png  \n",
            "  inflating: hateful_memes/img/47532.png  \n",
            "  inflating: hateful_memes/img/70148.png  \n",
            "  inflating: hateful_memes/img/58194.png  \n",
            "  inflating: hateful_memes/img/31250.png  \n",
            "  inflating: hateful_memes/img/20674.png  \n",
            "  inflating: hateful_memes/img/26950.png  \n",
            "  inflating: hateful_memes/img/82704.png  \n",
            "  inflating: hateful_memes/img/78612.png  \n",
            "  inflating: hateful_memes/img/31068.png  \n",
            "  inflating: hateful_memes/img/75308.png  \n",
            "  inflating: hateful_memes/img/64839.png  \n",
            "  inflating: hateful_memes/img/48352.png  \n",
            "  inflating: hateful_memes/img/98526.png  \n",
            "  inflating: hateful_memes/img/86405.png  \n",
            "  inflating: hateful_memes/img/45018.png  \n",
            "  inflating: hateful_memes/img/76892.png  \n",
            "  inflating: hateful_memes/img/42589.png  \n",
            "  inflating: hateful_memes/img/69125.png  \n",
            "  inflating: hateful_memes/img/49510.png  \n",
            "  inflating: hateful_memes/img/79348.png  \n",
            "  inflating: hateful_memes/img/72936.png  \n",
            "  inflating: hateful_memes/img/35287.png  \n",
            "  inflating: hateful_memes/img/82547.png  \n",
            "  inflating: hateful_memes/img/94357.png  \n",
            "  inflating: hateful_memes/img/29380.png  \n",
            "  inflating: hateful_memes/img/27634.png  \n",
            "  inflating: hateful_memes/img/50679.png  \n",
            "  inflating: hateful_memes/img/71920.png  \n",
            "  inflating: hateful_memes/img/54608.png  \n",
            "  inflating: hateful_memes/img/72461.png  \n",
            "  inflating: hateful_memes/img/93076.png  \n",
            "  inflating: hateful_memes/img/50492.png  \n",
            "  inflating: hateful_memes/img/06491.png  \n",
            "  inflating: hateful_memes/img/51396.png  \n",
            "  inflating: hateful_memes/img/04758.png  \n",
            "  inflating: hateful_memes/img/90185.png  \n",
            "  inflating: hateful_memes/img/19234.png  \n",
            "  inflating: hateful_memes/img/57826.png  \n",
            "  inflating: hateful_memes/img/34078.png  \n",
            "  inflating: hateful_memes/img/41037.png  \n",
            "  inflating: hateful_memes/img/92450.png  \n",
            "  inflating: hateful_memes/img/38509.png  \n",
            "  inflating: hateful_memes/img/49387.png  \n",
            "  inflating: hateful_memes/img/09531.png  \n",
            "  inflating: hateful_memes/img/38702.png  \n",
            "  inflating: hateful_memes/img/95176.png  \n",
            "  inflating: hateful_memes/img/34768.png  \n",
            "  inflating: hateful_memes/img/67092.png  \n",
            "  inflating: hateful_memes/img/73406.png  \n",
            "  inflating: hateful_memes/img/53967.png  \n",
            "  inflating: hateful_memes/img/42903.png  \n",
            "  inflating: hateful_memes/img/64935.png  \n",
            "  inflating: hateful_memes/img/31896.png  \n",
            "  inflating: hateful_memes/img/48790.png  \n",
            "  inflating: hateful_memes/img/72469.png  \n",
            "  inflating: hateful_memes/img/94378.png  \n",
            "  inflating: hateful_memes/img/78592.png  \n",
            "  inflating: hateful_memes/img/72591.png  \n",
            "  inflating: hateful_memes/img/76108.png  \n",
            "  inflating: hateful_memes/img/04185.png  \n",
            "  inflating: hateful_memes/img/64189.png  \n",
            "  inflating: hateful_memes/img/13450.png  \n",
            "  inflating: hateful_memes/img/86512.png  \n",
            "  inflating: hateful_memes/img/13962.png  \n",
            "  inflating: hateful_memes/img/54726.png  \n",
            "  inflating: hateful_memes/img/97531.png  \n",
            "  inflating: hateful_memes/img/80921.png  \n",
            "  inflating: hateful_memes/img/97345.png  \n",
            "  inflating: hateful_memes/img/47561.png  \n",
            "  inflating: hateful_memes/img/51029.png  \n",
            "  inflating: hateful_memes/img/07194.png  \n",
            "  inflating: hateful_memes/img/16049.png  \n",
            "  inflating: hateful_memes/img/31602.png  \n",
            "  inflating: hateful_memes/img/02384.png  \n",
            "  inflating: hateful_memes/img/83925.png  \n",
            "  inflating: hateful_memes/img/41796.png  \n",
            "  inflating: hateful_memes/img/07528.png  \n",
            "  inflating: hateful_memes/img/39526.png  \n",
            "  inflating: hateful_memes/img/28463.png  \n",
            "  inflating: hateful_memes/img/94571.png  \n",
            "  inflating: hateful_memes/img/90742.png  \n",
            "  inflating: hateful_memes/img/90576.png  \n",
            "  inflating: hateful_memes/img/94813.png  \n",
            "  inflating: hateful_memes/img/37419.png  \n",
            "  inflating: hateful_memes/img/86509.png  \n",
            "  inflating: hateful_memes/img/89076.png  \n",
            "  inflating: hateful_memes/img/26348.png  \n",
            "  inflating: hateful_memes/img/32981.png  \n",
            "  inflating: hateful_memes/img/62751.png  \n",
            "  inflating: hateful_memes/img/75920.png  \n",
            "  inflating: hateful_memes/img/90247.png  \n",
            "  inflating: hateful_memes/img/84362.png  \n",
            "  inflating: hateful_memes/img/52809.png  \n",
            "  inflating: hateful_memes/img/12376.png  \n",
            "  inflating: hateful_memes/img/57984.png  \n",
            "  inflating: hateful_memes/img/78132.png  \n",
            "  inflating: hateful_memes/img/58706.png  \n",
            "  inflating: hateful_memes/img/39456.png  \n",
            "  inflating: hateful_memes/img/42876.png  \n",
            "  inflating: hateful_memes/img/29463.png  \n",
            "  inflating: hateful_memes/img/36590.png  \n",
            "  inflating: hateful_memes/img/67953.png  \n",
            "  inflating: hateful_memes/img/86052.png  \n",
            "  inflating: hateful_memes/img/37180.png  \n",
            "  inflating: hateful_memes/img/47825.png  \n",
            "  inflating: hateful_memes/img/19426.png  \n",
            "  inflating: hateful_memes/img/29841.png  \n",
            "  inflating: hateful_memes/img/81942.png  \n",
            "  inflating: hateful_memes/img/10486.png  \n",
            "  inflating: hateful_memes/img/50386.png  \n",
            "  inflating: hateful_memes/img/24083.png  \n",
            "  inflating: hateful_memes/img/89326.png  \n",
            "  inflating: hateful_memes/img/41782.png  \n",
            "  inflating: hateful_memes/img/16380.png  \n",
            "  inflating: hateful_memes/img/96345.png  \n",
            "  inflating: hateful_memes/img/81576.png  \n",
            "  inflating: hateful_memes/img/31096.png  \n",
            "  inflating: hateful_memes/img/10274.png  \n",
            "  inflating: hateful_memes/img/45702.png  \n",
            "  inflating: hateful_memes/img/34782.png  \n",
            "  inflating: hateful_memes/img/87501.png  \n",
            "  inflating: hateful_memes/img/27436.png  \n",
            "  inflating: hateful_memes/img/03798.png  \n",
            "  inflating: hateful_memes/img/47629.png  \n",
            "  inflating: hateful_memes/img/12958.png  \n",
            "  inflating: hateful_memes/img/75693.png  \n",
            "  inflating: hateful_memes/img/65401.png  \n",
            "  inflating: hateful_memes/img/98315.png  \n",
            "  inflating: hateful_memes/img/72965.png  \n",
            "  inflating: hateful_memes/img/16798.png  \n",
            "  inflating: hateful_memes/img/49758.png  \n",
            "  inflating: hateful_memes/img/98071.png  \n",
            "  inflating: hateful_memes/img/40125.png  \n",
            "  inflating: hateful_memes/img/70426.png  \n",
            "  inflating: hateful_memes/img/57193.png  \n",
            "  inflating: hateful_memes/img/43089.png  \n",
            "  inflating: hateful_memes/img/46837.png  \n",
            "  inflating: hateful_memes/img/80317.png  \n",
            "  inflating: hateful_memes/img/36201.png  \n",
            "  inflating: hateful_memes/img/62398.png  \n",
            "  inflating: hateful_memes/img/61589.png  \n",
            "  inflating: hateful_memes/img/87052.png  \n",
            "  inflating: hateful_memes/img/13574.png  \n",
            "  inflating: hateful_memes/img/39758.png  \n",
            "  inflating: hateful_memes/img/53219.png  \n",
            "  inflating: hateful_memes/img/36597.png  \n",
            "  inflating: hateful_memes/img/83960.png  \n",
            "  inflating: hateful_memes/img/18307.png  \n",
            "  inflating: hateful_memes/img/63712.png  \n",
            "  inflating: hateful_memes/img/86209.png  \n",
            "  inflating: hateful_memes/img/74652.png  \n",
            "  inflating: hateful_memes/img/96213.png  \n",
            "  inflating: hateful_memes/img/58674.png  \n",
            "  inflating: hateful_memes/img/29351.png  \n",
            "  inflating: hateful_memes/img/79146.png  \n",
            "  inflating: hateful_memes/img/81529.png  \n",
            "  inflating: hateful_memes/img/96431.png  \n",
            "  inflating: hateful_memes/img/31627.png  \n",
            "  inflating: hateful_memes/img/40675.png  \n",
            "  inflating: hateful_memes/img/37658.png  \n",
            "  inflating: hateful_memes/img/63082.png  \n",
            "  inflating: hateful_memes/img/43218.png  \n",
            "  inflating: hateful_memes/img/91268.png  \n",
            "  inflating: hateful_memes/img/40326.png  \n",
            "  inflating: hateful_memes/img/74953.png  \n",
            "  inflating: hateful_memes/img/23578.png  \n",
            "  inflating: hateful_memes/img/46387.png  \n",
            "  inflating: hateful_memes/img/70691.png  \n",
            "  inflating: hateful_memes/img/23514.png  \n",
            "  inflating: hateful_memes/img/54016.png  \n",
            "  inflating: hateful_memes/img/93162.png  \n",
            "  inflating: hateful_memes/img/19860.png  \n",
            "  inflating: hateful_memes/img/80165.png  \n",
            "  inflating: hateful_memes/img/92405.png  \n",
            "  inflating: hateful_memes/img/41860.png  \n",
            "  inflating: hateful_memes/img/21043.png  \n",
            "  inflating: hateful_memes/img/29054.png  \n",
            "  inflating: hateful_memes/img/24580.png  \n",
            "  inflating: hateful_memes/img/83720.png  \n",
            "  inflating: hateful_memes/img/92816.png  \n",
            "  inflating: hateful_memes/img/78351.png  \n",
            "  inflating: hateful_memes/img/39748.png  \n",
            "  inflating: hateful_memes/img/32174.png  \n",
            "  inflating: hateful_memes/img/47581.png  \n",
            "  inflating: hateful_memes/img/03527.png  \n",
            "  inflating: hateful_memes/img/87239.png  \n",
            "  inflating: hateful_memes/img/60834.png  \n",
            "  inflating: hateful_memes/img/83916.png  \n",
            "  inflating: hateful_memes/img/90146.png  \n",
            "  inflating: hateful_memes/img/49603.png  \n",
            "  inflating: hateful_memes/img/07389.png  \n",
            "  inflating: hateful_memes/img/34068.png  \n",
            "  inflating: hateful_memes/img/97261.png  \n",
            "  inflating: hateful_memes/img/83206.png  \n",
            "  inflating: hateful_memes/img/63792.png  \n",
            "  inflating: hateful_memes/img/20948.png  \n",
            "  inflating: hateful_memes/img/86907.png  \n",
            "  inflating: hateful_memes/img/36895.png  \n",
            "  inflating: hateful_memes/img/01268.png  \n",
            "  inflating: hateful_memes/img/91537.png  \n",
            "  inflating: hateful_memes/img/87436.png  \n",
            "  inflating: hateful_memes/img/06198.png  \n",
            "  inflating: hateful_memes/img/86425.png  \n",
            "  inflating: hateful_memes/img/57923.png  \n",
            "  inflating: hateful_memes/img/16042.png  \n",
            "  inflating: hateful_memes/img/30256.png  \n",
            "  inflating: hateful_memes/img/31625.png  \n",
            "  inflating: hateful_memes/img/80976.png  \n",
            "  inflating: hateful_memes/img/25681.png  \n",
            "  inflating: hateful_memes/img/35081.png  \n",
            "  inflating: hateful_memes/img/27803.png  \n",
            "  inflating: hateful_memes/img/86253.png  \n",
            "  inflating: hateful_memes/img/49726.png  \n",
            "  inflating: hateful_memes/img/02789.png  \n",
            "  inflating: hateful_memes/img/51469.png  \n",
            "  inflating: hateful_memes/img/68253.png  \n",
            "  inflating: hateful_memes/img/63951.png  \n",
            "  inflating: hateful_memes/img/58479.png  \n",
            "  inflating: hateful_memes/img/24517.png  \n",
            "  inflating: hateful_memes/img/49128.png  \n",
            "  inflating: hateful_memes/img/53462.png  \n",
            "  inflating: hateful_memes/img/61308.png  \n",
            "  inflating: hateful_memes/img/31687.png  \n",
            "  inflating: hateful_memes/img/43805.png  \n",
            "  inflating: hateful_memes/img/35902.png  \n",
            "  inflating: hateful_memes/img/98421.png  \n",
            "  inflating: hateful_memes/img/85902.png  \n",
            "  inflating: hateful_memes/img/92643.png  \n",
            "  inflating: hateful_memes/img/58317.png  \n",
            "  inflating: hateful_memes/img/71943.png  \n",
            "  inflating: hateful_memes/img/23748.png  \n",
            "  inflating: hateful_memes/img/74038.png  \n",
            "  inflating: hateful_memes/img/51248.png  \n",
            "  inflating: hateful_memes/img/84903.png  \n",
            "  inflating: hateful_memes/img/54368.png  \n",
            "  inflating: hateful_memes/img/57120.png  \n",
            "  inflating: hateful_memes/img/49201.png  \n",
            "  inflating: hateful_memes/img/03745.png  \n",
            "  inflating: hateful_memes/img/65094.png  \n",
            "  inflating: hateful_memes/img/43180.png  \n",
            "  inflating: hateful_memes/img/56739.png  \n",
            "  inflating: hateful_memes/img/47612.png  \n",
            "  inflating: hateful_memes/img/01627.png  \n",
            "  inflating: hateful_memes/img/98362.png  \n",
            "  inflating: hateful_memes/img/08534.png  \n",
            "  inflating: hateful_memes/img/27948.png  \n",
            "  inflating: hateful_memes/img/74890.png  \n",
            "  inflating: hateful_memes/img/02519.png  \n",
            "  inflating: hateful_memes/img/32781.png  \n",
            "  inflating: hateful_memes/img/85306.png  \n",
            "  inflating: hateful_memes/img/78903.png  \n",
            "  inflating: hateful_memes/img/16895.png  \n",
            "  inflating: hateful_memes/img/57418.png  \n",
            "  inflating: hateful_memes/img/51746.png  \n",
            "  inflating: hateful_memes/img/36429.png  \n",
            "  inflating: hateful_memes/img/58297.png  \n",
            "  inflating: hateful_memes/img/58312.png  \n",
            "  inflating: hateful_memes/img/97160.png  \n",
            "  inflating: hateful_memes/img/25714.png  \n",
            "  inflating: hateful_memes/img/57280.png  \n",
            "  inflating: hateful_memes/img/52074.png  \n",
            "  inflating: hateful_memes/img/19034.png  \n",
            "  inflating: hateful_memes/img/38714.png  \n",
            "  inflating: hateful_memes/img/56741.png  \n",
            "  inflating: hateful_memes/img/94581.png  \n",
            "  inflating: hateful_memes/img/42073.png  \n",
            "  inflating: hateful_memes/img/31786.png  \n",
            "  inflating: hateful_memes/img/61489.png  \n",
            "  inflating: hateful_memes/img/59801.png  \n",
            "  inflating: hateful_memes/img/75481.png  \n",
            "  inflating: hateful_memes/img/49360.png  \n",
            "  inflating: hateful_memes/img/78192.png  \n",
            "  inflating: hateful_memes/img/27308.png  \n",
            "  inflating: hateful_memes/img/68759.png  \n",
            "  inflating: hateful_memes/img/67385.png  \n",
            "  inflating: hateful_memes/img/91768.png  \n",
            "  inflating: hateful_memes/img/16253.png  \n",
            "  inflating: hateful_memes/img/53810.png  \n",
            "  inflating: hateful_memes/img/76038.png  \n",
            "  inflating: hateful_memes/img/08964.png  \n",
            "  inflating: hateful_memes/img/84325.png  \n",
            "  inflating: hateful_memes/img/17853.png  \n",
            "  inflating: hateful_memes/img/63159.png  \n",
            "  inflating: hateful_memes/img/65037.png  \n",
            "  inflating: hateful_memes/img/02374.png  \n",
            "  inflating: hateful_memes/img/37681.png  \n",
            "  inflating: hateful_memes/img/02614.png  \n",
            "  inflating: hateful_memes/img/72946.png  \n",
            "  inflating: hateful_memes/img/79134.png  \n",
            "  inflating: hateful_memes/img/21534.png  \n",
            "  inflating: hateful_memes/img/59873.png  \n",
            "  inflating: hateful_memes/img/64172.png  \n",
            "  inflating: hateful_memes/img/47125.png  \n",
            "  inflating: hateful_memes/img/91627.png  \n",
            "  inflating: hateful_memes/img/41539.png  \n",
            "  inflating: hateful_memes/img/28176.png  \n",
            "  inflating: hateful_memes/img/61347.png  \n",
            "  inflating: hateful_memes/img/69518.png  \n",
            "  inflating: hateful_memes/img/58069.png  \n",
            "  inflating: hateful_memes/img/52479.png  \n",
            "  inflating: hateful_memes/img/34728.png  \n",
            "  inflating: hateful_memes/img/34095.png  \n",
            "  inflating: hateful_memes/img/26049.png  \n",
            "  inflating: hateful_memes/img/24875.png  \n",
            "  inflating: hateful_memes/img/03847.png  \n",
            "  inflating: hateful_memes/img/37580.png  \n",
            "  inflating: hateful_memes/img/52473.png  \n",
            "  inflating: hateful_memes/img/69140.png  \n",
            "  inflating: hateful_memes/img/57618.png  \n",
            "  inflating: hateful_memes/img/15872.png  \n",
            "  inflating: hateful_memes/img/78560.png  \n",
            "  inflating: hateful_memes/img/65281.png  \n",
            "  inflating: hateful_memes/img/79680.png  \n",
            "  inflating: hateful_memes/img/19780.png  \n",
            "  inflating: hateful_memes/img/76490.png  \n",
            "  inflating: hateful_memes/img/16297.png  \n",
            "  inflating: hateful_memes/img/95714.png  \n",
            "  inflating: hateful_memes/img/78124.png  \n",
            "  inflating: hateful_memes/img/25748.png  \n",
            "  inflating: hateful_memes/img/78495.png  \n",
            "  inflating: hateful_memes/img/13045.png  \n",
            "  inflating: hateful_memes/img/28516.png  \n",
            "  inflating: hateful_memes/img/01762.png  \n",
            "  inflating: hateful_memes/img/25467.png  \n",
            "  inflating: hateful_memes/img/58276.png  \n",
            "  inflating: hateful_memes/img/54690.png  \n",
            "  inflating: hateful_memes/img/75461.png  \n",
            "  inflating: hateful_memes/img/86457.png  \n",
            "  inflating: hateful_memes/img/19457.png  \n",
            "  inflating: hateful_memes/img/53764.png  \n",
            "  inflating: hateful_memes/img/68325.png  \n",
            "  inflating: hateful_memes/img/31527.png  \n",
            "  inflating: hateful_memes/img/03917.png  \n",
            "  inflating: hateful_memes/img/17634.png  \n",
            "  inflating: hateful_memes/img/58421.png  \n",
            "  inflating: hateful_memes/img/12873.png  \n",
            "  inflating: hateful_memes/img/58904.png  \n",
            "  inflating: hateful_memes/img/51473.png  \n",
            "  inflating: hateful_memes/img/62134.png  \n",
            "  inflating: hateful_memes/img/10489.png  \n",
            "  inflating: hateful_memes/img/05847.png  \n",
            "  inflating: hateful_memes/img/09738.png  \n",
            "  inflating: hateful_memes/img/57869.png  \n",
            "  inflating: hateful_memes/img/96308.png  \n",
            "  inflating: hateful_memes/img/54028.png  \n",
            "  inflating: hateful_memes/img/41527.png  \n",
            "  inflating: hateful_memes/img/36972.png  \n",
            "  inflating: hateful_memes/img/72016.png  \n",
            "  inflating: hateful_memes/img/91468.png  \n",
            "  inflating: hateful_memes/img/05936.png  \n",
            "  inflating: hateful_memes/img/53782.png  \n",
            "  inflating: hateful_memes/img/07658.png  \n",
            "  inflating: hateful_memes/img/65178.png  \n",
            "  inflating: hateful_memes/img/30576.png  \n",
            "  inflating: hateful_memes/img/95427.png  \n",
            "  inflating: hateful_memes/img/46270.png  \n",
            "  inflating: hateful_memes/img/86357.png  \n",
            "  inflating: hateful_memes/img/29316.png  \n",
            "  inflating: hateful_memes/img/67398.png  \n",
            "  inflating: hateful_memes/img/26835.png  \n",
            "  inflating: hateful_memes/img/28964.png  \n",
            "  inflating: hateful_memes/img/19567.png  \n",
            "  inflating: hateful_memes/img/39061.png  \n",
            "  inflating: hateful_memes/img/34091.png  \n",
            "  inflating: hateful_memes/img/60281.png  \n",
            "  inflating: hateful_memes/img/85970.png  \n",
            "  inflating: hateful_memes/img/07983.png  \n",
            "  inflating: hateful_memes/img/29764.png  \n",
            "  inflating: hateful_memes/img/42650.png  \n",
            "  inflating: hateful_memes/img/62739.png  \n",
            "  inflating: hateful_memes/img/05297.png  \n",
            "  inflating: hateful_memes/img/52179.png  \n",
            "  inflating: hateful_memes/img/28491.png  \n",
            "  inflating: hateful_memes/img/10832.png  \n",
            "  inflating: hateful_memes/img/73129.png  \n",
            "  inflating: hateful_memes/img/78062.png  \n",
            "  inflating: hateful_memes/img/50682.png  \n",
            "  inflating: hateful_memes/img/74612.png  \n",
            "  inflating: hateful_memes/img/98531.png  \n",
            "  inflating: hateful_memes/img/28765.png  \n",
            "  inflating: hateful_memes/img/90136.png  \n",
            "  inflating: hateful_memes/img/25413.png  \n",
            "  inflating: hateful_memes/img/69203.png  \n",
            "  inflating: hateful_memes/img/14083.png  \n",
            "  inflating: hateful_memes/img/81349.png  \n",
            "  inflating: hateful_memes/img/86730.png  \n",
            "  inflating: hateful_memes/img/97105.png  \n",
            "  inflating: hateful_memes/img/48302.png  \n",
            "  inflating: hateful_memes/img/79036.png  \n",
            "  inflating: hateful_memes/img/47960.png  \n",
            "  inflating: hateful_memes/img/06824.png  \n",
            "  inflating: hateful_memes/img/27016.png  \n",
            "  inflating: hateful_memes/img/19352.png  \n",
            "  inflating: hateful_memes/img/45263.png  \n",
            "  inflating: hateful_memes/img/24189.png  \n",
            "  inflating: hateful_memes/img/61205.png  \n",
            "  inflating: hateful_memes/img/14598.png  \n",
            "  inflating: hateful_memes/img/81956.png  \n",
            "  inflating: hateful_memes/img/54682.png  \n",
            "  inflating: hateful_memes/img/67810.png  \n",
            "  inflating: hateful_memes/img/30742.png  \n",
            "  inflating: hateful_memes/img/86413.png  \n",
            "  inflating: hateful_memes/img/90276.png  \n",
            "  inflating: hateful_memes/img/58936.png  \n",
            "  inflating: hateful_memes/img/59817.png  \n",
            "  inflating: hateful_memes/img/09238.png  \n",
            "  inflating: hateful_memes/img/54789.png  \n",
            "  inflating: hateful_memes/img/26731.png  \n",
            "  inflating: hateful_memes/img/89104.png  \n",
            "  inflating: hateful_memes/img/25610.png  \n",
            "  inflating: hateful_memes/img/48291.png  \n",
            "  inflating: hateful_memes/img/35097.png  \n",
            "  inflating: hateful_memes/img/10269.png  \n",
            "  inflating: hateful_memes/img/52903.png  \n",
            "  inflating: hateful_memes/img/35478.png  \n",
            "  inflating: hateful_memes/img/02814.png  \n",
            "  inflating: hateful_memes/img/46357.png  \n",
            "  inflating: hateful_memes/img/61752.png  \n",
            "  inflating: hateful_memes/img/26715.png  \n",
            "  inflating: hateful_memes/img/31270.png  \n",
            "  inflating: hateful_memes/img/42351.png  \n",
            "  inflating: hateful_memes/img/05618.png  \n",
            "  inflating: hateful_memes/img/17425.png  \n",
            "  inflating: hateful_memes/img/02571.png  \n",
            "  inflating: hateful_memes/img/81645.png  \n",
            "  inflating: hateful_memes/img/73146.png  \n",
            "  inflating: hateful_memes/img/01926.png  \n",
            "  inflating: hateful_memes/img/58490.png  \n",
            "  inflating: hateful_memes/img/30567.png  \n",
            "  inflating: hateful_memes/img/83076.png  \n",
            "  inflating: hateful_memes/img/36058.png  \n",
            "  inflating: hateful_memes/img/68230.png  \n",
            "  inflating: hateful_memes/img/31805.png  \n",
            "  inflating: hateful_memes/img/71083.png  \n",
            "  inflating: hateful_memes/img/23801.png  \n",
            "  inflating: hateful_memes/img/71905.png  \n",
            "  inflating: hateful_memes/img/61859.png  \n",
            "  inflating: hateful_memes/img/60329.png  \n",
            "  inflating: hateful_memes/img/39285.png  \n",
            "  inflating: hateful_memes/img/02483.png  \n",
            "  inflating: hateful_memes/img/21064.png  \n",
            "  inflating: hateful_memes/img/86217.png  \n",
            "  inflating: hateful_memes/img/75128.png  \n",
            "  inflating: hateful_memes/img/79624.png  \n",
            "  inflating: hateful_memes/img/82903.png  \n",
            "  inflating: hateful_memes/img/20438.png  \n",
            "  inflating: hateful_memes/img/06325.png  \n",
            "  inflating: hateful_memes/img/43520.png  \n",
            "  inflating: hateful_memes/img/79512.png  \n",
            "  inflating: hateful_memes/img/17096.png  \n",
            "  inflating: hateful_memes/img/92473.png  \n",
            "  inflating: hateful_memes/img/32568.png  \n",
            "  inflating: hateful_memes/img/31406.png  \n",
            "  inflating: hateful_memes/img/81320.png  \n",
            "  inflating: hateful_memes/img/78923.png  \n",
            "  inflating: hateful_memes/img/27950.png  \n",
            "  inflating: hateful_memes/img/07239.png  \n",
            "  inflating: hateful_memes/img/58079.png  \n",
            "  inflating: hateful_memes/img/45206.png  \n",
            "  inflating: hateful_memes/img/75104.png  \n",
            "  inflating: hateful_memes/img/61592.png  \n",
            "  inflating: hateful_memes/img/47391.png  \n",
            "  inflating: hateful_memes/img/31794.png  \n",
            "  inflating: hateful_memes/img/83907.png  \n",
            "  inflating: hateful_memes/img/04319.png  \n",
            "  inflating: hateful_memes/img/52108.png  \n",
            "  inflating: hateful_memes/img/27801.png  \n",
            "  inflating: hateful_memes/img/15097.png  \n",
            "  inflating: hateful_memes/img/97162.png  \n",
            "  inflating: hateful_memes/img/97013.png  \n",
            "  inflating: hateful_memes/img/05198.png  \n",
            "  inflating: hateful_memes/img/01498.png  \n",
            "  inflating: hateful_memes/img/03421.png  \n",
            "  inflating: hateful_memes/img/40815.png  \n",
            "  inflating: hateful_memes/img/87309.png  \n",
            "  inflating: hateful_memes/img/50817.png  \n",
            "  inflating: hateful_memes/img/14906.png  \n",
            "  inflating: hateful_memes/img/14582.png  \n",
            "  inflating: hateful_memes/img/89543.png  \n",
            "  inflating: hateful_memes/img/04361.png  \n",
            "  inflating: hateful_memes/img/21607.png  \n",
            "  inflating: hateful_memes/img/49813.png  \n",
            "  inflating: hateful_memes/img/54761.png  \n",
            "  inflating: hateful_memes/img/60931.png  \n",
            "  inflating: hateful_memes/img/23785.png  \n",
            "  inflating: hateful_memes/img/92783.png  \n",
            "  inflating: hateful_memes/img/01459.png  \n",
            "  inflating: hateful_memes/img/87241.png  \n",
            "  inflating: hateful_memes/img/92358.png  \n",
            "  inflating: hateful_memes/img/87645.png  \n",
            "  inflating: hateful_memes/img/79451.png  \n",
            "  inflating: hateful_memes/img/82761.png  \n",
            "  inflating: hateful_memes/img/36974.png  \n",
            "  inflating: hateful_memes/img/30281.png  \n",
            "  inflating: hateful_memes/img/45862.png  \n",
            "  inflating: hateful_memes/img/03926.png  \n",
            "  inflating: hateful_memes/img/38127.png  \n",
            "  inflating: hateful_memes/img/65237.png  \n",
            "  inflating: hateful_memes/img/75493.png  \n",
            "  inflating: hateful_memes/img/72981.png  \n",
            "  inflating: hateful_memes/img/96208.png  \n",
            "  inflating: hateful_memes/img/58613.png  \n",
            "  inflating: hateful_memes/img/90158.png  \n",
            "  inflating: hateful_memes/img/65341.png  \n",
            "  inflating: hateful_memes/img/87432.png  \n",
            "  inflating: hateful_memes/img/54176.png  \n",
            "  inflating: hateful_memes/img/49063.png  \n",
            "  inflating: hateful_memes/img/81395.png  \n",
            "  inflating: hateful_memes/img/50389.png  \n",
            "  inflating: hateful_memes/img/79850.png  \n",
            "  inflating: hateful_memes/img/06547.png  \n",
            "  inflating: hateful_memes/img/34872.png  \n",
            "  inflating: hateful_memes/img/32480.png  \n",
            "  inflating: hateful_memes/img/52340.png  \n",
            "  inflating: hateful_memes/img/60827.png  \n",
            "  inflating: hateful_memes/img/21548.png  \n",
            "  inflating: hateful_memes/img/70935.png  \n",
            "  inflating: hateful_memes/img/04967.png  \n",
            "  inflating: hateful_memes/img/40316.png  \n",
            "  inflating: hateful_memes/img/09128.png  \n",
            "  inflating: hateful_memes/img/16047.png  \n",
            "  inflating: hateful_memes/img/65704.png  \n",
            "  inflating: hateful_memes/img/78039.png  \n",
            "  inflating: hateful_memes/img/94067.png  \n",
            "  inflating: hateful_memes/img/42836.png  \n",
            "  inflating: hateful_memes/img/62174.png  \n",
            "  inflating: hateful_memes/img/85012.png  \n",
            "  inflating: hateful_memes/img/25381.png  \n",
            "  inflating: hateful_memes/img/23875.png  \n",
            "  inflating: hateful_memes/img/38261.png  \n",
            "  inflating: hateful_memes/img/31928.png  \n",
            "  inflating: hateful_memes/img/80713.png  \n",
            "  inflating: hateful_memes/img/70296.png  \n",
            "  inflating: hateful_memes/img/61905.png  \n",
            "  inflating: hateful_memes/img/87941.png  \n",
            "  inflating: hateful_memes/img/47836.png  \n",
            "  inflating: hateful_memes/img/09467.png  \n",
            "  inflating: hateful_memes/img/82195.png  \n",
            "  inflating: hateful_memes/img/50762.png  \n",
            "  inflating: hateful_memes/img/72891.png  \n",
            "  inflating: hateful_memes/img/91052.png  \n",
            "  inflating: hateful_memes/img/34075.png  \n",
            "  inflating: hateful_memes/img/68927.png  \n",
            "  inflating: hateful_memes/img/80195.png  \n",
            "  inflating: hateful_memes/img/89743.png  \n",
            "  inflating: hateful_memes/img/78643.png  \n",
            "  inflating: hateful_memes/img/54972.png  \n",
            "  inflating: hateful_memes/img/47698.png  \n",
            "  inflating: hateful_memes/img/25639.png  \n",
            "  inflating: hateful_memes/img/02537.png  \n",
            "  inflating: hateful_memes/img/82563.png  \n",
            "  inflating: hateful_memes/img/25468.png  \n",
            "  inflating: hateful_memes/img/79314.png  \n",
            "  inflating: hateful_memes/img/26095.png  \n",
            "  inflating: hateful_memes/img/67439.png  \n",
            "  inflating: hateful_memes/img/18963.png  \n",
            "  inflating: hateful_memes/img/36804.png  \n",
            "  inflating: hateful_memes/img/96150.png  \n",
            "  inflating: hateful_memes/img/29308.png  \n",
            "  inflating: hateful_memes/img/90843.png  \n",
            "  inflating: hateful_memes/img/28716.png  \n",
            "  inflating: hateful_memes/img/08369.png  \n",
            "  inflating: hateful_memes/img/54831.png  \n",
            "  inflating: hateful_memes/img/17462.png  \n",
            "  inflating: hateful_memes/img/53084.png  \n",
            "  inflating: hateful_memes/img/80967.png  \n",
            "  inflating: hateful_memes/img/27456.png  \n",
            "  inflating: hateful_memes/img/65041.png  \n",
            "  inflating: hateful_memes/img/15267.png  \n",
            "  inflating: hateful_memes/img/48216.png  \n",
            "  inflating: hateful_memes/img/92086.png  \n",
            "  inflating: hateful_memes/img/41269.png  \n",
            "  inflating: hateful_memes/img/35084.png  \n",
            "  inflating: hateful_memes/img/75468.png  \n",
            "  inflating: hateful_memes/img/18432.png  \n",
            "  inflating: hateful_memes/img/51462.png  \n",
            "  inflating: hateful_memes/img/62083.png  \n",
            "  inflating: hateful_memes/img/61935.png  \n",
            "  inflating: hateful_memes/img/27360.png  \n",
            "  inflating: hateful_memes/img/16278.png  \n",
            "  inflating: hateful_memes/img/19543.png  \n",
            "  inflating: hateful_memes/img/45732.png  \n",
            "  inflating: hateful_memes/img/26481.png  \n",
            "  inflating: hateful_memes/img/93524.png  \n",
            "  inflating: hateful_memes/img/12374.png  \n",
            "  inflating: hateful_memes/img/87165.png  \n",
            "  inflating: hateful_memes/img/97314.png  \n",
            "  inflating: hateful_memes/img/10789.png  \n",
            "  inflating: hateful_memes/img/97610.png  \n",
            "  inflating: hateful_memes/img/53682.png  \n",
            "  inflating: hateful_memes/img/12378.png  \n",
            "  inflating: hateful_memes/img/29046.png  \n",
            "  inflating: hateful_memes/img/87059.png  \n",
            "  inflating: hateful_memes/img/40563.png  \n",
            "  inflating: hateful_memes/img/13492.png  \n",
            "  inflating: hateful_memes/img/15029.png  \n",
            "  inflating: hateful_memes/img/70953.png  \n",
            "  inflating: hateful_memes/img/21348.png  \n",
            "  inflating: hateful_memes/img/83745.png  \n",
            "  inflating: hateful_memes/img/91432.png  \n",
            "  inflating: hateful_memes/img/41875.png  \n",
            "  inflating: hateful_memes/img/39264.png  \n",
            "  inflating: hateful_memes/img/93268.png  \n",
            "  inflating: hateful_memes/img/39652.png  \n",
            "  inflating: hateful_memes/img/18045.png  \n",
            "  inflating: hateful_memes/img/74192.png  \n",
            "  inflating: hateful_memes/img/38524.png  \n",
            "  inflating: hateful_memes/img/04132.png  \n",
            "  inflating: hateful_memes/img/29013.png  \n",
            "  inflating: hateful_memes/img/78014.png  \n",
            "  inflating: hateful_memes/img/57982.png  \n",
            "  inflating: hateful_memes/img/16082.png  \n",
            "  inflating: hateful_memes/img/84916.png  \n",
            "  inflating: hateful_memes/img/05978.png  \n",
            "  inflating: hateful_memes/img/78623.png  \n",
            "  inflating: hateful_memes/img/06795.png  \n",
            "  inflating: hateful_memes/img/65794.png  \n",
            "  inflating: hateful_memes/img/38624.png  \n",
            "  inflating: hateful_memes/img/63580.png  \n",
            "  inflating: hateful_memes/img/61038.png  \n",
            "  inflating: hateful_memes/img/53214.png  \n",
            "  inflating: hateful_memes/img/75846.png  \n",
            "  inflating: hateful_memes/img/60345.png  \n",
            "  inflating: hateful_memes/img/80734.png  \n",
            "  inflating: hateful_memes/img/68450.png  \n",
            "  inflating: hateful_memes/img/34796.png  \n",
            "  inflating: hateful_memes/img/16973.png  \n",
            "  inflating: hateful_memes/img/72150.png  \n",
            "  inflating: hateful_memes/img/20958.png  \n",
            "  inflating: hateful_memes/img/83492.png  \n",
            "  inflating: hateful_memes/img/54692.png  \n",
            "  inflating: hateful_memes/img/06827.png  \n",
            "  inflating: hateful_memes/img/29437.png  \n",
            "  inflating: hateful_memes/img/05498.png  \n",
            "  inflating: hateful_memes/img/18526.png  \n",
            "  inflating: hateful_memes/img/09831.png  \n",
            "  inflating: hateful_memes/img/16520.png  \n",
            "  inflating: hateful_memes/img/83402.png  \n",
            "  inflating: hateful_memes/img/20374.png  \n",
            "  inflating: hateful_memes/img/04765.png  \n",
            "  inflating: hateful_memes/img/27548.png  \n",
            "  inflating: hateful_memes/img/45017.png  \n",
            "  inflating: hateful_memes/img/83124.png  \n",
            "  inflating: hateful_memes/img/41983.png  \n",
            "  inflating: hateful_memes/img/24319.png  \n",
            "  inflating: hateful_memes/img/12657.png  \n",
            "  inflating: hateful_memes/img/47829.png  \n",
            "  inflating: hateful_memes/img/52190.png  \n",
            "  inflating: hateful_memes/img/71596.png  \n",
            "  inflating: hateful_memes/img/92607.png  \n",
            "  inflating: hateful_memes/img/79053.png  \n",
            "  inflating: hateful_memes/img/61597.png  \n",
            "  inflating: hateful_memes/img/38416.png  \n",
            "  inflating: hateful_memes/img/20396.png  \n",
            "  inflating: hateful_memes/img/75186.png  \n",
            "  inflating: hateful_memes/img/27914.png  \n",
            "  inflating: hateful_memes/img/62081.png  \n",
            "  inflating: hateful_memes/img/74502.png  \n",
            "  inflating: hateful_memes/img/13469.png  \n",
            "  inflating: hateful_memes/img/57941.png  \n",
            "  inflating: hateful_memes/img/40821.png  \n",
            "  inflating: hateful_memes/img/29703.png  \n",
            "  inflating: hateful_memes/img/07562.png  \n",
            "  inflating: hateful_memes/img/59420.png  \n",
            "  inflating: hateful_memes/img/71693.png  \n",
            "  inflating: hateful_memes/img/87061.png  \n",
            "  inflating: hateful_memes/img/91273.png  \n",
            "  inflating: hateful_memes/img/47259.png  \n",
            "  inflating: hateful_memes/img/36724.png  \n",
            "  inflating: hateful_memes/img/68520.png  \n",
            "  inflating: hateful_memes/img/34816.png  \n",
            "  inflating: hateful_memes/img/02436.png  \n",
            "  inflating: hateful_memes/img/39504.png  \n",
            "  inflating: hateful_memes/img/26537.png  \n",
            "  inflating: hateful_memes/img/63709.png  \n",
            "  inflating: hateful_memes/img/07125.png  \n",
            "  inflating: hateful_memes/img/10948.png  \n",
            "  inflating: hateful_memes/img/94031.png  \n",
            "  inflating: hateful_memes/img/16283.png  \n",
            "  inflating: hateful_memes/img/81943.png  \n",
            "  inflating: hateful_memes/img/63472.png  \n",
            "  inflating: hateful_memes/img/73256.png  \n",
            "  inflating: hateful_memes/img/38726.png  \n",
            "  inflating: hateful_memes/img/25103.png  \n",
            "  inflating: hateful_memes/img/81054.png  \n",
            "  inflating: hateful_memes/img/38576.png  \n",
            "  inflating: hateful_memes/img/10548.png  \n",
            "  inflating: hateful_memes/img/75068.png  \n",
            "  inflating: hateful_memes/img/15638.png  \n",
            "  inflating: hateful_memes/img/19452.png  \n",
            "  inflating: hateful_memes/img/16894.png  \n",
            "  inflating: hateful_memes/img/80157.png  \n",
            "  inflating: hateful_memes/img/16734.png  \n",
            "  inflating: hateful_memes/img/75209.png  \n",
            "  inflating: hateful_memes/img/75680.png  \n",
            "  inflating: hateful_memes/img/17023.png  \n",
            "  inflating: hateful_memes/img/84901.png  \n",
            "  inflating: hateful_memes/img/71682.png  \n",
            "  inflating: hateful_memes/img/47826.png  \n",
            "  inflating: hateful_memes/img/47098.png  \n",
            "  inflating: hateful_memes/img/85310.png  \n",
            "  inflating: hateful_memes/img/28197.png  \n",
            "  inflating: hateful_memes/img/48710.png  \n",
            "  inflating: hateful_memes/img/79524.png  \n",
            "  inflating: hateful_memes/img/58760.png  \n",
            "  inflating: hateful_memes/img/48917.png  \n",
            "  inflating: hateful_memes/img/92136.png  \n",
            "  inflating: hateful_memes/img/71625.png  \n",
            "  inflating: hateful_memes/img/93128.png  \n",
            "  inflating: hateful_memes/img/12067.png  \n",
            "  inflating: hateful_memes/img/89750.png  \n",
            "  inflating: hateful_memes/img/40721.png  \n",
            "  inflating: hateful_memes/img/98105.png  \n",
            "  inflating: hateful_memes/img/48529.png  \n",
            "  inflating: hateful_memes/img/10384.png  \n",
            "  inflating: hateful_memes/img/51943.png  \n",
            "  inflating: hateful_memes/img/12534.png  \n",
            "  inflating: hateful_memes/img/63210.png  \n",
            "  inflating: hateful_memes/img/98416.png  \n",
            "  inflating: hateful_memes/img/36450.png  \n",
            "  inflating: hateful_memes/img/04712.png  \n",
            "  inflating: hateful_memes/img/10483.png  \n",
            "  inflating: hateful_memes/img/98706.png  \n",
            "  inflating: hateful_memes/img/39078.png  \n",
            "  inflating: hateful_memes/img/98513.png  \n",
            "  inflating: hateful_memes/img/81043.png  \n",
            "  inflating: hateful_memes/img/34675.png  \n",
            "  inflating: hateful_memes/img/19458.png  \n",
            "  inflating: hateful_memes/img/50239.png  \n",
            "  inflating: hateful_memes/img/01643.png  \n",
            "  inflating: hateful_memes/img/32604.png  \n",
            "  inflating: hateful_memes/img/06951.png  \n",
            "  inflating: hateful_memes/img/76032.png  \n",
            "  inflating: hateful_memes/img/71620.png  \n",
            "  inflating: hateful_memes/img/76821.png  \n",
            "  inflating: hateful_memes/img/84269.png  \n",
            "  inflating: hateful_memes/img/21973.png  \n",
            "  inflating: hateful_memes/img/75984.png  \n",
            "  inflating: hateful_memes/img/63859.png  \n",
            "  inflating: hateful_memes/img/47385.png  \n",
            "  inflating: hateful_memes/img/92058.png  \n",
            "  inflating: hateful_memes/img/85976.png  \n",
            "  inflating: hateful_memes/img/78092.png  \n",
            "  inflating: hateful_memes/img/38529.png  \n",
            "  inflating: hateful_memes/img/59701.png  \n",
            "  inflating: hateful_memes/img/03874.png  \n",
            "  inflating: hateful_memes/img/95426.png  \n",
            "  inflating: hateful_memes/img/74912.png  \n",
            "  inflating: hateful_memes/img/90842.png  \n",
            "  inflating: hateful_memes/img/97436.png  \n",
            "  inflating: hateful_memes/img/96270.png  \n",
            "  inflating: hateful_memes/img/60197.png  \n",
            "  inflating: hateful_memes/img/29035.png  \n",
            "  inflating: hateful_memes/img/10385.png  \n",
            "  inflating: hateful_memes/img/46390.png  \n",
            "  inflating: hateful_memes/img/36954.png  \n",
            "  inflating: hateful_memes/img/02795.png  \n",
            "  inflating: hateful_memes/img/17246.png  \n",
            "  inflating: hateful_memes/img/45621.png  \n",
            "  inflating: hateful_memes/img/05827.png  \n",
            "  inflating: hateful_memes/img/52894.png  \n",
            "  inflating: hateful_memes/img/35601.png  \n",
            "  inflating: hateful_memes/img/86320.png  \n",
            "  inflating: hateful_memes/img/16245.png  \n",
            "  inflating: hateful_memes/img/76293.png  \n",
            "  inflating: hateful_memes/img/93521.png  \n",
            "  inflating: hateful_memes/img/52860.png  \n",
            "  inflating: hateful_memes/img/04923.png  \n",
            "  inflating: hateful_memes/img/41276.png  \n",
            "  inflating: hateful_memes/img/51894.png  \n",
            "  inflating: hateful_memes/img/56917.png  \n",
            "  inflating: hateful_memes/img/47615.png  \n",
            "  inflating: hateful_memes/img/05869.png  \n",
            "  inflating: hateful_memes/img/17385.png  \n",
            "  inflating: hateful_memes/img/59217.png  \n",
            "  inflating: hateful_memes/img/23941.png  \n",
            "  inflating: hateful_memes/img/09785.png  \n",
            "  inflating: hateful_memes/img/72160.png  \n",
            "  inflating: hateful_memes/img/51284.png  \n",
            "  inflating: hateful_memes/img/26891.png  \n",
            "  inflating: hateful_memes/img/79185.png  \n",
            "  inflating: hateful_memes/img/50869.png  \n",
            "  inflating: hateful_memes/img/17324.png  \n",
            "  inflating: hateful_memes/img/74318.png  \n",
            "  inflating: hateful_memes/img/06123.png  \n",
            "  inflating: hateful_memes/img/40372.png  \n",
            "  inflating: hateful_memes/img/05614.png  \n",
            "  inflating: hateful_memes/img/35417.png  \n",
            "  inflating: hateful_memes/img/12536.png  \n",
            "  inflating: hateful_memes/img/95078.png  \n",
            "  inflating: hateful_memes/img/76910.png  \n",
            "  inflating: hateful_memes/img/45871.png  \n",
            "  inflating: hateful_memes/img/81026.png  \n",
            "  inflating: hateful_memes/img/32964.png  \n",
            "  inflating: hateful_memes/img/25874.png  \n",
            "  inflating: hateful_memes/img/60971.png  \n",
            "  inflating: hateful_memes/img/78034.png  \n",
            "  inflating: hateful_memes/img/23105.png  \n",
            "  inflating: hateful_memes/img/42538.png  \n",
            "  inflating: hateful_memes/img/70452.png  \n",
            "  inflating: hateful_memes/img/30276.png  \n",
            "  inflating: hateful_memes/img/08423.png  \n",
            "  inflating: hateful_memes/img/17392.png  \n",
            "  inflating: hateful_memes/img/64752.png  \n",
            "  inflating: hateful_memes/img/30714.png  \n",
            "  inflating: hateful_memes/img/96402.png  \n",
            "  inflating: hateful_memes/img/69150.png  \n",
            "  inflating: hateful_memes/img/02983.png  \n",
            "  inflating: hateful_memes/img/47305.png  \n",
            "  inflating: hateful_memes/img/13675.png  \n",
            "  inflating: hateful_memes/img/39051.png  \n",
            "  inflating: hateful_memes/img/45062.png  \n",
            "  inflating: hateful_memes/img/91245.png  \n",
            "  inflating: hateful_memes/img/90627.png  \n",
            "  inflating: hateful_memes/img/56974.png  \n",
            "  inflating: hateful_memes/img/62854.png  \n",
            "  inflating: hateful_memes/img/48703.png  \n",
            "  inflating: hateful_memes/img/37298.png  \n",
            "  inflating: hateful_memes/img/38057.png  \n",
            "  inflating: hateful_memes/img/71634.png  \n",
            "  inflating: hateful_memes/img/83905.png  \n",
            "  inflating: hateful_memes/img/43152.png  \n",
            "  inflating: hateful_memes/img/95237.png  \n",
            "  inflating: hateful_memes/img/53962.png  \n",
            "  inflating: hateful_memes/img/74862.png  \n",
            "  inflating: hateful_memes/img/61037.png  \n",
            "  inflating: hateful_memes/img/10238.png  \n",
            "  inflating: hateful_memes/img/34082.png  \n",
            "  inflating: hateful_memes/img/53249.png  \n",
            "  inflating: hateful_memes/img/98170.png  \n",
            "  inflating: hateful_memes/img/85721.png  \n",
            "  inflating: hateful_memes/img/71480.png  \n",
            "  inflating: hateful_memes/img/03285.png  \n",
            "  inflating: hateful_memes/img/35917.png  \n",
            "  inflating: hateful_memes/img/69410.png  \n",
            "  inflating: hateful_memes/img/08219.png  \n",
            "  inflating: hateful_memes/img/60254.png  \n",
            "  inflating: hateful_memes/img/29756.png  \n",
            "  inflating: hateful_memes/img/24573.png  \n",
            "  inflating: hateful_memes/img/26981.png  \n",
            "  inflating: hateful_memes/img/45120.png  \n",
            "  inflating: hateful_memes/img/71653.png  \n",
            "  inflating: hateful_memes/img/16935.png  \n",
            "  inflating: hateful_memes/img/17860.png  \n",
            "  inflating: hateful_memes/img/80316.png  \n",
            "  inflating: hateful_memes/img/08732.png  \n",
            "  inflating: hateful_memes/img/45960.png  \n",
            "  inflating: hateful_memes/img/16587.png  \n",
            "  inflating: hateful_memes/img/97361.png  \n",
            "  inflating: hateful_memes/img/91348.png  \n",
            "  inflating: hateful_memes/img/50942.png  \n",
            "  inflating: hateful_memes/img/54968.png  \n",
            "  inflating: hateful_memes/img/50689.png  \n",
            "  inflating: hateful_memes/img/19406.png  \n",
            "  inflating: hateful_memes/img/93102.png  \n",
            "  inflating: hateful_memes/img/45978.png  \n",
            "  inflating: hateful_memes/img/08215.png  \n",
            "  inflating: hateful_memes/img/89206.png  \n",
            "  inflating: hateful_memes/img/19358.png  \n",
            "  inflating: hateful_memes/img/63192.png  \n",
            "  inflating: hateful_memes/img/29710.png  \n",
            "  inflating: hateful_memes/img/10743.png  \n",
            "  inflating: hateful_memes/img/20591.png  \n",
            "  inflating: hateful_memes/img/31508.png  \n",
            "  inflating: hateful_memes/img/92104.png  \n",
            "  inflating: hateful_memes/img/32608.png  \n",
            "  inflating: hateful_memes/img/13098.png  \n",
            "  inflating: hateful_memes/img/63845.png  \n",
            "  inflating: hateful_memes/img/07269.png  \n",
            "  inflating: hateful_memes/img/53426.png  \n",
            "  inflating: hateful_memes/img/21486.png  \n",
            "  inflating: hateful_memes/img/34652.png  \n",
            "  inflating: hateful_memes/img/76285.png  \n",
            "  inflating: hateful_memes/img/10732.png  \n",
            "  inflating: hateful_memes/img/50738.png  \n",
            "  inflating: hateful_memes/img/41936.png  \n",
            "  inflating: hateful_memes/img/87563.png  \n",
            "  inflating: hateful_memes/img/69425.png  \n",
            "  inflating: hateful_memes/img/05627.png  \n",
            "  inflating: hateful_memes/img/05874.png  \n",
            "  inflating: hateful_memes/img/52019.png  \n",
            "  inflating: hateful_memes/img/86437.png  \n",
            "  inflating: hateful_memes/img/61980.png  \n",
            "  inflating: hateful_memes/img/37261.png  \n",
            "  inflating: hateful_memes/img/42058.png  \n",
            "  inflating: hateful_memes/img/27816.png  \n",
            "  inflating: hateful_memes/img/30492.png  \n",
            "  inflating: hateful_memes/img/42368.png  \n",
            "  inflating: hateful_memes/img/35408.png  \n",
            "  inflating: hateful_memes/img/27953.png  \n",
            "  inflating: hateful_memes/img/78631.png  \n",
            "  inflating: hateful_memes/img/10748.png  \n",
            "  inflating: hateful_memes/img/87125.png  \n",
            "  inflating: hateful_memes/img/72095.png  \n",
            "  inflating: hateful_memes/img/62917.png  \n",
            "  inflating: hateful_memes/img/94217.png  \n",
            "  inflating: hateful_memes/img/86927.png  \n",
            "  inflating: hateful_memes/img/43792.png  \n",
            "  inflating: hateful_memes/img/63041.png  \n",
            "  inflating: hateful_memes/img/76091.png  \n",
            "  inflating: hateful_memes/img/17932.png  \n",
            "  inflating: hateful_memes/img/64720.png  \n",
            "  inflating: hateful_memes/img/32150.png  \n",
            "  inflating: hateful_memes/img/01349.png  \n",
            "  inflating: hateful_memes/img/60578.png  \n",
            "  inflating: hateful_memes/img/76158.png  \n",
            "  inflating: hateful_memes/img/52864.png  \n",
            "  inflating: hateful_memes/img/03472.png  \n",
            "  inflating: hateful_memes/img/61904.png  \n",
            "  inflating: hateful_memes/img/50163.png  \n",
            "  inflating: hateful_memes/img/20857.png  \n",
            "  inflating: hateful_memes/img/90187.png  \n",
            "  inflating: hateful_memes/img/95720.png  \n",
            "  inflating: hateful_memes/img/48213.png  \n",
            "  inflating: hateful_memes/img/82716.png  \n",
            "  inflating: hateful_memes/img/79250.png  \n",
            "  inflating: hateful_memes/img/17352.png  \n",
            "  inflating: hateful_memes/img/64059.png  \n",
            "  inflating: hateful_memes/img/41623.png  \n",
            "  inflating: hateful_memes/img/17438.png  \n",
            "  inflating: hateful_memes/img/42503.png  \n",
            "  inflating: hateful_memes/img/94501.png  \n",
            "  inflating: hateful_memes/img/09812.png  \n",
            "  inflating: hateful_memes/img/36128.png  \n",
            "  inflating: hateful_memes/img/57619.png  \n",
            "  inflating: hateful_memes/img/43198.png  \n",
            "  inflating: hateful_memes/img/36179.png  \n",
            "  inflating: hateful_memes/img/57638.png  \n",
            "  inflating: hateful_memes/img/62198.png  \n",
            "  inflating: hateful_memes/img/30412.png  \n",
            "  inflating: hateful_memes/img/43759.png  \n",
            "  inflating: hateful_memes/img/73604.png  \n",
            "  inflating: hateful_memes/img/13802.png  \n",
            "  inflating: hateful_memes/img/46790.png  \n",
            "  inflating: hateful_memes/img/37254.png  \n",
            "  inflating: hateful_memes/img/57132.png  \n",
            "  inflating: hateful_memes/img/28759.png  \n",
            "  inflating: hateful_memes/img/90748.png  \n",
            "  inflating: hateful_memes/img/51476.png  \n",
            "  inflating: hateful_memes/img/25107.png  \n",
            "  inflating: hateful_memes/img/50871.png  \n",
            "  inflating: hateful_memes/img/65298.png  \n",
            "  inflating: hateful_memes/img/54689.png  \n",
            "  inflating: hateful_memes/img/09374.png  \n",
            "  inflating: hateful_memes/img/45730.png  \n",
            "  inflating: hateful_memes/img/74215.png  \n",
            "  inflating: hateful_memes/img/02569.png  \n",
            "  inflating: hateful_memes/img/93852.png  \n",
            "  inflating: hateful_memes/img/79586.png  \n",
            "  inflating: hateful_memes/img/32586.png  \n",
            "  inflating: hateful_memes/img/43651.png  \n",
            "  inflating: hateful_memes/img/67348.png  \n",
            "  inflating: hateful_memes/img/09482.png  \n",
            "  inflating: hateful_memes/img/20975.png  \n",
            "  inflating: hateful_memes/img/74350.png  \n",
            "  inflating: hateful_memes/img/02957.png  \n",
            "  inflating: hateful_memes/img/43895.png  \n",
            "  inflating: hateful_memes/img/98316.png  \n",
            "  inflating: hateful_memes/img/87903.png  \n",
            "  inflating: hateful_memes/img/71593.png  \n",
            "  inflating: hateful_memes/img/15076.png  \n",
            "  inflating: hateful_memes/img/20781.png  \n",
            "  inflating: hateful_memes/img/15230.png  \n",
            "  inflating: hateful_memes/img/83517.png  \n",
            "  inflating: hateful_memes/img/73168.png  \n",
            "  inflating: hateful_memes/img/28497.png  \n",
            "  inflating: hateful_memes/img/62357.png  \n",
            "  inflating: hateful_memes/img/24351.png  \n",
            "  inflating: hateful_memes/img/01894.png  \n",
            "  inflating: hateful_memes/img/45109.png  \n",
            "  inflating: hateful_memes/img/18794.png  \n",
            "  inflating: hateful_memes/img/56108.png  \n",
            "  inflating: hateful_memes/img/36417.png  \n",
            "  inflating: hateful_memes/img/69428.png  \n",
            "  inflating: hateful_memes/img/69205.png  \n",
            "  inflating: hateful_memes/img/51789.png  \n",
            "  inflating: hateful_memes/img/81206.png  \n",
            "  inflating: hateful_memes/img/62510.png  \n",
            "  inflating: hateful_memes/img/04863.png  \n",
            "  inflating: hateful_memes/img/25193.png  \n",
            "  inflating: hateful_memes/img/67498.png  \n",
            "  inflating: hateful_memes/img/67091.png  \n",
            "  inflating: hateful_memes/img/61054.png  \n",
            "  inflating: hateful_memes/img/49806.png  \n",
            "  inflating: hateful_memes/img/07415.png  \n",
            "  inflating: hateful_memes/img/63714.png  \n",
            "  inflating: hateful_memes/img/27384.png  \n",
            "  inflating: hateful_memes/img/43971.png  \n",
            "  inflating: hateful_memes/img/60357.png  \n",
            "  inflating: hateful_memes/img/98613.png  \n",
            "  inflating: hateful_memes/img/19420.png  \n",
            "  inflating: hateful_memes/img/36195.png  \n",
            "  inflating: hateful_memes/img/68721.png  \n",
            "  inflating: hateful_memes/img/12045.png  \n",
            "  inflating: hateful_memes/img/75420.png  \n",
            "  inflating: hateful_memes/img/52096.png  \n",
            "  inflating: hateful_memes/img/89126.png  \n",
            "  inflating: hateful_memes/img/35642.png  \n",
            "  inflating: hateful_memes/img/49832.png  \n",
            "  inflating: hateful_memes/img/41853.png  \n",
            "  inflating: hateful_memes/img/02674.png  \n",
            "  inflating: hateful_memes/img/82507.png  \n",
            "  inflating: hateful_memes/img/94718.png  \n",
            "  inflating: hateful_memes/img/38056.png  \n",
            "  inflating: hateful_memes/img/38041.png  \n",
            "  inflating: hateful_memes/img/34162.png  \n",
            "  inflating: hateful_memes/img/72380.png  \n",
            "  inflating: hateful_memes/img/83765.png  \n",
            "  inflating: hateful_memes/img/93401.png  \n",
            "  inflating: hateful_memes/img/09364.png  \n",
            "  inflating: hateful_memes/img/40731.png  \n",
            "  inflating: hateful_memes/img/91234.png  \n",
            "  inflating: hateful_memes/img/81902.png  \n",
            "  inflating: hateful_memes/img/07469.png  \n",
            "  inflating: hateful_memes/img/82419.png  \n",
            "  inflating: hateful_memes/img/28936.png  \n",
            "  inflating: hateful_memes/img/42315.png  \n",
            "  inflating: hateful_memes/img/74205.png  \n",
            "  inflating: hateful_memes/img/14907.png  \n",
            "  inflating: hateful_memes/img/21387.png  \n",
            "  inflating: hateful_memes/img/51293.png  \n",
            "  inflating: hateful_memes/img/07591.png  \n",
            "  inflating: hateful_memes/img/07456.png  \n",
            "  inflating: hateful_memes/img/57430.png  \n",
            "  inflating: hateful_memes/img/18529.png  \n",
            "  inflating: hateful_memes/img/78321.png  \n",
            "  inflating: hateful_memes/img/86249.png  \n",
            "  inflating: hateful_memes/img/92013.png  \n",
            "  inflating: hateful_memes/img/85213.png  \n",
            "  inflating: hateful_memes/img/07218.png  \n",
            "  inflating: hateful_memes/img/28196.png  \n",
            "  inflating: hateful_memes/img/78296.png  \n",
            "  inflating: hateful_memes/img/90465.png  \n",
            "  inflating: hateful_memes/img/90178.png  \n",
            "  inflating: hateful_memes/img/76521.png  \n",
            "  inflating: hateful_memes/img/98401.png  \n",
            "  inflating: hateful_memes/img/12607.png  \n",
            "  inflating: hateful_memes/img/34927.png  \n",
            "  inflating: hateful_memes/img/21963.png  \n",
            "  inflating: hateful_memes/img/54670.png  \n",
            "  inflating: hateful_memes/img/30486.png  \n",
            "  inflating: hateful_memes/img/08179.png  \n",
            "  inflating: hateful_memes/img/63814.png  \n",
            "  inflating: hateful_memes/img/12675.png  \n",
            "  inflating: hateful_memes/img/76850.png  \n",
            "  inflating: hateful_memes/img/69842.png  \n",
            "  inflating: hateful_memes/img/90654.png  \n",
            "  inflating: hateful_memes/img/42975.png  \n",
            "  inflating: hateful_memes/img/90564.png  \n",
            "  inflating: hateful_memes/img/43925.png  \n",
            "  inflating: hateful_memes/img/45316.png  \n",
            "  inflating: hateful_memes/img/81764.png  \n",
            "  inflating: hateful_memes/img/25706.png  \n",
            "  inflating: hateful_memes/img/50714.png  \n",
            "  inflating: hateful_memes/img/46097.png  \n",
            "  inflating: hateful_memes/img/04695.png  \n",
            "  inflating: hateful_memes/img/42958.png  \n",
            "  inflating: hateful_memes/img/18273.png  \n",
            "  inflating: hateful_memes/img/47053.png  \n",
            "  inflating: hateful_memes/img/98015.png  \n",
            "  inflating: hateful_memes/img/90573.png  \n",
            "  inflating: hateful_memes/img/17359.png  \n",
            "  inflating: hateful_memes/img/17356.png  \n",
            "  inflating: hateful_memes/img/20541.png  \n",
            "  inflating: hateful_memes/img/89726.png  \n",
            "  inflating: hateful_memes/img/48539.png  \n",
            "  inflating: hateful_memes/img/86431.png  \n",
            "  inflating: hateful_memes/img/34518.png  \n",
            "  inflating: hateful_memes/img/03197.png  \n",
            "  inflating: hateful_memes/img/26940.png  \n",
            "  inflating: hateful_memes/img/59716.png  \n",
            "  inflating: hateful_memes/img/06291.png  \n",
            "  inflating: hateful_memes/img/21053.png  \n",
            "  inflating: hateful_memes/img/48063.png  \n",
            "  inflating: hateful_memes/img/28639.png  \n",
            "  inflating: hateful_memes/img/05863.png  \n",
            "  inflating: hateful_memes/img/38150.png  \n",
            "  inflating: hateful_memes/img/25498.png  \n",
            "  inflating: hateful_memes/img/49023.png  \n",
            "  inflating: hateful_memes/img/05283.png  \n",
            "  inflating: hateful_memes/img/69421.png  \n",
            "  inflating: hateful_memes/img/45297.png  \n",
            "  inflating: hateful_memes/img/63295.png  \n",
            "  inflating: hateful_memes/img/34975.png  \n",
            "  inflating: hateful_memes/img/94617.png  \n",
            "  inflating: hateful_memes/img/96250.png  \n",
            "  inflating: hateful_memes/img/31592.png  \n",
            "  inflating: hateful_memes/img/47652.png  \n",
            "  inflating: hateful_memes/img/67528.png  \n",
            "  inflating: hateful_memes/img/13587.png  \n",
            "  inflating: hateful_memes/img/48756.png  \n",
            "  inflating: hateful_memes/img/39867.png  \n",
            "  inflating: hateful_memes/img/29067.png  \n",
            "  inflating: hateful_memes/img/30581.png  \n",
            "  inflating: hateful_memes/img/24389.png  \n",
            "  inflating: hateful_memes/img/68472.png  \n",
            "  inflating: hateful_memes/img/09843.png  \n",
            "  inflating: hateful_memes/img/05213.png  \n",
            "  inflating: hateful_memes/img/13856.png  \n",
            "  inflating: hateful_memes/img/65378.png  \n",
            "  inflating: hateful_memes/img/18960.png  \n",
            "  inflating: hateful_memes/img/41972.png  \n",
            "  inflating: hateful_memes/img/71253.png  \n",
            "  inflating: hateful_memes/img/92108.png  \n",
            "  inflating: hateful_memes/img/52183.png  \n",
            "  inflating: hateful_memes/img/15824.png  \n",
            "  inflating: hateful_memes/img/28173.png  \n",
            "  inflating: hateful_memes/img/68954.png  \n",
            "  inflating: hateful_memes/img/57932.png  \n",
            "  inflating: hateful_memes/img/71365.png  \n",
            "  inflating: hateful_memes/img/82603.png  \n",
            "  inflating: hateful_memes/img/79603.png  \n",
            "  inflating: hateful_memes/img/43610.png  \n",
            "  inflating: hateful_memes/img/14697.png  \n",
            "  inflating: hateful_memes/img/17529.png  \n",
            "  inflating: hateful_memes/img/86045.png  \n",
            "  inflating: hateful_memes/img/21456.png  \n",
            "  inflating: hateful_memes/img/42309.png  \n",
            "  inflating: hateful_memes/img/73680.png  \n",
            "  inflating: hateful_memes/img/26379.png  \n",
            "  inflating: hateful_memes/img/94170.png  \n",
            "  inflating: hateful_memes/img/28164.png  \n",
            "  inflating: hateful_memes/img/85920.png  \n",
            "  inflating: hateful_memes/img/09386.png  \n",
            "  inflating: hateful_memes/img/21769.png  \n",
            "  inflating: hateful_memes/img/62031.png  \n",
            "  inflating: hateful_memes/img/12945.png  \n",
            "  inflating: hateful_memes/img/79312.png  \n",
            "  inflating: hateful_memes/img/61938.png  \n",
            "  inflating: hateful_memes/img/01439.png  \n",
            "  inflating: hateful_memes/img/60759.png  \n",
            "  inflating: hateful_memes/img/56287.png  \n",
            "  inflating: hateful_memes/img/63092.png  \n",
            "  inflating: hateful_memes/img/26781.png  \n",
            "  inflating: hateful_memes/img/40512.png  \n",
            "  inflating: hateful_memes/img/43186.png  \n",
            "  inflating: hateful_memes/img/09248.png  \n",
            "  inflating: hateful_memes/img/56124.png  \n",
            "  inflating: hateful_memes/img/70835.png  \n",
            "  inflating: hateful_memes/img/98473.png  \n",
            "  inflating: hateful_memes/img/96054.png  \n",
            "  inflating: hateful_memes/img/89761.png  \n",
            "  inflating: hateful_memes/img/51630.png  \n",
            "  inflating: hateful_memes/img/54936.png  \n",
            "  inflating: hateful_memes/img/78345.png  \n",
            "  inflating: hateful_memes/img/17548.png  \n",
            "  inflating: hateful_memes/img/48512.png  \n",
            "  inflating: hateful_memes/img/67140.png  \n",
            "  inflating: hateful_memes/img/61948.png  \n",
            "  inflating: hateful_memes/img/43052.png  \n",
            "  inflating: hateful_memes/img/85379.png  \n",
            "  inflating: hateful_memes/img/26057.png  \n",
            "  inflating: hateful_memes/img/41296.png  \n",
            "  inflating: hateful_memes/img/78125.png  \n",
            "  inflating: hateful_memes/img/23745.png  \n",
            "  inflating: hateful_memes/img/46359.png  \n",
            "  inflating: hateful_memes/img/08376.png  \n",
            "  inflating: hateful_memes/img/76809.png  \n",
            "  inflating: hateful_memes/img/96284.png  \n",
            "  inflating: hateful_memes/img/14259.png  \n",
            "  inflating: hateful_memes/img/49351.png  \n",
            "  inflating: hateful_memes/img/62391.png  \n",
            "  inflating: hateful_memes/img/37854.png  \n",
            "  inflating: hateful_memes/img/63720.png  \n",
            "  inflating: hateful_memes/img/47896.png  \n",
            "  inflating: hateful_memes/img/63871.png  \n",
            "  inflating: hateful_memes/img/82473.png  \n",
            "  inflating: hateful_memes/img/96872.png  \n",
            "  inflating: hateful_memes/img/93251.png  \n",
            "  inflating: hateful_memes/img/72805.png  \n",
            "  inflating: hateful_memes/img/76592.png  \n",
            "  inflating: hateful_memes/img/15270.png  \n",
            "  inflating: hateful_memes/img/97685.png  \n",
            "  inflating: hateful_memes/img/90367.png  \n",
            "  inflating: hateful_memes/img/26598.png  \n",
            "  inflating: hateful_memes/img/28451.png  \n",
            "  inflating: hateful_memes/img/25416.png  \n",
            "  inflating: hateful_memes/img/13870.png  \n",
            "  inflating: hateful_memes/img/67912.png  \n",
            "  inflating: hateful_memes/img/78619.png  \n",
            "  inflating: hateful_memes/img/12630.png  \n",
            "  inflating: hateful_memes/img/56401.png  \n",
            "  inflating: hateful_memes/img/14920.png  \n",
            "  inflating: hateful_memes/img/87905.png  \n",
            "  inflating: hateful_memes/img/62509.png  \n",
            "  inflating: hateful_memes/img/39860.png  \n",
            "  inflating: hateful_memes/img/23597.png  \n",
            "  inflating: hateful_memes/img/98604.png  \n",
            "  inflating: hateful_memes/img/72061.png  \n",
            "  inflating: hateful_memes/img/26078.png  \n",
            "  inflating: hateful_memes/img/23968.png  \n",
            "  inflating: hateful_memes/img/40256.png  \n",
            "  inflating: hateful_memes/img/40237.png  \n",
            "  inflating: hateful_memes/img/89536.png  \n",
            "  inflating: hateful_memes/img/64027.png  \n",
            "  inflating: hateful_memes/img/60892.png  \n",
            "  inflating: hateful_memes/img/96734.png  \n",
            "  inflating: hateful_memes/img/83754.png  \n",
            "  inflating: hateful_memes/img/91562.png  \n",
            "  inflating: hateful_memes/img/10746.png  \n",
            "  inflating: hateful_memes/img/83591.png  \n",
            "  inflating: hateful_memes/img/92854.png  \n",
            "  inflating: hateful_memes/img/23168.png  \n",
            "  inflating: hateful_memes/img/84951.png  \n",
            "  inflating: hateful_memes/img/20598.png  \n",
            "  inflating: hateful_memes/img/92876.png  \n",
            "  inflating: hateful_memes/img/08645.png  \n",
            "  inflating: hateful_memes/img/38697.png  \n",
            "  inflating: hateful_memes/img/01834.png  \n",
            "  inflating: hateful_memes/img/24197.png  \n",
            "  inflating: hateful_memes/img/09384.png  \n",
            "  inflating: hateful_memes/img/57169.png  \n",
            "  inflating: hateful_memes/img/58407.png  \n",
            "  inflating: hateful_memes/img/04912.png  \n",
            "  inflating: hateful_memes/img/53419.png  \n",
            "  inflating: hateful_memes/img/23954.png  \n",
            "  inflating: hateful_memes/img/60982.png  \n",
            "  inflating: hateful_memes/img/94721.png  \n",
            "  inflating: hateful_memes/img/48930.png  \n",
            "  inflating: hateful_memes/img/78163.png  \n",
            "  inflating: hateful_memes/img/43258.png  \n",
            "  inflating: hateful_memes/img/90817.png  \n",
            "  inflating: hateful_memes/img/95380.png  \n",
            "  inflating: hateful_memes/img/82537.png  \n",
            "  inflating: hateful_memes/img/36501.png  \n",
            "  inflating: hateful_memes/img/31702.png  \n",
            "  inflating: hateful_memes/img/21450.png  \n",
            "  inflating: hateful_memes/img/04687.png  \n",
            "  inflating: hateful_memes/img/09156.png  \n",
            "  inflating: hateful_memes/img/65204.png  \n",
            "  inflating: hateful_memes/img/15648.png  \n",
            "  inflating: hateful_memes/img/91453.png  \n",
            "  inflating: hateful_memes/img/34762.png  \n",
            "  inflating: hateful_memes/img/65289.png  \n",
            "  inflating: hateful_memes/img/69357.png  \n",
            "  inflating: hateful_memes/img/06418.png  \n",
            "  inflating: hateful_memes/img/42317.png  \n",
            "  inflating: hateful_memes/img/27041.png  \n",
            "  inflating: hateful_memes/img/30642.png  \n",
            "  inflating: hateful_memes/img/42673.png  \n",
            "  inflating: hateful_memes/img/87341.png  \n",
            "  inflating: hateful_memes/img/03128.png  \n",
            "  inflating: hateful_memes/img/81254.png  \n",
            "  inflating: hateful_memes/img/62581.png  \n",
            "  inflating: hateful_memes/img/39560.png  \n",
            "  inflating: hateful_memes/img/62571.png  \n",
            "  inflating: hateful_memes/img/97523.png  \n",
            "  inflating: hateful_memes/img/96058.png  \n",
            "  inflating: hateful_memes/img/89056.png  \n",
            "  inflating: hateful_memes/img/10285.png  \n",
            "  inflating: hateful_memes/img/81257.png  \n",
            "  inflating: hateful_memes/img/91026.png  \n",
            "  inflating: hateful_memes/img/81932.png  \n",
            "  inflating: hateful_memes/img/53167.png  \n",
            "  inflating: hateful_memes/img/89527.png  \n",
            "  inflating: hateful_memes/img/87251.png  \n",
            "  inflating: hateful_memes/img/96451.png  \n",
            "  inflating: hateful_memes/img/90183.png  \n",
            "  inflating: hateful_memes/img/72491.png  \n",
            "  inflating: hateful_memes/img/89723.png  \n",
            "  inflating: hateful_memes/img/21604.png  \n",
            "  inflating: hateful_memes/img/09617.png  \n",
            "  inflating: hateful_memes/img/60985.png  \n",
            "  inflating: hateful_memes/img/31694.png  \n",
            "  inflating: hateful_memes/img/54376.png  \n",
            "  inflating: hateful_memes/img/61479.png  \n",
            "  inflating: hateful_memes/img/41283.png  \n",
            "  inflating: hateful_memes/img/16509.png  \n",
            "  inflating: hateful_memes/img/34509.png  \n",
            "  inflating: hateful_memes/img/05387.png  \n",
            "  inflating: hateful_memes/img/54196.png  \n",
            "  inflating: hateful_memes/img/24857.png  \n",
            "  inflating: hateful_memes/img/81692.png  \n",
            "  inflating: hateful_memes/img/12935.png  \n",
            "  inflating: hateful_memes/img/76815.png  \n",
            "  inflating: hateful_memes/img/54701.png  \n",
            "  inflating: hateful_memes/img/63957.png  \n",
            "  inflating: hateful_memes/img/37451.png  \n",
            "  inflating: hateful_memes/img/76083.png  \n",
            "  inflating: hateful_memes/img/53291.png  \n",
            "  inflating: hateful_memes/img/28146.png  \n",
            "  inflating: hateful_memes/img/12495.png  \n",
            "  inflating: hateful_memes/img/70519.png  \n",
            "  inflating: hateful_memes/img/43609.png  \n",
            "  inflating: hateful_memes/img/71395.png  \n",
            "  inflating: hateful_memes/img/52918.png  \n",
            "  inflating: hateful_memes/img/80612.png  \n",
            "  inflating: hateful_memes/img/57698.png  \n",
            "  inflating: hateful_memes/img/90723.png  \n",
            "  inflating: hateful_memes/img/04917.png  \n",
            "  inflating: hateful_memes/img/48295.png  \n",
            "  inflating: hateful_memes/img/37802.png  \n",
            "  inflating: hateful_memes/img/60852.png  \n",
            "  inflating: hateful_memes/img/78263.png  \n",
            "  inflating: hateful_memes/img/13986.png  \n",
            "  inflating: hateful_memes/img/67029.png  \n",
            "  inflating: hateful_memes/img/68943.png  \n",
            "  inflating: hateful_memes/img/46380.png  \n",
            "  inflating: hateful_memes/img/12349.png  \n",
            "  inflating: hateful_memes/img/57148.png  \n",
            "  inflating: hateful_memes/img/21509.png  \n",
            "  inflating: hateful_memes/img/40876.png  \n",
            "  inflating: hateful_memes/img/43728.png  \n",
            "  inflating: hateful_memes/img/94578.png  \n",
            "  inflating: hateful_memes/img/23760.png  \n",
            "  inflating: hateful_memes/img/57490.png  \n",
            "  inflating: hateful_memes/img/78610.png  \n",
            "  inflating: hateful_memes/img/81243.png  \n",
            "  inflating: hateful_memes/img/87065.png  \n",
            "  inflating: hateful_memes/img/36945.png  \n",
            "  inflating: hateful_memes/img/90461.png  \n",
            "  inflating: hateful_memes/img/48523.png  \n",
            "  inflating: hateful_memes/img/71380.png  \n",
            "  inflating: hateful_memes/img/09162.png  \n",
            "  inflating: hateful_memes/img/12594.png  \n",
            "  inflating: hateful_memes/img/23074.png  \n",
            "  inflating: hateful_memes/img/76583.png  \n",
            "  inflating: hateful_memes/img/06948.png  \n",
            "  inflating: hateful_memes/img/10793.png  \n",
            "  inflating: hateful_memes/img/42361.png  \n",
            "  inflating: hateful_memes/img/48153.png  \n",
            "  inflating: hateful_memes/img/43259.png  \n",
            "  inflating: hateful_memes/img/62981.png  \n",
            "  inflating: hateful_memes/img/17034.png  \n",
            "  inflating: hateful_memes/img/32960.png  \n",
            "  inflating: hateful_memes/img/48715.png  \n",
            "  inflating: hateful_memes/img/01524.png  \n",
            "  inflating: hateful_memes/img/61458.png  \n",
            "  inflating: hateful_memes/img/50918.png  \n",
            "  inflating: hateful_memes/img/87403.png  \n",
            "  inflating: hateful_memes/img/20578.png  \n",
            "  inflating: hateful_memes/img/53768.png  \n",
            "  inflating: hateful_memes/img/01284.png  \n",
            "  inflating: hateful_memes/img/87426.png  \n",
            "  inflating: hateful_memes/img/07451.png  \n",
            "  inflating: hateful_memes/img/56082.png  \n",
            "  inflating: hateful_memes/img/68042.png  \n",
            "  inflating: hateful_memes/img/01936.png  \n",
            "  inflating: hateful_memes/img/09461.png  \n",
            "  inflating: hateful_memes/img/75014.png  \n",
            "  inflating: hateful_memes/img/46123.png  \n",
            "  inflating: hateful_memes/img/07426.png  \n",
            "  inflating: hateful_memes/img/17829.png  \n",
            "  inflating: hateful_memes/img/06897.png  \n",
            "  inflating: hateful_memes/img/92710.png  \n",
            "  inflating: hateful_memes/img/12769.png  \n",
            "  inflating: hateful_memes/img/08495.png  \n",
            "  inflating: hateful_memes/img/26394.png  \n",
            "  inflating: hateful_memes/img/68327.png  \n",
            "  inflating: hateful_memes/img/25017.png  \n",
            "  inflating: hateful_memes/img/61823.png  \n",
            "  inflating: hateful_memes/img/31684.png  \n",
            "  inflating: hateful_memes/img/86237.png  \n",
            "  inflating: hateful_memes/img/65714.png  \n",
            "  inflating: hateful_memes/img/29761.png  \n",
            "  inflating: hateful_memes/img/70269.png  \n",
            "  inflating: hateful_memes/img/43816.png  \n",
            "  inflating: hateful_memes/img/20871.png  \n",
            "  inflating: hateful_memes/img/41087.png  \n",
            "  inflating: hateful_memes/img/92417.png  \n",
            "  inflating: hateful_memes/img/07465.png  \n",
            "  inflating: hateful_memes/img/61580.png  \n",
            "  inflating: hateful_memes/img/82693.png  \n",
            "  inflating: hateful_memes/img/81950.png  \n",
            "  inflating: hateful_memes/img/28534.png  \n",
            "  inflating: hateful_memes/img/90614.png  \n",
            "  inflating: hateful_memes/img/18420.png  \n",
            "  inflating: hateful_memes/img/53904.png  \n",
            "  inflating: hateful_memes/img/31629.png  \n",
            "  inflating: hateful_memes/img/07935.png  \n",
            "  inflating: hateful_memes/img/45128.png  \n",
            "  inflating: hateful_memes/img/67084.png  \n",
            "  inflating: hateful_memes/img/35896.png  \n",
            "  inflating: hateful_memes/img/65240.png  \n",
            "  inflating: hateful_memes/img/21978.png  \n",
            "  inflating: hateful_memes/img/49703.png  \n",
            "  inflating: hateful_memes/img/76098.png  \n",
            "  inflating: hateful_memes/img/87209.png  \n",
            "  inflating: hateful_memes/img/85173.png  \n",
            "  inflating: hateful_memes/img/06195.png  \n",
            "  inflating: hateful_memes/img/48320.png  \n",
            "  inflating: hateful_memes/img/82457.png  \n",
            "  inflating: hateful_memes/img/69084.png  \n",
            "  inflating: hateful_memes/img/37569.png  \n",
            "  inflating: hateful_memes/img/28039.png  \n",
            "  inflating: hateful_memes/img/34056.png  \n",
            "  inflating: hateful_memes/img/15847.png  \n",
            "  inflating: hateful_memes/img/52948.png  \n",
            "  inflating: hateful_memes/img/20879.png  \n",
            "  inflating: hateful_memes/img/76431.png  \n",
            "  inflating: hateful_memes/img/93650.png  \n",
            "  inflating: hateful_memes/img/54629.png  \n",
            "  inflating: hateful_memes/img/05792.png  \n",
            "  inflating: hateful_memes/img/42895.png  \n",
            "  inflating: hateful_memes/img/19257.png  \n",
            "  inflating: hateful_memes/img/12356.png  \n",
            "  inflating: hateful_memes/img/20846.png  \n",
            "  inflating: hateful_memes/img/67130.png  \n",
            "  inflating: hateful_memes/img/05398.png  \n",
            "  inflating: hateful_memes/img/47051.png  \n",
            "  inflating: hateful_memes/img/93642.png  \n",
            "  inflating: hateful_memes/img/98530.png  \n",
            "  inflating: hateful_memes/img/10527.png  \n",
            "  inflating: hateful_memes/img/10839.png  \n",
            "  inflating: hateful_memes/img/95386.png  \n",
            "  inflating: hateful_memes/img/14953.png  \n",
            "  inflating: hateful_memes/img/23859.png  \n",
            "  inflating: hateful_memes/img/95038.png  \n",
            "  inflating: hateful_memes/img/39284.png  \n",
            "  inflating: hateful_memes/img/01235.png  \n",
            "  inflating: hateful_memes/img/19427.png  \n",
            "  inflating: hateful_memes/img/95863.png  \n",
            "  inflating: hateful_memes/img/37821.png  \n",
            "  inflating: hateful_memes/img/57302.png  \n",
            "  inflating: hateful_memes/img/61723.png  \n",
            "  inflating: hateful_memes/img/35174.png  \n",
            "  inflating: hateful_memes/img/65201.png  \n",
            "  inflating: hateful_memes/img/89642.png  \n",
            "  inflating: hateful_memes/img/42167.png  \n",
            "  inflating: hateful_memes/img/83976.png  \n",
            "  inflating: hateful_memes/img/76243.png  \n",
            "  inflating: hateful_memes/img/43658.png  \n",
            "  inflating: hateful_memes/img/76819.png  \n",
            "  inflating: hateful_memes/img/57389.png  \n",
            "  inflating: hateful_memes/img/43069.png  \n",
            "  inflating: hateful_memes/img/87513.png  \n",
            "  inflating: hateful_memes/img/67108.png  \n",
            "  inflating: hateful_memes/img/59178.png  \n",
            "  inflating: hateful_memes/img/43087.png  \n",
            "  inflating: hateful_memes/img/71263.png  \n",
            "  inflating: hateful_memes/img/97184.png  \n",
            "  inflating: hateful_memes/img/50498.png  \n",
            "  inflating: hateful_memes/img/24365.png  \n",
            "  inflating: hateful_memes/img/70432.png  \n",
            "  inflating: hateful_memes/img/19752.png  \n",
            "  inflating: hateful_memes/img/94823.png  \n",
            "  inflating: hateful_memes/img/19302.png  \n",
            "  inflating: hateful_memes/img/39470.png  \n",
            "  inflating: hateful_memes/img/52964.png  \n",
            "  inflating: hateful_memes/img/60371.png  \n",
            "  inflating: hateful_memes/img/72608.png  \n",
            "  inflating: hateful_memes/img/21763.png  \n",
            "  inflating: hateful_memes/img/18325.png  \n",
            "  inflating: hateful_memes/img/56981.png  \n",
            "  inflating: hateful_memes/img/76213.png  \n",
            "  inflating: hateful_memes/img/72645.png  \n",
            "  inflating: hateful_memes/img/94180.png  \n",
            "  inflating: hateful_memes/img/84013.png  \n",
            "  inflating: hateful_memes/img/52938.png  \n",
            "  inflating: hateful_memes/img/47208.png  \n",
            "  inflating: hateful_memes/img/93618.png  \n",
            "  inflating: hateful_memes/img/36028.png  \n",
            "  inflating: hateful_memes/img/67025.png  \n",
            "  inflating: hateful_memes/img/91274.png  \n",
            "  inflating: hateful_memes/img/29416.png  \n",
            "  inflating: hateful_memes/img/10579.png  \n",
            "  inflating: hateful_memes/img/12876.png  \n",
            "  inflating: hateful_memes/img/27591.png  \n",
            "  inflating: hateful_memes/img/30267.png  \n",
            "  inflating: hateful_memes/img/69237.png  \n",
            "  inflating: hateful_memes/img/97146.png  \n",
            "  inflating: hateful_memes/img/02631.png  \n",
            "  inflating: hateful_memes/img/04675.png  \n",
            "  inflating: hateful_memes/img/09486.png  \n",
            "  inflating: hateful_memes/img/19540.png  \n",
            "  inflating: hateful_memes/img/74203.png  \n",
            "  inflating: hateful_memes/img/86021.png  \n",
            "  inflating: hateful_memes/img/50461.png  \n",
            "  inflating: hateful_memes/img/16702.png  \n",
            "  inflating: hateful_memes/img/16573.png  \n",
            "  inflating: hateful_memes/img/35264.png  \n",
            "  inflating: hateful_memes/img/18075.png  \n",
            "  inflating: hateful_memes/img/51890.png  \n",
            "  inflating: hateful_memes/img/16759.png  \n",
            "  inflating: hateful_memes/img/82946.png  \n",
            "  inflating: hateful_memes/img/06892.png  \n",
            "  inflating: hateful_memes/img/25180.png  \n",
            "  inflating: hateful_memes/img/95831.png  \n",
            "  inflating: hateful_memes/img/37824.png  \n",
            "  inflating: hateful_memes/img/17643.png  \n",
            "  inflating: hateful_memes/img/59163.png  \n",
            "  inflating: hateful_memes/img/07539.png  \n",
            "  inflating: hateful_memes/img/21504.png  \n",
            "  inflating: hateful_memes/img/34765.png  \n",
            "  inflating: hateful_memes/img/64029.png  \n",
            "  inflating: hateful_memes/img/79105.png  \n",
            "  inflating: hateful_memes/img/57128.png  \n",
            "  inflating: hateful_memes/img/76023.png  \n",
            "  inflating: hateful_memes/img/37924.png  \n",
            "  inflating: hateful_memes/img/12094.png  \n",
            "  inflating: hateful_memes/img/46218.png  \n",
            "  inflating: hateful_memes/img/90365.png  \n",
            "  inflating: hateful_memes/img/48976.png  \n",
            "  inflating: hateful_memes/img/48509.png  \n",
            "  inflating: hateful_memes/img/24658.png  \n",
            "  inflating: hateful_memes/img/23018.png  \n",
            "  inflating: hateful_memes/img/97348.png  \n",
            "  inflating: hateful_memes/img/10627.png  \n",
            "  inflating: hateful_memes/img/36178.png  \n",
            "  inflating: hateful_memes/img/37502.png  \n",
            "  inflating: hateful_memes/img/84097.png  \n",
            "  inflating: hateful_memes/img/79405.png  \n",
            "  inflating: hateful_memes/img/39170.png  \n",
            "  inflating: hateful_memes/img/68254.png  \n",
            "  inflating: hateful_memes/img/43950.png  \n",
            "  inflating: hateful_memes/img/85410.png  \n",
            "  inflating: hateful_memes/img/90236.png  \n",
            "  inflating: hateful_memes/img/56247.png  \n",
            "  inflating: hateful_memes/img/87054.png  \n",
            "  inflating: hateful_memes/img/07286.png  \n",
            "  inflating: hateful_memes/img/68231.png  \n",
            "  inflating: hateful_memes/img/25384.png  \n",
            "  inflating: hateful_memes/img/09643.png  \n",
            "  inflating: hateful_memes/img/63280.png  \n",
            "  inflating: hateful_memes/img/78936.png  \n",
            "  inflating: hateful_memes/img/67051.png  \n",
            "  inflating: hateful_memes/img/45968.png  \n",
            "  inflating: hateful_memes/img/28604.png  \n",
            "  inflating: hateful_memes/img/87925.png  \n",
            "  inflating: hateful_memes/img/51628.png  \n",
            "  inflating: hateful_memes/img/07254.png  \n",
            "  inflating: hateful_memes/img/01548.png  \n",
            "  inflating: hateful_memes/img/05762.png  \n",
            "  inflating: hateful_memes/img/54317.png  \n",
            "  inflating: hateful_memes/img/62580.png  \n",
            "  inflating: hateful_memes/img/62378.png  \n",
            "  inflating: hateful_memes/img/27318.png  \n",
            "  inflating: hateful_memes/img/83560.png  \n",
            "  inflating: hateful_memes/img/15069.png  \n",
            "  inflating: hateful_memes/img/68017.png  \n",
            "  inflating: hateful_memes/img/12784.png  \n",
            "  inflating: hateful_memes/img/28954.png  \n",
            "  inflating: hateful_memes/img/61847.png  \n",
            "  inflating: hateful_memes/img/08517.png  \n",
            "  inflating: hateful_memes/img/24316.png  \n",
            "  inflating: hateful_memes/img/72409.png  \n",
            "  inflating: hateful_memes/img/68917.png  \n",
            "  inflating: hateful_memes/img/57823.png  \n",
            "  inflating: hateful_memes/img/63572.png  \n",
            "  inflating: hateful_memes/img/03291.png  \n",
            "  inflating: hateful_memes/img/51482.png  \n",
            "  inflating: hateful_memes/img/74059.png  \n",
            "  inflating: hateful_memes/img/91708.png  \n",
            "  inflating: hateful_memes/img/85790.png  \n",
            "  inflating: hateful_memes/img/43527.png  \n",
            "  inflating: hateful_memes/img/58609.png  \n",
            "  inflating: hateful_memes/img/56843.png  \n",
            "  inflating: hateful_memes/img/23059.png  \n",
            "  inflating: hateful_memes/img/35678.png  \n",
            "  inflating: hateful_memes/img/64513.png  \n",
            "  inflating: hateful_memes/img/16075.png  \n",
            "  inflating: hateful_memes/img/26198.png  \n",
            "  inflating: hateful_memes/img/93125.png  \n",
            "  inflating: hateful_memes/img/53289.png  \n",
            "  inflating: hateful_memes/img/56280.png  \n",
            "  inflating: hateful_memes/img/87654.png  \n",
            "  inflating: hateful_memes/img/42173.png  \n",
            "  inflating: hateful_memes/img/63582.png  \n",
            "  inflating: hateful_memes/img/57401.png  \n",
            "  inflating: hateful_memes/img/34687.png  \n",
            "  inflating: hateful_memes/img/84502.png  \n",
            "  inflating: hateful_memes/img/03642.png  \n",
            "  inflating: hateful_memes/img/69123.png  \n",
            "  inflating: hateful_memes/img/75840.png  \n",
            "  inflating: hateful_memes/img/80942.png  \n",
            "  inflating: hateful_memes/img/08654.png  \n",
            "  inflating: hateful_memes/img/43615.png  \n",
            "  inflating: hateful_memes/img/27430.png  \n",
            "  inflating: hateful_memes/img/30145.png  \n",
            "  inflating: hateful_memes/img/30621.png  \n",
            "  inflating: hateful_memes/img/52936.png  \n",
            "  inflating: hateful_memes/img/17532.png  \n",
            "  inflating: hateful_memes/img/34901.png  \n",
            "  inflating: hateful_memes/img/18504.png  \n",
            "  inflating: hateful_memes/img/20915.png  \n",
            "  inflating: hateful_memes/img/62147.png  \n",
            "  inflating: hateful_memes/img/51379.png  \n",
            "  inflating: hateful_memes/img/58364.png  \n",
            "  inflating: hateful_memes/img/78956.png  \n",
            "  inflating: hateful_memes/img/67419.png  \n",
            "  inflating: hateful_memes/img/32904.png  \n",
            "  inflating: hateful_memes/img/05349.png  \n",
            "  inflating: hateful_memes/img/13289.png  \n",
            "  inflating: hateful_memes/img/68193.png  \n",
            "  inflating: hateful_memes/img/98256.png  \n",
            "  inflating: hateful_memes/img/29507.png  \n",
            "  inflating: hateful_memes/img/70142.png  \n",
            "  inflating: hateful_memes/img/68137.png  \n",
            "  inflating: hateful_memes/img/72054.png  \n",
            "  inflating: hateful_memes/img/19834.png  \n",
            "  inflating: hateful_memes/img/42091.png  \n",
            "  inflating: hateful_memes/img/37260.png  \n",
            "  inflating: hateful_memes/img/96581.png  \n",
            "  inflating: hateful_memes/img/38271.png  \n",
            "  inflating: hateful_memes/img/04791.png  \n",
            "  inflating: hateful_memes/img/34520.png  \n",
            "  inflating: hateful_memes/img/12678.png  \n",
            "  inflating: hateful_memes/img/20943.png  \n",
            "  inflating: hateful_memes/img/07284.png  \n",
            "  inflating: hateful_memes/img/34972.png  \n",
            "  inflating: hateful_memes/img/10524.png  \n",
            "  inflating: hateful_memes/img/78962.png  \n",
            "  inflating: hateful_memes/img/28517.png  \n",
            "  inflating: hateful_memes/img/58239.png  \n",
            "  inflating: hateful_memes/img/35910.png  \n",
            "  inflating: hateful_memes/img/38095.png  \n",
            "  inflating: hateful_memes/img/57621.png  \n",
            "  inflating: hateful_memes/img/68201.png  \n",
            "  inflating: hateful_memes/img/26043.png  \n",
            "  inflating: hateful_memes/img/47618.png  \n",
            "  inflating: hateful_memes/img/52847.png  \n",
            "  inflating: hateful_memes/img/16259.png  \n",
            "  inflating: hateful_memes/img/73049.png  \n",
            "  inflating: hateful_memes/img/94380.png  \n",
            "  inflating: hateful_memes/img/50968.png  \n",
            "  inflating: hateful_memes/img/79865.png  \n",
            "  inflating: hateful_memes/img/21740.png  \n",
            "  inflating: hateful_memes/img/14892.png  \n",
            "  inflating: hateful_memes/img/14573.png  \n",
            "  inflating: hateful_memes/img/16072.png  \n",
            "  inflating: hateful_memes/img/28574.png  \n",
            "  inflating: hateful_memes/img/38712.png  \n",
            "  inflating: hateful_memes/img/64219.png  \n",
            "  inflating: hateful_memes/img/62498.png  \n",
            "  inflating: hateful_memes/img/31082.png  \n",
            "  inflating: hateful_memes/img/38460.png  \n",
            "  inflating: hateful_memes/img/04126.png  \n",
            "  inflating: hateful_memes/img/47056.png  \n",
            "  inflating: hateful_memes/img/94675.png  \n",
            "  inflating: hateful_memes/img/75290.png  \n",
            "  inflating: hateful_memes/img/57631.png  \n",
            "  inflating: hateful_memes/img/58672.png  \n",
            "  inflating: hateful_memes/img/43185.png  \n",
            "  inflating: hateful_memes/img/06589.png  \n",
            "  inflating: hateful_memes/img/17508.png  \n",
            "  inflating: hateful_memes/img/15738.png  \n",
            "  inflating: hateful_memes/img/79315.png  \n",
            "  inflating: hateful_memes/img/93725.png  \n",
            "  inflating: hateful_memes/img/85192.png  \n",
            "  inflating: hateful_memes/img/25079.png  \n",
            "  inflating: hateful_memes/img/28437.png  \n",
            "  inflating: hateful_memes/img/14275.png  \n",
            "  inflating: hateful_memes/img/36175.png  \n",
            "  inflating: hateful_memes/img/60724.png  \n",
            "  inflating: hateful_memes/img/38401.png  \n",
            "  inflating: hateful_memes/img/65917.png  \n",
            "  inflating: hateful_memes/img/83615.png  \n",
            "  inflating: hateful_memes/img/45269.png  \n",
            "  inflating: hateful_memes/img/84719.png  \n",
            "  inflating: hateful_memes/img/05148.png  \n",
            "  inflating: hateful_memes/img/38902.png  \n",
            "  inflating: hateful_memes/img/59072.png  \n",
            "  inflating: hateful_memes/img/16540.png  \n",
            "  inflating: hateful_memes/img/20314.png  \n",
            "  inflating: hateful_memes/img/17305.png  \n",
            "  inflating: hateful_memes/img/30851.png  \n",
            "  inflating: hateful_memes/img/51237.png  \n",
            "  inflating: hateful_memes/img/41925.png  \n",
            "  inflating: hateful_memes/img/92867.png  \n",
            "  inflating: hateful_memes/img/18597.png  \n",
            "  inflating: hateful_memes/img/17962.png  \n",
            "  inflating: hateful_memes/img/72345.png  \n",
            "  inflating: hateful_memes/img/30519.png  \n",
            "  inflating: hateful_memes/img/56071.png  \n",
            "  inflating: hateful_memes/img/95402.png  \n",
            "  inflating: hateful_memes/img/96240.png  \n",
            "  inflating: hateful_memes/img/15306.png  \n",
            "  inflating: hateful_memes/img/01269.png  \n",
            "  inflating: hateful_memes/img/62804.png  \n",
            "  inflating: hateful_memes/img/34275.png  \n",
            "  inflating: hateful_memes/img/27169.png  \n",
            "  inflating: hateful_memes/img/40791.png  \n",
            "  inflating: hateful_memes/img/19630.png  \n",
            "  inflating: hateful_memes/img/72514.png  \n",
            "  inflating: hateful_memes/img/13798.png  \n",
            "  inflating: hateful_memes/img/51973.png  \n",
            "  inflating: hateful_memes/img/23516.png  \n",
            "  inflating: hateful_memes/img/59784.png  \n",
            "  inflating: hateful_memes/img/51708.png  \n",
            "  inflating: hateful_memes/img/69728.png  \n",
            "  inflating: hateful_memes/img/62904.png  \n",
            "  inflating: hateful_memes/img/90582.png  \n",
            "  inflating: hateful_memes/img/36185.png  \n",
            "  inflating: hateful_memes/img/49021.png  \n",
            "  inflating: hateful_memes/img/89647.png  \n",
            "  inflating: hateful_memes/img/73851.png  \n",
            "  inflating: hateful_memes/img/61495.png  \n",
            "  inflating: hateful_memes/img/48327.png  \n",
            "  inflating: hateful_memes/img/59871.png  \n",
            "  inflating: hateful_memes/img/82459.png  \n",
            "  inflating: hateful_memes/img/21468.png  \n",
            "  inflating: hateful_memes/img/95072.png  \n",
            "  inflating: hateful_memes/img/31925.png  \n",
            "  inflating: hateful_memes/img/46150.png  \n",
            "  inflating: hateful_memes/img/42039.png  \n",
            "  inflating: hateful_memes/img/81305.png  \n",
            "  inflating: hateful_memes/img/95806.png  \n",
            "  inflating: hateful_memes/img/51023.png  \n",
            "  inflating: hateful_memes/img/13695.png  \n",
            "  inflating: hateful_memes/img/62178.png  \n",
            "  inflating: hateful_memes/img/98654.png  \n",
            "  inflating: hateful_memes/img/93142.png  \n",
            "  inflating: hateful_memes/img/48932.png  \n",
            "  inflating: hateful_memes/img/01245.png  \n",
            "  inflating: hateful_memes/img/37620.png  \n",
            "  inflating: hateful_memes/img/02164.png  \n",
            "  inflating: hateful_memes/img/17852.png  \n",
            "  inflating: hateful_memes/img/20815.png  \n",
            "  inflating: hateful_memes/img/02975.png  \n",
            "  inflating: hateful_memes/img/87206.png  \n",
            "  inflating: hateful_memes/img/04138.png  \n",
            "  inflating: hateful_memes/img/36850.png  \n",
            "  inflating: hateful_memes/img/10268.png  \n",
            "  inflating: hateful_memes/img/80974.png  \n",
            "  inflating: hateful_memes/img/90538.png  \n",
            "  inflating: hateful_memes/img/21836.png  \n",
            "  inflating: hateful_memes/img/39217.png  \n",
            "  inflating: hateful_memes/img/26739.png  \n",
            "  inflating: hateful_memes/img/37084.png  \n",
            "  inflating: hateful_memes/img/21658.png  \n",
            "  inflating: hateful_memes/img/70594.png  \n",
            "  inflating: hateful_memes/img/14026.png  \n",
            "  inflating: hateful_memes/img/56123.png  \n",
            "  inflating: hateful_memes/img/46013.png  \n",
            "  inflating: hateful_memes/img/07516.png  \n",
            "  inflating: hateful_memes/img/26410.png  \n",
            "  inflating: hateful_memes/img/17320.png  \n",
            "  inflating: hateful_memes/img/36089.png  \n",
            "  inflating: hateful_memes/img/41962.png  \n",
            "  inflating: hateful_memes/img/41967.png  \n",
            "  inflating: hateful_memes/img/78325.png  \n",
            "  inflating: hateful_memes/img/78420.png  \n",
            "  inflating: hateful_memes/img/24368.png  \n",
            "  inflating: hateful_memes/img/32069.png  \n",
            "  inflating: hateful_memes/img/84360.png  \n",
            "  inflating: hateful_memes/img/62143.png  \n",
            "  inflating: hateful_memes/img/47103.png  \n",
            "  inflating: hateful_memes/img/75894.png  \n",
            "  inflating: hateful_memes/img/14590.png  \n",
            "  inflating: hateful_memes/img/37146.png  \n",
            "  inflating: hateful_memes/img/05249.png  \n",
            "  inflating: hateful_memes/img/18379.png  \n",
            "  inflating: hateful_memes/img/43617.png  \n",
            "  inflating: hateful_memes/img/70561.png  \n",
            "  inflating: hateful_memes/img/32806.png  \n",
            "  inflating: hateful_memes/img/54062.png  \n",
            "  inflating: hateful_memes/img/73198.png  \n",
            "  inflating: hateful_memes/img/12936.png  \n",
            "  inflating: hateful_memes/img/09561.png  \n",
            "  inflating: hateful_memes/img/07258.png  \n",
            "  inflating: hateful_memes/img/85916.png  \n",
            "  inflating: hateful_memes/img/15278.png  \n",
            "  inflating: hateful_memes/img/89140.png  \n",
            "  inflating: hateful_memes/img/26159.png  \n",
            "  inflating: hateful_memes/img/29475.png  \n",
            "  inflating: hateful_memes/img/97142.png  \n",
            "  inflating: hateful_memes/img/61748.png  \n",
            "  inflating: hateful_memes/img/31287.png  \n",
            "  inflating: hateful_memes/img/47935.png  \n",
            "  inflating: hateful_memes/img/96510.png  \n",
            "  inflating: hateful_memes/img/91680.png  \n",
            "  inflating: hateful_memes/img/01492.png  \n",
            "  inflating: hateful_memes/img/42659.png  \n",
            "  inflating: hateful_memes/img/04281.png  \n",
            "  inflating: hateful_memes/img/75962.png  \n",
            "  inflating: hateful_memes/img/10675.png  \n",
            "  inflating: hateful_memes/img/10572.png  \n",
            "  inflating: hateful_memes/img/73489.png  \n",
            "  inflating: hateful_memes/img/52978.png  \n",
            "  inflating: hateful_memes/img/74358.png  \n",
            "  inflating: hateful_memes/img/84910.png  \n",
            "  inflating: hateful_memes/img/31764.png  \n",
            "  inflating: hateful_memes/img/49327.png  \n",
            "  inflating: hateful_memes/img/54108.png  \n",
            "  inflating: hateful_memes/img/95830.png  \n",
            "  inflating: hateful_memes/img/97320.png  \n",
            "  inflating: hateful_memes/img/86013.png  \n",
            "  inflating: hateful_memes/img/81603.png  \n",
            "  inflating: hateful_memes/img/14726.png  \n",
            "  inflating: hateful_memes/img/64853.png  \n",
            "  inflating: hateful_memes/img/46301.png  \n",
            "  inflating: hateful_memes/img/71543.png  \n",
            "  inflating: hateful_memes/img/50184.png  \n",
            "  inflating: hateful_memes/img/70826.png  \n",
            "  inflating: hateful_memes/img/24836.png  \n",
            "  inflating: hateful_memes/img/49180.png  \n",
            "  inflating: hateful_memes/img/92341.png  \n",
            "  inflating: hateful_memes/img/39214.png  \n",
            "  inflating: hateful_memes/img/32965.png  \n",
            "  inflating: hateful_memes/img/98341.png  \n",
            "  inflating: hateful_memes/img/37458.png  \n",
            "  inflating: hateful_memes/img/32957.png  \n",
            "  inflating: hateful_memes/img/46198.png  \n",
            "  inflating: hateful_memes/img/65148.png  \n",
            "  inflating: hateful_memes/img/35429.png  \n",
            "  inflating: hateful_memes/img/86912.png  \n",
            "  inflating: hateful_memes/img/37945.png  \n",
            "  inflating: hateful_memes/img/87954.png  \n",
            "  inflating: hateful_memes/img/03479.png  \n",
            "  inflating: hateful_memes/img/93426.png  \n",
            "  inflating: hateful_memes/img/72658.png  \n",
            "  inflating: hateful_memes/img/14728.png  \n",
            "  inflating: hateful_memes/img/12968.png  \n",
            "  inflating: hateful_memes/img/49385.png  \n",
            "  inflating: hateful_memes/img/60314.png  \n",
            "  inflating: hateful_memes/img/62913.png  \n",
            "  inflating: hateful_memes/img/37284.png  \n",
            "  inflating: hateful_memes/img/89740.png  \n",
            "  inflating: hateful_memes/img/27609.png  \n",
            "  inflating: hateful_memes/img/81423.png  \n",
            "  inflating: hateful_memes/img/90263.png  \n",
            "  inflating: hateful_memes/img/16409.png  \n",
            "  inflating: hateful_memes/img/51209.png  \n",
            "  inflating: hateful_memes/img/81705.png  \n",
            "  inflating: hateful_memes/img/68934.png  \n",
            "  inflating: hateful_memes/img/64037.png  \n",
            "  inflating: hateful_memes/img/81934.png  \n",
            "  inflating: hateful_memes/img/14856.png  \n",
            "  inflating: hateful_memes/img/94150.png  \n",
            "  inflating: hateful_memes/img/89320.png  \n",
            "  inflating: hateful_memes/img/38159.png  \n",
            "  inflating: hateful_memes/img/97180.png  \n",
            "  inflating: hateful_memes/img/97316.png  \n",
            "  inflating: hateful_memes/img/42387.png  \n",
            "  inflating: hateful_memes/img/53278.png  \n",
            "  inflating: hateful_memes/img/58621.png  \n",
            "  inflating: hateful_memes/img/34217.png  \n",
            "  inflating: hateful_memes/img/84629.png  \n",
            "  inflating: hateful_memes/img/75028.png  \n",
            "  inflating: hateful_memes/img/76208.png  \n",
            "  inflating: hateful_memes/img/48965.png  \n",
            "  inflating: hateful_memes/img/90845.png  \n",
            "  inflating: hateful_memes/img/15846.png  \n",
            "  inflating: hateful_memes/img/07268.png  \n",
            "  inflating: hateful_memes/img/71420.png  \n",
            "  inflating: hateful_memes/img/96804.png  \n",
            "  inflating: hateful_memes/img/79825.png  \n",
            "  inflating: hateful_memes/img/40529.png  \n",
            "  inflating: hateful_memes/img/68034.png  \n",
            "  inflating: hateful_memes/img/40561.png  \n",
            "  inflating: hateful_memes/img/68321.png  \n",
            "  inflating: hateful_memes/img/60257.png  \n",
            "  inflating: hateful_memes/img/50816.png  \n",
            "  inflating: hateful_memes/img/65730.png  \n",
            "  inflating: hateful_memes/img/97853.png  \n",
            "  inflating: hateful_memes/img/19238.png  \n",
            "  inflating: hateful_memes/img/79845.png  \n",
            "  inflating: hateful_memes/img/04162.png  \n",
            "  inflating: hateful_memes/img/48031.png  \n",
            "  inflating: hateful_memes/img/25861.png  \n",
            "  inflating: hateful_memes/img/51806.png  \n",
            "  inflating: hateful_memes/img/37056.png  \n",
            "  inflating: hateful_memes/img/24765.png  \n",
            "  inflating: hateful_memes/img/82950.png  \n",
            "  inflating: hateful_memes/img/65130.png  \n",
            "  inflating: hateful_memes/img/46239.png  \n",
            "  inflating: hateful_memes/img/20913.png  \n",
            "  inflating: hateful_memes/img/54093.png  \n",
            "  inflating: hateful_memes/img/70293.png  \n",
            "  inflating: hateful_memes/img/13460.png  \n",
            "  inflating: hateful_memes/img/19206.png  \n",
            "  inflating: hateful_memes/img/64537.png  \n",
            "  inflating: hateful_memes/img/45293.png  \n",
            "  inflating: hateful_memes/img/96873.png  \n",
            "  inflating: hateful_memes/img/81276.png  \n",
            "  inflating: hateful_memes/img/40752.png  \n",
            "  inflating: hateful_memes/img/59467.png  \n",
            "  inflating: hateful_memes/img/31284.png  \n",
            "  inflating: hateful_memes/img/75496.png  \n",
            "  inflating: hateful_memes/img/58491.png  \n",
            "  inflating: hateful_memes/img/75438.png  \n",
            "  inflating: hateful_memes/img/31205.png  \n",
            "  inflating: hateful_memes/img/91856.png  \n",
            "  inflating: hateful_memes/img/82541.png  \n",
            "  inflating: hateful_memes/img/03276.png  \n",
            "  inflating: hateful_memes/img/23657.png  \n",
            "  inflating: hateful_memes/img/14306.png  \n",
            "  inflating: hateful_memes/img/96023.png  \n",
            "  inflating: hateful_memes/img/01649.png  \n",
            "  inflating: hateful_memes/img/93071.png  \n",
            "  inflating: hateful_memes/img/86491.png  \n",
            "  inflating: hateful_memes/img/57146.png  \n",
            "  inflating: hateful_memes/img/13470.png  \n",
            "  inflating: hateful_memes/img/27614.png  \n",
            "  inflating: hateful_memes/img/14837.png  \n",
            "  inflating: hateful_memes/img/90274.png  \n",
            "  inflating: hateful_memes/img/40361.png  \n",
            "  inflating: hateful_memes/img/41863.png  \n",
            "  inflating: hateful_memes/img/70153.png  \n",
            "  inflating: hateful_memes/img/87094.png  \n",
            "  inflating: hateful_memes/img/40693.png  \n",
            "  inflating: hateful_memes/img/62381.png  \n",
            "  inflating: hateful_memes/img/76923.png  \n",
            "  inflating: hateful_memes/img/94278.png  \n",
            "  inflating: hateful_memes/img/51046.png  \n",
            "  inflating: hateful_memes/img/04538.png  \n",
            "  inflating: hateful_memes/img/89430.png  \n",
            "  inflating: hateful_memes/img/20684.png  \n",
            "  inflating: hateful_memes/img/06893.png  \n",
            "  inflating: hateful_memes/img/41362.png  \n",
            "  inflating: hateful_memes/img/14695.png  \n",
            "  inflating: hateful_memes/img/26459.png  \n",
            "  inflating: hateful_memes/img/27506.png  \n",
            "  inflating: hateful_memes/img/30251.png  \n",
            "  inflating: hateful_memes/img/32706.png  \n",
            "  inflating: hateful_memes/img/70645.png  \n",
            "  inflating: hateful_memes/img/46850.png  \n",
            "  inflating: hateful_memes/img/69403.png  \n",
            "  inflating: hateful_memes/img/98736.png  \n",
            "  inflating: hateful_memes/img/08719.png  \n",
            "  inflating: hateful_memes/img/83514.png  \n",
            "  inflating: hateful_memes/img/57831.png  \n",
            "  inflating: hateful_memes/img/46283.png  \n",
            "  inflating: hateful_memes/img/67298.png  \n",
            "  inflating: hateful_memes/img/07918.png  \n",
            "  inflating: hateful_memes/img/13428.png  \n",
            "  inflating: hateful_memes/img/92831.png  \n",
            "  inflating: hateful_memes/img/50142.png  \n",
            "  inflating: hateful_memes/img/97514.png  \n",
            "  inflating: hateful_memes/img/30456.png  \n",
            "  inflating: hateful_memes/img/42638.png  \n",
            "  inflating: hateful_memes/img/13690.png  \n",
            "  inflating: hateful_memes/img/10725.png  \n",
            "  inflating: hateful_memes/img/38071.png  \n",
            "  inflating: hateful_memes/img/76984.png  \n",
            "  inflating: hateful_memes/img/97245.png  \n",
            "  inflating: hateful_memes/img/81624.png  \n",
            "  inflating: hateful_memes/img/64320.png  \n",
            "  inflating: hateful_memes/img/65301.png  \n",
            "  inflating: hateful_memes/img/30571.png  \n",
            "  inflating: hateful_memes/img/07398.png  \n",
            "  inflating: hateful_memes/img/96408.png  \n",
            "  inflating: hateful_memes/img/60895.png  \n",
            "  inflating: hateful_memes/img/21637.png  \n",
            "  inflating: hateful_memes/img/79568.png  \n",
            "  inflating: hateful_memes/img/43976.png  \n",
            "  inflating: hateful_memes/img/29364.png  \n",
            "  inflating: hateful_memes/img/12036.png  \n",
            "  inflating: hateful_memes/img/86075.png  \n",
            "  inflating: hateful_memes/img/54082.png  \n",
            "  inflating: hateful_memes/img/90321.png  \n",
            "  inflating: hateful_memes/img/96502.png  \n",
            "  inflating: hateful_memes/img/80425.png  \n",
            "  inflating: hateful_memes/img/82310.png  \n",
            "  inflating: hateful_memes/img/58971.png  \n",
            "  inflating: hateful_memes/img/69870.png  \n",
            "  inflating: hateful_memes/img/71432.png  \n",
            "  inflating: hateful_memes/img/05279.png  \n",
            "  inflating: hateful_memes/img/96810.png  \n",
            "  inflating: hateful_memes/img/64281.png  \n",
            "  inflating: hateful_memes/img/14657.png  \n",
            "  inflating: hateful_memes/img/07213.png  \n",
            "  inflating: hateful_memes/img/37294.png  \n",
            "  inflating: hateful_memes/img/02845.png  \n",
            "  inflating: hateful_memes/img/51836.png  \n",
            "  inflating: hateful_memes/img/92835.png  \n",
            "  inflating: hateful_memes/img/93750.png  \n",
            "  inflating: hateful_memes/img/03196.png  \n",
            "  inflating: hateful_memes/img/51863.png  \n",
            "  inflating: hateful_memes/img/54389.png  \n",
            "  inflating: hateful_memes/img/51608.png  \n",
            "  inflating: hateful_memes/img/29708.png  \n",
            "  inflating: hateful_memes/img/30618.png  \n",
            "  inflating: hateful_memes/img/71863.png  \n",
            "  inflating: hateful_memes/img/96381.png  \n",
            "  inflating: hateful_memes/img/30249.png  \n",
            "  inflating: hateful_memes/img/30762.png  \n",
            "  inflating: hateful_memes/img/85417.png  \n",
            "  inflating: hateful_memes/img/93051.png  \n",
            "  inflating: hateful_memes/img/37918.png  \n",
            "  inflating: hateful_memes/img/48039.png  \n",
            "  inflating: hateful_memes/img/10659.png  \n",
            "  inflating: hateful_memes/img/69758.png  \n",
            "  inflating: hateful_memes/img/04658.png  \n",
            "  inflating: hateful_memes/img/81752.png  \n",
            "  inflating: hateful_memes/img/21403.png  \n",
            "  inflating: hateful_memes/img/62718.png  \n",
            "  inflating: hateful_memes/img/05741.png  \n",
            "  inflating: hateful_memes/img/78169.png  \n",
            "  inflating: hateful_memes/img/74019.png  \n",
            "  inflating: hateful_memes/img/21345.png  \n",
            "  inflating: hateful_memes/img/60714.png  \n",
            "  inflating: hateful_memes/img/31549.png  \n",
            "  inflating: hateful_memes/img/89473.png  \n",
            "  inflating: hateful_memes/img/63042.png  \n",
            "  inflating: hateful_memes/img/54319.png  \n",
            "  inflating: hateful_memes/img/01324.png  \n",
            "  inflating: hateful_memes/img/90165.png  \n",
            "  inflating: hateful_memes/img/41986.png  \n",
            "  inflating: hateful_memes/img/43680.png  \n",
            "  inflating: hateful_memes/img/52710.png  \n",
            "  inflating: hateful_memes/img/28751.png  \n",
            "  inflating: hateful_memes/img/50361.png  \n",
            "  inflating: hateful_memes/img/15072.png  \n",
            "  inflating: hateful_memes/img/23905.png  \n",
            "  inflating: hateful_memes/img/39028.png  \n",
            "  inflating: hateful_memes/img/47196.png  \n",
            "  inflating: hateful_memes/img/12956.png  \n",
            "  inflating: hateful_memes/img/07219.png  \n",
            "  inflating: hateful_memes/img/62394.png  \n",
            "  inflating: hateful_memes/img/50739.png  \n",
            "  inflating: hateful_memes/img/75048.png  \n",
            "  inflating: hateful_memes/img/34186.png  \n",
            "  inflating: hateful_memes/img/02718.png  \n",
            "  inflating: hateful_memes/img/86372.png  \n",
            "  inflating: hateful_memes/img/34570.png  \n",
            "  inflating: hateful_memes/img/09468.png  \n",
            "  inflating: hateful_memes/img/14569.png  \n",
            "  inflating: hateful_memes/img/83709.png  \n",
            "  inflating: hateful_memes/img/75601.png  \n",
            "  inflating: hateful_memes/img/40896.png  \n",
            "  inflating: hateful_memes/img/36214.png  \n",
            "  inflating: hateful_memes/img/74031.png  \n",
            "  inflating: hateful_memes/img/43128.png  \n",
            "  inflating: hateful_memes/img/49865.png  \n",
            "  inflating: hateful_memes/img/54201.png  \n",
            "  inflating: hateful_memes/img/36870.png  \n",
            "  inflating: hateful_memes/img/87140.png  \n",
            "  inflating: hateful_memes/img/40829.png  \n",
            "  inflating: hateful_memes/img/58361.png  \n",
            "  inflating: hateful_memes/img/25310.png  \n",
            "  inflating: hateful_memes/img/72364.png  \n",
            "  inflating: hateful_memes/img/20671.png  \n",
            "  inflating: hateful_memes/img/84673.png  \n",
            "  inflating: hateful_memes/img/54927.png  \n",
            "  inflating: hateful_memes/img/64590.png  \n",
            "  inflating: hateful_memes/img/72810.png  \n",
            "  inflating: hateful_memes/img/14096.png  \n",
            "  inflating: hateful_memes/img/01567.png  \n",
            "  inflating: hateful_memes/img/16837.png  \n",
            "  inflating: hateful_memes/img/35189.png  \n",
            "  inflating: hateful_memes/img/93487.png  \n",
            "  inflating: hateful_memes/img/21609.png  \n",
            "  inflating: hateful_memes/img/57012.png  \n",
            "  inflating: hateful_memes/img/01392.png  \n",
            "  inflating: hateful_memes/img/35627.png  \n",
            "  inflating: hateful_memes/img/20459.png  \n",
            "  inflating: hateful_memes/img/58371.png  \n",
            "  inflating: hateful_memes/img/85392.png  \n",
            "  inflating: hateful_memes/img/61840.png  \n",
            "  inflating: hateful_memes/img/56091.png  \n",
            "  inflating: hateful_memes/img/05763.png  \n",
            "  inflating: hateful_memes/img/70162.png  \n",
            "  inflating: hateful_memes/img/39610.png  \n",
            "  inflating: hateful_memes/img/71954.png  \n",
            "  inflating: hateful_memes/img/54863.png  \n",
            "  inflating: hateful_memes/img/32746.png  \n",
            "  inflating: hateful_memes/img/54397.png  \n",
            "  inflating: hateful_memes/img/08795.png  \n",
            "  inflating: hateful_memes/img/34281.png  \n",
            "  inflating: hateful_memes/img/97542.png  \n",
            "  inflating: hateful_memes/img/06458.png  \n",
            "  inflating: hateful_memes/img/37865.png  \n",
            "  inflating: hateful_memes/img/05294.png  \n",
            "  inflating: hateful_memes/img/89102.png  \n",
            "  inflating: hateful_memes/img/24038.png  \n",
            "  inflating: hateful_memes/img/97642.png  \n",
            "  inflating: hateful_memes/img/83456.png  \n",
            "  inflating: hateful_memes/img/26031.png  \n",
            "  inflating: hateful_memes/img/36781.png  \n",
            "  inflating: hateful_memes/img/24630.png  \n",
            "  inflating: hateful_memes/img/75139.png  \n",
            "  inflating: hateful_memes/img/42601.png  \n",
            "  inflating: hateful_memes/img/78964.png  \n",
            "  inflating: hateful_memes/img/39710.png  \n",
            "  inflating: hateful_memes/img/57312.png  \n",
            "  inflating: hateful_memes/img/17386.png  \n",
            "  inflating: hateful_memes/img/02578.png  \n",
            "  inflating: hateful_memes/img/82731.png  \n",
            "  inflating: hateful_memes/img/61753.png  \n",
            "  inflating: hateful_memes/img/97502.png  \n",
            "  inflating: hateful_memes/img/24806.png  \n",
            "  inflating: hateful_memes/img/28905.png  \n",
            "  inflating: hateful_memes/img/75439.png  \n",
            "  inflating: hateful_memes/img/41508.png  \n",
            "  inflating: hateful_memes/img/02461.png  \n",
            "  inflating: hateful_memes/img/35497.png  \n",
            "  inflating: hateful_memes/img/27613.png  \n",
            "  inflating: hateful_memes/img/21867.png  \n",
            "  inflating: hateful_memes/img/71463.png  \n",
            "  inflating: hateful_memes/img/68930.png  \n",
            "  inflating: hateful_memes/img/46205.png  \n",
            "  inflating: hateful_memes/img/34096.png  \n",
            "  inflating: hateful_memes/img/10358.png  \n",
            "  inflating: hateful_memes/img/73924.png  \n",
            "  inflating: hateful_memes/img/01794.png  \n",
            "  inflating: hateful_memes/img/26174.png  \n",
            "  inflating: hateful_memes/img/52614.png  \n",
            "  inflating: hateful_memes/img/29478.png  \n",
            "  inflating: hateful_memes/img/05864.png  \n",
            "  inflating: hateful_memes/img/24853.png  \n",
            "  inflating: hateful_memes/img/53260.png  \n",
            "  inflating: hateful_memes/img/43521.png  \n",
            "  inflating: hateful_memes/img/83701.png  \n",
            "  inflating: hateful_memes/img/52748.png  \n",
            "  inflating: hateful_memes/img/54672.png  \n",
            "  inflating: hateful_memes/img/09283.png  \n",
            "  inflating: hateful_memes/img/78594.png  \n",
            "  inflating: hateful_memes/img/46183.png  \n",
            "  inflating: hateful_memes/img/27608.png  \n",
            "  inflating: hateful_memes/img/86749.png  \n",
            "  inflating: hateful_memes/img/83421.png  \n",
            "  inflating: hateful_memes/img/37285.png  \n",
            "  inflating: hateful_memes/img/51389.png  \n",
            "  inflating: hateful_memes/img/13249.png  \n",
            "  inflating: hateful_memes/img/86954.png  \n",
            "  inflating: hateful_memes/img/63152.png  \n",
            "  inflating: hateful_memes/img/06543.png  \n",
            "  inflating: hateful_memes/img/28051.png  \n",
            "  inflating: hateful_memes/img/96752.png  \n",
            "  inflating: hateful_memes/img/19247.png  \n",
            "  inflating: hateful_memes/img/93105.png  \n",
            "  inflating: hateful_memes/img/26014.png  \n",
            "  inflating: hateful_memes/img/16532.png  \n",
            "  inflating: hateful_memes/img/47625.png  \n",
            "  inflating: hateful_memes/img/21903.png  \n",
            "  inflating: hateful_memes/img/34216.png  \n",
            "  inflating: hateful_memes/img/47386.png  \n",
            "  inflating: hateful_memes/img/65187.png  \n",
            "  inflating: hateful_memes/img/59781.png  \n",
            "  inflating: hateful_memes/img/87526.png  \n",
            "  inflating: hateful_memes/img/98463.png  \n",
            "  inflating: hateful_memes/img/13085.png  \n",
            "  inflating: hateful_memes/img/25713.png  \n",
            "  inflating: hateful_memes/img/94352.png  \n",
            "  inflating: hateful_memes/img/71630.png  \n",
            "  inflating: hateful_memes/img/02751.png  \n",
            "  inflating: hateful_memes/img/18730.png  \n",
            "  inflating: hateful_memes/img/56307.png  \n",
            "  inflating: hateful_memes/img/09321.png  \n",
            "  inflating: hateful_memes/img/49638.png  \n",
            "  inflating: hateful_memes/img/74630.png  \n",
            "  inflating: hateful_memes/img/93572.png  \n",
            "  inflating: hateful_memes/img/94230.png  \n",
            "  inflating: hateful_memes/img/81365.png  \n",
            "  inflating: hateful_memes/img/71453.png  \n",
            "  inflating: hateful_memes/img/93152.png  \n",
            "  inflating: hateful_memes/img/45869.png  \n",
            "  inflating: hateful_memes/img/64350.png  \n",
            "  inflating: hateful_memes/img/82719.png  \n",
            "  inflating: hateful_memes/img/75631.png  \n",
            "  inflating: hateful_memes/img/17265.png  \n",
            "  inflating: hateful_memes/img/21904.png  \n",
            "  inflating: hateful_memes/img/12768.png  \n",
            "  inflating: hateful_memes/img/97246.png  \n",
            "  inflating: hateful_memes/img/27056.png  \n",
            "  inflating: hateful_memes/img/05813.png  \n",
            "  inflating: hateful_memes/img/35210.png  \n",
            "  inflating: hateful_memes/img/25340.png  \n",
            "  inflating: hateful_memes/img/59806.png  \n",
            "  inflating: hateful_memes/img/19027.png  \n",
            "  inflating: hateful_memes/img/74218.png  \n",
            "  inflating: hateful_memes/img/08275.png  \n",
            "  inflating: hateful_memes/img/98412.png  \n",
            "  inflating: hateful_memes/img/81063.png  \n",
            "  inflating: hateful_memes/img/02816.png  \n",
            "  inflating: hateful_memes/img/82316.png  \n",
            "  inflating: hateful_memes/img/63052.png  \n",
            "  inflating: hateful_memes/img/45601.png  \n",
            "  inflating: hateful_memes/img/61940.png  \n",
            "  inflating: hateful_memes/img/42597.png  \n",
            "  inflating: hateful_memes/img/31760.png  \n",
            "  inflating: hateful_memes/img/04326.png  \n",
            "  inflating: hateful_memes/img/47205.png  \n",
            "  inflating: hateful_memes/img/64291.png  \n",
            "  inflating: hateful_memes/img/83296.png  \n",
            "  inflating: hateful_memes/img/23746.png  \n",
            "  inflating: hateful_memes/img/67825.png  \n",
            "  inflating: hateful_memes/img/05712.png  \n",
            "  inflating: hateful_memes/img/83415.png  \n",
            "  inflating: hateful_memes/img/29438.png  \n",
            "  inflating: hateful_memes/img/01476.png  \n",
            "  inflating: hateful_memes/img/08725.png  \n",
            "  inflating: hateful_memes/img/53647.png  \n",
            "  inflating: hateful_memes/img/03681.png  \n",
            "  inflating: hateful_memes/img/47831.png  \n",
            "  inflating: hateful_memes/img/25170.png  \n",
            "  inflating: hateful_memes/img/46130.png  \n",
            "  inflating: hateful_memes/img/84517.png  \n",
            "  inflating: hateful_memes/img/02761.png  \n",
            "  inflating: hateful_memes/img/12980.png  \n",
            "  inflating: hateful_memes/img/28561.png  \n",
            "  inflating: hateful_memes/img/35460.png  \n",
            "  inflating: hateful_memes/img/92637.png  \n",
            "  inflating: hateful_memes/img/34215.png  \n",
            "  inflating: hateful_memes/img/84153.png  \n",
            "  inflating: hateful_memes/img/34206.png  \n",
            "  inflating: hateful_memes/img/49671.png  \n",
            "  inflating: hateful_memes/img/63917.png  \n",
            "  inflating: hateful_memes/img/53140.png  \n",
            "  inflating: hateful_memes/img/49762.png  \n",
            "  inflating: hateful_memes/img/56184.png  \n",
            "  inflating: hateful_memes/img/40756.png  \n",
            "  inflating: hateful_memes/img/76103.png  \n",
            "  inflating: hateful_memes/img/05719.png  \n",
            "  inflating: hateful_memes/img/34875.png  \n",
            "  inflating: hateful_memes/img/68019.png  \n",
            "  inflating: hateful_memes/img/94508.png  \n",
            "  inflating: hateful_memes/img/72406.png  \n",
            "  inflating: hateful_memes/img/60487.png  \n",
            "  inflating: hateful_memes/img/37160.png  \n",
            "  inflating: hateful_memes/img/62719.png  \n",
            "  inflating: hateful_memes/img/67531.png  \n",
            "  inflating: hateful_memes/img/83704.png  \n",
            "  inflating: hateful_memes/img/62409.png  \n",
            "  inflating: hateful_memes/img/80231.png  \n",
            "  inflating: hateful_memes/img/51094.png  \n",
            "  inflating: hateful_memes/img/91584.png  \n",
            "  inflating: hateful_memes/img/43859.png  \n",
            "  inflating: hateful_memes/img/14079.png  \n",
            "  inflating: hateful_memes/img/29468.png  \n",
            "  inflating: hateful_memes/img/75360.png  \n",
            "  inflating: hateful_memes/img/01258.png  \n",
            "  inflating: hateful_memes/img/74621.png  \n",
            "  inflating: hateful_memes/img/75918.png  \n",
            "  inflating: hateful_memes/img/80654.png  \n",
            "  inflating: hateful_memes/img/90352.png  \n",
            "  inflating: hateful_memes/img/93586.png  \n",
            "  inflating: hateful_memes/img/76250.png  \n",
            "  inflating: hateful_memes/img/57049.png  \n",
            "  inflating: hateful_memes/img/29158.png  \n",
            "  inflating: hateful_memes/img/03485.png  \n",
            "  inflating: hateful_memes/img/21086.png  \n",
            "  inflating: hateful_memes/img/94620.png  \n",
            "  inflating: hateful_memes/img/34961.png  \n",
            "  inflating: hateful_memes/img/41206.png  \n",
            "  inflating: hateful_memes/img/49168.png  \n",
            "  inflating: hateful_memes/img/49031.png  \n",
            "  inflating: hateful_memes/img/58309.png  \n",
            "  inflating: hateful_memes/img/31590.png  \n",
            "  inflating: hateful_memes/img/51694.png  \n",
            "  inflating: hateful_memes/img/38612.png  \n",
            "  inflating: hateful_memes/img/59870.png  \n",
            "  inflating: hateful_memes/img/59062.png  \n",
            "  inflating: hateful_memes/img/35604.png  \n",
            "  inflating: hateful_memes/img/63974.png  \n",
            "  inflating: hateful_memes/img/76435.png  \n",
            "  inflating: hateful_memes/img/05749.png  \n",
            "  inflating: hateful_memes/img/18406.png  \n",
            "  inflating: hateful_memes/img/74839.png  \n",
            "  inflating: hateful_memes/img/70394.png  \n",
            "  inflating: hateful_memes/img/52863.png  \n",
            "  inflating: hateful_memes/img/24178.png  \n",
            "  inflating: hateful_memes/img/19470.png  \n",
            "  inflating: hateful_memes/img/83470.png  \n",
            "  inflating: hateful_memes/img/72481.png  \n",
            "  inflating: hateful_memes/img/62541.png  \n",
            "  inflating: hateful_memes/img/28350.png  \n",
            "  inflating: hateful_memes/img/19650.png  \n",
            "  inflating: hateful_memes/img/48573.png  \n",
            "  inflating: hateful_memes/img/19032.png  \n",
            "  inflating: hateful_memes/img/81092.png  \n",
            "  inflating: hateful_memes/img/20861.png  \n",
            "  inflating: hateful_memes/img/37864.png  \n",
            "  inflating: hateful_memes/img/89607.png  \n",
            "  inflating: hateful_memes/img/48307.png  \n",
            "  inflating: hateful_memes/img/59876.png  \n",
            "  inflating: hateful_memes/img/30174.png  \n",
            "  inflating: hateful_memes/img/45176.png  \n",
            "  inflating: hateful_memes/img/56812.png  \n",
            "  inflating: hateful_memes/img/71094.png  \n",
            "  inflating: hateful_memes/img/75639.png  \n",
            "  inflating: hateful_memes/img/91586.png  \n",
            "  inflating: hateful_memes/img/04529.png  \n",
            "  inflating: hateful_memes/img/10786.png  \n",
            "  inflating: hateful_memes/img/15839.png  \n",
            "  inflating: hateful_memes/img/23054.png  \n",
            "  inflating: hateful_memes/img/37984.png  \n",
            "  inflating: hateful_memes/img/61048.png  \n",
            "  inflating: hateful_memes/img/53148.png  \n",
            "  inflating: hateful_memes/img/65372.png  \n",
            "  inflating: hateful_memes/img/61092.png  \n",
            "  inflating: hateful_memes/img/03756.png  \n",
            "  inflating: hateful_memes/img/02587.png  \n",
            "  inflating: hateful_memes/img/41672.png  \n",
            "  inflating: hateful_memes/img/60938.png  \n",
            "  inflating: hateful_memes/img/52018.png  \n",
            "  inflating: hateful_memes/img/13960.png  \n",
            "  inflating: hateful_memes/img/69054.png  \n",
            "  inflating: hateful_memes/img/20395.png  \n",
            "  inflating: hateful_memes/img/49083.png  \n",
            "  inflating: hateful_memes/img/17029.png  \n",
            "  inflating: hateful_memes/img/71259.png  \n",
            "  inflating: hateful_memes/img/46827.png  \n",
            "  inflating: hateful_memes/img/17530.png  \n",
            "  inflating: hateful_memes/img/05948.png  \n",
            "  inflating: hateful_memes/img/56248.png  \n",
            "  inflating: hateful_memes/img/17369.png  \n",
            "  inflating: hateful_memes/img/48516.png  \n",
            "  inflating: hateful_memes/img/09465.png  \n",
            "  inflating: hateful_memes/img/63458.png  \n",
            "  inflating: hateful_memes/img/48927.png  \n",
            "  inflating: hateful_memes/img/97250.png  \n",
            "  inflating: hateful_memes/img/86293.png  \n",
            "  inflating: hateful_memes/img/94512.png  \n",
            "  inflating: hateful_memes/img/97045.png  \n",
            "  inflating: hateful_memes/img/75910.png  \n",
            "  inflating: hateful_memes/img/62485.png  \n",
            "  inflating: hateful_memes/img/07291.png  \n",
            "  inflating: hateful_memes/img/28061.png  \n",
            "  inflating: hateful_memes/img/64089.png  \n",
            "  inflating: hateful_memes/img/13276.png  \n",
            "  inflating: hateful_memes/img/01468.png  \n",
            "  inflating: hateful_memes/img/24835.png  \n",
            "  inflating: hateful_memes/img/84379.png  \n",
            "  inflating: hateful_memes/img/78259.png  \n",
            "  inflating: hateful_memes/img/48673.png  \n",
            "  inflating: hateful_memes/img/51208.png  \n",
            "  inflating: hateful_memes/img/28364.png  \n",
            "  inflating: hateful_memes/img/32789.png  \n",
            "  inflating: hateful_memes/img/80397.png  \n",
            "  inflating: hateful_memes/img/75806.png  \n",
            "  inflating: hateful_memes/img/98176.png  \n",
            "  inflating: hateful_memes/img/83219.png  \n",
            "  inflating: hateful_memes/img/54097.png  \n",
            "  inflating: hateful_memes/img/19275.png  \n",
            "  inflating: hateful_memes/img/73819.png  \n",
            "  inflating: hateful_memes/img/07825.png  \n",
            "  inflating: hateful_memes/img/37201.png  \n",
            "  inflating: hateful_memes/img/34756.png  \n",
            "  inflating: hateful_memes/img/02413.png  \n",
            "  inflating: hateful_memes/img/03189.png  \n",
            "  inflating: hateful_memes/img/32945.png  \n",
            "  inflating: hateful_memes/img/19604.png  \n",
            "  inflating: hateful_memes/img/67328.png  \n",
            "  inflating: hateful_memes/img/70143.png  \n",
            "  inflating: hateful_memes/img/21749.png  \n",
            "  inflating: hateful_memes/img/98642.png  \n",
            "  inflating: hateful_memes/img/62589.png  \n",
            "  inflating: hateful_memes/img/51263.png  \n",
            "  inflating: hateful_memes/img/49615.png  \n",
            "  inflating: hateful_memes/img/71965.png  \n",
            "  inflating: hateful_memes/img/06425.png  \n",
            "  inflating: hateful_memes/img/13540.png  \n",
            "  inflating: hateful_memes/img/30896.png  \n",
            "  inflating: hateful_memes/img/68043.png  \n",
            "  inflating: hateful_memes/img/76254.png  \n",
            "  inflating: hateful_memes/img/19647.png  \n",
            "  inflating: hateful_memes/img/26375.png  \n",
            "  inflating: hateful_memes/img/64810.png  \n",
            "  inflating: hateful_memes/img/76145.png  \n",
            "  inflating: hateful_memes/img/79531.png  \n",
            "  inflating: hateful_memes/img/05476.png  \n",
            "  inflating: hateful_memes/img/52761.png  \n",
            "  inflating: hateful_memes/img/18453.png  \n",
            "  inflating: hateful_memes/img/50327.png  \n",
            "  inflating: hateful_memes/img/08571.png  \n",
            "  inflating: hateful_memes/img/90382.png  \n",
            "  inflating: hateful_memes/img/03864.png  \n",
            "  inflating: hateful_memes/img/38215.png  \n",
            "  inflating: hateful_memes/img/57324.png  \n",
            "  inflating: hateful_memes/img/38762.png  \n",
            "  inflating: hateful_memes/img/92430.png  \n",
            "  inflating: hateful_memes/img/81069.png  \n",
            "  inflating: hateful_memes/img/75231.png  \n",
            "  inflating: hateful_memes/img/54891.png  \n",
            "  inflating: hateful_memes/img/13520.png  \n",
            "  inflating: hateful_memes/img/30785.png  \n",
            "  inflating: hateful_memes/img/41027.png  \n",
            "  inflating: hateful_memes/img/52071.png  \n",
            "  inflating: hateful_memes/img/58170.png  \n",
            "  inflating: hateful_memes/img/49801.png  \n",
            "  inflating: hateful_memes/img/71095.png  \n",
            "  inflating: hateful_memes/img/71360.png  \n",
            "  inflating: hateful_memes/img/46938.png  \n",
            "  inflating: hateful_memes/img/61780.png  \n",
            "  inflating: hateful_memes/img/96073.png  \n",
            "  inflating: hateful_memes/img/64127.png  \n",
            "  inflating: hateful_memes/img/04639.png  \n",
            "  inflating: hateful_memes/img/19324.png  \n",
            "  inflating: hateful_memes/img/12839.png  \n",
            "  inflating: hateful_memes/img/73426.png  \n",
            "  inflating: hateful_memes/img/18546.png  \n",
            "  inflating: hateful_memes/img/87160.png  \n",
            "  inflating: hateful_memes/img/07249.png  \n",
            "  inflating: hateful_memes/img/08912.png  \n",
            "  inflating: hateful_memes/img/96405.png  \n",
            "  inflating: hateful_memes/img/46153.png  \n",
            "  inflating: hateful_memes/img/56038.png  \n",
            "  inflating: hateful_memes/img/73028.png  \n",
            "  inflating: hateful_memes/img/24738.png  \n",
            "  inflating: hateful_memes/img/78052.png  \n",
            "  inflating: hateful_memes/img/09387.png  \n",
            "  inflating: hateful_memes/img/43791.png  \n",
            "  inflating: hateful_memes/img/04163.png  \n",
            "  inflating: hateful_memes/img/73615.png  \n",
            "  inflating: hateful_memes/img/26905.png  \n",
            "  inflating: hateful_memes/img/84092.png  \n",
            "  inflating: hateful_memes/img/02497.png  \n",
            "  inflating: hateful_memes/img/86231.png  \n",
            "  inflating: hateful_memes/img/12468.png  \n",
            "  inflating: hateful_memes/img/92584.png  \n",
            "  inflating: hateful_memes/img/49205.png  \n",
            "  inflating: hateful_memes/img/37289.png  \n",
            "  inflating: hateful_memes/img/95071.png  \n",
            "  inflating: hateful_memes/img/42983.png  \n",
            "  inflating: hateful_memes/img/25614.png  \n",
            "  inflating: hateful_memes/img/50487.png  \n",
            "  inflating: hateful_memes/img/86750.png  \n",
            "  inflating: hateful_memes/img/97185.png  \n",
            "  inflating: hateful_memes/img/71529.png  \n",
            "  inflating: hateful_memes/img/69875.png  \n",
            "  inflating: hateful_memes/img/20386.png  \n",
            "  inflating: hateful_memes/img/54720.png  \n",
            "  inflating: hateful_memes/img/40576.png  \n",
            "  inflating: hateful_memes/img/27305.png  \n",
            "  inflating: hateful_memes/img/65103.png  \n",
            "  inflating: hateful_memes/img/17649.png  \n",
            "  inflating: hateful_memes/img/28096.png  \n",
            "  inflating: hateful_memes/img/20859.png  \n",
            "  inflating: hateful_memes/img/94231.png  \n",
            "  inflating: hateful_memes/img/25690.png  \n",
            "  inflating: hateful_memes/img/07486.png  \n",
            "  inflating: hateful_memes/img/30871.png  \n",
            "  inflating: hateful_memes/img/15209.png  \n",
            "  inflating: hateful_memes/img/23971.png  \n",
            "  inflating: hateful_memes/img/32540.png  \n",
            "  inflating: hateful_memes/img/65801.png  \n",
            "  inflating: hateful_memes/img/52106.png  \n",
            "  inflating: hateful_memes/img/87120.png  \n",
            "  inflating: hateful_memes/img/64391.png  \n",
            "  inflating: hateful_memes/img/65189.png  \n",
            "  inflating: hateful_memes/img/81642.png  \n",
            "  inflating: hateful_memes/img/79452.png  \n",
            "  inflating: hateful_memes/img/61953.png  \n",
            "  inflating: hateful_memes/img/97068.png  \n",
            "  inflating: hateful_memes/img/46902.png  \n",
            "  inflating: hateful_memes/img/49650.png  \n",
            "  inflating: hateful_memes/img/61590.png  \n",
            "  inflating: hateful_memes/img/97543.png  \n",
            "  inflating: hateful_memes/img/81926.png  \n",
            "  inflating: hateful_memes/img/87453.png  \n",
            "  inflating: hateful_memes/img/56873.png  \n",
            "  inflating: hateful_memes/img/30168.png  \n",
            "  inflating: hateful_memes/img/61257.png  \n",
            "  inflating: hateful_memes/img/65312.png  \n",
            "  inflating: hateful_memes/img/91730.png  \n",
            "  inflating: hateful_memes/img/60278.png  \n",
            "  inflating: hateful_memes/img/80957.png  \n",
            "  inflating: hateful_memes/img/28396.png  \n",
            "  inflating: hateful_memes/img/79846.png  \n",
            "  inflating: hateful_memes/img/58027.png  \n",
            "  inflating: hateful_memes/img/76012.png  \n",
            "  inflating: hateful_memes/img/19587.png  \n",
            "  inflating: hateful_memes/img/17326.png  \n",
            "  inflating: hateful_memes/img/26530.png  \n",
            "  inflating: hateful_memes/img/65728.png  \n",
            "  inflating: hateful_memes/img/34506.png  \n",
            "  inflating: hateful_memes/img/80395.png  \n",
            "  inflating: hateful_memes/img/35091.png  \n",
            "  inflating: hateful_memes/img/40569.png  \n",
            "  inflating: hateful_memes/img/98163.png  \n",
            "  inflating: hateful_memes/img/62531.png  \n",
            "  inflating: hateful_memes/img/27518.png  \n",
            "  inflating: hateful_memes/img/07824.png  \n",
            "  inflating: hateful_memes/img/16032.png  \n",
            "  inflating: hateful_memes/img/10567.png  \n",
            "  inflating: hateful_memes/img/89267.png  \n",
            "  inflating: hateful_memes/img/61482.png  \n",
            "  inflating: hateful_memes/img/71548.png  \n",
            "  inflating: hateful_memes/img/69487.png  \n",
            "  inflating: hateful_memes/img/16487.png  \n",
            "  inflating: hateful_memes/img/21560.png  \n",
            "  inflating: hateful_memes/img/26419.png  \n",
            "  inflating: hateful_memes/img/42185.png  \n",
            "  inflating: hateful_memes/img/15768.png  \n",
            "  inflating: hateful_memes/img/26543.png  \n",
            "  inflating: hateful_memes/img/90531.png  \n",
            "  inflating: hateful_memes/img/43675.png  \n",
            "  inflating: hateful_memes/img/01469.png  \n",
            "  inflating: hateful_memes/img/26538.png  \n",
            "  inflating: hateful_memes/img/53471.png  \n",
            "  inflating: hateful_memes/img/76581.png  \n",
            "  inflating: hateful_memes/img/31280.png  \n",
            "  inflating: hateful_memes/img/34586.png  \n",
            "  inflating: hateful_memes/img/14603.png  \n",
            "  inflating: hateful_memes/img/68423.png  \n",
            "  inflating: hateful_memes/img/23198.png  \n",
            "  inflating: hateful_memes/img/07694.png  \n",
            "  inflating: hateful_memes/img/42830.png  \n",
            "  inflating: hateful_memes/img/35480.png  \n",
            "  inflating: hateful_memes/img/90814.png  \n",
            "  inflating: hateful_memes/img/53769.png  \n",
            "  inflating: hateful_memes/img/05736.png  \n",
            "  inflating: hateful_memes/img/57821.png  \n",
            "  inflating: hateful_memes/img/85097.png  \n",
            "  inflating: hateful_memes/img/94237.png  \n",
            "  inflating: hateful_memes/img/86925.png  \n",
            "  inflating: hateful_memes/img/72450.png  \n",
            "  inflating: hateful_memes/img/63029.png  \n",
            "  inflating: hateful_memes/img/57093.png  \n",
            "  inflating: hateful_memes/img/78205.png  \n",
            "  inflating: hateful_memes/img/29843.png  \n",
            "  inflating: hateful_memes/img/52069.png  \n",
            "  inflating: hateful_memes/img/84237.png  \n",
            "  inflating: hateful_memes/img/94350.png  \n",
            "  inflating: hateful_memes/img/86059.png  \n",
            "  inflating: hateful_memes/img/32605.png  \n",
            "  inflating: hateful_memes/img/75310.png  \n",
            "  inflating: hateful_memes/img/51479.png  \n",
            "  inflating: hateful_memes/img/07425.png  \n",
            "  inflating: hateful_memes/img/87364.png  \n",
            "  inflating: hateful_memes/img/09715.png  \n",
            "  inflating: hateful_memes/img/18506.png  \n",
            "  inflating: hateful_memes/img/24390.png  \n",
            "  inflating: hateful_memes/img/40286.png  \n",
            "  inflating: hateful_memes/img/20184.png  \n",
            "  inflating: hateful_memes/img/12450.png  \n",
            "  inflating: hateful_memes/img/07926.png  \n",
            "  inflating: hateful_memes/img/25914.png  \n",
            "  inflating: hateful_memes/img/97628.png  \n",
            "  inflating: hateful_memes/img/20736.png  \n",
            "  inflating: hateful_memes/img/09315.png  \n",
            "  inflating: hateful_memes/img/46075.png  \n",
            "  inflating: hateful_memes/img/24601.png  \n",
            "  inflating: hateful_memes/img/90125.png  \n",
            "  inflating: hateful_memes/img/53210.png  \n",
            "  inflating: hateful_memes/img/15328.png  \n",
            "  inflating: hateful_memes/img/37408.png  \n",
            "  inflating: hateful_memes/img/56290.png  \n",
            "  inflating: hateful_memes/img/04786.png  \n",
            "  inflating: hateful_memes/img/29483.png  \n",
            "  inflating: hateful_memes/img/09217.png  \n",
            "  inflating: hateful_memes/img/08162.png  \n",
            "  inflating: hateful_memes/img/18052.png  \n",
            "  inflating: hateful_memes/img/26170.png  \n",
            "  inflating: hateful_memes/img/82604.png  \n",
            "  inflating: hateful_memes/img/48015.png  \n",
            "  inflating: hateful_memes/img/51397.png  \n",
            "  inflating: hateful_memes/img/68213.png  \n",
            "  inflating: hateful_memes/img/76405.png  \n",
            "  inflating: hateful_memes/img/25806.png  \n",
            "  inflating: hateful_memes/img/76894.png  \n",
            "  inflating: hateful_memes/img/38076.png  \n",
            "  inflating: hateful_memes/img/31647.png  \n",
            "  inflating: hateful_memes/img/01456.png  \n",
            "  inflating: hateful_memes/img/04256.png  \n",
            "  inflating: hateful_memes/img/10956.png  \n",
            "  inflating: hateful_memes/img/23815.png  \n",
            "  inflating: hateful_memes/img/18764.png  \n",
            "  inflating: hateful_memes/img/59240.png  \n",
            "  inflating: hateful_memes/img/76305.png  \n",
            "  inflating: hateful_memes/img/59364.png  \n",
            "  inflating: hateful_memes/img/52786.png  \n",
            "  inflating: hateful_memes/img/10362.png  \n",
            "  inflating: hateful_memes/img/12039.png  \n",
            "  inflating: hateful_memes/img/79132.png  \n",
            "  inflating: hateful_memes/img/30761.png  \n",
            "  inflating: hateful_memes/img/09385.png  \n",
            "  inflating: hateful_memes/img/29387.png  \n",
            "  inflating: hateful_memes/img/17469.png  \n",
            "  inflating: hateful_memes/img/29173.png  \n",
            "  inflating: hateful_memes/img/79463.png  \n",
            "  inflating: hateful_memes/img/49315.png  \n",
            "  inflating: hateful_memes/img/42803.png  \n",
            "  inflating: hateful_memes/img/74126.png  \n",
            "  inflating: hateful_memes/img/57861.png  \n",
            "  inflating: hateful_memes/img/64390.png  \n",
            "  inflating: hateful_memes/img/13895.png  \n",
            "  inflating: hateful_memes/img/13958.png  \n",
            "  inflating: hateful_memes/img/49807.png  \n",
            "  inflating: hateful_memes/img/21946.png  \n",
            "  inflating: hateful_memes/img/63025.png  \n",
            "  inflating: hateful_memes/img/72301.png  \n",
            "  inflating: hateful_memes/img/06937.png  \n",
            "  inflating: hateful_memes/img/40761.png  \n",
            "  inflating: hateful_memes/img/34618.png  \n",
            "  inflating: hateful_memes/img/97153.png  \n",
            "  inflating: hateful_memes/img/29376.png  \n",
            "  inflating: hateful_memes/img/16478.png  \n",
            "  inflating: hateful_memes/img/17834.png  \n",
            "  inflating: hateful_memes/img/53184.png  \n",
            "  inflating: hateful_memes/img/08743.png  \n",
            "  inflating: hateful_memes/img/75340.png  \n",
            "  inflating: hateful_memes/img/79182.png  \n",
            "  inflating: hateful_memes/img/68579.png  \n",
            "  inflating: hateful_memes/img/67082.png  \n",
            "  inflating: hateful_memes/img/20971.png  \n",
            "  inflating: hateful_memes/img/86974.png  \n",
            "  inflating: hateful_memes/img/34870.png  \n",
            "  inflating: hateful_memes/img/54709.png  \n",
            "  inflating: hateful_memes/img/69085.png  \n",
            "  inflating: hateful_memes/img/54738.png  \n",
            "  inflating: hateful_memes/img/82137.png  \n",
            "  inflating: hateful_memes/img/12394.png  \n",
            "  inflating: hateful_memes/img/76258.png  \n",
            "  inflating: hateful_memes/img/91208.png  \n",
            "  inflating: hateful_memes/img/92645.png  \n",
            "  inflating: hateful_memes/img/83095.png  \n",
            "  inflating: hateful_memes/img/54316.png  \n",
            "  inflating: hateful_memes/img/71925.png  \n",
            "  inflating: hateful_memes/img/73981.png  \n",
            "  inflating: hateful_memes/img/52960.png  \n",
            "  inflating: hateful_memes/img/02381.png  \n",
            "  inflating: hateful_memes/img/14570.png  \n",
            "  inflating: hateful_memes/img/35247.png  \n",
            "  inflating: hateful_memes/img/18673.png  \n",
            "  inflating: hateful_memes/img/78931.png  \n",
            "  inflating: hateful_memes/img/74801.png  \n",
            "  inflating: hateful_memes/img/91824.png  \n",
            "  inflating: hateful_memes/img/96415.png  \n",
            "  inflating: hateful_memes/img/15489.png  \n",
            "  inflating: hateful_memes/img/28579.png  \n",
            "  inflating: hateful_memes/img/65491.png  \n",
            "  inflating: hateful_memes/img/64198.png  \n",
            "  inflating: hateful_memes/img/05612.png  \n",
            "  inflating: hateful_memes/img/91374.png  \n",
            "  inflating: hateful_memes/img/58301.png  \n",
            "  inflating: hateful_memes/img/42065.png  \n",
            "  inflating: hateful_memes/img/10642.png  \n",
            "  inflating: hateful_memes/img/53017.png  \n",
            "  inflating: hateful_memes/img/47026.png  \n",
            "  inflating: hateful_memes/img/36497.png  \n",
            "  inflating: hateful_memes/img/52036.png  \n",
            "  inflating: hateful_memes/img/29608.png  \n",
            "  inflating: hateful_memes/img/17082.png  \n",
            "  inflating: hateful_memes/img/31907.png  \n",
            "  inflating: hateful_memes/img/84372.png  \n",
            "  inflating: hateful_memes/img/68743.png  \n",
            "  inflating: hateful_memes/img/74312.png  \n",
            "  inflating: hateful_memes/img/90768.png  \n",
            "  inflating: hateful_memes/img/49685.png  \n",
            "  inflating: hateful_memes/img/87564.png  \n",
            "  inflating: hateful_memes/img/38209.png  \n",
            "  inflating: hateful_memes/img/94015.png  \n",
            "  inflating: hateful_memes/img/12350.png  \n",
            "  inflating: hateful_memes/img/04183.png  \n",
            "  inflating: hateful_memes/img/72641.png  \n",
            "  inflating: hateful_memes/img/94372.png  \n",
            "  inflating: hateful_memes/img/93425.png  \n",
            "  inflating: hateful_memes/img/87106.png  \n",
            "  inflating: hateful_memes/img/94013.png  \n",
            "  inflating: hateful_memes/img/19357.png  \n",
            "  inflating: hateful_memes/img/25198.png  \n",
            "  inflating: hateful_memes/img/46759.png  \n",
            "  inflating: hateful_memes/img/59763.png  \n",
            "  inflating: hateful_memes/img/16407.png  \n",
            "  inflating: hateful_memes/img/91526.png  \n",
            "  inflating: hateful_memes/img/05192.png  \n",
            "  inflating: hateful_memes/img/63805.png  \n",
            "  inflating: hateful_memes/img/06125.png  \n",
            "  inflating: hateful_memes/img/24907.png  \n",
            "  inflating: hateful_memes/img/10857.png  \n",
            "  inflating: hateful_memes/img/37250.png  \n",
            "  inflating: hateful_memes/img/37548.png  \n",
            "  inflating: hateful_memes/img/19084.png  \n",
            "  inflating: hateful_memes/img/31420.png  \n",
            "  inflating: hateful_memes/img/21038.png  \n",
            "  inflating: hateful_memes/img/04928.png  \n",
            "  inflating: hateful_memes/img/92836.png  \n",
            "  inflating: hateful_memes/img/52806.png  \n",
            "  inflating: hateful_memes/img/32617.png  \n",
            "  inflating: hateful_memes/img/51467.png  \n",
            "  inflating: hateful_memes/img/64820.png  \n",
            "  inflating: hateful_memes/img/46279.png  \n",
            "  inflating: hateful_memes/img/37560.png  \n",
            "  inflating: hateful_memes/img/61420.png  \n",
            "  inflating: hateful_memes/img/94083.png  \n",
            "  inflating: hateful_memes/img/48396.png  \n",
            "  inflating: hateful_memes/img/52084.png  \n",
            "  inflating: hateful_memes/img/70652.png  \n",
            "  inflating: hateful_memes/img/34721.png  \n",
            "  inflating: hateful_memes/img/32956.png  \n",
            "  inflating: hateful_memes/img/36748.png  \n",
            "  inflating: hateful_memes/img/61378.png  \n",
            "  inflating: hateful_memes/img/07834.png  \n",
            "  inflating: hateful_memes/img/92870.png  \n",
            "  inflating: hateful_memes/img/03971.png  \n",
            "  inflating: hateful_memes/img/50146.png  \n",
            "  inflating: hateful_memes/img/02584.png  \n",
            "  inflating: hateful_memes/img/07265.png  \n",
            "  inflating: hateful_memes/img/67410.png  \n",
            "  inflating: hateful_memes/img/54168.png  \n",
            "  inflating: hateful_memes/img/53108.png  \n",
            "  inflating: hateful_memes/img/01562.png  \n",
            "  inflating: hateful_memes/img/29760.png  \n",
            "  inflating: hateful_memes/img/46783.png  \n",
            "  inflating: hateful_memes/img/92085.png  \n",
            "  inflating: hateful_memes/img/50371.png  \n",
            "  inflating: hateful_memes/img/84135.png  \n",
            "  inflating: hateful_memes/img/67214.png  \n",
            "  inflating: hateful_memes/img/74013.png  \n",
            "  inflating: hateful_memes/img/78652.png  \n",
            "  inflating: hateful_memes/img/24698.png  \n",
            "  inflating: hateful_memes/img/46352.png  \n",
            "  inflating: hateful_memes/img/41068.png  \n",
            "  inflating: hateful_memes/img/19740.png  \n",
            "  inflating: hateful_memes/img/56310.png  \n",
            "  inflating: hateful_memes/img/34218.png  \n",
            "  inflating: hateful_memes/img/51864.png  \n",
            "  inflating: hateful_memes/img/37615.png  \n",
            "  inflating: hateful_memes/img/94085.png  \n",
            "  inflating: hateful_memes/img/15409.png  \n",
            "  inflating: hateful_memes/img/16843.png  \n",
            "  inflating: hateful_memes/img/48236.png  \n",
            "  inflating: hateful_memes/img/04379.png  \n",
            "  inflating: hateful_memes/img/08234.png  \n",
            "  inflating: hateful_memes/img/23685.png  \n",
            "  inflating: hateful_memes/img/60784.png  \n",
            "  inflating: hateful_memes/img/28356.png  \n",
            "  inflating: hateful_memes/img/93410.png  \n",
            "  inflating: hateful_memes/img/30865.png  \n",
            "  inflating: hateful_memes/img/40217.png  \n",
            "  inflating: hateful_memes/img/67892.png  \n",
            "  inflating: hateful_memes/img/27304.png  \n",
            "  inflating: hateful_memes/img/13809.png  \n",
            "  inflating: hateful_memes/img/86401.png  \n",
            "  inflating: hateful_memes/img/45126.png  \n",
            "  inflating: hateful_memes/img/48920.png  \n",
            "  inflating: hateful_memes/img/36578.png  \n",
            "  inflating: hateful_memes/img/49267.png  \n",
            "  inflating: hateful_memes/img/48062.png  \n",
            "  inflating: hateful_memes/img/62573.png  \n",
            "  inflating: hateful_memes/img/48923.png  \n",
            "  inflating: hateful_memes/img/91320.png  \n",
            "  inflating: hateful_memes/img/93164.png  \n",
            "  inflating: hateful_memes/img/38920.png  \n",
            "  inflating: hateful_memes/img/98314.png  \n",
            "  inflating: hateful_memes/img/91540.png  \n",
            "  inflating: hateful_memes/img/23751.png  \n",
            "  inflating: hateful_memes/img/06479.png  \n",
            "  inflating: hateful_memes/img/79316.png  \n",
            "  inflating: hateful_memes/img/48792.png  \n",
            "  inflating: hateful_memes/img/98731.png  \n",
            "  inflating: hateful_memes/img/86024.png  \n",
            "  inflating: hateful_memes/img/63507.png  \n",
            "  inflating: hateful_memes/img/93208.png  \n",
            "  inflating: hateful_memes/img/36752.png  \n",
            "  inflating: hateful_memes/img/81496.png  \n",
            "  inflating: hateful_memes/img/96541.png  \n",
            "  inflating: hateful_memes/img/15902.png  \n",
            "  inflating: hateful_memes/img/89136.png  \n",
            "  inflating: hateful_memes/img/89417.png  \n",
            "  inflating: hateful_memes/img/48260.png  \n",
            "  inflating: hateful_memes/img/82609.png  \n",
            "  inflating: hateful_memes/img/79823.png  \n",
            "  inflating: hateful_memes/img/30982.png  \n",
            "  inflating: hateful_memes/img/06415.png  \n",
            "  inflating: hateful_memes/img/79652.png  \n",
            "  inflating: hateful_memes/img/87924.png  \n",
            "  inflating: hateful_memes/img/40329.png  \n",
            "  inflating: hateful_memes/img/85329.png  \n",
            "  inflating: hateful_memes/img/01953.png  \n",
            "  inflating: hateful_memes/img/60143.png  \n",
            "  inflating: hateful_memes/img/05986.png  \n",
            "  inflating: hateful_memes/img/05126.png  \n",
            "  inflating: hateful_memes/img/35802.png  \n",
            "  inflating: hateful_memes/img/51409.png  \n",
            "  inflating: hateful_memes/img/57463.png  \n",
            "  inflating: hateful_memes/img/89360.png  \n",
            "  inflating: hateful_memes/img/94351.png  \n",
            "  inflating: hateful_memes/img/92581.png  \n",
            "  inflating: hateful_memes/img/46201.png  \n",
            "  inflating: hateful_memes/img/40137.png  \n",
            "  inflating: hateful_memes/img/96312.png  \n",
            "  inflating: hateful_memes/img/84762.png  \n",
            "  inflating: hateful_memes/img/78904.png  \n",
            "  inflating: hateful_memes/img/17398.png  \n",
            "  inflating: hateful_memes/img/65482.png  \n",
            "  inflating: hateful_memes/img/27915.png  \n",
            "  inflating: hateful_memes/img/54837.png  \n",
            "  inflating: hateful_memes/img/56417.png  \n",
            "  inflating: hateful_memes/img/17203.png  \n",
            "  inflating: hateful_memes/img/30675.png  \n",
            "  inflating: hateful_memes/img/70198.png  \n",
            "  inflating: hateful_memes/img/36019.png  \n",
            "  inflating: hateful_memes/img/64071.png  \n",
            "  inflating: hateful_memes/img/82359.png  \n",
            "  inflating: hateful_memes/img/71586.png  \n",
            "  inflating: hateful_memes/img/94158.png  \n",
            "  inflating: hateful_memes/img/54190.png  \n",
            "  inflating: hateful_memes/img/30165.png  \n",
            "  inflating: hateful_memes/img/30864.png  \n",
            "  inflating: hateful_memes/img/19586.png  \n",
            "  inflating: hateful_memes/img/70146.png  \n",
            "  inflating: hateful_memes/img/13095.png  \n",
            "  inflating: hateful_memes/img/08374.png  \n",
            "  inflating: hateful_memes/img/75469.png  \n",
            "  inflating: hateful_memes/img/06427.png  \n",
            "  inflating: hateful_memes/img/89067.png  \n",
            "  inflating: hateful_memes/img/19036.png  \n",
            "  inflating: hateful_memes/img/96371.png  \n",
            "  inflating: hateful_memes/img/34602.png  \n",
            "  inflating: hateful_memes/img/48276.png  \n",
            "  inflating: hateful_memes/img/21408.png  \n",
            "  inflating: hateful_memes/img/96145.png  \n",
            "  inflating: hateful_memes/img/78429.png  \n",
            "  inflating: hateful_memes/img/18732.png  \n",
            "  inflating: hateful_memes/img/53467.png  \n",
            "  inflating: hateful_memes/img/94305.png  \n",
            "  inflating: hateful_memes/img/27154.png  \n",
            "  inflating: hateful_memes/img/84576.png  \n",
            "  inflating: hateful_memes/img/71689.png  \n",
            "  inflating: hateful_memes/img/26590.png  \n",
            "  inflating: hateful_memes/img/42693.png  \n",
            "  inflating: hateful_memes/img/04735.png  \n",
            "  inflating: hateful_memes/img/18564.png  \n",
            "  inflating: hateful_memes/img/28541.png  \n",
            "  inflating: hateful_memes/img/53094.png  \n",
            "  inflating: hateful_memes/img/64735.png  \n",
            "  inflating: hateful_memes/img/97438.png  \n",
            "  inflating: hateful_memes/img/67935.png  \n",
            "  inflating: hateful_memes/img/98564.png  \n",
            "  inflating: hateful_memes/img/21547.png  \n",
            "  inflating: hateful_memes/img/29138.png  \n",
            "  inflating: hateful_memes/img/51934.png  \n",
            "  inflating: hateful_memes/img/78164.png  \n",
            "  inflating: hateful_memes/img/80792.png  \n",
            "  inflating: hateful_memes/img/98035.png  \n",
            "  inflating: hateful_memes/img/67312.png  \n",
            "  inflating: hateful_memes/img/43197.png  \n",
            "  inflating: hateful_memes/img/29706.png  \n",
            "  inflating: hateful_memes/img/71429.png  \n",
            "  inflating: hateful_memes/img/36710.png  \n",
            "  inflating: hateful_memes/img/02937.png  \n",
            "  inflating: hateful_memes/img/72816.png  \n",
            "  inflating: hateful_memes/img/18469.png  \n",
            "  inflating: hateful_memes/img/31892.png  \n",
            "  inflating: hateful_memes/img/23075.png  \n",
            "  inflating: hateful_memes/img/17263.png  \n",
            "  inflating: hateful_memes/img/84120.png  \n",
            "  inflating: hateful_memes/img/93578.png  \n",
            "  inflating: hateful_memes/img/75102.png  \n",
            "  inflating: hateful_memes/img/17248.png  \n",
            "  inflating: hateful_memes/img/72956.png  \n",
            "  inflating: hateful_memes/img/16780.png  \n",
            "  inflating: hateful_memes/img/92573.png  \n",
            "  inflating: hateful_memes/img/86139.png  \n",
            "  inflating: hateful_memes/img/10976.png  \n",
            "  inflating: hateful_memes/img/04892.png  \n",
            "  inflating: hateful_memes/img/35869.png  \n",
            "  inflating: hateful_memes/img/60173.png  \n",
            "  inflating: hateful_memes/img/75981.png  \n",
            "  inflating: hateful_memes/img/52738.png  \n",
            "  inflating: hateful_memes/img/05461.png  \n",
            "  inflating: hateful_memes/img/45739.png  \n",
            "  inflating: hateful_memes/img/04782.png  \n",
            "  inflating: hateful_memes/img/23841.png  \n",
            "  inflating: hateful_memes/img/65741.png  \n",
            "  inflating: hateful_memes/img/30569.png  \n",
            "  inflating: hateful_memes/img/67913.png  \n",
            "  inflating: hateful_memes/img/19384.png  \n",
            "  inflating: hateful_memes/img/81630.png  \n",
            "  inflating: hateful_memes/img/62094.png  \n",
            "  inflating: hateful_memes/img/90524.png  \n",
            "  inflating: hateful_memes/img/71649.png  \n",
            "  inflating: hateful_memes/img/46721.png  \n",
            "  inflating: hateful_memes/img/25710.png  \n",
            "  inflating: hateful_memes/img/34965.png  \n",
            "  inflating: hateful_memes/img/46735.png  \n",
            "  inflating: hateful_memes/img/03568.png  \n",
            "  inflating: hateful_memes/img/31957.png  \n",
            "  inflating: hateful_memes/img/23508.png  \n",
            "  inflating: hateful_memes/img/52431.png  \n",
            "  inflating: hateful_memes/img/28507.png  \n",
            "  inflating: hateful_memes/img/96524.png  \n",
            "  inflating: hateful_memes/img/54391.png  \n",
            "  inflating: hateful_memes/img/47189.png  \n",
            "  inflating: hateful_memes/img/19203.png  \n",
            "  inflating: hateful_memes/img/62934.png  \n",
            "  inflating: hateful_memes/img/27580.png  \n",
            "  inflating: hateful_memes/img/04798.png  \n",
            "  inflating: hateful_memes/img/24061.png  \n",
            "  inflating: hateful_memes/img/45307.png  \n",
            "  inflating: hateful_memes/img/01578.png  \n",
            "  inflating: hateful_memes/img/03692.png  \n",
            "  inflating: hateful_memes/img/08925.png  \n",
            "  inflating: hateful_memes/img/84316.png  \n",
            "  inflating: hateful_memes/img/14067.png  \n",
            "  inflating: hateful_memes/img/01527.png  \n",
            "  inflating: hateful_memes/img/01576.png  \n",
            "  inflating: hateful_memes/img/56104.png  \n",
            "  inflating: hateful_memes/img/17645.png  \n",
            "  inflating: hateful_memes/img/81093.png  \n",
            "  inflating: hateful_memes/img/23046.png  \n",
            "  inflating: hateful_memes/img/29345.png  \n",
            "  inflating: hateful_memes/img/71845.png  \n",
            "  inflating: hateful_memes/img/43691.png  \n",
            "  inflating: hateful_memes/img/56790.png  \n",
            "  inflating: hateful_memes/img/65234.png  \n",
            "  inflating: hateful_memes/img/59130.png  \n",
            "  inflating: hateful_memes/img/58036.png  \n",
            "  inflating: hateful_memes/img/91563.png  \n",
            "  inflating: hateful_memes/img/56291.png  \n",
            "  inflating: hateful_memes/img/76402.png  \n",
            "  inflating: hateful_memes/img/82714.png  \n",
            "  inflating: hateful_memes/img/72910.png  \n",
            "  inflating: hateful_memes/img/45930.png  \n",
            "  inflating: hateful_memes/img/14865.png  \n",
            "  inflating: hateful_memes/img/43701.png  \n",
            "  inflating: hateful_memes/img/65347.png  \n",
            "  inflating: hateful_memes/img/34178.png  \n",
            "  inflating: hateful_memes/img/15749.png  \n",
            "  inflating: hateful_memes/img/10649.png  \n",
            "  inflating: hateful_memes/img/62941.png  \n",
            "  inflating: hateful_memes/img/13287.png  \n",
            "  inflating: hateful_memes/img/47862.png  \n",
            "  inflating: hateful_memes/img/43125.png  \n",
            "  inflating: hateful_memes/img/17652.png  \n",
            "  inflating: hateful_memes/img/97053.png  \n",
            "  inflating: hateful_memes/img/47136.png  \n",
            "  inflating: hateful_memes/img/59402.png  \n",
            "  inflating: hateful_memes/img/16054.png  \n",
            "  inflating: hateful_memes/img/67193.png  \n",
            "  inflating: hateful_memes/img/12547.png  \n",
            "  inflating: hateful_memes/img/13876.png  \n",
            "  inflating: hateful_memes/img/98735.png  \n",
            "  inflating: hateful_memes/img/82437.png  \n",
            "  inflating: hateful_memes/img/63479.png  \n",
            "  inflating: hateful_memes/img/85796.png  \n",
            "  inflating: hateful_memes/img/07452.png  \n",
            "  inflating: hateful_memes/img/30764.png  \n",
            "  inflating: hateful_memes/img/43956.png  \n",
            "  inflating: hateful_memes/img/29178.png  \n",
            "  inflating: hateful_memes/img/75039.png  \n",
            "  inflating: hateful_memes/img/86705.png  \n",
            "  inflating: hateful_memes/img/26837.png  \n",
            "  inflating: hateful_memes/img/30162.png  \n",
            "  inflating: hateful_memes/img/82596.png  \n",
            "  inflating: hateful_memes/img/73956.png  \n",
            "  inflating: hateful_memes/img/50748.png  \n",
            "  inflating: hateful_memes/img/49075.png  \n",
            "  inflating: hateful_memes/img/08937.png  \n",
            "  inflating: hateful_memes/img/08924.png  \n",
            "  inflating: hateful_memes/img/05468.png  \n",
            "  inflating: hateful_memes/img/56912.png  \n",
            "  inflating: hateful_memes/img/84150.png  \n",
            "  inflating: hateful_memes/img/16490.png  \n",
            "  inflating: hateful_memes/img/08269.png  \n",
            "  inflating: hateful_memes/img/68527.png  \n",
            "  inflating: hateful_memes/img/96514.png  \n",
            "  inflating: hateful_memes/img/47913.png  \n",
            "  inflating: hateful_memes/img/17934.png  \n",
            "  inflating: hateful_memes/img/92375.png  \n",
            "  inflating: hateful_memes/img/39528.png  \n",
            "  inflating: hateful_memes/img/58694.png  \n",
            "  inflating: hateful_memes/img/76398.png  \n",
            "  inflating: hateful_memes/img/01465.png  \n",
            "  inflating: hateful_memes/img/54930.png  \n",
            "  inflating: hateful_memes/img/32876.png  \n",
            "  inflating: hateful_memes/img/73154.png  \n",
            "  inflating: hateful_memes/img/71364.png  \n",
            "  inflating: hateful_memes/img/75608.png  \n",
            "  inflating: hateful_memes/img/61274.png  \n",
            "  inflating: hateful_memes/img/50198.png  \n",
            "  inflating: hateful_memes/img/17908.png  \n",
            "  inflating: hateful_memes/img/16593.png  \n",
            "  inflating: hateful_memes/img/78214.png  \n",
            "  inflating: hateful_memes/img/60439.png  \n",
            "  inflating: hateful_memes/img/47369.png  \n",
            "  inflating: hateful_memes/img/65127.png  \n",
            "  inflating: hateful_memes/img/34502.png  \n",
            "  inflating: hateful_memes/img/29508.png  \n",
            "  inflating: hateful_memes/img/93610.png  \n",
            "  inflating: hateful_memes/img/76825.png  \n",
            "  inflating: hateful_memes/img/68751.png  \n",
            "  inflating: hateful_memes/img/73681.png  \n",
            "  inflating: hateful_memes/img/68519.png  \n",
            "  inflating: hateful_memes/img/50823.png  \n",
            "  inflating: hateful_memes/img/52801.png  \n",
            "  inflating: hateful_memes/img/26418.png  \n",
            "  inflating: hateful_memes/img/94786.png  \n",
            "  inflating: hateful_memes/img/31690.png  \n",
            "  inflating: hateful_memes/img/14896.png  \n",
            "  inflating: hateful_memes/img/08621.png  \n",
            "  inflating: hateful_memes/img/93046.png  \n",
            "  inflating: hateful_memes/img/84307.png  \n",
            "  inflating: hateful_memes/img/48957.png  \n",
            "  inflating: hateful_memes/img/52783.png  \n",
            "  inflating: hateful_memes/img/60451.png  \n",
            "  inflating: hateful_memes/img/13679.png  \n",
            "  inflating: hateful_memes/img/57681.png  \n",
            "  inflating: hateful_memes/img/49602.png  \n",
            "  inflating: hateful_memes/img/06712.png  \n",
            "  inflating: hateful_memes/img/28394.png  \n",
            "  inflating: hateful_memes/img/61793.png  \n",
            "  inflating: hateful_memes/img/16892.png  \n",
            "  inflating: hateful_memes/img/37185.png  \n",
            "  inflating: hateful_memes/img/15479.png  \n",
            "  inflating: hateful_memes/img/31526.png  \n",
            "  inflating: hateful_memes/img/80521.png  \n",
            "  inflating: hateful_memes/img/03271.png  \n",
            "  inflating: hateful_memes/img/10537.png  \n",
            "  inflating: hateful_memes/img/42579.png  \n",
            "  inflating: hateful_memes/img/69804.png  \n",
            "  inflating: hateful_memes/img/93015.png  \n",
            "  inflating: hateful_memes/img/50427.png  \n",
            "  inflating: hateful_memes/img/05479.png  \n",
            "  inflating: hateful_memes/img/40865.png  \n",
            "  inflating: hateful_memes/img/36749.png  \n",
            "  inflating: hateful_memes/img/12754.png  \n",
            "  inflating: hateful_memes/img/95263.png  \n",
            "  inflating: hateful_memes/img/18267.png  \n",
            "  inflating: hateful_memes/img/92768.png  \n",
            "  inflating: hateful_memes/img/49120.png  \n",
            "  inflating: hateful_memes/img/49213.png  \n",
            "  inflating: hateful_memes/img/47620.png  \n",
            "  inflating: hateful_memes/img/43207.png  \n",
            "  inflating: hateful_memes/img/07248.png  \n",
            "  inflating: hateful_memes/img/97601.png  \n",
            "  inflating: hateful_memes/img/98724.png  \n",
            "  inflating: hateful_memes/img/40982.png  \n",
            "  inflating: hateful_memes/img/70512.png  \n",
            "  inflating: hateful_memes/img/03581.png  \n",
            "  inflating: hateful_memes/img/98075.png  \n",
            "  inflating: hateful_memes/img/79024.png  \n",
            "  inflating: hateful_memes/img/01793.png  \n",
            "  inflating: hateful_memes/img/78492.png  \n",
            "  inflating: hateful_memes/img/67384.png  \n",
            "  inflating: hateful_memes/img/70654.png  \n",
            "  inflating: hateful_memes/img/18207.png  \n",
            "  inflating: hateful_memes/img/09841.png  \n",
            "  inflating: hateful_memes/img/28935.png  \n",
            "  inflating: hateful_memes/img/04726.png  \n",
            "  inflating: hateful_memes/img/78624.png  \n",
            "  inflating: hateful_memes/img/52097.png  \n",
            "  inflating: hateful_memes/img/08567.png  \n",
            "  inflating: hateful_memes/img/89275.png  \n",
            "  inflating: hateful_memes/img/53624.png  \n",
            "  inflating: hateful_memes/img/35780.png  \n",
            "  inflating: hateful_memes/img/93216.png  \n",
            "  inflating: hateful_memes/img/32415.png  \n",
            "  inflating: hateful_memes/img/10652.png  \n",
            "  inflating: hateful_memes/img/21698.png  \n",
            "  inflating: hateful_memes/img/71320.png  \n",
            "  inflating: hateful_memes/img/09623.png  \n",
            "  inflating: hateful_memes/img/83127.png  \n",
            "  inflating: hateful_memes/img/24395.png  \n",
            "  inflating: hateful_memes/img/52780.png  \n",
            "  inflating: hateful_memes/img/48579.png  \n",
            "  inflating: hateful_memes/img/79610.png  \n",
            "  inflating: hateful_memes/img/72563.png  \n",
            "  inflating: hateful_memes/img/42736.png  \n",
            "  inflating: hateful_memes/img/52469.png  \n",
            "  inflating: hateful_memes/img/08769.png  \n",
            "  inflating: hateful_memes/img/38654.png  \n",
            "  inflating: hateful_memes/img/07438.png  \n",
            "  inflating: hateful_memes/img/14893.png  \n",
            "  inflating: hateful_memes/img/58197.png  \n",
            "  inflating: hateful_memes/img/52603.png  \n",
            "  inflating: hateful_memes/img/04295.png  \n",
            "  inflating: hateful_memes/img/63985.png  \n",
            "  inflating: hateful_memes/img/65108.png  \n",
            "  inflating: hateful_memes/img/67801.png  \n",
            "  inflating: hateful_memes/img/25709.png  \n",
            "  inflating: hateful_memes/img/78314.png  \n",
            "  inflating: hateful_memes/img/20876.png  \n",
            "  inflating: hateful_memes/img/76542.png  \n",
            "  inflating: hateful_memes/img/47912.png  \n",
            "  inflating: hateful_memes/img/63105.png  \n",
            "  inflating: hateful_memes/img/73965.png  \n",
            "  inflating: hateful_memes/img/84639.png  \n",
            "  inflating: hateful_memes/img/75382.png  \n",
            "  inflating: hateful_memes/img/85274.png  \n",
            "  inflating: hateful_memes/img/07354.png  \n",
            "  inflating: hateful_memes/img/02581.png  \n",
            "  inflating: hateful_memes/img/35860.png  \n",
            "  inflating: hateful_memes/img/09174.png  \n",
            "  inflating: hateful_memes/img/64081.png  \n",
            "  inflating: hateful_memes/img/31072.png  \n",
            "  inflating: hateful_memes/img/20513.png  \n",
            "  inflating: hateful_memes/img/83024.png  \n",
            "  inflating: hateful_memes/img/91754.png  \n",
            "  inflating: hateful_memes/img/90471.png  \n",
            "  inflating: hateful_memes/img/27963.png  \n",
            "  inflating: hateful_memes/img/02543.png  \n",
            "  inflating: hateful_memes/img/80319.png  \n",
            "  inflating: hateful_memes/img/90427.png  \n",
            "  inflating: hateful_memes/img/72698.png  \n",
            "  inflating: hateful_memes/img/40198.png  \n",
            "  inflating: hateful_memes/img/25397.png  \n",
            "  inflating: hateful_memes/img/16423.png  \n",
            "  inflating: hateful_memes/img/72598.png  \n",
            "  inflating: hateful_memes/img/65843.png  \n",
            "  inflating: hateful_memes/img/42816.png  \n",
            "  inflating: hateful_memes/img/61280.png  \n",
            "  inflating: hateful_memes/img/98621.png  \n",
            "  inflating: hateful_memes/img/58917.png  \n",
            "  inflating: hateful_memes/img/08524.png  \n",
            "  inflating: hateful_memes/img/42380.png  \n",
            "  inflating: hateful_memes/img/83649.png  \n",
            "  inflating: hateful_memes/img/87592.png  \n",
            "  inflating: hateful_memes/img/35470.png  \n",
            "  inflating: hateful_memes/img/74562.png  \n",
            "  inflating: hateful_memes/img/69304.png  \n",
            "  inflating: hateful_memes/img/10965.png  \n",
            "  inflating: hateful_memes/img/64310.png  \n",
            "  inflating: hateful_memes/img/08961.png  \n",
            "  inflating: hateful_memes/img/02486.png  \n",
            "  inflating: hateful_memes/img/19487.png  \n",
            "  inflating: hateful_memes/img/69873.png  \n",
            "  inflating: hateful_memes/img/80279.png  \n",
            "  inflating: hateful_memes/img/92167.png  \n",
            "  inflating: hateful_memes/img/14260.png  \n",
            "  inflating: hateful_memes/img/53876.png  \n",
            "  inflating: hateful_memes/img/62814.png  \n",
            "  inflating: hateful_memes/img/21078.png  \n",
            "  inflating: hateful_memes/img/06245.png  \n",
            "  inflating: hateful_memes/img/50894.png  \n",
            "  inflating: hateful_memes/img/95817.png  \n",
            "  inflating: hateful_memes/img/27369.png  \n",
            "  inflating: hateful_memes/img/93605.png  \n",
            "  inflating: hateful_memes/img/91056.png  \n",
            "  inflating: hateful_memes/img/14236.png  \n",
            "  inflating: hateful_memes/img/36970.png  \n",
            "  inflating: hateful_memes/img/71563.png  \n",
            "  inflating: hateful_memes/img/95813.png  \n",
            "  inflating: hateful_memes/img/74253.png  \n",
            "  inflating: hateful_memes/img/34072.png  \n",
            "  inflating: hateful_memes/img/40832.png  \n",
            "  inflating: hateful_memes/img/39527.png  \n",
            "  inflating: hateful_memes/img/01829.png  \n",
            "  inflating: hateful_memes/img/78450.png  \n",
            "  inflating: hateful_memes/img/42103.png  \n",
            "  inflating: hateful_memes/img/89406.png  \n",
            "  inflating: hateful_memes/img/69057.png  \n",
            "  inflating: hateful_memes/img/05327.png  \n",
            "  inflating: hateful_memes/img/21780.png  \n",
            "  inflating: hateful_memes/img/74368.png  \n",
            "  inflating: hateful_memes/img/86203.png  \n",
            "  inflating: hateful_memes/img/46872.png  \n",
            "  inflating: hateful_memes/img/07164.png  \n",
            "  inflating: hateful_memes/img/25481.png  \n",
            "  inflating: hateful_memes/img/92437.png  \n",
            "  inflating: hateful_memes/img/52708.png  \n",
            "  inflating: hateful_memes/img/23658.png  \n",
            "  inflating: hateful_memes/img/74206.png  \n",
            "  inflating: hateful_memes/img/16870.png  \n",
            "  inflating: hateful_memes/img/52874.png  \n",
            "  inflating: hateful_memes/img/70825.png  \n",
            "  inflating: hateful_memes/img/20867.png  \n",
            "  inflating: hateful_memes/img/64157.png  \n",
            "  inflating: hateful_memes/img/02471.png  \n",
            "  inflating: hateful_memes/img/73159.png  \n",
            "  inflating: hateful_memes/img/02987.png  \n",
            "  inflating: hateful_memes/img/26549.png  \n",
            "  inflating: hateful_memes/img/76015.png  \n",
            "  inflating: hateful_memes/img/54978.png  \n",
            "  inflating: hateful_memes/img/90657.png  \n",
            "  inflating: hateful_memes/img/94361.png  \n",
            "  inflating: hateful_memes/img/63491.png  \n",
            "  inflating: hateful_memes/img/89567.png  \n",
            "  inflating: hateful_memes/img/59237.png  \n",
            "  inflating: hateful_memes/img/72968.png  \n",
            "  inflating: hateful_memes/img/32564.png  \n",
            "  inflating: hateful_memes/img/25986.png  \n",
            "  inflating: hateful_memes/img/56187.png  \n",
            "  inflating: hateful_memes/img/87324.png  \n",
            "  inflating: hateful_memes/img/89137.png  \n",
            "  inflating: hateful_memes/img/28479.png  \n",
            "  inflating: hateful_memes/img/85204.png  \n",
            "  inflating: hateful_memes/img/42865.png  \n",
            "  inflating: hateful_memes/img/61928.png  \n",
            "  inflating: hateful_memes/img/05781.png  \n",
            "  inflating: hateful_memes/img/27864.png  \n",
            "  inflating: hateful_memes/img/47819.png  \n",
            "  inflating: hateful_memes/img/02683.png  \n",
            "  inflating: hateful_memes/img/07895.png  \n",
            "  inflating: hateful_memes/img/05841.png  \n",
            "  inflating: hateful_memes/img/60217.png  \n",
            "  inflating: hateful_memes/img/17458.png  \n",
            "  inflating: hateful_memes/img/87913.png  \n",
            "  inflating: hateful_memes/img/17843.png  \n",
            "  inflating: hateful_memes/img/46193.png  \n",
            "  inflating: hateful_memes/img/02764.png  \n",
            "  inflating: hateful_memes/img/80925.png  \n",
            "  inflating: hateful_memes/img/94162.png  \n",
            "  inflating: hateful_memes/img/97365.png  \n",
            "  inflating: hateful_memes/img/62093.png  \n",
            "  inflating: hateful_memes/img/57298.png  \n",
            "  inflating: hateful_memes/img/84692.png  \n",
            "  inflating: hateful_memes/img/02185.png  \n",
            "  inflating: hateful_memes/img/07853.png  \n",
            "  inflating: hateful_memes/img/68713.png  \n",
            "  inflating: hateful_memes/img/45082.png  \n",
            "  inflating: hateful_memes/img/38094.png  \n",
            "  inflating: hateful_memes/img/52746.png  \n",
            "  inflating: hateful_memes/img/82450.png  \n",
            "  inflating: hateful_memes/img/12560.png  \n",
            "  inflating: hateful_memes/img/47589.png  \n",
            "  inflating: hateful_memes/img/93548.png  \n",
            "  inflating: hateful_memes/img/39820.png  \n",
            "  inflating: hateful_memes/img/57284.png  \n",
            "  inflating: hateful_memes/img/85271.png  \n",
            "  inflating: hateful_memes/img/82301.png  \n",
            "  inflating: hateful_memes/img/42019.png  \n",
            "  inflating: hateful_memes/img/61932.png  \n",
            "  inflating: hateful_memes/img/36480.png  \n",
            "  inflating: hateful_memes/img/50934.png  \n",
            "  inflating: hateful_memes/img/53012.png  \n",
            "  inflating: hateful_memes/img/65203.png  \n",
            "  inflating: hateful_memes/img/76120.png  \n",
            "  inflating: hateful_memes/img/29863.png  \n",
            "  inflating: hateful_memes/img/78953.png  \n",
            "  inflating: hateful_memes/img/65107.png  \n",
            "  inflating: hateful_memes/img/51304.png  \n",
            "  inflating: hateful_memes/img/68921.png  \n",
            "  inflating: hateful_memes/img/06934.png  \n",
            "  inflating: hateful_memes/img/19256.png  \n",
            "  inflating: hateful_memes/img/76495.png  \n",
            "  inflating: hateful_memes/img/37621.png  \n",
            "  inflating: hateful_memes/img/34985.png  \n",
            "  inflating: hateful_memes/img/60823.png  \n",
            "  inflating: hateful_memes/img/97814.png  \n",
            "  inflating: hateful_memes/img/64905.png  \n",
            "  inflating: hateful_memes/img/85324.png  \n",
            "  inflating: hateful_memes/img/75403.png  \n",
            "  inflating: hateful_memes/img/25718.png  \n",
            "  inflating: hateful_memes/img/50768.png  \n",
            "  inflating: hateful_memes/img/24579.png  \n",
            "  inflating: hateful_memes/img/98670.png  \n",
            "  inflating: hateful_memes/img/96874.png  \n",
            "  inflating: hateful_memes/img/86205.png  \n",
            "  inflating: hateful_memes/img/45069.png  \n",
            "  inflating: hateful_memes/img/97832.png  \n",
            "  inflating: hateful_memes/img/49831.png  \n",
            "  inflating: hateful_memes/img/85190.png  \n",
            "  inflating: hateful_memes/img/01974.png  \n",
            "  inflating: hateful_memes/img/64130.png  \n",
            "  inflating: hateful_memes/img/96317.png  \n",
            "  inflating: hateful_memes/img/56210.png  \n",
            "  inflating: hateful_memes/img/80672.png  \n",
            "  inflating: hateful_memes/img/36281.png  \n",
            "  inflating: hateful_memes/img/04263.png  \n",
            "  inflating: hateful_memes/img/27153.png  \n",
            "  inflating: hateful_memes/img/35096.png  \n",
            "  inflating: hateful_memes/img/49635.png  \n",
            "  inflating: hateful_memes/img/25367.png  \n",
            "  inflating: hateful_memes/img/95203.png  \n",
            "  inflating: hateful_memes/img/79352.png  \n",
            "  inflating: hateful_memes/img/57319.png  \n",
            "  inflating: hateful_memes/img/61827.png  \n",
            "  inflating: hateful_memes/img/75816.png  \n",
            "  inflating: hateful_memes/img/68120.png  \n",
            "  inflating: hateful_memes/img/62107.png  \n",
            "  inflating: hateful_memes/img/41280.png  \n",
            "  inflating: hateful_memes/img/16430.png  \n",
            "  inflating: hateful_memes/img/04153.png  \n",
            "  inflating: hateful_memes/img/48052.png  \n",
            "  inflating: hateful_memes/img/74509.png  \n",
            "  inflating: hateful_memes/img/97624.png  \n",
            "  inflating: hateful_memes/img/83125.png  \n",
            "  inflating: hateful_memes/img/34581.png  \n",
            "  inflating: hateful_memes/img/36021.png  \n",
            "  inflating: hateful_memes/img/92514.png  \n",
            "  inflating: hateful_memes/img/59264.png  \n",
            "  inflating: hateful_memes/img/87290.png  \n",
            "  inflating: hateful_memes/img/30546.png  \n",
            "  inflating: hateful_memes/img/81679.png  \n",
            "  inflating: hateful_memes/img/35781.png  \n",
            "  inflating: hateful_memes/img/26439.png  \n",
            "  inflating: hateful_memes/img/49150.png  \n",
            "  inflating: hateful_memes/img/36470.png  \n",
            "  inflating: hateful_memes/img/14672.png  \n",
            "  inflating: hateful_memes/img/69528.png  \n",
            "  inflating: hateful_memes/img/35684.png  \n",
            "  inflating: hateful_memes/img/63075.png  \n",
            "  inflating: hateful_memes/img/23570.png  \n",
            "  inflating: hateful_memes/img/14238.png  \n",
            "  inflating: hateful_memes/img/73962.png  \n",
            "  inflating: hateful_memes/img/82674.png  \n",
            "  inflating: hateful_memes/img/25719.png  \n",
            "  inflating: hateful_memes/img/95764.png  \n",
            "  inflating: hateful_memes/img/70395.png  \n",
            "  inflating: hateful_memes/img/03612.png  \n",
            "  inflating: hateful_memes/img/51073.png  \n",
            "  inflating: hateful_memes/img/16824.png  \n",
            "  inflating: hateful_memes/img/31059.png  \n",
            "  inflating: hateful_memes/img/70294.png  \n",
            "  inflating: hateful_memes/img/97562.png  \n",
            "  inflating: hateful_memes/img/52476.png  \n",
            "  inflating: hateful_memes/img/53820.png  \n",
            "  inflating: hateful_memes/img/23619.png  \n",
            "  inflating: hateful_memes/img/36508.png  \n",
            "  inflating: hateful_memes/img/56723.png  \n",
            "  inflating: hateful_memes/img/41728.png  \n",
            "  inflating: hateful_memes/img/35907.png  \n",
            "  inflating: hateful_memes/img/37465.png  \n",
            "  inflating: hateful_memes/img/16807.png  \n",
            "  inflating: hateful_memes/img/73601.png  \n",
            "  inflating: hateful_memes/img/92418.png  \n",
            "  inflating: hateful_memes/img/56712.png  \n",
            "  inflating: hateful_memes/img/16385.png  \n",
            "  inflating: hateful_memes/img/89436.png  \n",
            "  inflating: hateful_memes/img/76132.png  \n",
            "  inflating: hateful_memes/img/69380.png  \n",
            "  inflating: hateful_memes/img/75146.png  \n",
            "  inflating: hateful_memes/img/97621.png  \n",
            "  inflating: hateful_memes/img/05768.png  \n",
            "  inflating: hateful_memes/img/03718.png  \n",
            "  inflating: hateful_memes/img/92038.png  \n",
            "  inflating: hateful_memes/img/26914.png  \n",
            "  inflating: hateful_memes/img/69078.png  \n",
            "  inflating: hateful_memes/img/13857.png  \n",
            "  inflating: hateful_memes/img/01694.png  \n",
            "  inflating: hateful_memes/img/09765.png  \n",
            "  inflating: hateful_memes/img/06153.png  \n",
            "  inflating: hateful_memes/img/05142.png  \n",
            "  inflating: hateful_memes/img/36915.png  \n",
            "  inflating: hateful_memes/img/12957.png  \n",
            "  inflating: hateful_memes/img/72541.png  \n",
            "  inflating: hateful_memes/img/97051.png  \n",
            "  inflating: hateful_memes/img/69032.png  \n",
            "  inflating: hateful_memes/img/39851.png  \n",
            "  inflating: hateful_memes/img/20538.png  \n",
            "  inflating: hateful_memes/img/64701.png  \n",
            "  inflating: hateful_memes/img/56243.png  \n",
            "  inflating: hateful_memes/img/73562.png  \n",
            "  inflating: hateful_memes/img/57962.png  \n",
            "  inflating: hateful_memes/img/67180.png  \n",
            "  inflating: hateful_memes/img/93284.png  \n",
            "  inflating: hateful_memes/img/92680.png  \n",
            "  inflating: hateful_memes/img/23715.png  \n",
            "  inflating: hateful_memes/img/34628.png  \n",
            "  inflating: hateful_memes/img/06731.png  \n",
            "  inflating: hateful_memes/img/34910.png  \n",
            "  inflating: hateful_memes/img/53609.png  \n",
            "  inflating: hateful_memes/img/73152.png  \n",
            "  inflating: hateful_memes/img/05832.png  \n",
            "  inflating: hateful_memes/img/80154.png  \n",
            "  inflating: hateful_memes/img/36248.png  \n",
            "  inflating: hateful_memes/img/16052.png  \n",
            "  inflating: hateful_memes/img/34598.png  \n",
            "  inflating: hateful_memes/img/29635.png  \n",
            "  inflating: hateful_memes/img/45810.png  \n",
            "  inflating: hateful_memes/img/21530.png  \n",
            "  inflating: hateful_memes/img/85741.png  \n",
            "  inflating: hateful_memes/img/06825.png  \n",
            "  inflating: hateful_memes/img/47159.png  \n",
            "  inflating: hateful_memes/img/20543.png  \n",
            "  inflating: hateful_memes/img/87126.png  \n",
            "  inflating: hateful_memes/img/71624.png  \n",
            "  inflating: hateful_memes/img/49752.png  \n",
            "  inflating: hateful_memes/img/51862.png  \n",
            "  inflating: hateful_memes/img/94608.png  \n",
            "  inflating: hateful_memes/img/39085.png  \n",
            "  inflating: hateful_memes/img/25830.png  \n",
            "  inflating: hateful_memes/img/46879.png  \n",
            "  inflating: hateful_memes/img/75320.png  \n",
            "  inflating: hateful_memes/img/47506.png  \n",
            "  inflating: hateful_memes/img/16370.png  \n",
            "  inflating: hateful_memes/img/83547.png  \n",
            "  inflating: hateful_memes/img/62974.png  \n",
            "  inflating: hateful_memes/img/07965.png  \n",
            "  inflating: hateful_memes/img/46870.png  \n",
            "  inflating: hateful_memes/img/74810.png  \n",
            "  inflating: hateful_memes/img/23690.png  \n",
            "  inflating: hateful_memes/img/78913.png  \n",
            "  inflating: hateful_memes/img/30185.png  \n",
            "  inflating: hateful_memes/img/49630.png  \n",
            "  inflating: hateful_memes/img/76298.png  \n",
            "  inflating: hateful_memes/img/87620.png  \n",
            "  inflating: hateful_memes/img/50674.png  \n",
            "  inflating: hateful_memes/img/74508.png  \n",
            "  inflating: hateful_memes/img/57348.png  \n",
            "  inflating: hateful_memes/img/76214.png  \n",
            "  inflating: hateful_memes/img/16579.png  \n",
            "  inflating: hateful_memes/img/72984.png  \n",
            "  inflating: hateful_memes/img/15632.png  \n",
            "  inflating: hateful_memes/img/81720.png  \n",
            "  inflating: hateful_memes/img/87219.png  \n",
            "  inflating: hateful_memes/img/32897.png  \n",
            "  inflating: hateful_memes/img/38129.png  \n",
            "  inflating: hateful_memes/img/84017.png  \n",
            "  inflating: hateful_memes/img/13528.png  \n",
            "  inflating: hateful_memes/img/94650.png  \n",
            "  inflating: hateful_memes/img/98374.png  \n",
            "  inflating: hateful_memes/img/89613.png  \n",
            "  inflating: hateful_memes/img/63250.png  \n",
            "  inflating: hateful_memes/img/69327.png  \n",
            "  inflating: hateful_memes/img/78239.png  \n",
            "  inflating: hateful_memes/img/05917.png  \n",
            "  inflating: hateful_memes/img/03984.png  \n",
            "  inflating: hateful_memes/img/35861.png  \n",
            "  inflating: hateful_memes/img/20984.png  \n",
            "  inflating: hateful_memes/img/13457.png  \n",
            "  inflating: hateful_memes/img/89063.png  \n",
            "  inflating: hateful_memes/img/67543.png  \n",
            "  inflating: hateful_memes/img/92741.png  \n",
            "  inflating: hateful_memes/img/39624.png  \n",
            "  inflating: hateful_memes/img/86504.png  \n",
            "  inflating: hateful_memes/img/24135.png  \n",
            "  inflating: hateful_memes/img/15927.png  \n",
            "  inflating: hateful_memes/img/97128.png  \n",
            "  inflating: hateful_memes/img/06842.png  \n",
            "  inflating: hateful_memes/img/05872.png  \n",
            "  inflating: hateful_memes/img/17845.png  \n",
            "  inflating: hateful_memes/img/46920.png  \n",
            "  inflating: hateful_memes/img/23504.png  \n",
            "  inflating: hateful_memes/img/92640.png  \n",
            "  inflating: hateful_memes/img/19730.png  \n",
            "  inflating: hateful_memes/img/98345.png  \n",
            "  inflating: hateful_memes/img/12650.png  \n",
            "  inflating: hateful_memes/img/68742.png  \n",
            "  inflating: hateful_memes/img/07134.png  \n",
            "  inflating: hateful_memes/img/96517.png  \n",
            "  inflating: hateful_memes/img/89512.png  \n",
            "  inflating: hateful_memes/img/31709.png  \n",
            "  inflating: hateful_memes/img/19386.png  \n",
            "  inflating: hateful_memes/img/62351.png  \n",
            "  inflating: hateful_memes/img/84032.png  \n",
            "  inflating: hateful_memes/img/29503.png  \n",
            "  inflating: hateful_memes/img/71035.png  \n",
            "  inflating: hateful_memes/img/47015.png  \n",
            "  inflating: hateful_memes/img/19634.png  \n",
            "  inflating: hateful_memes/img/10853.png  \n",
            "  inflating: hateful_memes/img/23794.png  \n",
            "  inflating: hateful_memes/img/86250.png  \n",
            "  inflating: hateful_memes/img/36592.png  \n",
            "  inflating: hateful_memes/img/08794.png  \n",
            "  inflating: hateful_memes/img/36521.png  \n",
            "  inflating: hateful_memes/img/80251.png  \n",
            "  inflating: hateful_memes/img/02158.png  \n",
            "  inflating: hateful_memes/img/08917.png  \n",
            "  inflating: hateful_memes/img/26930.png  \n",
            "  inflating: hateful_memes/img/37296.png  \n",
            "  inflating: hateful_memes/img/70132.png  \n",
            "  inflating: hateful_memes/img/19873.png  \n",
            "  inflating: hateful_memes/img/32695.png  \n",
            "  inflating: hateful_memes/img/16439.png  \n",
            "  inflating: hateful_memes/img/53187.png  \n",
            "  inflating: hateful_memes/img/04175.png  \n",
            "  inflating: hateful_memes/img/03524.png  \n",
            "  inflating: hateful_memes/img/65124.png  \n",
            "  inflating: hateful_memes/img/21354.png  \n",
            "  inflating: hateful_memes/img/90847.png  \n",
            "  inflating: hateful_memes/img/23154.png  \n",
            "  inflating: hateful_memes/img/14523.png  \n",
            "  inflating: hateful_memes/img/17453.png  \n",
            "  inflating: hateful_memes/img/90875.png  \n",
            "  inflating: hateful_memes/img/31645.png  \n",
            "  inflating: hateful_memes/img/92160.png  \n",
            "  inflating: hateful_memes/img/42810.png  \n",
            "  inflating: hateful_memes/img/10254.png  \n",
            "  inflating: hateful_memes/img/70492.png  \n",
            "  inflating: hateful_memes/img/10723.png  \n",
            "  inflating: hateful_memes/img/80947.png  \n",
            "  inflating: hateful_memes/img/65832.png  \n",
            "  inflating: hateful_memes/img/70341.png  \n",
            "  inflating: hateful_memes/img/49716.png  \n",
            "  inflating: hateful_memes/img/60972.png  \n",
            "  inflating: hateful_memes/img/89042.png  \n",
            "  inflating: hateful_memes/img/02169.png  \n",
            "  inflating: hateful_memes/img/76321.png  \n",
            "  inflating: hateful_memes/img/94185.png  \n",
            "  inflating: hateful_memes/img/39076.png  \n",
            "  inflating: hateful_memes/img/75192.png  \n",
            "  inflating: hateful_memes/img/34795.png  \n",
            "  inflating: hateful_memes/img/30928.png  \n",
            "  inflating: hateful_memes/img/81245.png  \n",
            "  inflating: hateful_memes/img/08172.png  \n",
            "  inflating: hateful_memes/img/31824.png  \n",
            "  inflating: hateful_memes/img/23164.png  \n",
            "  inflating: hateful_memes/img/15394.png  \n",
            "  inflating: hateful_memes/img/62514.png  \n",
            "  inflating: hateful_memes/img/07259.png  \n",
            "  inflating: hateful_memes/img/67852.png  \n",
            "  inflating: hateful_memes/img/20835.png  \n",
            "  inflating: hateful_memes/img/70435.png  \n",
            "  inflating: hateful_memes/img/81625.png  \n",
            "  inflating: hateful_memes/img/75682.png  \n",
            "  inflating: hateful_memes/img/19523.png  \n",
            "  inflating: hateful_memes/img/85421.png  \n",
            "  inflating: hateful_memes/img/16048.png  \n",
            "  inflating: hateful_memes/img/46813.png  \n",
            "  inflating: hateful_memes/img/48617.png  \n",
            "  inflating: hateful_memes/img/54236.png  \n",
            "  inflating: hateful_memes/img/47931.png  \n",
            "  inflating: hateful_memes/img/90827.png  \n",
            "  inflating: hateful_memes/img/96583.png  \n",
            "  inflating: hateful_memes/img/61537.png  \n",
            "  inflating: hateful_memes/img/40239.png  \n",
            "  inflating: hateful_memes/img/78459.png  \n",
            "  inflating: hateful_memes/img/10938.png  \n",
            "  inflating: hateful_memes/img/21650.png  \n",
            "  inflating: hateful_memes/img/82940.png  \n",
            "  inflating: hateful_memes/img/54310.png  \n",
            "  inflating: hateful_memes/img/72146.png  \n",
            "  inflating: hateful_memes/img/32941.png  \n",
            "  inflating: hateful_memes/img/84317.png  \n",
            "  inflating: hateful_memes/img/29348.png  \n",
            "  inflating: hateful_memes/img/72610.png  \n",
            "  inflating: hateful_memes/img/64385.png  \n",
            "  inflating: hateful_memes/img/24651.png  \n",
            "  inflating: hateful_memes/img/13042.png  \n",
            "  inflating: hateful_memes/img/02879.png  \n",
            "  inflating: hateful_memes/img/74096.png  \n",
            "  inflating: hateful_memes/img/72193.png  \n",
            "  inflating: hateful_memes/img/42093.png  \n",
            "  inflating: hateful_memes/img/91648.png  \n",
            "  inflating: hateful_memes/img/58367.png  \n",
            "  inflating: hateful_memes/img/57849.png  \n",
            "  inflating: hateful_memes/img/54962.png  \n",
            "  inflating: hateful_memes/img/58310.png  \n",
            "  inflating: hateful_memes/img/65034.png  \n",
            "  inflating: hateful_memes/img/97506.png  \n",
            "  inflating: hateful_memes/img/97238.png  \n",
            "  inflating: hateful_memes/img/75602.png  \n",
            "  inflating: hateful_memes/img/75392.png  \n",
            "  inflating: hateful_memes/img/04728.png  \n",
            "  inflating: hateful_memes/img/95278.png  \n",
            "  inflating: hateful_memes/img/85642.png  \n",
            "  inflating: hateful_memes/img/60123.png  \n",
            "  inflating: hateful_memes/img/06148.png  \n",
            "  inflating: hateful_memes/img/20936.png  \n",
            "  inflating: hateful_memes/img/19845.png  \n",
            "  inflating: hateful_memes/img/38251.png  \n",
            "  inflating: hateful_memes/img/64539.png  \n",
            "  inflating: hateful_memes/img/76842.png  \n",
            "  inflating: hateful_memes/img/13570.png  \n",
            "  inflating: hateful_memes/img/39427.png  \n",
            "  inflating: hateful_memes/img/12750.png  \n",
            "  inflating: hateful_memes/img/95184.png  \n",
            "  inflating: hateful_memes/img/17495.png  \n",
            "  inflating: hateful_memes/img/41597.png  \n",
            "  inflating: hateful_memes/img/20615.png  \n",
            "  inflating: hateful_memes/img/38046.png  \n",
            "  inflating: hateful_memes/img/23056.png  \n",
            "  inflating: hateful_memes/img/94870.png  \n",
            "  inflating: hateful_memes/img/30246.png  \n",
            "  inflating: hateful_memes/img/57034.png  \n",
            "  inflating: hateful_memes/img/13576.png  \n",
            "  inflating: hateful_memes/img/54801.png  \n",
            "  inflating: hateful_memes/img/89324.png  \n",
            "  inflating: hateful_memes/img/20691.png  \n",
            "  inflating: hateful_memes/img/42897.png  \n",
            "  inflating: hateful_memes/img/69548.png  \n",
            "  inflating: hateful_memes/img/58901.png  \n",
            "  inflating: hateful_memes/img/13650.png  \n",
            "  inflating: hateful_memes/img/91367.png  \n",
            "  inflating: hateful_memes/img/40621.png  \n",
            "  inflating: hateful_memes/img/75160.png  \n",
            "  inflating: hateful_memes/img/02768.png  \n",
            "  inflating: hateful_memes/img/89435.png  \n",
            "  inflating: hateful_memes/img/39612.png  \n",
            "  inflating: hateful_memes/img/83476.png  \n",
            "  inflating: hateful_memes/img/16059.png  \n",
            "  inflating: hateful_memes/img/32698.png  \n",
            "  inflating: hateful_memes/img/10582.png  \n",
            "  inflating: hateful_memes/img/80759.png  \n",
            "  inflating: hateful_memes/img/89741.png  \n",
            "  inflating: hateful_memes/img/38210.png  \n",
            "  inflating: hateful_memes/img/12793.png  \n",
            "  inflating: hateful_memes/img/64215.png  \n",
            "  inflating: hateful_memes/img/63509.png  \n",
            "  inflating: hateful_memes/img/17894.png  \n",
            "  inflating: hateful_memes/img/89532.png  \n",
            "  inflating: hateful_memes/img/63908.png  \n",
            "  inflating: hateful_memes/img/47609.png  \n",
            "  inflating: hateful_memes/img/32791.png  \n",
            "  inflating: hateful_memes/img/75380.png  \n",
            "  inflating: hateful_memes/img/19065.png  \n",
            "  inflating: hateful_memes/img/16280.png  \n",
            "  inflating: hateful_memes/img/36718.png  \n",
            "  inflating: hateful_memes/img/06439.png  \n",
            "  inflating: hateful_memes/img/07652.png  \n",
            "  inflating: hateful_memes/img/04918.png  \n",
            "  inflating: hateful_memes/img/59860.png  \n",
            "  inflating: hateful_memes/img/81439.png  \n",
            "  inflating: hateful_memes/img/83756.png  \n",
            "  inflating: hateful_memes/img/69017.png  \n",
            "  inflating: hateful_memes/img/52386.png  \n",
            "  inflating: hateful_memes/img/36821.png  \n",
            "  inflating: hateful_memes/img/53691.png  \n",
            "  inflating: hateful_memes/img/63784.png  \n",
            "  inflating: hateful_memes/img/86920.png  \n",
            "  inflating: hateful_memes/img/32640.png  \n",
            "  inflating: hateful_memes/img/95062.png  \n",
            "  inflating: hateful_memes/img/79325.png  \n",
            "  inflating: hateful_memes/img/92317.png  \n",
            "  inflating: hateful_memes/img/60427.png  \n",
            "  inflating: hateful_memes/img/50743.png  \n",
            "  inflating: hateful_memes/img/46537.png  \n",
            "  inflating: hateful_memes/img/83527.png  \n",
            "  inflating: hateful_memes/img/05728.png  \n",
            "  inflating: hateful_memes/img/05471.png  \n",
            "  inflating: hateful_memes/img/64051.png  \n",
            "  inflating: hateful_memes/img/24783.png  \n",
            "  inflating: hateful_memes/img/60193.png  \n",
            "  inflating: hateful_memes/img/41607.png  \n",
            "  inflating: hateful_memes/img/37601.png  \n",
            "  inflating: hateful_memes/img/02691.png  \n",
            "  inflating: hateful_memes/img/58260.png  \n",
            "  inflating: hateful_memes/img/67250.png  \n",
            "  inflating: hateful_memes/img/29354.png  \n",
            "  inflating: hateful_memes/img/31657.png  \n",
            "  inflating: hateful_memes/img/76548.png  \n",
            "  inflating: hateful_memes/img/98523.png  \n",
            "  inflating: hateful_memes/img/82760.png  \n",
            "  inflating: hateful_memes/img/03591.png  \n",
            "  inflating: hateful_memes/img/65809.png  \n",
            "  inflating: hateful_memes/img/35967.png  \n",
            "  inflating: hateful_memes/img/90175.png  \n",
            "  inflating: hateful_memes/img/35840.png  \n",
            "  inflating: hateful_memes/img/32647.png  \n",
            "  inflating: hateful_memes/img/41605.png  \n",
            "  inflating: hateful_memes/img/70564.png  \n",
            "  inflating: hateful_memes/img/42953.png  \n",
            "  inflating: hateful_memes/img/30154.png  \n",
            "  inflating: hateful_memes/img/41768.png  \n",
            "  inflating: hateful_memes/img/07315.png  \n",
            "  inflating: hateful_memes/img/68204.png  \n",
            "  inflating: hateful_memes/img/70189.png  \n",
            "  inflating: hateful_memes/img/41057.png  \n",
            "  inflating: hateful_memes/img/31485.png  \n",
            "  inflating: hateful_memes/img/53418.png  \n",
            "  inflating: hateful_memes/img/87320.png  \n",
            "  inflating: hateful_memes/img/45231.png  \n",
            "  inflating: hateful_memes/img/64137.png  \n",
            "  inflating: hateful_memes/img/64283.png  \n",
            "  inflating: hateful_memes/img/86173.png  \n",
            "  inflating: hateful_memes/img/82964.png  \n",
            "  inflating: hateful_memes/img/74361.png  \n",
            "  inflating: hateful_memes/img/48196.png  \n",
            "  inflating: hateful_memes/img/96340.png  \n",
            "  inflating: hateful_memes/img/43271.png  \n",
            "  inflating: hateful_memes/img/94576.png  \n",
            "  inflating: hateful_memes/img/16758.png  \n",
            "  inflating: hateful_memes/img/09316.png  \n",
            "  inflating: hateful_memes/img/42786.png  \n",
            "  inflating: hateful_memes/img/69127.png  \n",
            "  inflating: hateful_memes/img/35490.png  \n",
            "  inflating: hateful_memes/img/75138.png  \n",
            "  inflating: hateful_memes/img/75810.png  \n",
            "  inflating: hateful_memes/img/14276.png  \n",
            "  inflating: hateful_memes/img/97583.png  \n",
            "  inflating: hateful_memes/img/27986.png  \n",
            "  inflating: hateful_memes/img/47309.png  \n",
            "  inflating: hateful_memes/img/74016.png  \n",
            "  inflating: hateful_memes/img/97143.png  \n",
            "  inflating: hateful_memes/img/25097.png  \n",
            "  inflating: hateful_memes/img/23047.png  \n",
            "  inflating: hateful_memes/img/84970.png  \n",
            "  inflating: hateful_memes/img/02149.png  \n",
            "  inflating: hateful_memes/img/91527.png  \n",
            "  inflating: hateful_memes/img/69845.png  \n",
            "  inflating: hateful_memes/img/05928.png  \n",
            "  inflating: hateful_memes/img/34291.png  \n",
            "  inflating: hateful_memes/img/56942.png  \n",
            "  inflating: hateful_memes/img/42153.png  \n",
            "  inflating: hateful_memes/img/76953.png  \n",
            "  inflating: hateful_memes/img/80629.png  \n",
            "  inflating: hateful_memes/img/97520.png  \n",
            "  inflating: hateful_memes/img/90826.png  \n",
            "  inflating: hateful_memes/img/97836.png  \n",
            "  inflating: hateful_memes/img/70231.png  \n",
            "  inflating: hateful_memes/img/76539.png  \n",
            "  inflating: hateful_memes/img/62483.png  \n",
            "  inflating: hateful_memes/img/32701.png  \n",
            "  inflating: hateful_memes/img/96382.png  \n",
            "  inflating: hateful_memes/img/02317.png  \n",
            "  inflating: hateful_memes/img/92483.png  \n",
            "  inflating: hateful_memes/img/87169.png  \n",
            "  inflating: hateful_memes/img/46231.png  \n",
            "  inflating: hateful_memes/img/32416.png  \n",
            "  inflating: hateful_memes/img/40862.png  \n",
            "  inflating: hateful_memes/img/68549.png  \n",
            "  inflating: hateful_memes/img/71042.png  \n",
            "  inflating: hateful_memes/img/83207.png  \n",
            "  inflating: hateful_memes/img/19306.png  \n",
            "  inflating: hateful_memes/img/19653.png  \n",
            "  inflating: hateful_memes/img/08941.png  \n",
            "  inflating: hateful_memes/img/16538.png  \n",
            "  inflating: hateful_memes/img/30915.png  \n",
            "  inflating: hateful_memes/img/48315.png  \n",
            "  inflating: hateful_memes/img/06329.png  \n",
            "  inflating: hateful_memes/img/23519.png  \n",
            "  inflating: hateful_memes/img/84516.png  \n",
            "  inflating: hateful_memes/img/80512.png  \n",
            "  inflating: hateful_memes/img/75216.png  \n",
            "  inflating: hateful_memes/img/78231.png  \n",
            "  inflating: hateful_memes/img/27845.png  \n",
            "  inflating: hateful_memes/img/14263.png  \n",
            "  inflating: hateful_memes/img/50638.png  \n",
            "  inflating: hateful_memes/img/48329.png  \n",
            "  inflating: hateful_memes/img/72864.png  \n",
            "  inflating: hateful_memes/img/64279.png  \n",
            "  inflating: hateful_memes/img/53607.png  \n",
            "  inflating: hateful_memes/img/53089.png  \n",
            "  inflating: hateful_memes/img/69427.png  \n",
            "  inflating: hateful_memes/img/01823.png  \n",
            "  inflating: hateful_memes/img/83257.png  \n",
            "  inflating: hateful_memes/img/57986.png  \n",
            "  inflating: hateful_memes/img/34591.png  \n",
            "  inflating: hateful_memes/img/23197.png  \n",
            "  inflating: hateful_memes/img/52804.png  \n",
            "  inflating: hateful_memes/img/75960.png  \n",
            "  inflating: hateful_memes/img/54137.png  \n",
            "  inflating: hateful_memes/img/91487.png  \n",
            "  inflating: hateful_memes/img/42986.png  \n",
            "  inflating: hateful_memes/img/36982.png  \n",
            "  inflating: hateful_memes/img/61549.png  \n",
            "  inflating: hateful_memes/img/71260.png  \n",
            "  inflating: hateful_memes/img/07392.png  \n",
            "  inflating: hateful_memes/img/70315.png  \n",
            "  inflating: hateful_memes/img/72914.png  \n",
            "  inflating: hateful_memes/img/42853.png  \n",
            "  inflating: hateful_memes/img/61385.png  \n",
            "  inflating: hateful_memes/img/96204.png  \n",
            "  inflating: hateful_memes/img/32691.png  \n",
            "  inflating: hateful_memes/img/04719.png  \n",
            "  inflating: hateful_memes/img/56497.png  \n",
            "  inflating: hateful_memes/img/58476.png  \n",
            "  inflating: hateful_memes/img/45320.png  \n",
            "  inflating: hateful_memes/img/50491.png  \n",
            "  inflating: hateful_memes/img/48205.png  \n",
            "  inflating: hateful_memes/img/98437.png  \n",
            "  inflating: hateful_memes/img/13567.png  \n",
            "  inflating: hateful_memes/img/42813.png  \n",
            "  inflating: hateful_memes/img/43920.png  \n",
            "  inflating: hateful_memes/img/51278.png  \n",
            "  inflating: hateful_memes/img/47605.png  \n",
            "  inflating: hateful_memes/img/04265.png  \n",
            "  inflating: hateful_memes/img/42987.png  \n",
            "  inflating: hateful_memes/img/25780.png  \n",
            "  inflating: hateful_memes/img/14769.png  \n",
            "  inflating: hateful_memes/img/15746.png  \n",
            "  inflating: hateful_memes/img/82701.png  \n",
            "  inflating: hateful_memes/img/71032.png  \n",
            "  inflating: hateful_memes/img/04879.png  \n",
            "  inflating: hateful_memes/img/51802.png  \n",
            "  inflating: hateful_memes/img/79103.png  \n",
            "  inflating: hateful_memes/img/94138.png  \n",
            "  inflating: hateful_memes/img/04971.png  \n",
            "  inflating: hateful_memes/img/56302.png  \n",
            "  inflating: hateful_memes/img/14059.png  \n",
            "  inflating: hateful_memes/img/60913.png  \n",
            "  inflating: hateful_memes/img/20791.png  \n",
            "  inflating: hateful_memes/img/09263.png  \n",
            "  inflating: hateful_memes/img/15324.png  \n",
            "  inflating: hateful_memes/img/07893.png  \n",
            "  inflating: hateful_memes/img/14968.png  \n",
            "  inflating: hateful_memes/img/69087.png  \n",
            "  inflating: hateful_memes/img/86751.png  \n",
            "  inflating: hateful_memes/img/70592.png  \n",
            "  inflating: hateful_memes/img/98637.png  \n",
            "  inflating: hateful_memes/img/93084.png  \n",
            "  inflating: hateful_memes/img/67413.png  \n",
            "  inflating: hateful_memes/img/07693.png  \n",
            "  inflating: hateful_memes/img/37592.png  \n",
            "  inflating: hateful_memes/img/47593.png  \n",
            "  inflating: hateful_memes/img/18257.png  \n",
            "  inflating: hateful_memes/img/96174.png  \n",
            "  inflating: hateful_memes/img/37198.png  \n",
            "  inflating: hateful_memes/img/80941.png  \n",
            "  inflating: hateful_memes/img/05769.png  \n",
            "  inflating: hateful_memes/img/51849.png  \n",
            "  inflating: hateful_memes/img/20634.png  \n",
            "  inflating: hateful_memes/img/04362.png  \n",
            "  inflating: hateful_memes/img/18679.png  \n",
            "  inflating: hateful_memes/img/42015.png  \n",
            "  inflating: hateful_memes/img/56273.png  \n",
            "  inflating: hateful_memes/img/09572.png  \n",
            "  inflating: hateful_memes/img/60527.png  \n",
            "  inflating: hateful_memes/img/05273.png  \n",
            "  inflating: hateful_memes/img/08451.png  \n",
            "  inflating: hateful_memes/img/92308.png  \n",
            "  inflating: hateful_memes/img/31042.png  \n",
            "  inflating: hateful_memes/img/06584.png  \n",
            "  inflating: hateful_memes/img/48635.png  \n",
            "  inflating: hateful_memes/img/79032.png  \n",
            "  inflating: hateful_memes/img/20786.png  \n",
            "  inflating: hateful_memes/img/51368.png  \n",
            "  inflating: hateful_memes/img/94356.png  \n",
            "  inflating: hateful_memes/img/57914.png  \n",
            "  inflating: hateful_memes/img/89632.png  \n",
            "  inflating: hateful_memes/img/34658.png  \n",
            "  inflating: hateful_memes/img/62135.png  \n",
            "  inflating: hateful_memes/img/27805.png  \n",
            "  inflating: hateful_memes/img/79406.png  \n",
            "  inflating: hateful_memes/img/64327.png  \n",
            "  inflating: hateful_memes/img/25904.png  \n",
            "  inflating: hateful_memes/img/45831.png  \n",
            "  inflating: hateful_memes/img/86394.png  \n",
            "  inflating: hateful_memes/img/98271.png  \n",
            "  inflating: hateful_memes/img/68179.png  \n",
            "  inflating: hateful_memes/img/43175.png  \n",
            "  inflating: hateful_memes/img/76253.png  \n",
            "  inflating: hateful_memes/img/28461.png  \n",
            "  inflating: hateful_memes/img/03876.png  \n",
            "  inflating: hateful_memes/img/26378.png  \n",
            "  inflating: hateful_memes/img/46831.png  \n",
            "  inflating: hateful_memes/img/09247.png  \n",
            "  inflating: hateful_memes/img/37420.png  \n",
            "  inflating: hateful_memes/img/17268.png  \n",
            "  inflating: hateful_memes/img/08241.png  \n",
            "  inflating: hateful_memes/img/53941.png  \n",
            "  inflating: hateful_memes/img/25971.png  \n",
            "  inflating: hateful_memes/img/34067.png  \n",
            "  inflating: hateful_memes/img/42860.png  \n",
            "  inflating: hateful_memes/img/98543.png  \n",
            "  inflating: hateful_memes/img/07241.png  \n",
            "  inflating: hateful_memes/img/95086.png  \n",
            "  inflating: hateful_memes/img/39164.png  \n",
            "  inflating: hateful_memes/img/76342.png  \n",
            "  inflating: hateful_memes/img/03928.png  \n",
            "  inflating: hateful_memes/img/92157.png  \n",
            "  inflating: hateful_memes/img/16289.png  \n",
            "  inflating: hateful_memes/img/25368.png  \n",
            "  inflating: hateful_memes/img/74198.png  \n",
            "  inflating: hateful_memes/img/03957.png  \n",
            "  inflating: hateful_memes/img/59623.png  \n",
            "  inflating: hateful_memes/img/57462.png  \n",
            "  inflating: hateful_memes/img/80162.png  \n",
            "  inflating: hateful_memes/img/45379.png  \n",
            "  inflating: hateful_memes/img/84536.png  \n",
            "  inflating: hateful_memes/img/84052.png  \n",
            "  inflating: hateful_memes/img/52068.png  \n",
            "  inflating: hateful_memes/img/63057.png  \n",
            "  inflating: hateful_memes/img/32189.png  \n",
            "  inflating: hateful_memes/img/75362.png  \n",
            "  inflating: hateful_memes/img/86934.png  \n",
            "  inflating: hateful_memes/img/02943.png  \n",
            "  inflating: hateful_memes/img/80916.png  \n",
            "  inflating: hateful_memes/img/40231.png  \n",
            "  inflating: hateful_memes/img/89245.png  \n",
            "  inflating: hateful_memes/img/86179.png  \n",
            "  inflating: hateful_memes/img/34510.png  \n",
            "  inflating: hateful_memes/img/98517.png  \n",
            "  inflating: hateful_memes/img/65740.png  \n",
            "  inflating: hateful_memes/img/65429.png  \n",
            "  inflating: hateful_memes/img/39871.png  \n",
            "  inflating: hateful_memes/img/51682.png  \n",
            "  inflating: hateful_memes/img/02634.png  \n",
            "  inflating: hateful_memes/img/91375.png  \n",
            "  inflating: hateful_memes/img/04897.png  \n",
            "  inflating: hateful_memes/img/14520.png  \n",
            "  inflating: hateful_memes/img/89106.png  \n",
            "  inflating: hateful_memes/img/34065.png  \n",
            "  inflating: hateful_memes/img/61730.png  \n",
            "  inflating: hateful_memes/img/27059.png  \n",
            "  inflating: hateful_memes/img/45708.png  \n",
            "  inflating: hateful_memes/img/69018.png  \n",
            "  inflating: hateful_memes/img/90345.png  \n",
            "  inflating: hateful_memes/img/50341.png  \n",
            "  inflating: hateful_memes/img/13792.png  \n",
            "  inflating: hateful_memes/img/32704.png  \n",
            "  inflating: hateful_memes/img/41538.png  \n",
            "  inflating: hateful_memes/img/91847.png  \n",
            "  inflating: hateful_memes/img/72839.png  \n",
            "  inflating: hateful_memes/img/07649.png  \n",
            "  inflating: hateful_memes/img/87904.png  \n",
            "  inflating: hateful_memes/img/87326.png  \n",
            "  inflating: hateful_memes/img/03125.png  \n",
            "  inflating: hateful_memes/img/71249.png  \n",
            "  inflating: hateful_memes/img/38156.png  \n",
            "  inflating: hateful_memes/img/52316.png  \n",
            "  inflating: hateful_memes/img/83152.png  \n",
            "  inflating: hateful_memes/img/41263.png  \n",
            "  inflating: hateful_memes/img/38072.png  \n",
            "  inflating: hateful_memes/img/72408.png  \n",
            "  inflating: hateful_memes/img/06237.png  \n",
            "  inflating: hateful_memes/img/97512.png  \n",
            "  inflating: hateful_memes/img/64329.png  \n",
            "  inflating: hateful_memes/img/80379.png  \n",
            "  inflating: hateful_memes/img/74923.png  \n",
            "  inflating: hateful_memes/img/78190.png  \n",
            "  inflating: hateful_memes/img/63270.png  \n",
            "  inflating: hateful_memes/img/70845.png  \n",
            "  inflating: hateful_memes/img/09187.png  \n",
            "  inflating: hateful_memes/img/14362.png  \n",
            "  inflating: hateful_memes/img/02156.png  \n",
            "  inflating: hateful_memes/img/75421.png  \n",
            "  inflating: hateful_memes/img/30196.png  \n",
            "  inflating: hateful_memes/img/21704.png  \n",
            "  inflating: hateful_memes/img/10396.png  \n",
            "  inflating: hateful_memes/img/53872.png  \n",
            "  inflating: hateful_memes/img/79368.png  \n",
            "  inflating: hateful_memes/img/46178.png  \n",
            "  inflating: hateful_memes/img/46127.png  \n",
            "  inflating: hateful_memes/img/56738.png  \n",
            "  inflating: hateful_memes/img/83427.png  \n",
            "  inflating: hateful_memes/img/69042.png  \n",
            "  inflating: hateful_memes/img/39281.png  \n",
            "  inflating: hateful_memes/img/60841.png  \n",
            "  inflating: hateful_memes/img/08741.png  \n",
            "  inflating: hateful_memes/img/97860.png  \n",
            "  inflating: hateful_memes/img/91423.png  \n",
            "  inflating: hateful_memes/img/38912.png  \n",
            "  inflating: hateful_memes/img/63920.png  \n",
            "  inflating: hateful_memes/img/50489.png  \n",
            "  inflating: hateful_memes/img/86572.png  \n",
            "  inflating: hateful_memes/img/75482.png  \n",
            "  inflating: hateful_memes/img/13624.png  \n",
            "  inflating: hateful_memes/img/10398.png  \n",
            "  inflating: hateful_memes/img/04569.png  \n",
            "  inflating: hateful_memes/img/74513.png  \n",
            "  inflating: hateful_memes/img/81497.png  \n",
            "  inflating: hateful_memes/img/80537.png  \n",
            "  inflating: hateful_memes/img/49673.png  \n",
            "  inflating: hateful_memes/img/03751.png  \n",
            "  inflating: hateful_memes/img/71983.png  \n",
            "  inflating: hateful_memes/img/72451.png  \n",
            "  inflating: hateful_memes/img/34079.png  \n",
            "  inflating: hateful_memes/img/37429.png  \n",
            "  inflating: hateful_memes/img/48536.png  \n",
            "  inflating: hateful_memes/img/43612.png  \n",
            "  inflating: hateful_memes/img/84927.png  \n",
            "  inflating: hateful_memes/img/89432.png  \n",
            "  inflating: hateful_memes/img/49028.png  \n",
            "  inflating: hateful_memes/img/93786.png  \n",
            "  inflating: hateful_memes/img/45630.png  \n",
            "  inflating: hateful_memes/img/72390.png  \n",
            "  inflating: hateful_memes/img/70356.png  \n",
            "  inflating: hateful_memes/img/42571.png  \n",
            "  inflating: hateful_memes/img/93086.png  \n",
            "  inflating: hateful_memes/img/63124.png  \n",
            "  inflating: hateful_memes/img/92534.png  \n",
            "  inflating: hateful_memes/img/78405.png  \n",
            "  inflating: hateful_memes/img/41308.png  \n",
            "  inflating: hateful_memes/img/19682.png  \n",
            "  inflating: hateful_memes/img/68304.png  \n",
            "  inflating: hateful_memes/img/20957.png  \n",
            "  inflating: hateful_memes/img/95683.png  \n",
            "  inflating: hateful_memes/img/18940.png  \n",
            "  inflating: hateful_memes/img/26185.png  \n",
            "  inflating: hateful_memes/img/71506.png  \n",
            "  inflating: hateful_memes/img/34785.png  \n",
            "  inflating: hateful_memes/img/98751.png  \n",
            "  inflating: hateful_memes/img/60937.png  \n",
            "  inflating: hateful_memes/img/03256.png  \n",
            "  inflating: hateful_memes/img/13620.png  \n",
            "  inflating: hateful_memes/img/13748.png  \n",
            "  inflating: hateful_memes/img/84971.png  \n",
            "  inflating: hateful_memes/img/52031.png  \n",
            "  inflating: hateful_memes/img/54179.png  \n",
            "  inflating: hateful_memes/img/12604.png  \n",
            "  inflating: hateful_memes/img/85473.png  \n",
            "  inflating: hateful_memes/img/18593.png  \n",
            "  inflating: hateful_memes/img/86540.png  \n",
            "  inflating: hateful_memes/img/35724.png  \n",
            "  inflating: hateful_memes/img/65708.png  \n",
            "  inflating: hateful_memes/img/78915.png  \n",
            "  inflating: hateful_memes/img/63017.png  \n",
            "  inflating: hateful_memes/img/65432.png  \n",
            "  inflating: hateful_memes/img/29481.png  \n",
            "  inflating: hateful_memes/img/97213.png  \n",
            "  inflating: hateful_memes/img/29574.png  \n",
            "  inflating: hateful_memes/img/10926.png  \n",
            "  inflating: hateful_memes/img/75142.png  \n",
            "  inflating: hateful_memes/img/60238.png  \n",
            "  inflating: hateful_memes/img/38019.png  \n",
            "  inflating: hateful_memes/img/84107.png  \n",
            "  inflating: hateful_memes/img/85413.png  \n",
            "  inflating: hateful_memes/img/69014.png  \n",
            "  inflating: hateful_memes/img/87520.png  \n",
            "  inflating: hateful_memes/img/98427.png  \n",
            "  inflating: hateful_memes/img/74310.png  \n",
            "  inflating: hateful_memes/img/87902.png  \n",
            "  inflating: hateful_memes/img/53027.png  \n",
            "  inflating: hateful_memes/img/05462.png  \n",
            "  inflating: hateful_memes/img/30264.png  \n",
            "  inflating: hateful_memes/img/83954.png  \n",
            "  inflating: hateful_memes/img/26138.png  \n",
            "  inflating: hateful_memes/img/59714.png  \n",
            "  inflating: hateful_memes/img/10329.png  \n",
            "  inflating: hateful_memes/img/94738.png  \n",
            "  inflating: hateful_memes/img/94625.png  \n",
            "  inflating: hateful_memes/img/74132.png  \n",
            "  inflating: hateful_memes/img/35916.png  \n",
            "  inflating: hateful_memes/img/10784.png  \n",
            "  inflating: hateful_memes/img/94836.png  \n",
            "  inflating: hateful_memes/img/62307.png  \n",
            "  inflating: hateful_memes/img/58321.png  \n",
            "  inflating: hateful_memes/img/72306.png  \n",
            "  inflating: hateful_memes/img/12694.png  \n",
            "  inflating: hateful_memes/img/59478.png  \n",
            "  inflating: hateful_memes/img/36981.png  \n",
            "  inflating: hateful_memes/img/01423.png  \n",
            "  inflating: hateful_memes/img/27895.png  \n",
            "  inflating: hateful_memes/img/45817.png  \n",
            "  inflating: hateful_memes/img/70948.png  \n",
            "  inflating: hateful_memes/img/32657.png  \n",
            "  inflating: hateful_memes/img/46295.png  \n",
            "  inflating: hateful_memes/img/07689.png  \n",
            "  inflating: hateful_memes/img/39478.png  \n",
            "  inflating: hateful_memes/img/12608.png  \n",
            "  inflating: hateful_memes/img/96258.png  \n",
            "  inflating: hateful_memes/img/67138.png  \n",
            "  inflating: hateful_memes/img/93528.png  \n",
            "  inflating: hateful_memes/img/85394.png  \n",
            "  inflating: hateful_memes/img/69751.png  \n",
            "  inflating: hateful_memes/img/50237.png  \n",
            "  inflating: hateful_memes/img/59301.png  \n",
            "  inflating: hateful_memes/img/16845.png  \n",
            "  inflating: hateful_memes/img/89371.png  \n",
            "  inflating: hateful_memes/img/68349.png  \n",
            "  inflating: hateful_memes/img/09413.png  \n",
            "  inflating: hateful_memes/img/05421.png  \n",
            "  inflating: hateful_memes/img/19532.png  \n",
            "  inflating: hateful_memes/img/62085.png  \n",
            "  inflating: hateful_memes/img/68923.png  \n",
            "  inflating: hateful_memes/img/35412.png  \n",
            "  inflating: hateful_memes/img/94651.png  \n",
            "  inflating: hateful_memes/img/14872.png  \n",
            "  inflating: hateful_memes/img/21083.png  \n",
            "  inflating: hateful_memes/img/17953.png  \n",
            "  inflating: hateful_memes/img/27856.png  \n",
            "  inflating: hateful_memes/img/29873.png  \n",
            "  inflating: hateful_memes/img/67983.png  \n",
            "  inflating: hateful_memes/img/74825.png  \n",
            "  inflating: hateful_memes/img/68294.png  \n",
            "  inflating: hateful_memes/img/10389.png  \n",
            "  inflating: hateful_memes/img/96104.png  \n",
            "  inflating: hateful_memes/img/87695.png  \n",
            "  inflating: hateful_memes/img/03124.png  \n",
            "  inflating: hateful_memes/img/14589.png  \n",
            "  inflating: hateful_memes/img/75801.png  \n",
            "  inflating: hateful_memes/img/42653.png  \n",
            "  inflating: hateful_memes/img/57814.png  \n",
            "  inflating: hateful_memes/img/02475.png  \n",
            "  inflating: hateful_memes/img/46730.png  \n",
            "  inflating: hateful_memes/img/70614.png  \n",
            "  inflating: hateful_memes/img/80126.png  \n",
            "  inflating: hateful_memes/img/34016.png  \n",
            "  inflating: hateful_memes/img/32485.png  \n",
            "  inflating: hateful_memes/img/31024.png  \n",
            "  inflating: hateful_memes/img/24306.png  \n",
            "  inflating: hateful_memes/img/63078.png  \n",
            "  inflating: hateful_memes/img/85216.png  \n",
            "  inflating: hateful_memes/img/73205.png  \n",
            "  inflating: hateful_memes/img/71856.png  \n",
            "  inflating: hateful_memes/img/51497.png  \n",
            "  inflating: hateful_memes/img/93405.png  \n",
            "  inflating: hateful_memes/img/82549.png  \n",
            "  inflating: hateful_memes/img/43725.png  \n",
            "  inflating: hateful_memes/img/13697.png  \n",
            "  inflating: hateful_memes/img/56491.png  \n",
            "  inflating: hateful_memes/img/21479.png  \n",
            "  inflating: hateful_memes/img/54812.png  \n",
            "  inflating: hateful_memes/img/74930.png  \n",
            "  inflating: hateful_memes/img/32794.png  \n",
            "  inflating: hateful_memes/img/74298.png  \n",
            "  inflating: hateful_memes/img/56419.png  \n",
            "  inflating: hateful_memes/img/68390.png  \n",
            "  inflating: hateful_memes/img/68745.png  \n",
            "  inflating: hateful_memes/img/23957.png  \n",
            "  inflating: hateful_memes/img/80593.png  \n",
            "  inflating: hateful_memes/img/61234.png  \n",
            "  inflating: hateful_memes/img/28973.png  \n",
            "  inflating: hateful_memes/img/97023.png  \n",
            "  inflating: hateful_memes/img/08469.png  \n",
            "  inflating: hateful_memes/img/34825.png  \n",
            "  inflating: hateful_memes/img/87064.png  \n",
            "  inflating: hateful_memes/img/01682.png  \n",
            "  inflating: hateful_memes/img/52837.png  \n",
            "  inflating: hateful_memes/img/49608.png  \n",
            "  inflating: hateful_memes/img/39704.png  \n",
            "  inflating: hateful_memes/img/16903.png  \n",
            "  inflating: hateful_memes/img/39041.png  \n",
            "  inflating: hateful_memes/img/98547.png  \n",
            "  inflating: hateful_memes/img/16302.png  \n",
            "  inflating: hateful_memes/img/83150.png  \n",
            "  inflating: hateful_memes/img/02793.png  \n",
            "  inflating: hateful_memes/img/86417.png  \n",
            "  inflating: hateful_memes/img/48069.png  \n",
            "  inflating: hateful_memes/img/57326.png  \n",
            "  inflating: hateful_memes/img/53064.png  \n",
            "  inflating: hateful_memes/img/41207.png  \n",
            "  inflating: hateful_memes/img/68374.png  \n",
            "  inflating: hateful_memes/img/51629.png  \n",
            "  inflating: hateful_memes/img/28601.png  \n",
            "  inflating: hateful_memes/img/36708.png  \n",
            "  inflating: hateful_memes/img/57426.png  \n",
            "  inflating: hateful_memes/img/39741.png  \n",
            "  inflating: hateful_memes/img/96380.png  \n",
            "  inflating: hateful_memes/img/38621.png  \n",
            "  inflating: hateful_memes/img/02763.png  \n",
            "  inflating: hateful_memes/img/14802.png  \n",
            "  inflating: hateful_memes/img/70136.png  \n",
            "  inflating: hateful_memes/img/57029.png  \n",
            "  inflating: hateful_memes/img/08943.png  \n",
            "  inflating: hateful_memes/img/62184.png  \n",
            "  inflating: hateful_memes/img/10834.png  \n",
            "  inflating: hateful_memes/img/15892.png  \n",
            "  inflating: hateful_memes/img/13908.png  \n",
            "  inflating: hateful_memes/img/92016.png  \n",
            "  inflating: hateful_memes/img/58906.png  \n",
            "  inflating: hateful_memes/img/14965.png  \n",
            "  inflating: hateful_memes/img/56107.png  \n",
            "  inflating: hateful_memes/img/59031.png  \n",
            "  inflating: hateful_memes/img/82501.png  \n",
            "  inflating: hateful_memes/img/98145.png  \n",
            "  inflating: hateful_memes/img/56327.png  \n",
            "  inflating: hateful_memes/img/81970.png  \n",
            "  inflating: hateful_memes/img/56328.png  \n",
            "  inflating: hateful_memes/img/46580.png  \n",
            "  inflating: hateful_memes/img/97635.png  \n",
            "  inflating: hateful_memes/img/19253.png  \n",
            "  inflating: hateful_memes/img/24716.png  \n",
            "  inflating: hateful_memes/img/96238.png  \n",
            "  inflating: hateful_memes/img/63129.png  \n",
            "  inflating: hateful_memes/img/93042.png  \n",
            "  inflating: hateful_memes/img/42391.png  \n",
            "  inflating: hateful_memes/img/90673.png  \n",
            "  inflating: hateful_memes/img/58916.png  \n",
            "  inflating: hateful_memes/img/63028.png  \n",
            "  inflating: hateful_memes/img/23498.png  \n",
            "  inflating: hateful_memes/img/24130.png  \n",
            "  inflating: hateful_memes/img/32798.png  \n",
            "  inflating: hateful_memes/img/30597.png  \n",
            "  inflating: hateful_memes/img/21869.png  \n",
            "  inflating: hateful_memes/img/76540.png  \n",
            "  inflating: hateful_memes/img/13572.png  \n",
            "  inflating: hateful_memes/img/91462.png  \n",
            "  inflating: hateful_memes/img/06147.png  \n",
            "  inflating: hateful_memes/img/42187.png  \n",
            "  inflating: hateful_memes/img/71439.png  \n",
            "  inflating: hateful_memes/img/08276.png  \n",
            "  inflating: hateful_memes/img/96235.png  \n",
            "  inflating: hateful_memes/img/82379.png  \n",
            "  inflating: hateful_memes/img/21048.png  \n",
            "  inflating: hateful_memes/img/18475.png  \n",
            "  inflating: hateful_memes/img/78401.png  \n",
            "  inflating: hateful_memes/img/69043.png  \n",
            "  inflating: hateful_memes/img/79681.png  \n",
            "  inflating: hateful_memes/img/78035.png  \n",
            "  inflating: hateful_memes/img/84321.png  \n",
            "  inflating: hateful_memes/img/32854.png  \n",
            "  inflating: hateful_memes/img/52304.png  \n",
            "  inflating: hateful_memes/img/53280.png  \n",
            "  inflating: hateful_memes/img/71903.png  \n",
            "  inflating: hateful_memes/img/79413.png  \n",
            "  inflating: hateful_memes/img/36174.png  \n",
            "  inflating: hateful_memes/img/97315.png  \n",
            "  inflating: hateful_memes/img/51738.png  \n",
            "  inflating: hateful_memes/img/53068.png  \n",
            "  inflating: hateful_memes/img/18942.png  \n",
            "  inflating: hateful_memes/img/25461.png  \n",
            "  inflating: hateful_memes/img/67594.png  \n",
            "  inflating: hateful_memes/img/17504.png  \n",
            "  inflating: hateful_memes/img/67538.png  \n",
            "  inflating: hateful_memes/img/70932.png  \n",
            "  inflating: hateful_memes/img/68429.png  \n",
            "  inflating: hateful_memes/img/82973.png  \n",
            "  inflating: hateful_memes/img/17536.png  \n",
            "  inflating: hateful_memes/img/62731.png  \n",
            "  inflating: hateful_memes/img/71628.png  \n",
            "  inflating: hateful_memes/img/19382.png  \n",
            "  inflating: hateful_memes/img/31987.png  \n",
            "  inflating: hateful_memes/img/03854.png  \n",
            "  inflating: hateful_memes/img/51283.png  \n",
            "  inflating: hateful_memes/img/89521.png  \n",
            "  inflating: hateful_memes/img/46078.png  \n",
            "  inflating: hateful_memes/img/67593.png  \n",
            "  inflating: hateful_memes/img/98321.png  \n",
            "  inflating: hateful_memes/img/61725.png  \n",
            "  inflating: hateful_memes/img/07839.png  \n",
            "  inflating: hateful_memes/img/89421.png  \n",
            "  inflating: hateful_memes/img/79150.png  \n",
            "  inflating: hateful_memes/img/69503.png  \n",
            "  inflating: hateful_memes/img/12967.png  \n",
            "  inflating: hateful_memes/img/45189.png  \n",
            "  inflating: hateful_memes/img/85476.png  \n",
            "  inflating: hateful_memes/img/14897.png  \n",
            "  inflating: hateful_memes/img/87234.png  \n",
            "  inflating: hateful_memes/img/47901.png  \n",
            "  inflating: hateful_memes/img/60973.png  \n",
            "  inflating: hateful_memes/img/97564.png  \n",
            "  inflating: hateful_memes/img/51768.png  \n",
            "  inflating: hateful_memes/img/04278.png  \n",
            "  inflating: hateful_memes/img/10492.png  \n",
            "  inflating: hateful_memes/img/60421.png  \n",
            "  inflating: hateful_memes/img/50126.png  \n",
            "  inflating: hateful_memes/img/05942.png  \n",
            "  inflating: hateful_memes/img/96057.png  \n",
            "  inflating: hateful_memes/img/83567.png  \n",
            "  inflating: hateful_memes/img/84270.png  \n",
            "  inflating: hateful_memes/img/69720.png  \n",
            "  inflating: hateful_memes/img/31920.png  \n",
            "  inflating: hateful_memes/img/15478.png  \n",
            "  inflating: hateful_memes/img/69815.png  \n",
            "  inflating: hateful_memes/img/93416.png  \n",
            "  inflating: hateful_memes/img/35104.png  \n",
            "  inflating: hateful_memes/img/25974.png  \n",
            "  inflating: hateful_memes/img/31074.png  \n",
            "  inflating: hateful_memes/img/09423.png  \n",
            "  inflating: hateful_memes/img/67142.png  \n",
            "  inflating: hateful_memes/img/13475.png  \n",
            "  inflating: hateful_memes/img/59321.png  \n",
            "  inflating: hateful_memes/img/05984.png  \n",
            "  inflating: hateful_memes/img/19705.png  \n",
            "  inflating: hateful_memes/img/26489.png  \n",
            "  inflating: hateful_memes/img/95780.png  \n",
            "  inflating: hateful_memes/img/25071.png  \n",
            "  inflating: hateful_memes/img/86910.png  \n",
            "  inflating: hateful_memes/img/37140.png  \n",
            "  inflating: hateful_memes/img/95421.png  \n",
            "  inflating: hateful_memes/img/58306.png  \n",
            "  inflating: hateful_memes/img/20341.png  \n",
            "  inflating: hateful_memes/img/96083.png  \n",
            "  inflating: hateful_memes/img/98276.png  \n",
            "  inflating: hateful_memes/img/65904.png  \n",
            "  inflating: hateful_memes/img/27603.png  \n",
            "  inflating: hateful_memes/img/26738.png  \n",
            "  inflating: hateful_memes/img/67190.png  \n",
            "  inflating: hateful_memes/img/76534.png  \n",
            "  inflating: hateful_memes/img/16354.png  \n",
            "  inflating: hateful_memes/img/57469.png  \n",
            "  inflating: hateful_memes/img/64901.png  \n",
            "  inflating: hateful_memes/img/10539.png  \n",
            "  inflating: hateful_memes/img/35298.png  \n",
            "  inflating: hateful_memes/img/27341.png  \n",
            "  inflating: hateful_memes/img/63578.png  \n",
            "  inflating: hateful_memes/img/41389.png  \n",
            "  inflating: hateful_memes/img/86453.png  \n",
            "  inflating: hateful_memes/img/08297.png  \n",
            "  inflating: hateful_memes/img/81972.png  \n",
            "  inflating: hateful_memes/img/10629.png  \n",
            "  inflating: hateful_memes/img/02146.png  \n",
            "  inflating: hateful_memes/img/70319.png  \n",
            "  inflating: hateful_memes/img/92617.png  \n",
            "  inflating: hateful_memes/img/48517.png  \n",
            "  inflating: hateful_memes/img/45203.png  \n",
            "  inflating: hateful_memes/img/82765.png  \n",
            "  inflating: hateful_memes/img/05918.png  \n",
            "  inflating: hateful_memes/img/52719.png  \n",
            "  inflating: hateful_memes/img/37680.png  \n",
            "  inflating: hateful_memes/img/15368.png  \n",
            "  inflating: hateful_memes/img/58341.png  \n",
            "  inflating: hateful_memes/img/79142.png  \n",
            "  inflating: hateful_memes/img/28674.png  \n",
            "  inflating: hateful_memes/img/31495.png  \n",
            "  inflating: hateful_memes/img/07826.png  \n",
            "  inflating: hateful_memes/img/58091.png  \n",
            "  inflating: hateful_memes/img/67841.png  \n",
            "  inflating: hateful_memes/img/42613.png  \n",
            "  inflating: hateful_memes/img/31752.png  \n",
            "  inflating: hateful_memes/img/25693.png  \n",
            "  inflating: hateful_memes/img/41506.png  \n",
            "  inflating: hateful_memes/img/95024.png  \n",
            "  inflating: hateful_memes/img/35806.png  \n",
            "  inflating: hateful_memes/img/82531.png  \n",
            "  inflating: hateful_memes/img/36751.png  \n",
            "  inflating: hateful_memes/img/40916.png  \n",
            "  inflating: hateful_memes/img/20745.png  \n",
            "  inflating: hateful_memes/img/34670.png  \n",
            "  inflating: hateful_memes/img/06453.png  \n",
            "  inflating: hateful_memes/img/17089.png  \n",
            "  inflating: hateful_memes/img/76932.png  \n",
            "  inflating: hateful_memes/img/95846.png  \n",
            "  inflating: hateful_memes/img/97524.png  \n",
            "  inflating: hateful_memes/img/25917.png  \n",
            "  inflating: hateful_memes/img/16470.png  \n",
            "  inflating: hateful_memes/img/06831.png  \n",
            "  inflating: hateful_memes/img/46302.png  \n",
            "  inflating: hateful_memes/img/64309.png  \n",
            "  inflating: hateful_memes/img/75108.png  \n",
            "  inflating: hateful_memes/img/57043.png  \n",
            "  inflating: hateful_memes/img/95487.png  \n",
            "  inflating: hateful_memes/img/67034.png  \n",
            "  inflating: hateful_memes/img/93502.png  \n",
            "  inflating: hateful_memes/img/07912.png  \n",
            "  inflating: hateful_memes/img/85947.png  \n",
            "  inflating: hateful_memes/img/09713.png  \n",
            "  inflating: hateful_memes/img/95087.png  \n",
            "  inflating: hateful_memes/img/72509.png  \n",
            "  inflating: hateful_memes/img/79124.png  \n",
            "  inflating: hateful_memes/img/14870.png  \n",
            "  inflating: hateful_memes/img/29785.png  \n",
            "  inflating: hateful_memes/img/08761.png  \n",
            "  inflating: hateful_memes/img/16240.png  \n",
            "  inflating: hateful_memes/img/13657.png  \n",
            "  inflating: hateful_memes/img/14750.png  \n",
            "  inflating: hateful_memes/img/27958.png  \n",
            "  inflating: hateful_memes/img/17254.png  \n",
            "  inflating: hateful_memes/img/14762.png  \n",
            "  inflating: hateful_memes/img/98632.png  \n",
            "  inflating: hateful_memes/img/20173.png  \n",
            "  inflating: hateful_memes/img/63185.png  \n",
            "  inflating: hateful_memes/img/89407.png  \n",
            "  inflating: hateful_memes/img/72519.png  \n",
            "  inflating: hateful_memes/img/71869.png  \n",
            "  inflating: hateful_memes/img/87539.png  \n",
            "  inflating: hateful_memes/img/26093.png  \n",
            "  inflating: hateful_memes/img/70123.png  \n",
            "  inflating: hateful_memes/img/72609.png  \n",
            "  inflating: hateful_memes/img/23048.png  \n",
            "  inflating: hateful_memes/img/58426.png  \n",
            "  inflating: hateful_memes/img/80652.png  \n",
            "  inflating: hateful_memes/img/68594.png  \n",
            "  inflating: hateful_memes/img/90481.png  \n",
            "  inflating: hateful_memes/img/07594.png  \n",
            "  inflating: hateful_memes/img/94172.png  \n",
            "  inflating: hateful_memes/img/29150.png  \n",
            "  inflating: hateful_memes/img/47180.png  \n",
            "  inflating: hateful_memes/img/32168.png  \n",
            "  inflating: hateful_memes/img/92075.png  \n",
            "  inflating: hateful_memes/img/54318.png  \n",
            "  inflating: hateful_memes/img/15064.png  \n",
            "  inflating: hateful_memes/img/02853.png  \n",
            "  inflating: hateful_memes/img/28970.png  \n",
            "  inflating: hateful_memes/img/90586.png  \n",
            "  inflating: hateful_memes/img/34807.png  \n",
            "  inflating: hateful_memes/img/43650.png  \n",
            "  inflating: hateful_memes/img/60589.png  \n",
            "  inflating: hateful_memes/img/45286.png  \n",
            "  inflating: hateful_memes/img/16275.png  \n",
            "  inflating: hateful_memes/img/68192.png  \n",
            "  inflating: hateful_memes/img/35924.png  \n",
            "  inflating: hateful_memes/img/72354.png  \n",
            "  inflating: hateful_memes/img/71206.png  \n",
            "  inflating: hateful_memes/img/70268.png  \n",
            "  inflating: hateful_memes/img/20819.png  \n",
            "  inflating: hateful_memes/img/94106.png  \n",
            "  inflating: hateful_memes/img/42861.png  \n",
            "  inflating: hateful_memes/img/94720.png  \n",
            "  inflating: hateful_memes/img/30186.png  \n",
            "  inflating: hateful_memes/img/09825.png  \n",
            "  inflating: hateful_memes/img/05276.png  \n",
            "  inflating: hateful_memes/img/18094.png  \n",
            "  inflating: hateful_memes/img/48652.png  \n",
            "  inflating: hateful_memes/img/02315.png  \n",
            "  inflating: hateful_memes/img/04398.png  \n",
            "  inflating: hateful_memes/img/02367.png  \n",
            "  inflating: hateful_memes/img/89574.png  \n",
            "  inflating: hateful_memes/img/80769.png  \n",
            "  inflating: hateful_memes/img/17590.png  \n",
            "  inflating: hateful_memes/img/10835.png  \n",
            "  inflating: hateful_memes/img/10479.png  \n",
            "  inflating: hateful_memes/img/16437.png  \n",
            "  inflating: hateful_memes/img/98426.png  \n",
            "  inflating: hateful_memes/img/40819.png  \n",
            "  inflating: hateful_memes/img/68154.png  \n",
            "  inflating: hateful_memes/img/30721.png  \n",
            "  inflating: hateful_memes/img/51903.png  \n",
            "  inflating: hateful_memes/img/56019.png  \n",
            "  inflating: hateful_memes/img/74892.png  \n",
            "  inflating: hateful_memes/img/06175.png  \n",
            "  inflating: hateful_memes/img/94205.png  \n",
            "  inflating: hateful_memes/img/69702.png  \n",
            "  inflating: hateful_memes/img/24106.png  \n",
            "  inflating: hateful_memes/img/48326.png  \n",
            "  inflating: hateful_memes/img/47529.png  \n",
            "  inflating: hateful_memes/img/29187.png  \n",
            "  inflating: hateful_memes/img/78659.png  \n",
            "  inflating: hateful_memes/img/43569.png  \n",
            "  inflating: hateful_memes/img/30756.png  \n",
            "  inflating: hateful_memes/img/06483.png  \n",
            "  inflating: hateful_memes/img/72340.png  \n",
            "  inflating: hateful_memes/img/39601.png  \n",
            "  inflating: hateful_memes/img/93462.png  \n",
            "  inflating: hateful_memes/img/70842.png  \n",
            "  inflating: hateful_memes/img/78215.png  \n",
            "  inflating: hateful_memes/img/67194.png  \n",
            "  inflating: hateful_memes/img/19678.png  \n",
            "  inflating: hateful_memes/img/78095.png  \n",
            "  inflating: hateful_memes/img/69731.png  \n",
            "  inflating: hateful_memes/img/10397.png  \n",
            "  inflating: hateful_memes/img/28690.png  \n",
            "  inflating: hateful_memes/img/69273.png  \n",
            "  inflating: hateful_memes/img/01264.png  \n",
            "  inflating: hateful_memes/img/85621.png  \n",
            "  inflating: hateful_memes/img/13964.png  \n",
            "  inflating: hateful_memes/img/75321.png  \n",
            "  inflating: hateful_memes/img/24865.png  \n",
            "  inflating: hateful_memes/img/78534.png  \n",
            "  inflating: hateful_memes/img/04568.png  \n",
            "  inflating: hateful_memes/img/96143.png  \n",
            "  inflating: hateful_memes/img/38764.png  \n",
            "  inflating: hateful_memes/img/73248.png  \n",
            "  inflating: hateful_memes/img/73596.png  \n",
            "  inflating: hateful_memes/img/83504.png  \n",
            "  inflating: hateful_memes/img/87420.png  \n",
            "  inflating: hateful_memes/img/51726.png  \n",
            "  inflating: hateful_memes/img/45216.png  \n",
            "  inflating: hateful_memes/img/80156.png  \n",
            "  inflating: hateful_memes/img/21347.png  \n",
            "  inflating: hateful_memes/img/40987.png  \n",
            "  inflating: hateful_memes/img/81239.png  \n",
            "  inflating: hateful_memes/img/74021.png  \n",
            "  inflating: hateful_memes/img/18074.png  \n",
            "  inflating: hateful_memes/img/25847.png  \n",
            "  inflating: hateful_memes/img/19758.png  \n",
            "  inflating: hateful_memes/img/19243.png  \n",
            "  inflating: hateful_memes/img/41358.png  \n",
            "  inflating: hateful_memes/img/04651.png  \n",
            "  inflating: hateful_memes/img/19840.png  \n",
            "  inflating: hateful_memes/img/82593.png  \n",
            "  inflating: hateful_memes/img/73964.png  \n",
            "  inflating: hateful_memes/img/04298.png  \n",
            "  inflating: hateful_memes/img/41250.png  \n",
            "  inflating: hateful_memes/img/67402.png  \n",
            "  inflating: hateful_memes/img/52168.png  \n",
            "  inflating: hateful_memes/img/25913.png  \n",
            "  inflating: hateful_memes/img/24653.png  \n",
            "  inflating: hateful_memes/img/38590.png  \n",
            "  inflating: hateful_memes/img/25408.png  \n",
            "  inflating: hateful_memes/img/59142.png  \n",
            "  inflating: hateful_memes/img/97263.png  \n",
            "  inflating: hateful_memes/img/24019.png  \n",
            "  inflating: hateful_memes/img/72814.png  \n",
            "  inflating: hateful_memes/img/42608.png  \n",
            "  inflating: hateful_memes/img/26813.png  \n",
            "  inflating: hateful_memes/img/98057.png  \n",
            "  inflating: hateful_memes/img/87016.png  \n",
            "  inflating: hateful_memes/img/58369.png  \n",
            "  inflating: hateful_memes/img/08641.png  \n",
            "  inflating: hateful_memes/img/02538.png  \n",
            "  inflating: hateful_memes/img/78542.png  \n",
            "  inflating: hateful_memes/img/68937.png  \n",
            "  inflating: hateful_memes/img/14859.png  \n",
            "  inflating: hateful_memes/img/13465.png  \n",
            "  inflating: hateful_memes/img/60917.png  \n",
            "  inflating: hateful_memes/img/36142.png  \n",
            "  inflating: hateful_memes/img/64803.png  \n",
            "  inflating: hateful_memes/img/18943.png  \n",
            "  inflating: hateful_memes/img/71892.png  \n",
            "  inflating: hateful_memes/img/69013.png  \n",
            "  inflating: hateful_memes/img/36415.png  \n",
            "  inflating: hateful_memes/img/13875.png  \n",
            "  inflating: hateful_memes/img/91403.png  \n",
            "  inflating: hateful_memes/img/67584.png  \n",
            "  inflating: hateful_memes/img/51783.png  \n",
            "  inflating: hateful_memes/img/98406.png  \n",
            "  inflating: hateful_memes/img/46238.png  \n",
            "  inflating: hateful_memes/img/82713.png  \n",
            "  inflating: hateful_memes/img/79386.png  \n",
            "  inflating: hateful_memes/img/10542.png  \n",
            "  inflating: hateful_memes/img/56948.png  \n",
            "  inflating: hateful_memes/img/09326.png  \n",
            "  inflating: hateful_memes/img/67520.png  \n",
            "  inflating: hateful_memes/img/14367.png  \n",
            "  inflating: hateful_memes/img/30478.png  \n",
            "  inflating: hateful_memes/img/57183.png  \n",
            "  inflating: hateful_memes/img/03246.png  \n",
            "  inflating: hateful_memes/img/41679.png  \n",
            "  inflating: hateful_memes/img/52743.png  \n",
            "  inflating: hateful_memes/img/64032.png  \n",
            "  inflating: hateful_memes/img/72893.png  \n",
            "  inflating: hateful_memes/img/37182.png  \n",
            "  inflating: hateful_memes/img/69015.png  \n",
            "  inflating: hateful_memes/img/70829.png  \n",
            "  inflating: hateful_memes/img/54217.png  \n",
            "  inflating: hateful_memes/img/60721.png  \n",
            "  inflating: hateful_memes/img/87260.png  \n",
            "  inflating: hateful_memes/img/38679.png  \n",
            "  inflating: hateful_memes/img/42398.png  \n",
            "  inflating: hateful_memes/img/80436.png  \n",
            "  inflating: hateful_memes/img/21394.png  \n",
            "  inflating: hateful_memes/img/70936.png  \n",
            "  inflating: hateful_memes/img/25037.png  \n",
            "  inflating: hateful_memes/img/18450.png  \n",
            "  inflating: hateful_memes/img/83074.png  \n",
            "  inflating: hateful_memes/img/54209.png  \n",
            "  inflating: hateful_memes/img/05819.png  \n",
            "  inflating: hateful_memes/img/53491.png  \n",
            "  inflating: hateful_memes/img/95413.png  \n",
            "  inflating: hateful_memes/img/92513.png  \n",
            "  inflating: hateful_memes/img/95872.png  \n",
            "  inflating: hateful_memes/img/20134.png  \n",
            "  inflating: hateful_memes/img/81293.png  \n",
            "  inflating: hateful_memes/img/62471.png  \n",
            "  inflating: hateful_memes/img/65407.png  \n",
            "  inflating: hateful_memes/img/04371.png  \n",
            "  inflating: hateful_memes/img/13640.png  \n",
            "  inflating: hateful_memes/img/90214.png  \n",
            "  inflating: hateful_memes/img/09514.png  \n",
            "  inflating: hateful_memes/img/05716.png  \n",
            "  inflating: hateful_memes/img/23076.png  \n",
            "  inflating: hateful_memes/img/83461.png  \n",
            "  inflating: hateful_memes/img/51670.png  \n",
            "  inflating: hateful_memes/img/05174.png  \n",
            "  inflating: hateful_memes/img/59261.png  \n",
            "  inflating: hateful_memes/img/31765.png  \n",
            "  inflating: hateful_memes/img/76421.png  \n",
            "  inflating: hateful_memes/img/36075.png  \n",
            "  inflating: hateful_memes/img/14038.png  \n",
            "  inflating: hateful_memes/img/28436.png  \n",
            "  inflating: hateful_memes/img/62849.png  \n",
            "  inflating: hateful_memes/img/26084.png  \n",
            "  inflating: hateful_memes/img/35716.png  \n",
            "  inflating: hateful_memes/img/72634.png  \n",
            "  inflating: hateful_memes/img/39854.png  \n",
            "  inflating: hateful_memes/img/97465.png  \n",
            "  inflating: hateful_memes/img/25893.png  \n",
            "  inflating: hateful_memes/img/75210.png  \n",
            "  inflating: hateful_memes/img/41803.png  \n",
            "  inflating: hateful_memes/img/70214.png  \n",
            "  inflating: hateful_memes/img/01472.png  \n",
            "  inflating: hateful_memes/img/62374.png  \n",
            "  inflating: hateful_memes/img/15936.png  \n",
            "  inflating: hateful_memes/img/86952.png  \n",
            "  inflating: hateful_memes/img/54129.png  \n",
            "  inflating: hateful_memes/img/86017.png  \n",
            "  inflating: hateful_memes/img/92147.png  \n",
            "  inflating: hateful_memes/img/34678.png  \n",
            "  inflating: hateful_memes/img/07369.png  \n",
            "  inflating: hateful_memes/img/87340.png  \n",
            "  inflating: hateful_memes/img/65320.png  \n",
            "  inflating: hateful_memes/img/37096.png  \n",
            "  inflating: hateful_memes/img/02349.png  \n",
            "  inflating: hateful_memes/img/59203.png  \n",
            "  inflating: hateful_memes/img/14682.png  \n",
            "  inflating: hateful_memes/img/34596.png  \n",
            "  inflating: hateful_memes/img/86023.png  \n",
            "  inflating: hateful_memes/img/51962.png  \n",
            "  inflating: hateful_memes/img/74951.png  \n",
            "  inflating: hateful_memes/img/83271.png  \n",
            "  inflating: hateful_memes/img/09634.png  \n",
            "  inflating: hateful_memes/img/65829.png  \n",
            "  inflating: hateful_memes/img/39241.png  \n",
            "  inflating: hateful_memes/img/40265.png  \n",
            "  inflating: hateful_memes/img/34170.png  \n",
            "  inflating: hateful_memes/img/08163.png  \n",
            "  inflating: hateful_memes/img/48270.png  \n",
            "  inflating: hateful_memes/img/93082.png  \n",
            "  inflating: hateful_memes/img/32980.png  \n",
            "  inflating: hateful_memes/img/92185.png  \n",
            "  inflating: hateful_memes/img/06749.png  \n",
            "  inflating: hateful_memes/img/76491.png  \n",
            "  inflating: hateful_memes/img/12637.png  \n",
            "  inflating: hateful_memes/img/69534.png  \n",
            "  inflating: hateful_memes/img/92064.png  \n",
            "  inflating: hateful_memes/img/67580.png  \n",
            "  inflating: hateful_memes/img/74061.png  \n",
            "  inflating: hateful_memes/img/90127.png  \n",
            "  inflating: hateful_memes/img/78930.png  \n",
            "  inflating: hateful_memes/img/10952.png  \n",
            "  inflating: hateful_memes/img/02145.png  \n",
            "  inflating: hateful_memes/img/17538.png  \n",
            "  inflating: hateful_memes/img/64870.png  \n",
            "  inflating: hateful_memes/img/13459.png  \n",
            "  inflating: hateful_memes/img/72401.png  \n",
            "  inflating: hateful_memes/img/73982.png  \n",
            "  inflating: hateful_memes/img/34905.png  \n",
            "  inflating: hateful_memes/img/40679.png  \n",
            "  inflating: hateful_memes/img/10345.png  \n",
            "  inflating: hateful_memes/img/02153.png  \n",
            "  inflating: hateful_memes/img/35784.png  \n",
            "  inflating: hateful_memes/img/42179.png  \n",
            "  inflating: hateful_memes/img/06859.png  \n",
            "  inflating: hateful_memes/img/72980.png  \n",
            "  inflating: hateful_memes/img/92631.png  \n",
            "  inflating: hateful_memes/img/74583.png  \n",
            "  inflating: hateful_memes/img/63412.png  \n",
            "  inflating: hateful_memes/img/13046.png  \n",
            "  inflating: hateful_memes/img/67548.png  \n",
            "  inflating: hateful_memes/img/94528.png  \n",
            "  inflating: hateful_memes/img/14783.png  \n",
            "  inflating: hateful_memes/img/09432.png  \n",
            "  inflating: hateful_memes/img/30427.png  \n",
            "  inflating: hateful_memes/img/03987.png  \n",
            "  inflating: hateful_memes/img/42319.png  \n",
            "  inflating: hateful_memes/img/64287.png  \n",
            "  inflating: hateful_memes/img/82673.png  \n",
            "  inflating: hateful_memes/img/73605.png  \n",
            "  inflating: hateful_memes/img/38701.png  \n",
            "  inflating: hateful_memes/img/05372.png  \n",
            "  inflating: hateful_memes/img/72091.png  \n",
            "  inflating: hateful_memes/img/36054.png  \n",
            "  inflating: hateful_memes/img/42936.png  \n",
            "  inflating: hateful_memes/img/02593.png  \n",
            "  inflating: hateful_memes/img/60981.png  \n",
            "  inflating: hateful_memes/img/96785.png  \n",
            "  inflating: hateful_memes/img/71462.png  \n",
            "  inflating: hateful_memes/img/59837.png  \n",
            "  inflating: hateful_memes/img/08147.png  \n",
            "  inflating: hateful_memes/img/35401.png  \n",
            "  inflating: hateful_memes/img/76095.png  \n",
            "  inflating: hateful_memes/img/38720.png  \n",
            "  inflating: hateful_memes/img/56721.png  \n",
            "  inflating: hateful_memes/img/89105.png  \n",
            "  inflating: hateful_memes/img/91243.png  \n",
            "  inflating: hateful_memes/img/21364.png  \n",
            "  inflating: hateful_memes/img/84076.png  \n",
            "  inflating: hateful_memes/img/08695.png  \n",
            "  inflating: hateful_memes/img/85406.png  \n",
            "  inflating: hateful_memes/img/29513.png  \n",
            "  inflating: hateful_memes/img/98124.png  \n",
            "  inflating: hateful_memes/img/52839.png  \n",
            "  inflating: hateful_memes/img/64730.png  \n",
            "  inflating: hateful_memes/img/37609.png  \n",
            "  inflating: hateful_memes/img/81647.png  \n",
            "  inflating: hateful_memes/img/75432.png  \n",
            "  inflating: hateful_memes/img/41268.png  \n",
            "  inflating: hateful_memes/img/96180.png  \n",
            "  inflating: hateful_memes/img/05379.png  \n",
            "  inflating: hateful_memes/img/84537.png  \n",
            "  inflating: hateful_memes/img/38190.png  \n",
            "  inflating: hateful_memes/img/90326.png  \n",
            "  inflating: hateful_memes/img/89701.png  \n",
            "  inflating: hateful_memes/img/18452.png  \n",
            "  inflating: hateful_memes/img/15809.png  \n",
            "  inflating: hateful_memes/img/57094.png  \n",
            "  inflating: hateful_memes/img/71302.png  \n",
            "  inflating: hateful_memes/img/12894.png  \n",
            "  inflating: hateful_memes/img/59360.png  \n",
            "  inflating: hateful_memes/img/84670.png  \n",
            "  inflating: hateful_memes/img/60142.png  \n",
            "  inflating: hateful_memes/img/10536.png  \n",
            "  inflating: hateful_memes/img/89314.png  \n",
            "  inflating: hateful_memes/img/06579.png  \n",
            "  inflating: hateful_memes/img/90413.png  \n",
            "  inflating: hateful_memes/img/81962.png  \n",
            "  inflating: hateful_memes/img/05962.png  \n",
            "  inflating: hateful_memes/img/48160.png  \n",
            "  inflating: hateful_memes/img/25436.png  \n",
            "  inflating: hateful_memes/img/46712.png  \n",
            "  inflating: hateful_memes/img/65207.png  \n",
            "  inflating: hateful_memes/img/40127.png  \n",
            "  inflating: hateful_memes/img/17306.png  \n",
            "  inflating: hateful_memes/img/01325.png  \n",
            "  inflating: hateful_memes/img/96845.png  \n",
            "  inflating: hateful_memes/img/18532.png  \n",
            "  inflating: hateful_memes/img/23419.png  \n",
            "  inflating: hateful_memes/img/97510.png  \n",
            "  inflating: hateful_memes/img/59328.png  \n",
            "  inflating: hateful_memes/img/05238.png  \n",
            "  inflating: hateful_memes/img/37186.png  \n",
            "  inflating: hateful_memes/img/40796.png  \n",
            "  inflating: hateful_memes/img/47938.png  \n",
            "  inflating: hateful_memes/img/85764.png  \n",
            "  inflating: hateful_memes/img/23510.png  \n",
            "  inflating: hateful_memes/img/03962.png  \n",
            "  inflating: hateful_memes/img/37810.png  \n",
            "  inflating: hateful_memes/img/32481.png  \n",
            "  inflating: hateful_memes/img/64150.png  \n",
            "  inflating: hateful_memes/img/38790.png  \n",
            "  inflating: hateful_memes/img/65732.png  \n",
            "  inflating: hateful_memes/img/17345.png  \n",
            "  inflating: hateful_memes/img/67048.png  \n",
            "  inflating: hateful_memes/img/67059.png  \n",
            "  inflating: hateful_memes/img/21309.png  \n",
            "  inflating: hateful_memes/img/24109.png  \n",
            "  inflating: hateful_memes/img/61972.png  \n",
            "  inflating: hateful_memes/img/45367.png  \n",
            "  inflating: hateful_memes/img/50839.png  \n",
            "  inflating: hateful_memes/img/36408.png  \n",
            "  inflating: hateful_memes/img/29684.png  \n",
            "  inflating: hateful_memes/img/58129.png  \n",
            "  inflating: hateful_memes/img/32674.png  \n",
            "  inflating: hateful_memes/img/37459.png  \n",
            "  inflating: hateful_memes/img/41637.png  \n",
            "  inflating: hateful_memes/img/30428.png  \n",
            "  inflating: hateful_memes/dev_seen.jsonl  \n",
            "  inflating: hateful_memes/test_seen.jsonl  \n",
            "  inflating: hateful_memes/dev_unseen.jsonl  \n",
            "  inflating: hateful_memes/train.jsonl  \n",
            "  inflating: hateful_memes/test_unseen.jsonl  \n",
            "CPU times: user 1.72 s, sys: 191 ms, total: 1.91 s\n",
            "Wall time: 1min 46s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "!unzip -P \"pass\" hateful_memes.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Gp-nsomq0ohh"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "mv hateful_memes/* /content/vilio/ernie-vil/data/hm\n",
        "rm -r hateful_memes\n",
        "rm hateful_memes.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/vilio/ernie-vil/data/hm/* /content/vilio/data/"
      ],
      "metadata": {
        "id": "ctPo8l8vd8gP"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/vilio/ernie-vil/data/hm/img | wc -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4SJKLRUgoRm",
        "outputId": "6346d5c5-0c75-403e-dfe0-4fe2a9c54b45"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12140\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "VxFCb2BLxU8g"
      },
      "outputs": [],
      "source": [
        "# !cp -r /content/vilio/ernie-vil/data/hm/*  /content/vilio/data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "MHDb7BykfgGU"
      },
      "outputs": [],
      "source": [
        "# only needed if run models that are not ERNIE-Vil\n",
        "\n",
        "# %%bash\n",
        "# mv /content/vilio/ernie-vil/data/hm/*  /content/vilio/data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "khZf5FdKiIE9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23c3f6c3-e36f-49b6-eb10-548cb7cb3f4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "cp: -r not specified; omitting directory '/content/vilio/data/img'\n"
          ]
        }
      ],
      "source": [
        "# only needed to run py-bottom-up-attention\n",
        "\n",
        "%%bash\n",
        "cp /content/vilio/data/*  /content/vilio/py-bottom-up-attention/data/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/vilio/py-bottom-up-attention/data/* /content/vilio/data/"
      ],
      "metadata": {
        "id": "BPCzWAsKiRCo"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "2lPuOuUtiTdU"
      },
      "outputs": [],
      "source": [
        "# %%bash\n",
        "# cp -r /content/vilio/py-bottom-up-attention/data/*  /content/vilio/data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "5hnr7uKlqX3_"
      },
      "outputs": [],
      "source": [
        "# !cp -r /content/vilio/data/* /content/vilio/ernie-vil/data/hm/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udCFF9nsxx-O"
      },
      "source": [
        "##  <font color='#A8EB15'> Run Feature extraction\n",
        "\n",
        "*Skip (already runned) - just run !cp to copy features from `drive` to `/content/vilio/ernie-vil/data/hm`* \n",
        "\n",
        "- we must have 5 features needed to run **ERNIE-Vil**:\n",
        "  * hm_vgattr3636.tsv\n",
        "  * hm_vgattr7272.tsv\n",
        "  * hm_vgattr10100.tsv\n",
        "  * hm_vg5050.tsv\n",
        "  * hm_vg10100.tsv\n",
        "\n",
        "  (For the moment we use `hm_vgattr3636.tsv`)\n",
        "  (We gonna generate: `hm_vgattr10100.tsv`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xmlB5gvDGLF3"
      },
      "outputs": [],
      "source": [
        "#!cp /content/drive/MyDrive/hm_vgattr3636.tsv /content/vilio/ernie-vil/data/hm/hm_vgattr3636.tsv\n",
        "#!cp /content/drive/MyDrive/hm_vgattr10100.tsv /content/vilio/ernie-vil/data/hm/hm_vgattr10100.tsv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOofFrnqGLl2"
      },
      "source": [
        "* In case you need extract features RUN cells below changing `--minboxes 36 --maxboxes 36 `"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "AYhbhiBMzyr8"
      },
      "outputs": [],
      "source": [
        "os.chdir(\"/content/vilio/py-bottom-up-attention\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_q0CKAID4lNL"
      },
      "source": [
        "In the file `detectron2_mscoco_proposal_maxnms.py` you must modify:\n",
        "\n",
        "* Line 40: './data/' to '/content/vilio/data/' <- ALDREADY modificated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77PuhN9zxzvY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98c5ed23-8495-4d53-c686-54b517e7bb91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Config '/content/vilio/py-bottom-up-attention/configs/VG-Detection/faster_rcnn_R_101_C4_attr_caffemaxpool.yaml' has no VERSION. Assuming it to be compatible with latest v2.\n",
            "Modifications for VG in ResNet Backbone (modeling/backbone/resnet.py):\n",
            "\tUsing pad 0 in stem max_pool instead of pad 1.\n",
            "\n",
            "Modifications for VG in RPN (modeling/proposal_generator/rpn.py):\n",
            "\tUse hidden dim 512 instead fo the same dim as Res4 (1024).\n",
            "\n",
            "Modifications for VG in RoI heads (modeling/roi_heads/roi_heads.py):\n",
            "\t1. Change the stride of conv1 and shortcut in Res5.Block1 from 2 to 1.\n",
            "\t2. Modifying all conv2 with (padding: 1 --> 2) and (dilation: 1 --> 2).\n",
            "\tFor more details, please check 'https://github.com/peteanderson80/bottom-up-attention/blob/master/models/vg/ResNet-101/faster_rcnn_end2end_final/test.prototxt'.\n",
            "\n",
            "Modifications for VG in RoI heads (modeling/roi_heads/fast_rcnn.py))\n",
            "\tEmbedding: 1601 --> 256\tLinear: 2304 --> 512\tLinear: 512 --> 401\n",
            "\n",
            "faster_rcnn_from_caffe_attr.pkl: 262MB [00:09, 28.8MB/s]               \n",
            "100% 12140/12140 [48:18<00:00,  4.19it/s]\n"
          ]
        }
      ],
      "source": [
        "# !python detectron2_mscoco_proposal_maxnms.py --batchsize 4 --split img --weight vgattr --minboxes 36 --maxboxes 36"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !cp /content/vilio/data/hm_vgattr3636.tsv /content/drive/MyDrive/dataset"
      ],
      "metadata": {
        "id": "GXD_m6_PrKsn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9X114XaoqDZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac3d66c4-f895-4958-f3ad-4017d084d4cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Config '/content/vilio/py-bottom-up-attention/configs/VG-Detection/faster_rcnn_R_101_C4_attr_caffemaxpool.yaml' has no VERSION. Assuming it to be compatible with latest v2.\n",
            "Modifications for VG in ResNet Backbone (modeling/backbone/resnet.py):\n",
            "\tUsing pad 0 in stem max_pool instead of pad 1.\n",
            "\n",
            "Modifications for VG in RPN (modeling/proposal_generator/rpn.py):\n",
            "\tUse hidden dim 512 instead fo the same dim as Res4 (1024).\n",
            "\n",
            "Modifications for VG in RoI heads (modeling/roi_heads/roi_heads.py):\n",
            "\t1. Change the stride of conv1 and shortcut in Res5.Block1 from 2 to 1.\n",
            "\t2. Modifying all conv2 with (padding: 1 --> 2) and (dilation: 1 --> 2).\n",
            "\tFor more details, please check 'https://github.com/peteanderson80/bottom-up-attention/blob/master/models/vg/ResNet-101/faster_rcnn_end2end_final/test.prototxt'.\n",
            "\n",
            "Modifications for VG in RoI heads (modeling/roi_heads/fast_rcnn.py))\n",
            "\tEmbedding: 1601 --> 256\tLinear: 2304 --> 512\tLinear: 512 --> 401\n",
            "\n",
            "100% 12140/12140 [47:39<00:00,  4.25it/s]\n"
          ]
        }
      ],
      "source": [
        "# !python detectron2_mscoco_proposal_maxnms.py --batchsize 4 --split img --weight vgattr --minboxes 10 --maxboxes 100"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !cp /content/vilio/data/hm_vgattr10100.tsv /content/drive/MyDrive/dataset"
      ],
      "metadata": {
        "id": "cR4_uU8xr6Rv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVClNfTN2n4t"
      },
      "source": [
        "### <font color=\"#33FFE3\"> Run below in order to get the new features 5050, 7272 and VG features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LC0iNaR90132"
      },
      "outputs": [],
      "source": [
        "# !python detectron2_mscoco_proposal_maxnms.py --batchsize 4 --split img --weight vgattr --minboxes 50 --maxboxes 50 # not used for ernie-vil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OElJ8V0P1MIW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55c19896-82b6-4e00-b75a-3a39292b7186"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Config '/content/vilio/py-bottom-up-attention/configs/VG-Detection/faster_rcnn_R_101_C4_attr_caffemaxpool.yaml' has no VERSION. Assuming it to be compatible with latest v2.\n",
            "Modifications for VG in ResNet Backbone (modeling/backbone/resnet.py):\n",
            "\tUsing pad 0 in stem max_pool instead of pad 1.\n",
            "\n",
            "Modifications for VG in RPN (modeling/proposal_generator/rpn.py):\n",
            "\tUse hidden dim 512 instead fo the same dim as Res4 (1024).\n",
            "\n",
            "Modifications for VG in RoI heads (modeling/roi_heads/roi_heads.py):\n",
            "\t1. Change the stride of conv1 and shortcut in Res5.Block1 from 2 to 1.\n",
            "\t2. Modifying all conv2 with (padding: 1 --> 2) and (dilation: 1 --> 2).\n",
            "\tFor more details, please check 'https://github.com/peteanderson80/bottom-up-attention/blob/master/models/vg/ResNet-101/faster_rcnn_end2end_final/test.prototxt'.\n",
            "\n",
            "Modifications for VG in RoI heads (modeling/roi_heads/fast_rcnn.py))\n",
            "\tEmbedding: 1601 --> 256\tLinear: 2304 --> 512\tLinear: 512 --> 401\n",
            "\n",
            "100% 12140/12140 [51:17<00:00,  3.94it/s]\n"
          ]
        }
      ],
      "source": [
        "# !python detectron2_mscoco_proposal_maxnms.py --batchsize 4 --split img --weight vgattr --minboxes 72 --maxboxes 72"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !cp /content/vilio/data/hm_vgattr7272.tsv /content/drive/MyDrive/dataset"
      ],
      "metadata": {
        "id": "tj5BWYgr4EHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WfcNwf01TP8"
      },
      "source": [
        "* VG feats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8p9_Al-1tFP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9abebff5-eb85-414c-f5a0-51349aaf2aea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Config '/content/vilio/py-bottom-up-attention/configs/VG-Detection/faster_rcnn_R_101_C4_caffemaxpool.yaml' has no VERSION. Assuming it to be compatible with latest v2.\n",
            "Modifications for VG in ResNet Backbone (modeling/backbone/resnet.py):\n",
            "\tUsing pad 0 in stem max_pool instead of pad 1.\n",
            "\n",
            "Modifications for VG in RPN (modeling/proposal_generator/rpn.py):\n",
            "\tUse hidden dim 512 instead fo the same dim as Res4 (1024).\n",
            "\n",
            "Modifications for VG in RoI heads (modeling/roi_heads/roi_heads.py):\n",
            "\t1. Change the stride of conv1 and shortcut in Res5.Block1 from 2 to 1.\n",
            "\t2. Modifying all conv2 with (padding: 1 --> 2) and (dilation: 1 --> 2).\n",
            "\tFor more details, please check 'https://github.com/peteanderson80/bottom-up-attention/blob/master/models/vg/ResNet-101/faster_rcnn_end2end_final/test.prototxt'.\n",
            "\n",
            "faster_rcnn_from_caffe.pkl: 255MB [00:08, 28.7MB/s]               \n",
            "100% 3035/3035 [40:19<00:00,  1.25it/s]\n"
          ]
        }
      ],
      "source": [
        "# !python detectron2_mscoco_proposal_maxnms.py --batchsize 4 --split img --weight vg --minboxes 50 --maxboxes 50 "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !cp /content/vilio/data/hm_vg5050.tsv /content/drive/MyDrive/dataset"
      ],
      "metadata": {
        "id": "9s02k22bh6XP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "KrmAkpRW1y8O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83e19705-e307-47a3-a970-e8cf24edf24a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Config '/content/vilio/py-bottom-up-attention/configs/VG-Detection/faster_rcnn_R_101_C4_caffemaxpool.yaml' has no VERSION. Assuming it to be compatible with latest v2.\n",
            "Modifications for VG in ResNet Backbone (modeling/backbone/resnet.py):\n",
            "\tUsing pad 0 in stem max_pool instead of pad 1.\n",
            "\n",
            "Modifications for VG in RPN (modeling/proposal_generator/rpn.py):\n",
            "\tUse hidden dim 512 instead fo the same dim as Res4 (1024).\n",
            "\n",
            "Modifications for VG in RoI heads (modeling/roi_heads/roi_heads.py):\n",
            "\t1. Change the stride of conv1 and shortcut in Res5.Block1 from 2 to 1.\n",
            "\t2. Modifying all conv2 with (padding: 1 --> 2) and (dilation: 1 --> 2).\n",
            "\tFor more details, please check 'https://github.com/peteanderson80/bottom-up-attention/blob/master/models/vg/ResNet-101/faster_rcnn_end2end_final/test.prototxt'.\n",
            "\n",
            "faster_rcnn_from_caffe.pkl: 255MB [00:05, 43.5MB/s]               \n",
            "100% 3035/3035 [38:02<00:00,  1.33it/s]\n"
          ]
        }
      ],
      "source": [
        "# !python detectron2_mscoco_proposal_maxnms.py --batchsize 4 --split img --weight vg --minboxes 10 --maxboxes 100 "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !cp /content/vilio/data/hm_vg10100.tsv /content/drive/MyDrive/dataset"
      ],
      "metadata": {
        "id": "V62boQvai0mf"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C41Pvn9cdANW"
      },
      "outputs": [],
      "source": [
        "# !cp /content/vilio/data/hm_vgattr3636.tsv /content/drive/MyDrive/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# in case that we need lmbd features from `mmf`\n",
        "#wget https://www.kaggle.com/datasets/muennighoff/hmfeatureszipfin/download"
      ],
      "metadata": {
        "id": "LUyabhgs59Dc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we cp the features from Drive\n",
        "%%time\n",
        "%%bash\n",
        "\n",
        "\n",
        "# vg\n",
        "# cp /content/drive/MyDrive/dataset/hm_vg10100.tsv /content/vilio/data/hm_vg10100.tsv\n",
        "# cp /content/drive/MyDrive/dataset/hm_vg5050.tsv /content/vilio/data/hm_vg5050.tsv\n",
        "# #vga\n",
        "# cp /content/drive/MyDrive/dataset/hm_vgattr3636.tsv /content/vilio/data/hm_vgattr3636.tsv\n",
        "# cp /content/drive/MyDrive/dataset/hm_vgattr7272.tsv /content/vilio/data/hm_vgattr7272.tsv\n",
        "# cp /content/drive/MyDrive/dataset/hm_vgattr10100.tsv /content/vilio/data/hm_vgattr10100.tsv"
      ],
      "metadata": {
        "id": "AIP-x-N3uIV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e_QX1x864BL"
      },
      "source": [
        "##  <font color='#A8EB15'> <b> Modeling </b>\n",
        "\n",
        "\n",
        "#  <font color='#A8EB15'> <b> ERNIE-ViL  </b>\n",
        "###  <font color='#A8EB15'> PaddlePaddle\n",
        "\n",
        "If you choose to run one of the ERNIE models implemented in PaddlePaddle, I'd recommend making a copy of `vilio/ernie-vil/reader/hm_finetuning.py` and making necessary adjustments on the go, while going through the file, such as:\n",
        "\n",
        "- Add function in vilio/ernie-vil/baching/finetune_batching.py\n",
        "- Data handling in vilio/ernie-vil/reader/_tsv_reader.py\n",
        "- Copy the hm conf folder & adjust under vilio/ernie-vil/conf/\n",
        "- Add a data folder for your project at vilio/ernie-vil/data\n",
        "\n",
        "\n",
        "Run `vilio/ernie-vil/bash/training`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Phst9SvBjts1"
      },
      "source": [
        "We modify the bash files: `hm_EL.sh` in order to change ./bash .... to absolute path \"/content/vilio/ernie-vil/bash\".\n",
        "\n",
        "- We must download the pretrained models and put in the propetly folder:\n",
        "  * `/content/vilio/ernie-vil/data/ernielarge/params`\n",
        "  * `/content/vilio/ernie-vil/data/erniesmall/params`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dp2fgvy2-IWd"
      },
      "source": [
        "### <font color='#33F3FF'> Download Pre-trained small (base) ERNIE-Vil\n",
        "\n",
        "We need download two pretrained models for each model (small and large):\n",
        "* Model\n",
        "* VCR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNHtoJ1K7oq1",
        "outputId": "07c71e7f-40cf-4dfe-b00b-35eb7db50b42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-10 14:03:12--  https://ernie-github.cdn.bcebos.com/model-ernie-vil-base-en.1.tar.gz\n",
            "Resolving ernie-github.cdn.bcebos.com (ernie-github.cdn.bcebos.com)... 14.215.89.35, 121.32.228.35\n",
            "Connecting to ernie-github.cdn.bcebos.com (ernie-github.cdn.bcebos.com)|14.215.89.35|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 886162849 (845M) [application/x-gzip]\n",
            "Saving to: ‘model-ernie-vil-base-en.1.tar.gz’\n",
            "\n",
            "model-ernie-vil-bas 100%[===================>] 845.11M  12.0MB/s    in 61s     \n",
            "\n",
            "2022-05-10 14:04:15 (13.9 MB/s) - ‘model-ernie-vil-base-en.1.tar.gz’ saved [886162849/886162849]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os \n",
        "# Download pre-trained small Ernie-ViL\n",
        "os.chdir(\"/content/vilio/ernie-vil/data/erniesmall\")\n",
        "!wget https://ernie-github.cdn.bcebos.com/model-ernie-vil-base-en.1.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L691WQ6KG_Kr"
      },
      "outputs": [],
      "source": [
        "# unzip only params folder\n",
        "!tar -xzf model-ernie-vil-base-en.1.tar.gz --wildcards --no-anchored '*params*'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UXkUblAw_M_q"
      },
      "outputs": [],
      "source": [
        "# this unzip all folder\n",
        "# !tar -xf model-ernie-vil-base-en.1.tar.gz "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S9iPPEGxJSlT"
      },
      "outputs": [],
      "source": [
        "!mv /content/vilio/ernie-vil/data/erniesmall/model-ernie-vil-base-en/* /content/vilio/ernie-vil/data/erniesmall/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xlLdz1uIJd-q"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "rm model-ernie-vil-base-en.1.tar.gz\n",
        "rm -r model-ernie-vil-base-en"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVhfQPJSJDMf"
      },
      "source": [
        "* VCR pre-trained"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07D-BZ1I775s",
        "outputId": "a9a2aea4-114f-4649-e70e-0295704a57ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-10 14:04:26--  https://ernie-github.cdn.bcebos.com/model-ernie-vil-base-VCR-task-pre-en.1.tar.gz\n",
            "Resolving ernie-github.cdn.bcebos.com (ernie-github.cdn.bcebos.com)... 119.96.52.35, 14.29.98.35, 119.100.50.35, ...\n",
            "Connecting to ernie-github.cdn.bcebos.com (ernie-github.cdn.bcebos.com)|119.96.52.35|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 886087681 (845M) [application/x-gzip]\n",
            "Saving to: ‘model-ernie-vil-base-VCR-task-pre-en.1.tar.gz’\n",
            "\n",
            "model-ernie-vil-bas  99%[==================> ] 845.00M  13.5MB/s    in 63s     \n",
            "\n",
            "2022-05-10 14:05:31 (13.4 MB/s) - Connection closed at byte 886046720. Retrying.\n",
            "\n",
            "--2022-05-10 14:05:32--  (try: 2)  https://ernie-github.cdn.bcebos.com/model-ernie-vil-base-VCR-task-pre-en.1.tar.gz\n",
            "Connecting to ernie-github.cdn.bcebos.com (ernie-github.cdn.bcebos.com)|119.96.52.35|:443... connected.\n",
            "HTTP request sent, awaiting response... 206 Partial Content\n",
            "Length: 886087681 (845M), 40961 (40K) remaining [application/x-gzip]\n",
            "Saving to: ‘model-ernie-vil-base-VCR-task-pre-en.1.tar.gz’\n",
            "\n",
            "model-ernie-vil-bas  99%[+++++++++++++++++++ ] 845.00M  --.-KB/s    in 0s      \n",
            "\n",
            "2022-05-10 14:05:41 (0.00 B/s) - Connection closed at byte 886046720. Retrying.\n",
            "\n",
            "--2022-05-10 14:05:43--  (try: 3)  https://ernie-github.cdn.bcebos.com/model-ernie-vil-base-VCR-task-pre-en.1.tar.gz\n",
            "Connecting to ernie-github.cdn.bcebos.com (ernie-github.cdn.bcebos.com)|119.96.52.35|:443... connected.\n",
            "HTTP request sent, awaiting response... 206 Partial Content\n",
            "Length: 886087681 (845M), 40961 (40K) remaining [application/x-gzip]\n",
            "Saving to: ‘model-ernie-vil-base-VCR-task-pre-en.1.tar.gz’\n",
            "\n",
            "model-ernie-vil-bas  99%[+++++++++++++++++++ ] 845.00M  --.-KB/s    in 0s      \n",
            "\n",
            "2022-05-10 14:05:50 (0.00 B/s) - Connection closed at byte 886046720. Retrying.\n",
            "\n",
            "--2022-05-10 14:05:53--  (try: 4)  https://ernie-github.cdn.bcebos.com/model-ernie-vil-base-VCR-task-pre-en.1.tar.gz\n",
            "Connecting to ernie-github.cdn.bcebos.com (ernie-github.cdn.bcebos.com)|119.96.52.35|:443... connected.\n",
            "HTTP request sent, awaiting response... 206 Partial Content\n",
            "Length: 886087681 (845M), 40961 (40K) remaining [application/x-gzip]\n",
            "Saving to: ‘model-ernie-vil-base-VCR-task-pre-en.1.tar.gz’\n",
            "\n",
            "model-ernie-vil-bas  99%[+++++++++++++++++++ ] 845.00M  --.-KB/s    in 0s      \n",
            "\n",
            "2022-05-10 14:06:01 (0.00 B/s) - Connection closed at byte 886046720. Retrying.\n",
            "\n",
            "--2022-05-10 14:06:05--  (try: 5)  https://ernie-github.cdn.bcebos.com/model-ernie-vil-base-VCR-task-pre-en.1.tar.gz\n",
            "Connecting to ernie-github.cdn.bcebos.com (ernie-github.cdn.bcebos.com)|119.96.52.35|:443... connected.\n",
            "HTTP request sent, awaiting response... 206 Partial Content\n",
            "Length: 886087681 (845M), 40961 (40K) remaining [application/x-gzip]\n",
            "Saving to: ‘model-ernie-vil-base-VCR-task-pre-en.1.tar.gz’\n",
            "\n",
            "model-ernie-vil-bas  99%[+++++++++++++++++++ ] 845.00M  --.-KB/s    in 0s      \n",
            "\n",
            "2022-05-10 14:06:12 (0.00 B/s) - Connection closed at byte 886046720. Retrying.\n",
            "\n",
            "--2022-05-10 14:06:17--  (try: 6)  https://ernie-github.cdn.bcebos.com/model-ernie-vil-base-VCR-task-pre-en.1.tar.gz\n",
            "Connecting to ernie-github.cdn.bcebos.com (ernie-github.cdn.bcebos.com)|119.96.52.35|:443... connected.\n",
            "HTTP request sent, awaiting response... 206 Partial Content\n",
            "Length: 886087681 (845M), 40961 (40K) remaining [application/x-gzip]\n",
            "Saving to: ‘model-ernie-vil-base-VCR-task-pre-en.1.tar.gz’\n",
            "\n",
            "model-ernie-vil-bas  99%[+++++++++++++++++++ ] 845.00M  --.-KB/s    in 0s      \n",
            "\n",
            "2022-05-10 14:06:24 (0.00 B/s) - Connection closed at byte 886046720. Retrying.\n",
            "\n",
            "--2022-05-10 14:06:30--  (try: 7)  https://ernie-github.cdn.bcebos.com/model-ernie-vil-base-VCR-task-pre-en.1.tar.gz\n",
            "Connecting to ernie-github.cdn.bcebos.com (ernie-github.cdn.bcebos.com)|119.96.52.35|:443... connected.\n",
            "HTTP request sent, awaiting response... 206 Partial Content\n",
            "Length: 886087681 (845M), 40961 (40K) remaining [application/x-gzip]\n",
            "Saving to: ‘model-ernie-vil-base-VCR-task-pre-en.1.tar.gz’\n",
            "\n",
            "model-ernie-vil-bas  99%[+++++++++++++++++++ ] 845.00M  --.-KB/s    in 0s      \n",
            "\n",
            "2022-05-10 14:06:38 (0.00 B/s) - Connection closed at byte 886046720. Retrying.\n",
            "\n",
            "--2022-05-10 14:06:45--  (try: 8)  https://ernie-github.cdn.bcebos.com/model-ernie-vil-base-VCR-task-pre-en.1.tar.gz\n",
            "Connecting to ernie-github.cdn.bcebos.com (ernie-github.cdn.bcebos.com)|119.96.52.35|:443... connected.\n",
            "HTTP request sent, awaiting response... 206 Partial Content\n",
            "Length: 886087681 (845M), 40961 (40K) remaining [application/x-gzip]\n",
            "Saving to: ‘model-ernie-vil-base-VCR-task-pre-en.1.tar.gz’\n",
            "\n",
            "model-ernie-vil-bas  99%[+++++++++++++++++++ ] 845.00M  --.-KB/s    in 0s      \n",
            "\n",
            "2022-05-10 14:06:52 (0.00 B/s) - Connection closed at byte 886046720. Retrying.\n",
            "\n",
            "--2022-05-10 14:07:00--  (try: 9)  https://ernie-github.cdn.bcebos.com/model-ernie-vil-base-VCR-task-pre-en.1.tar.gz\n",
            "Connecting to ernie-github.cdn.bcebos.com (ernie-github.cdn.bcebos.com)|119.96.52.35|:443... connected.\n",
            "HTTP request sent, awaiting response... 206 Partial Content\n",
            "Length: 886087681 (845M), 40961 (40K) remaining [application/x-gzip]\n",
            "Saving to: ‘model-ernie-vil-base-VCR-task-pre-en.1.tar.gz’\n",
            "\n",
            "model-ernie-vil-bas  99%[+++++++++++++++++++ ] 845.00M  --.-KB/s    in 0s      \n",
            "\n",
            "2022-05-10 14:07:09 (0.00 B/s) - Connection closed at byte 886046720. Retrying.\n",
            "\n",
            "--2022-05-10 14:07:18--  (try:10)  https://ernie-github.cdn.bcebos.com/model-ernie-vil-base-VCR-task-pre-en.1.tar.gz\n",
            "Connecting to ernie-github.cdn.bcebos.com (ernie-github.cdn.bcebos.com)|119.96.52.35|:443... connected.\n",
            "HTTP request sent, awaiting response... 206 Partial Content\n",
            "Length: 886087681 (845M), 40961 (40K) remaining [application/x-gzip]\n",
            "Saving to: ‘model-ernie-vil-base-VCR-task-pre-en.1.tar.gz’\n",
            "\n",
            "model-ernie-vil-bas 100%[+++++++++++++++++++>] 845.04M   213KB/s    in 0.2s    \n",
            "\n",
            "2022-05-10 14:07:19 (213 KB/s) - ‘model-ernie-vil-base-VCR-task-pre-en.1.tar.gz’ saved [886087681/886087681]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "os.chdir(\"/content/vilio/ernie-vil/data/erniesmallvcr\")\n",
        "!wget https://ernie-github.cdn.bcebos.com/model-ernie-vil-base-VCR-task-pre-en.1.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxflLIf5Haf6"
      },
      "outputs": [],
      "source": [
        "# unzip only params folder\n",
        "!tar -xzf model-ernie-vil-base-VCR-task-pre-en.1.tar.gz --wildcards --no-anchored '*params*'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EsCVA04XIamS"
      },
      "outputs": [],
      "source": [
        "!mv /content/vilio/ernie-vil/data/erniesmallvcr/model-ernie-vil-base-VCR-task-pre-en/* /content/vilio/ernie-vil/data/erniesmallvcr/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eCVJHwKCIx-n"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "rm model-ernie-vil-base-VCR-task-pre-en.1.tar.gz\n",
        "rm -r model-ernie-vil-base-VCR-task-pre-en"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbgyMPys-j8W"
      },
      "source": [
        "### <font color='#33F3FF'> Download Pre-trained large ERNIE-Vil <- don't RUN need modifications\n",
        "\n",
        "* Model\n",
        "* VCR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wec8PSdb8hcF"
      },
      "outputs": [],
      "source": [
        "#import os \n",
        "# Download pre-trained large Ernie-ViL\n",
        "#os.chdir(\"/content/vilio/ernie-vil/data/ernielarge\")\n",
        "#!wget https://ernie-github.cdn.bcebos.com/model-ernie-vil-large-en.1.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJa1c07g9hzK"
      },
      "outputs": [],
      "source": [
        "#os.chdir(\"/content/vilio/ernie-vil/data/ernielargevcr\")\n",
        "#!wget https://ernie-github.cdn.bcebos.com/model-ernie-vil-large-VCR-task-pre-en.1.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l70OCx-t2Pix"
      },
      "source": [
        "### <font color='#A8EB15'> <b>  Train ERNIE-Vil Small </b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-9Q3p3H0VSx"
      },
      "source": [
        "#### <font color='#33F3FF'> Install packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XDV4EF570ZFN"
      },
      "outputs": [],
      "source": [
        "#!pip install -r requirements2.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xp9DwIE20XOP",
        "outputId": "150634f2-ac3a-4943-d32a-3950974a9e71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting imagehash\n",
            "  Downloading ImageHash-4.2.1.tar.gz (812 kB)\n",
            "\u001b[K     |████████████████████████████████| 812 kB 8.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imagehash) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from imagehash) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from imagehash) (1.4.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from imagehash) (7.1.2)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.7/dist-packages (from imagehash) (1.3.0)\n",
            "Building wheels for collected packages: imagehash\n",
            "  Building wheel for imagehash (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for imagehash: filename=ImageHash-4.2.1-py2.py3-none-any.whl size=295206 sha256=30fd2dd2d41e17fa925cd317efd1157e8ca6d205f2fe9f984d92e80d903531da\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/d5/59/5e3e297533ddb09407769762985d134135064c6831e29a914e\n",
            "Successfully built imagehash\n",
            "Installing collected packages: imagehash\n",
            "Successfully installed imagehash-4.2.1\n"
          ]
        }
      ],
      "source": [
        "!pip install imagehash"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Z5iM36B0Zn4",
        "outputId": "4f94c3a8-133b-4ead-a362-06c0a4796983"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting json_lines\n",
            "  Downloading json_lines-0.5.0-py2.py3-none-any.whl (6.8 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from json_lines) (1.15.0)\n",
            "Installing collected packages: json-lines\n",
            "Successfully installed json-lines-0.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install json_lines"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda install numpy==1.14.3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U17jJJDpSGDD",
        "outputId": "917e7caf-d88d-433e-cf51-8f83185aaba2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: conda: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGhW2y8P0dz7",
        "outputId": "c9f49533-b50e-4283-c7b5-cc87b7f7bb63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting paddlepaddle-gpu==1.8.3.post97\n",
            "  Downloading paddlepaddle_gpu-1.8.3.post97-cp37-cp37m-manylinux1_x86_64.whl (404.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 404.9 MB 15 kB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from paddlepaddle-gpu==1.8.3.post97) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from paddlepaddle-gpu==1.8.3.post97) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.7/dist-packages (from paddlepaddle-gpu==1.8.3.post97) (1.21.6)\n",
            "Requirement already satisfied: protobuf>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from paddlepaddle-gpu==1.8.3.post97) (3.17.3)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from paddlepaddle-gpu==1.8.3.post97) (0.10.1)\n",
            "Requirement already satisfied: pathlib in /usr/local/lib/python3.7/dist-packages (from paddlepaddle-gpu==1.8.3.post97) (1.0.1)\n",
            "Collecting rarfile\n",
            "  Downloading rarfile-4.0-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from paddlepaddle-gpu==1.8.3.post97) (4.1.2.30)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from paddlepaddle-gpu==1.8.3.post97) (3.13)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from paddlepaddle-gpu==1.8.3.post97) (3.2.5)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.7/dist-packages (from paddlepaddle-gpu==1.8.3.post97) (3.2.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from paddlepaddle-gpu==1.8.3.post97) (4.4.2)\n",
            "Collecting scipy<=1.3.1\n",
            "  Downloading scipy-1.3.1-cp37-cp37m-manylinux1_x86_64.whl (25.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.2 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from paddlepaddle-gpu==1.8.3.post97) (7.1.2)\n",
            "Collecting objgraph\n",
            "  Downloading objgraph-3.5.0-py2.py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: gast>=0.3.3 in /usr/local/lib/python3.7/dist-packages (from paddlepaddle-gpu==1.8.3.post97) (0.5.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from paddlepaddle-gpu==1.8.3.post97) (3.2.2)\n",
            "Collecting funcsigs\n",
            "  Downloading funcsigs-1.0.2-py2.py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.7/dist-packages (from paddlepaddle-gpu==1.8.3.post97) (0.8.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->paddlepaddle-gpu==1.8.3.post97) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->paddlepaddle-gpu==1.8.3.post97) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->paddlepaddle-gpu==1.8.3.post97) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->paddlepaddle-gpu==1.8.3.post97) (2.10)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->paddlepaddle-gpu==1.8.3.post97) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->paddlepaddle-gpu==1.8.3.post97) (3.0.8)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->paddlepaddle-gpu==1.8.3.post97) (1.4.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->paddlepaddle-gpu==1.8.3.post97) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->paddlepaddle-gpu==1.8.3.post97) (4.2.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prettytable->paddlepaddle-gpu==1.8.3.post97) (0.2.5)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from prettytable->paddlepaddle-gpu==1.8.3.post97) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->prettytable->paddlepaddle-gpu==1.8.3.post97) (3.8.0)\n",
            "Installing collected packages: scipy, rarfile, objgraph, funcsigs, paddlepaddle-gpu\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed funcsigs-1.0.2 objgraph-3.5.0 paddlepaddle-gpu-1.8.3.post97 rarfile-4.0 scipy-1.3.1\n"
          ]
        }
      ],
      "source": [
        "!pip install paddlepaddle-gpu==1.8.3.post97\n",
        "#!pip install pip install paddlepaddle-gpu "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda install pandas==1.0.5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qv0SM3fqTEay",
        "outputId": "792d57cd-3401-4fa8-c5d4-053bfa880584"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: conda: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda install json_lines"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAtokdlZTflQ",
        "outputId": "b09eb6b7-2ad5-4ae6-88e0-11ed23687bd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: conda: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rp2Wwp620iwW"
      },
      "source": [
        "#### <font color='#33F3FF'> Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YtCZIrSNnM3-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir(\"/content/vilio/ernie-vil\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "StFJL__0Zu25"
      },
      "outputs": [],
      "source": [
        "#!bash /content/vilio/ernie-vil/bash/training/ES/hm_ES.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbkyYWjJZioj",
        "outputId": "3f81fb87-e6fc-4d38-fc02-3b2524131315"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+ TASK_NAME=hm\n",
            "+ CONF_FILE=conf/hm/model_conf_hm\n",
            "+ VOCAB_PATH=/content/vilio/ernie-vil/data/erniesmall/vocab.txt\n",
            "+ ERNIE_VIL_CONFIG=/content/vilio/ernie-vil/data/erniesmall/ernie_vil_config.base.json\n",
            "+ PRETRAIN_MODELS=/content/vilio/ernie-vil/data/erniesmall/params\n",
            "+ SPLIT=train\n",
            "+ STOP=2500\n",
            "+ source conf/hm/model_conf_hm\n",
            "++ output_model_path=output_hm\n",
            "++ lr_scheduler=manual_warmup_decay\n",
            "++ decay_steps='13308;19962'\n",
            "++ lr_decay_ratio=0.1\n",
            "++ num_train_steps=5000\n",
            "++ SAVE_STEPS=1250\n",
            "++ WARMUP_STEPS=500\n",
            "++ BATCH_SIZE=8\n",
            "++ VALID_STEPS=20000\n",
            "++ LR_RATE=1e-5\n",
            "++ WEIGHT_DECAY=0.01\n",
            "++ MAX_LEN=128\n",
            "+ CUDA_VISIBLE_DEVICES=1\n",
            "+ export FLAGS_fast_eager_deletion_mode=1\n",
            "+ FLAGS_fast_eager_deletion_mode=1\n",
            "+ export FLAGS_eager_delete_tensor_gb=0.0\n",
            "+ FLAGS_eager_delete_tensor_gb=0.0\n",
            "+ export FLAGS_fraction_of_gpu_memory_to_use=0.98\n",
            "+ FLAGS_fraction_of_gpu_memory_to_use=0.98\n",
            "++ echo True\n",
            "++ tr '[A-Z]' '[a-z]'\n",
            "+ e_executor=true\n",
            "++ echo False\n",
            "++ tr '[A-Z]' '[a-z]'\n",
            "+ use_fuse=false\n",
            "+ [[ false == \\t\\r\\u\\e ]]\n",
            "+ TASK_GROUP_JSON=/content/vilio/ernie-vil/conf/hm/task_hm.json\n",
            "++ echo 1\n",
            "++ awk '-F\\t' '{len=split($0,vec,\",\");print len}'\n",
            "+ gpu_cnt=1\n",
            "+ echo gpu_cnt, 1\n",
            "gpu_cnt, 1\n",
            "+ python /content/vilio/ernie-vil/finetune.py --use_cuda True --is_distributed False --use_fast_executor true --nccl_comm_num 1 --batch_size 8 --do_train True --do_test False --task_name hm --vocab_path /content/vilio/ernie-vil/data/erniesmall/vocab.txt --task_group_json /content/vilio/ernie-vil/conf/hm/task_hm.json --lr_scheduler manual_warmup_decay --decay_steps '13308;19962' --lr_decay_ratio 0.1 --num_train_steps 5000 --checkpoints output_hm --save_steps 1250 --init_checkpoint /content/vilio/ernie-vil/data/erniesmall/params --ernie_config_path /content/vilio/ernie-vil/data/erniesmall/ernie_vil_config.base.json --learning_rate 1e-5 --warmup_steps 500 --weight_decay 0.01 --max_seq_len 128 --validation_steps 20000 --skip_steps 10 --split train --stop_steps 2500\n",
            "-----------  Configuration Arguments -----------\n",
            "batch_size: 8\n",
            "checkpoints: output_hm\n",
            "combine: False\n",
            "decay_steps: 13308;19962\n",
            "do_test: False\n",
            "do_train: True\n",
            "do_val: False\n",
            "epoch: 100\n",
            "ernie_config_path: /content/vilio/ernie-vil/data/erniesmall/ernie_vil_config.base.json\n",
            "exp: experiment\n",
            "feature_size: 2048\n",
            "fusion_method: sum\n",
            "hierarchical_allreduce_inter_nranks: 8\n",
            "init_checkpoint: /content/vilio/ernie-vil/data/erniesmall/params\n",
            "is_distributed: False\n",
            "learning_rate: 1e-05\n",
            "lr_decay_dict_file: \n",
            "lr_decay_ratio: 0.1\n",
            "lr_scheduler: manual_warmup_decay\n",
            "max_img_len: 100\n",
            "max_seq_len: 128\n",
            "nccl_comm_num: 1\n",
            "num_features: 50\n",
            "num_train_steps: 5000\n",
            "output_file: \n",
            "result_file: ./res_tmp\n",
            "save_steps: 1250\n",
            "skip_steps: 10\n",
            "split: train\n",
            "stop_steps: 2500\n",
            "subtrain: False\n",
            "task_group_json: /content/vilio/ernie-vil/conf/hm/task_hm.json\n",
            "task_name: hm\n",
            "test_filelist: \n",
            "test_split: test\n",
            "train_filelist: \n",
            "use_cuda: True\n",
            "use_fast_executor: True\n",
            "use_fuse: False\n",
            "use_gpu: True\n",
            "use_hierarchical_allreduce: False\n",
            "valid_filelist: \n",
            "validation_steps: 20000\n",
            "verbose: False\n",
            "vocab_path: /content/vilio/ernie-vil/data/erniesmall/vocab.txt\n",
            "warmup_steps: 500\n",
            "weight_decay: 0.01\n",
            "------------------------------------------------\n",
            "Preparing...\n",
            "finetuning tasks start\n",
            "attention_probs_dropout_prob: 0.1\n",
            "class_attr_size: 401\n",
            "class_size: 1601\n",
            "co_hidden_size: 1024\n",
            "co_intermediate_size: 1024\n",
            "co_num_attention_heads: 8\n",
            "hidden_act: gelu\n",
            "hidden_dropout_prob: 0.1\n",
            "hidden_size: 768\n",
            "initializer_range: 0.02\n",
            "max_position_embeddings: 512\n",
            "num_attention_heads: 12\n",
            "num_hidden_layers: 12\n",
            "sent_type_vocab_size: 4\n",
            "t_biattention_id: [6, 7, 8, 9, 10, 11]\n",
            "task_type_vocab_size: 16\n",
            "type_vocab_size: 2\n",
            "v_biattention_id: [0, 1, 2, 3, 4, 5]\n",
            "v_hidden_size: 1024\n",
            "v_intermediate_size: 1024\n",
            "v_num_attention_heads: 8\n",
            "vocab_size: 30522\n",
            "------------------------------------------------\n",
            "task:  [{'task': 'HM', 'num_choice': 1, 'annotations_jsonpath_train': '/content/vilio/ernie-vil/data/hm/train.jsonl', 'annotations_jsonpath_dev_seen': '/content/vilio/ernie-vil/data/hm/dev_seenlong.jsonl', 'annotations_jsonpath_traindev': '/content/vilio/ernie-vil/data/hm/traindev.jsonl', 'annotations_jsonpath_test_unseen': '/content/vilio/ernie-vil/data/hm/test_unseenlong.jsonl', 'annotations_jsonpath_test_seen': '/content/vilio/ernie-vil/data/hm/test_seenlong.jsonl', 'feature_lmdb_path': '/content/vilio/ernie-vil/data/hm/HM_img.tsv', 'gt_feature_lmdb_path': '/content/vilio/ernie-vil/data/hm/HM_gt_img.tsv', 'unisex_names_table': '/content/vilio/ernie-vil/data/vcr/unisex_names_table.csv', 'Proprocessor': 'PreprocessorBasic', 'tokenizer_name': 'FullTokenizer', 'fusion_method': 'mul', 'dropout_rate': 0.1, 'max_seq_len': 128, 'use_gt_fea': True, 'shufflekeep_across_task': True, 'shuffle_every_epoch': True, 'task_weight': 1.0, 'task_prefix': 'hm'}]\n",
            "2022-05-10 14:13:39,861-WARNING: paddle.fluid.layers.py_reader() may be deprecated in the near future. Please use paddle.fluid.io.DataLoader.from_generator() instead.\n",
            "/usr/local/lib/python3.7/dist-packages/paddle/fluid/clip.py:779: UserWarning: Caution! 'set_gradient_clip' is not recommended and may be deprecated in future! We recommend a new strategy: set 'grad_clip' when initializing the 'optimizer'. This method can reduce the mistakes, please refer to documention of 'optimizer'.\n",
            "  warnings.warn(\"Caution! 'set_gradient_clip' is not recommended \"\n",
            "theoretical memory usage: \n",
            "(18209.21138906479, 19076.31669330597, 'MB')\n",
            "args.is_distributed: False\n",
            "W0510 14:13:44.125491   530 device_context.cc:252] Please NOTE: device: 0, CUDA Capability: 60, Driver API Version: 11.2, Runtime API Version: 9.0\n",
            "W0510 14:13:44.430910   530 device_context.cc:260] device: 0, cuDNN Version: 7.6.\n",
            "Load pretraining parameters from /content/vilio/ernie-vil/data/erniesmall/params.\n",
            "SPLIT: train\n",
            "Start to load Faster-RCNN detected objects from /content/vilio/ernie-vil/data/hm/HM_img.tsv\n",
            "Loaded 8596 images in file /content/vilio/ernie-vil/data/hm/HM_img.tsv in 84 seconds.\n",
            "Start to load Faster-RCNN detected objects from /content/vilio/ernie-vil/data/hm/HM_gt_img.tsv\n",
            "Loaded 8596 images in file /content/vilio/ernie-vil/data/hm/HM_gt_img.tsv in 60 seconds.\n",
            "Load 8596 data from split(s) /content/vilio/ernie-vil/data/hm/train.jsonl.\n",
            "use gt featurre\n",
            "LEN:  8596\n",
            "shuffle epoch 0\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 10, loss: 0.741401, acc: 0.750000\n",
            "steps: 10\n",
            "save_steps: 1250\n",
            "20220510 14:16:23 current learning_rate:0.00000018\n",
            "used_time: 0.23634648323059082\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 20, loss: 0.691977, acc: 0.500000\n",
            "steps: 20\n",
            "save_steps: 1250\n",
            "20220510 14:16:24 current learning_rate:0.00000038\n",
            "used_time: 0.20966434478759766\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 30, loss: 0.696807, acc: 0.625000\n",
            "steps: 30\n",
            "save_steps: 1250\n",
            "20220510 14:16:26 current learning_rate:0.00000058\n",
            "used_time: 0.23759984970092773\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 40, loss: 0.717561, acc: 0.750000\n",
            "steps: 40\n",
            "save_steps: 1250\n",
            "20220510 14:16:28 current learning_rate:0.00000078\n",
            "used_time: 0.1914830207824707\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 50, loss: 0.693978, acc: 0.750000\n",
            "steps: 50\n",
            "save_steps: 1250\n",
            "20220510 14:16:30 current learning_rate:0.00000098\n",
            "used_time: 0.1983795166015625\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 60, loss: 0.709299, acc: 0.500000\n",
            "steps: 60\n",
            "save_steps: 1250\n",
            "20220510 14:16:32 current learning_rate:0.00000118\n",
            "used_time: 0.18543577194213867\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 70, loss: 0.654986, acc: 0.875000\n",
            "steps: 70\n",
            "save_steps: 1250\n",
            "20220510 14:16:34 current learning_rate:0.00000138\n",
            "used_time: 0.20781183242797852\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 80, loss: 0.668421, acc: 0.625000\n",
            "steps: 80\n",
            "save_steps: 1250\n",
            "20220510 14:16:36 current learning_rate:0.00000158\n",
            "used_time: 0.19083213806152344\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 90, loss: 0.755383, acc: 0.375000\n",
            "steps: 90\n",
            "save_steps: 1250\n",
            "20220510 14:16:38 current learning_rate:0.00000178\n",
            "used_time: 0.173187255859375\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 100, loss: 0.589700, acc: 0.750000\n",
            "steps: 100\n",
            "save_steps: 1250\n",
            "20220510 14:16:40 current learning_rate:0.00000198\n",
            "used_time: 0.20980548858642578\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 110, loss: 0.559522, acc: 0.875000\n",
            "steps: 110\n",
            "save_steps: 1250\n",
            "20220510 14:16:42 current learning_rate:0.00000218\n",
            "used_time: 0.21217870712280273\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 120, loss: 0.585685, acc: 0.875000\n",
            "steps: 120\n",
            "save_steps: 1250\n",
            "20220510 14:16:44 current learning_rate:0.00000238\n",
            "used_time: 0.17301607131958008\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 130, loss: 0.575157, acc: 0.750000\n",
            "steps: 130\n",
            "save_steps: 1250\n",
            "20220510 14:16:46 current learning_rate:0.00000258\n",
            "used_time: 0.20948576927185059\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 140, loss: 0.495474, acc: 0.875000\n",
            "steps: 140\n",
            "save_steps: 1250\n",
            "20220510 14:16:48 current learning_rate:0.00000278\n",
            "used_time: 0.18827295303344727\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 150, loss: 0.521147, acc: 0.875000\n",
            "steps: 150\n",
            "save_steps: 1250\n",
            "20220510 14:16:50 current learning_rate:0.00000298\n",
            "used_time: 0.17351341247558594\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 160, loss: 0.615356, acc: 0.625000\n",
            "steps: 160\n",
            "save_steps: 1250\n",
            "20220510 14:16:52 current learning_rate:0.00000318\n",
            "used_time: 0.17557239532470703\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 170, loss: 0.609877, acc: 0.625000\n",
            "steps: 170\n",
            "save_steps: 1250\n",
            "20220510 14:16:54 current learning_rate:0.00000338\n",
            "used_time: 0.18170785903930664\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 180, loss: 0.689257, acc: 0.750000\n",
            "steps: 180\n",
            "save_steps: 1250\n",
            "20220510 14:16:55 current learning_rate:0.00000358\n",
            "used_time: 0.18181467056274414\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 190, loss: 0.521727, acc: 0.750000\n",
            "steps: 190\n",
            "save_steps: 1250\n",
            "20220510 14:16:57 current learning_rate:0.00000378\n",
            "used_time: 0.19211959838867188\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 200, loss: 0.592006, acc: 0.500000\n",
            "steps: 200\n",
            "save_steps: 1250\n",
            "20220510 14:16:59 current learning_rate:0.00000398\n",
            "used_time: 0.1775493621826172\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 210, loss: 0.593204, acc: 0.500000\n",
            "steps: 210\n",
            "save_steps: 1250\n",
            "20220510 14:17:01 current learning_rate:0.00000418\n",
            "used_time: 0.1960148811340332\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 220, loss: 0.594709, acc: 0.500000\n",
            "steps: 220\n",
            "save_steps: 1250\n",
            "20220510 14:17:03 current learning_rate:0.00000438\n",
            "used_time: 0.17963027954101562\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 230, loss: 0.588312, acc: 0.625000\n",
            "steps: 230\n",
            "save_steps: 1250\n",
            "20220510 14:17:05 current learning_rate:0.00000458\n",
            "used_time: 0.17043447494506836\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 240, loss: 0.634475, acc: 0.625000\n",
            "steps: 240\n",
            "save_steps: 1250\n",
            "20220510 14:17:07 current learning_rate:0.00000478\n",
            "used_time: 0.192291259765625\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 250, loss: 0.798632, acc: 0.250000\n",
            "steps: 250\n",
            "save_steps: 1250\n",
            "20220510 14:17:09 current learning_rate:0.00000498\n",
            "used_time: 0.17462539672851562\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 260, loss: 0.703868, acc: 0.500000\n",
            "steps: 260\n",
            "save_steps: 1250\n",
            "20220510 14:17:11 current learning_rate:0.00000518\n",
            "used_time: 0.25913453102111816\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 270, loss: 0.508587, acc: 0.750000\n",
            "steps: 270\n",
            "save_steps: 1250\n",
            "20220510 14:17:13 current learning_rate:0.00000538\n",
            "used_time: 0.17564702033996582\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 280, loss: 0.761163, acc: 0.500000\n",
            "steps: 280\n",
            "save_steps: 1250\n",
            "20220510 14:17:15 current learning_rate:0.00000558\n",
            "used_time: 0.2558901309967041\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 290, loss: 0.665099, acc: 0.625000\n",
            "steps: 290\n",
            "save_steps: 1250\n",
            "20220510 14:17:17 current learning_rate:0.00000578\n",
            "used_time: 0.2048506736755371\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 300, loss: 0.498112, acc: 0.750000\n",
            "steps: 300\n",
            "save_steps: 1250\n",
            "20220510 14:17:19 current learning_rate:0.00000598\n",
            "used_time: 0.20351099967956543\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 310, loss: 0.392861, acc: 0.625000\n",
            "steps: 310\n",
            "save_steps: 1250\n",
            "20220510 14:17:20 current learning_rate:0.00000618\n",
            "used_time: 0.172959566116333\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 320, loss: 0.738931, acc: 0.500000\n",
            "steps: 320\n",
            "save_steps: 1250\n",
            "20220510 14:17:22 current learning_rate:0.00000638\n",
            "used_time: 0.2068173885345459\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 330, loss: 0.638656, acc: 0.500000\n",
            "steps: 330\n",
            "save_steps: 1250\n",
            "20220510 14:17:24 current learning_rate:0.00000658\n",
            "used_time: 0.1830301284790039\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 340, loss: 0.796134, acc: 0.500000\n",
            "steps: 340\n",
            "save_steps: 1250\n",
            "20220510 14:17:26 current learning_rate:0.00000678\n",
            "used_time: 0.18795251846313477\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 350, loss: 0.406164, acc: 0.875000\n",
            "steps: 350\n",
            "save_steps: 1250\n",
            "20220510 14:17:28 current learning_rate:0.00000698\n",
            "used_time: 0.1729133129119873\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 360, loss: 0.569716, acc: 0.625000\n",
            "steps: 360\n",
            "save_steps: 1250\n",
            "20220510 14:17:30 current learning_rate:0.00000718\n",
            "used_time: 0.17386221885681152\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 370, loss: 0.556417, acc: 1.000000\n",
            "steps: 370\n",
            "save_steps: 1250\n",
            "20220510 14:17:32 current learning_rate:0.00000738\n",
            "used_time: 0.1800823211669922\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 380, loss: 0.805424, acc: 0.750000\n",
            "steps: 380\n",
            "save_steps: 1250\n",
            "20220510 14:17:34 current learning_rate:0.00000758\n",
            "used_time: 0.25008702278137207\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 390, loss: 1.153107, acc: 0.375000\n",
            "steps: 390\n",
            "save_steps: 1250\n",
            "20220510 14:17:36 current learning_rate:0.00000778\n",
            "used_time: 0.20543217658996582\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 400, loss: 0.483274, acc: 0.750000\n",
            "steps: 400\n",
            "save_steps: 1250\n",
            "20220510 14:17:38 current learning_rate:0.00000798\n",
            "used_time: 0.2883188724517822\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 410, loss: 0.321408, acc: 0.750000\n",
            "steps: 410\n",
            "save_steps: 1250\n",
            "20220510 14:17:40 current learning_rate:0.00000818\n",
            "used_time: 0.2051239013671875\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 420, loss: 0.466448, acc: 0.875000\n",
            "steps: 420\n",
            "save_steps: 1250\n",
            "20220510 14:17:42 current learning_rate:0.00000838\n",
            "used_time: 0.17268872261047363\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 430, loss: 0.469630, acc: 0.750000\n",
            "steps: 430\n",
            "save_steps: 1250\n",
            "20220510 14:17:44 current learning_rate:0.00000858\n",
            "used_time: 0.20751070976257324\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 440, loss: 0.583087, acc: 0.375000\n",
            "steps: 440\n",
            "save_steps: 1250\n",
            "20220510 14:17:45 current learning_rate:0.00000878\n",
            "used_time: 0.1756596565246582\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 450, loss: 0.568614, acc: 0.375000\n",
            "steps: 450\n",
            "save_steps: 1250\n",
            "20220510 14:17:47 current learning_rate:0.00000898\n",
            "used_time: 0.2014303207397461\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 460, loss: 0.842694, acc: 0.625000\n",
            "steps: 460\n",
            "save_steps: 1250\n",
            "20220510 14:17:49 current learning_rate:0.00000918\n",
            "used_time: 0.18793153762817383\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 470, loss: 0.645855, acc: 0.625000\n",
            "steps: 470\n",
            "save_steps: 1250\n",
            "20220510 14:17:51 current learning_rate:0.00000938\n",
            "used_time: 0.20305085182189941\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 480, loss: 0.364390, acc: 0.625000\n",
            "steps: 480\n",
            "save_steps: 1250\n",
            "20220510 14:17:53 current learning_rate:0.00000958\n",
            "used_time: 0.16759920120239258\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 490, loss: 0.815866, acc: 0.500000\n",
            "steps: 490\n",
            "save_steps: 1250\n",
            "20220510 14:17:55 current learning_rate:0.00000978\n",
            "used_time: 0.1888411045074463\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 500, loss: 0.653140, acc: 0.375000\n",
            "steps: 500\n",
            "save_steps: 1250\n",
            "Train-RCAC 0.8270944741532977\n",
            "20220510 14:17:57 current learning_rate:0.00000998\n",
            "used_time: 0.19580483436584473\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 510, loss: 0.439931, acc: 0.875000\n",
            "steps: 510\n",
            "save_steps: 1250\n",
            "20220510 14:17:59 current learning_rate:0.00001000\n",
            "used_time: 0.1912374496459961\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 520, loss: 0.629793, acc: 0.625000\n",
            "steps: 520\n",
            "save_steps: 1250\n",
            "20220510 14:18:01 current learning_rate:0.00001000\n",
            "used_time: 0.20794677734375\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 530, loss: 0.636418, acc: 0.625000\n",
            "steps: 530\n",
            "save_steps: 1250\n",
            "20220510 14:18:03 current learning_rate:0.00001000\n",
            "used_time: 0.19388961791992188\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 540, loss: 0.340062, acc: 0.500000\n",
            "steps: 540\n",
            "save_steps: 1250\n",
            "20220510 14:18:05 current learning_rate:0.00001000\n",
            "used_time: 0.20050454139709473\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 550, loss: 0.642058, acc: 0.500000\n",
            "steps: 550\n",
            "save_steps: 1250\n",
            "20220510 14:18:07 current learning_rate:0.00001000\n",
            "used_time: 0.18819880485534668\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 560, loss: 0.311953, acc: 0.750000\n",
            "steps: 560\n",
            "save_steps: 1250\n",
            "20220510 14:18:09 current learning_rate:0.00001000\n",
            "used_time: 0.16882944107055664\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 570, loss: 0.162722, acc: 0.875000\n",
            "steps: 570\n",
            "save_steps: 1250\n",
            "20220510 14:18:11 current learning_rate:0.00001000\n",
            "used_time: 0.20707321166992188\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 580, loss: 0.177924, acc: 0.625000\n",
            "steps: 580\n",
            "save_steps: 1250\n",
            "20220510 14:18:12 current learning_rate:0.00001000\n",
            "used_time: 0.21301031112670898\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 590, loss: 0.257119, acc: 0.625000\n",
            "steps: 590\n",
            "save_steps: 1250\n",
            "20220510 14:18:14 current learning_rate:0.00001000\n",
            "used_time: 0.19672083854675293\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 600, loss: 0.437623, acc: 0.750000\n",
            "steps: 600\n",
            "save_steps: 1250\n",
            "20220510 14:18:16 current learning_rate:0.00001000\n",
            "used_time: 0.1872856616973877\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 610, loss: 0.978293, acc: 0.375000\n",
            "steps: 610\n",
            "save_steps: 1250\n",
            "20220510 14:18:18 current learning_rate:0.00001000\n",
            "used_time: 0.1840357780456543\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 620, loss: 0.495728, acc: 0.750000\n",
            "steps: 620\n",
            "save_steps: 1250\n",
            "20220510 14:18:20 current learning_rate:0.00001000\n",
            "used_time: 0.19882988929748535\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 630, loss: 0.482298, acc: 0.625000\n",
            "steps: 630\n",
            "save_steps: 1250\n",
            "20220510 14:18:22 current learning_rate:0.00001000\n",
            "used_time: 0.19513320922851562\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 640, loss: 0.101652, acc: 0.750000\n",
            "steps: 640\n",
            "save_steps: 1250\n",
            "20220510 14:18:24 current learning_rate:0.00001000\n",
            "used_time: 0.189361572265625\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 650, loss: 0.728504, acc: 0.875000\n",
            "steps: 650\n",
            "save_steps: 1250\n",
            "20220510 14:18:26 current learning_rate:0.00001000\n",
            "used_time: 0.20110821723937988\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 660, loss: 0.334021, acc: 1.000000\n",
            "steps: 660\n",
            "save_steps: 1250\n",
            "20220510 14:18:28 current learning_rate:0.00001000\n",
            "used_time: 0.17490816116333008\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 670, loss: 0.611394, acc: 0.625000\n",
            "steps: 670\n",
            "save_steps: 1250\n",
            "20220510 14:18:30 current learning_rate:0.00001000\n",
            "used_time: 0.1904902458190918\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 680, loss: 0.411179, acc: 0.625000\n",
            "steps: 680\n",
            "save_steps: 1250\n",
            "20220510 14:18:32 current learning_rate:0.00001000\n",
            "used_time: 0.19269657135009766\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 690, loss: 0.657009, acc: 0.625000\n",
            "steps: 690\n",
            "save_steps: 1250\n",
            "20220510 14:18:34 current learning_rate:0.00001000\n",
            "used_time: 0.18190574645996094\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 700, loss: 0.228537, acc: 1.000000\n",
            "steps: 700\n",
            "save_steps: 1250\n",
            "20220510 14:18:36 current learning_rate:0.00001000\n",
            "used_time: 0.18506145477294922\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 710, loss: 0.340712, acc: 0.625000\n",
            "steps: 710\n",
            "save_steps: 1250\n",
            "20220510 14:18:37 current learning_rate:0.00001000\n",
            "used_time: 0.2081007957458496\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 720, loss: 0.511531, acc: 0.500000\n",
            "steps: 720\n",
            "save_steps: 1250\n",
            "20220510 14:18:39 current learning_rate:0.00001000\n",
            "used_time: 0.18456745147705078\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 730, loss: 0.491817, acc: 0.500000\n",
            "steps: 730\n",
            "save_steps: 1250\n",
            "20220510 14:18:41 current learning_rate:0.00001000\n",
            "used_time: 0.19421863555908203\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 740, loss: 0.206541, acc: 0.500000\n",
            "steps: 740\n",
            "save_steps: 1250\n",
            "20220510 14:18:43 current learning_rate:0.00001000\n",
            "used_time: 0.16497397422790527\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 750, loss: 0.337435, acc: 0.750000\n",
            "steps: 750\n",
            "save_steps: 1250\n",
            "20220510 14:18:45 current learning_rate:0.00001000\n",
            "used_time: 0.16863036155700684\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 760, loss: 0.124244, acc: 0.875000\n",
            "steps: 760\n",
            "save_steps: 1250\n",
            "20220510 14:18:47 current learning_rate:0.00001000\n",
            "used_time: 0.18768310546875\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 770, loss: 0.242492, acc: 1.000000\n",
            "steps: 770\n",
            "save_steps: 1250\n",
            "20220510 14:18:49 current learning_rate:0.00001000\n",
            "used_time: 0.19075536727905273\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 780, loss: 0.753567, acc: 0.375000\n",
            "steps: 780\n",
            "save_steps: 1250\n",
            "20220510 14:18:51 current learning_rate:0.00001000\n",
            "used_time: 0.1885700225830078\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 790, loss: 0.369955, acc: 0.500000\n",
            "steps: 790\n",
            "save_steps: 1250\n",
            "20220510 14:18:53 current learning_rate:0.00001000\n",
            "used_time: 0.19962334632873535\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 800, loss: 0.320477, acc: 0.625000\n",
            "steps: 800\n",
            "save_steps: 1250\n",
            "20220510 14:18:55 current learning_rate:0.00001000\n",
            "used_time: 0.21669363975524902\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 810, loss: 0.490636, acc: 0.750000\n",
            "steps: 810\n",
            "save_steps: 1250\n",
            "20220510 14:18:56 current learning_rate:0.00001000\n",
            "used_time: 0.21763229370117188\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 820, loss: 0.928543, acc: 0.625000\n",
            "steps: 820\n",
            "save_steps: 1250\n",
            "20220510 14:18:58 current learning_rate:0.00001000\n",
            "used_time: 0.18225622177124023\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 830, loss: 0.434478, acc: 0.875000\n",
            "steps: 830\n",
            "save_steps: 1250\n",
            "20220510 14:19:00 current learning_rate:0.00001000\n",
            "used_time: 0.1923534870147705\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 840, loss: 0.534842, acc: 0.875000\n",
            "steps: 840\n",
            "save_steps: 1250\n",
            "20220510 14:19:02 current learning_rate:0.00001000\n",
            "used_time: 0.2550647258758545\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 850, loss: 0.254367, acc: 0.625000\n",
            "steps: 850\n",
            "save_steps: 1250\n",
            "20220510 14:19:04 current learning_rate:0.00001000\n",
            "used_time: 0.1952810287475586\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 860, loss: 0.105679, acc: 0.750000\n",
            "steps: 860\n",
            "save_steps: 1250\n",
            "20220510 14:19:06 current learning_rate:0.00001000\n",
            "used_time: 0.17418527603149414\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 870, loss: 0.524008, acc: 0.625000\n",
            "steps: 870\n",
            "save_steps: 1250\n",
            "20220510 14:19:08 current learning_rate:0.00001000\n",
            "used_time: 0.21108222007751465\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 880, loss: 0.312556, acc: 0.500000\n",
            "steps: 880\n",
            "save_steps: 1250\n",
            "20220510 14:19:10 current learning_rate:0.00001000\n",
            "used_time: 0.2165372371673584\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 890, loss: 0.290179, acc: 0.625000\n",
            "steps: 890\n",
            "save_steps: 1250\n",
            "20220510 14:19:12 current learning_rate:0.00001000\n",
            "used_time: 0.18065595626831055\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 900, loss: 1.020022, acc: 0.625000\n",
            "steps: 900\n",
            "save_steps: 1250\n",
            "20220510 14:19:14 current learning_rate:0.00001000\n",
            "used_time: 0.20019984245300293\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 910, loss: 0.959946, acc: 0.500000\n",
            "steps: 910\n",
            "save_steps: 1250\n",
            "20220510 14:19:16 current learning_rate:0.00001000\n",
            "used_time: 0.1839885711669922\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 920, loss: 0.781920, acc: 0.625000\n",
            "steps: 920\n",
            "save_steps: 1250\n",
            "20220510 14:19:18 current learning_rate:0.00001000\n",
            "used_time: 0.16250181198120117\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 930, loss: 0.418028, acc: 0.750000\n",
            "steps: 930\n",
            "save_steps: 1250\n",
            "20220510 14:19:20 current learning_rate:0.00001000\n",
            "used_time: 0.224531888961792\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 940, loss: 0.740601, acc: 0.750000\n",
            "steps: 940\n",
            "save_steps: 1250\n",
            "20220510 14:19:21 current learning_rate:0.00001000\n",
            "used_time: 0.207106351852417\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 950, loss: 0.374684, acc: 0.375000\n",
            "steps: 950\n",
            "save_steps: 1250\n",
            "20220510 14:19:23 current learning_rate:0.00001000\n",
            "used_time: 0.2087090015411377\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 960, loss: 0.198871, acc: 0.625000\n",
            "steps: 960\n",
            "save_steps: 1250\n",
            "20220510 14:19:25 current learning_rate:0.00001000\n",
            "used_time: 0.18675851821899414\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 970, loss: 0.834473, acc: 0.875000\n",
            "steps: 970\n",
            "save_steps: 1250\n",
            "20220510 14:19:27 current learning_rate:0.00001000\n",
            "used_time: 0.24886250495910645\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 980, loss: 0.155722, acc: 0.625000\n",
            "steps: 980\n",
            "save_steps: 1250\n",
            "20220510 14:19:29 current learning_rate:0.00001000\n",
            "used_time: 0.21020793914794922\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 990, loss: 0.903707, acc: 0.375000\n",
            "steps: 990\n",
            "save_steps: 1250\n",
            "20220510 14:19:31 current learning_rate:0.00001000\n",
            "used_time: 0.16743946075439453\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1000, loss: 0.578054, acc: 0.625000\n",
            "steps: 1000\n",
            "save_steps: 1250\n",
            "Train-RCAC 0.8044871794871795\n",
            "20220510 14:19:33 current learning_rate:0.00001000\n",
            "used_time: 0.17357540130615234\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1010, loss: 0.656069, acc: 0.625000\n",
            "steps: 1010\n",
            "save_steps: 1250\n",
            "20220510 14:19:35 current learning_rate:0.00001000\n",
            "used_time: 0.21834468841552734\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1020, loss: 0.769590, acc: 0.500000\n",
            "steps: 1020\n",
            "save_steps: 1250\n",
            "20220510 14:19:37 current learning_rate:0.00001000\n",
            "used_time: 0.20255398750305176\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1030, loss: 0.192347, acc: 0.875000\n",
            "steps: 1030\n",
            "save_steps: 1250\n",
            "20220510 14:19:39 current learning_rate:0.00001000\n",
            "used_time: 0.20273470878601074\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1040, loss: 0.278358, acc: 0.875000\n",
            "steps: 1040\n",
            "save_steps: 1250\n",
            "20220510 14:19:41 current learning_rate:0.00001000\n",
            "used_time: 0.18418478965759277\n",
            "shuffle epoch 1\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1050, loss: 0.562640, acc: 0.500000\n",
            "steps: 1050\n",
            "save_steps: 1250\n",
            "20220510 14:19:43 current learning_rate:0.00001000\n",
            "used_time: 0.19412541389465332\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1060, loss: 1.134525, acc: 0.250000\n",
            "steps: 1060\n",
            "save_steps: 1250\n",
            "20220510 14:19:44 current learning_rate:0.00001000\n",
            "used_time: 0.194627046585083\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1070, loss: 0.402435, acc: 0.500000\n",
            "steps: 1070\n",
            "save_steps: 1250\n",
            "20220510 14:19:46 current learning_rate:0.00001000\n",
            "used_time: 0.21810245513916016\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1080, loss: 0.308548, acc: 0.625000\n",
            "steps: 1080\n",
            "save_steps: 1250\n",
            "20220510 14:19:48 current learning_rate:0.00001000\n",
            "used_time: 0.18492841720581055\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1090, loss: 0.258049, acc: 0.875000\n",
            "steps: 1090\n",
            "save_steps: 1250\n",
            "20220510 14:19:50 current learning_rate:0.00001000\n",
            "used_time: 0.21457576751708984\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1100, loss: 0.304891, acc: 0.625000\n",
            "steps: 1100\n",
            "save_steps: 1250\n",
            "20220510 14:19:52 current learning_rate:0.00001000\n",
            "used_time: 0.2047135829925537\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1110, loss: 0.270037, acc: 0.625000\n",
            "steps: 1110\n",
            "save_steps: 1250\n",
            "20220510 14:19:54 current learning_rate:0.00001000\n",
            "used_time: 0.18854665756225586\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1120, loss: 0.155636, acc: 0.750000\n",
            "steps: 1120\n",
            "save_steps: 1250\n",
            "20220510 14:19:56 current learning_rate:0.00001000\n",
            "used_time: 0.19095110893249512\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1130, loss: 0.017538, acc: 0.750000\n",
            "steps: 1130\n",
            "save_steps: 1250\n",
            "20220510 14:19:58 current learning_rate:0.00001000\n",
            "used_time: 0.20096373558044434\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1140, loss: 0.298978, acc: 0.750000\n",
            "steps: 1140\n",
            "save_steps: 1250\n",
            "20220510 14:20:00 current learning_rate:0.00001000\n",
            "used_time: 0.1925828456878662\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1150, loss: 0.542836, acc: 0.500000\n",
            "steps: 1150\n",
            "save_steps: 1250\n",
            "20220510 14:20:02 current learning_rate:0.00001000\n",
            "used_time: 0.19204306602478027\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1160, loss: 0.542776, acc: 0.625000\n",
            "steps: 1160\n",
            "save_steps: 1250\n",
            "20220510 14:20:04 current learning_rate:0.00001000\n",
            "used_time: 0.20269083976745605\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1170, loss: 0.007682, acc: 0.750000\n",
            "steps: 1170\n",
            "save_steps: 1250\n",
            "20220510 14:20:06 current learning_rate:0.00001000\n",
            "used_time: 0.2199232578277588\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1180, loss: 0.415777, acc: 0.750000\n",
            "steps: 1180\n",
            "save_steps: 1250\n",
            "20220510 14:20:08 current learning_rate:0.00001000\n",
            "used_time: 0.18208813667297363\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1190, loss: 0.874394, acc: 0.500000\n",
            "steps: 1190\n",
            "save_steps: 1250\n",
            "20220510 14:20:09 current learning_rate:0.00001000\n",
            "used_time: 0.18245983123779297\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1200, loss: 0.121588, acc: 0.625000\n",
            "steps: 1200\n",
            "save_steps: 1250\n",
            "20220510 14:20:11 current learning_rate:0.00001000\n",
            "used_time: 0.2154254913330078\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1210, loss: 0.204478, acc: 0.875000\n",
            "steps: 1210\n",
            "save_steps: 1250\n",
            "20220510 14:20:13 current learning_rate:0.00001000\n",
            "used_time: 0.20548200607299805\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1220, loss: 0.358076, acc: 0.750000\n",
            "steps: 1220\n",
            "save_steps: 1250\n",
            "20220510 14:20:15 current learning_rate:0.00001000\n",
            "used_time: 0.18474125862121582\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1230, loss: 1.160554, acc: 0.625000\n",
            "steps: 1230\n",
            "save_steps: 1250\n",
            "20220510 14:20:17 current learning_rate:0.00001000\n",
            "used_time: 0.17072153091430664\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1240, loss: 0.427536, acc: 0.375000\n",
            "steps: 1240\n",
            "save_steps: 1250\n",
            "20220510 14:20:19 current learning_rate:0.00001000\n",
            "used_time: 0.20004749298095703\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1250, loss: 0.503692, acc: 0.625000\n",
            "steps: 1250\n",
            "save_steps: 1250\n",
            "20220510 14:20:21 current learning_rate:0.00001000\n",
            "save_path: output_hm/step_1250train\n",
            "used_time: 11.53239917755127\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1260, loss: 0.095442, acc: 0.625000\n",
            "steps: 1260\n",
            "save_steps: 1250\n",
            "20220510 14:20:34 current learning_rate:0.00001000\n",
            "used_time: 0.18247318267822266\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1270, loss: 0.609895, acc: 0.875000\n",
            "steps: 1270\n",
            "save_steps: 1250\n",
            "20220510 14:20:36 current learning_rate:0.00001000\n",
            "used_time: 0.16988444328308105\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1280, loss: 0.301008, acc: 0.875000\n",
            "steps: 1280\n",
            "save_steps: 1250\n",
            "20220510 14:20:38 current learning_rate:0.00001000\n",
            "used_time: 0.1695094108581543\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1290, loss: 0.396137, acc: 0.750000\n",
            "steps: 1290\n",
            "save_steps: 1250\n",
            "20220510 14:20:40 current learning_rate:0.00001000\n",
            "used_time: 0.1840806007385254\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1300, loss: 0.450728, acc: 0.500000\n",
            "steps: 1300\n",
            "save_steps: 1250\n",
            "20220510 14:20:42 current learning_rate:0.00001000\n",
            "used_time: 0.19152402877807617\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1310, loss: 0.824259, acc: 0.625000\n",
            "steps: 1310\n",
            "save_steps: 1250\n",
            "20220510 14:20:44 current learning_rate:0.00001000\n",
            "used_time: 0.20215272903442383\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1320, loss: 0.259564, acc: 0.500000\n",
            "steps: 1320\n",
            "save_steps: 1250\n",
            "20220510 14:20:46 current learning_rate:0.00001000\n",
            "used_time: 0.1765589714050293\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1330, loss: 0.114060, acc: 0.750000\n",
            "steps: 1330\n",
            "save_steps: 1250\n",
            "20220510 14:20:48 current learning_rate:0.00001000\n",
            "used_time: 0.1924588680267334\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1340, loss: 0.951838, acc: 0.750000\n",
            "steps: 1340\n",
            "save_steps: 1250\n",
            "20220510 14:20:49 current learning_rate:0.00001000\n",
            "used_time: 0.17241954803466797\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1350, loss: 0.056301, acc: 0.625000\n",
            "steps: 1350\n",
            "save_steps: 1250\n",
            "20220510 14:20:52 current learning_rate:0.00001000\n",
            "used_time: 0.19639039039611816\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1360, loss: 0.567331, acc: 0.875000\n",
            "steps: 1360\n",
            "save_steps: 1250\n",
            "20220510 14:20:53 current learning_rate:0.00001000\n",
            "used_time: 0.17850804328918457\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1370, loss: 0.054088, acc: 0.625000\n",
            "steps: 1370\n",
            "save_steps: 1250\n",
            "20220510 14:20:55 current learning_rate:0.00001000\n",
            "used_time: 0.20751142501831055\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1380, loss: 0.055089, acc: 0.375000\n",
            "steps: 1380\n",
            "save_steps: 1250\n",
            "20220510 14:20:57 current learning_rate:0.00001000\n",
            "used_time: 0.17326569557189941\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1390, loss: 0.070550, acc: 0.875000\n",
            "steps: 1390\n",
            "save_steps: 1250\n",
            "20220510 14:20:59 current learning_rate:0.00001000\n",
            "used_time: 0.17185544967651367\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1400, loss: 0.938650, acc: 0.125000\n",
            "steps: 1400\n",
            "save_steps: 1250\n",
            "20220510 14:21:01 current learning_rate:0.00001000\n",
            "used_time: 0.17111897468566895\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1410, loss: 0.078916, acc: 0.500000\n",
            "steps: 1410\n",
            "save_steps: 1250\n",
            "20220510 14:21:03 current learning_rate:0.00001000\n",
            "used_time: 0.19265079498291016\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1420, loss: 0.461661, acc: 0.875000\n",
            "steps: 1420\n",
            "save_steps: 1250\n",
            "20220510 14:21:05 current learning_rate:0.00001000\n",
            "used_time: 0.21394991874694824\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1430, loss: 0.856324, acc: 0.625000\n",
            "steps: 1430\n",
            "save_steps: 1250\n",
            "20220510 14:21:07 current learning_rate:0.00001000\n",
            "used_time: 0.1697254180908203\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1440, loss: 0.679697, acc: 0.625000\n",
            "steps: 1440\n",
            "save_steps: 1250\n",
            "20220510 14:21:09 current learning_rate:0.00001000\n",
            "used_time: 0.18398237228393555\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1450, loss: 0.587884, acc: 0.500000\n",
            "steps: 1450\n",
            "save_steps: 1250\n",
            "20220510 14:21:11 current learning_rate:0.00001000\n",
            "used_time: 0.18949484825134277\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1460, loss: 0.238770, acc: 0.875000\n",
            "steps: 1460\n",
            "save_steps: 1250\n",
            "20220510 14:21:13 current learning_rate:0.00001000\n",
            "used_time: 0.16798973083496094\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1470, loss: 0.142565, acc: 0.875000\n",
            "steps: 1470\n",
            "save_steps: 1250\n",
            "20220510 14:21:15 current learning_rate:0.00001000\n",
            "used_time: 0.18438434600830078\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1480, loss: 0.545929, acc: 0.625000\n",
            "steps: 1480\n",
            "save_steps: 1250\n",
            "20220510 14:21:17 current learning_rate:0.00001000\n",
            "used_time: 0.19213461875915527\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1490, loss: 0.542953, acc: 0.750000\n",
            "steps: 1490\n",
            "save_steps: 1250\n",
            "20220510 14:21:18 current learning_rate:0.00001000\n",
            "used_time: 0.17154526710510254\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1500, loss: 0.225454, acc: 0.625000\n",
            "steps: 1500\n",
            "save_steps: 1250\n",
            "Train-RCAC 0.8925000000000001\n",
            "20220510 14:21:20 current learning_rate:0.00001000\n",
            "used_time: 0.17986369132995605\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1510, loss: 0.255583, acc: 0.500000\n",
            "steps: 1510\n",
            "save_steps: 1250\n",
            "20220510 14:21:22 current learning_rate:0.00001000\n",
            "used_time: 0.1741809844970703\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1520, loss: 0.880022, acc: 0.875000\n",
            "steps: 1520\n",
            "save_steps: 1250\n",
            "20220510 14:21:24 current learning_rate:0.00001000\n",
            "used_time: 0.18254923820495605\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1530, loss: 0.529348, acc: 0.625000\n",
            "steps: 1530\n",
            "save_steps: 1250\n",
            "20220510 14:21:26 current learning_rate:0.00001000\n",
            "used_time: 0.19504165649414062\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1540, loss: 0.945095, acc: 0.375000\n",
            "steps: 1540\n",
            "save_steps: 1250\n",
            "20220510 14:21:28 current learning_rate:0.00001000\n",
            "used_time: 0.21484065055847168\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1550, loss: 0.595771, acc: 0.750000\n",
            "steps: 1550\n",
            "save_steps: 1250\n",
            "20220510 14:21:30 current learning_rate:0.00001000\n",
            "used_time: 0.18634343147277832\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1560, loss: 0.597225, acc: 1.000000\n",
            "steps: 1560\n",
            "save_steps: 1250\n",
            "20220510 14:21:32 current learning_rate:0.00001000\n",
            "used_time: 0.2106029987335205\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1570, loss: 0.941088, acc: 0.500000\n",
            "steps: 1570\n",
            "save_steps: 1250\n",
            "20220510 14:21:34 current learning_rate:0.00001000\n",
            "used_time: 0.19426631927490234\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1580, loss: 0.486259, acc: 1.000000\n",
            "steps: 1580\n",
            "save_steps: 1250\n",
            "20220510 14:21:36 current learning_rate:0.00001000\n",
            "used_time: 0.16619086265563965\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1590, loss: 0.800043, acc: 0.875000\n",
            "steps: 1590\n",
            "save_steps: 1250\n",
            "20220510 14:21:38 current learning_rate:0.00001000\n",
            "used_time: 0.19879603385925293\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1600, loss: 0.077596, acc: 0.500000\n",
            "steps: 1600\n",
            "save_steps: 1250\n",
            "20220510 14:21:40 current learning_rate:0.00001000\n",
            "used_time: 0.20721936225891113\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1610, loss: 0.604512, acc: 0.500000\n",
            "steps: 1610\n",
            "save_steps: 1250\n",
            "20220510 14:21:42 current learning_rate:0.00001000\n",
            "used_time: 0.19523000717163086\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1620, loss: 0.107541, acc: 0.375000\n",
            "steps: 1620\n",
            "save_steps: 1250\n",
            "20220510 14:21:44 current learning_rate:0.00001000\n",
            "used_time: 0.2042841911315918\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1630, loss: 0.898249, acc: 0.875000\n",
            "steps: 1630\n",
            "save_steps: 1250\n",
            "20220510 14:21:46 current learning_rate:0.00001000\n",
            "used_time: 0.18543028831481934\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1640, loss: 0.421896, acc: 0.875000\n",
            "steps: 1640\n",
            "save_steps: 1250\n",
            "20220510 14:21:47 current learning_rate:0.00001000\n",
            "used_time: 0.17532968521118164\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1650, loss: 0.051322, acc: 0.625000\n",
            "steps: 1650\n",
            "save_steps: 1250\n",
            "20220510 14:21:49 current learning_rate:0.00001000\n",
            "used_time: 0.2159438133239746\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1660, loss: 0.286258, acc: 0.750000\n",
            "steps: 1660\n",
            "save_steps: 1250\n",
            "20220510 14:21:51 current learning_rate:0.00001000\n",
            "used_time: 0.19794988632202148\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1670, loss: 0.270346, acc: 0.500000\n",
            "steps: 1670\n",
            "save_steps: 1250\n",
            "20220510 14:21:53 current learning_rate:0.00001000\n",
            "used_time: 0.1990184783935547\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1680, loss: 0.349406, acc: 0.750000\n",
            "steps: 1680\n",
            "save_steps: 1250\n",
            "20220510 14:21:55 current learning_rate:0.00001000\n",
            "used_time: 0.2145390510559082\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1690, loss: 0.484326, acc: 0.500000\n",
            "steps: 1690\n",
            "save_steps: 1250\n",
            "20220510 14:21:57 current learning_rate:0.00001000\n",
            "used_time: 0.18597769737243652\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1700, loss: 0.259018, acc: 0.875000\n",
            "steps: 1700\n",
            "save_steps: 1250\n",
            "20220510 14:21:59 current learning_rate:0.00001000\n",
            "used_time: 0.2093820571899414\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1710, loss: 0.185250, acc: 0.750000\n",
            "steps: 1710\n",
            "save_steps: 1250\n",
            "20220510 14:22:01 current learning_rate:0.00001000\n",
            "used_time: 0.16675257682800293\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1720, loss: 0.251869, acc: 0.625000\n",
            "steps: 1720\n",
            "save_steps: 1250\n",
            "20220510 14:22:03 current learning_rate:0.00001000\n",
            "used_time: 0.1758570671081543\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1730, loss: 0.017889, acc: 0.875000\n",
            "steps: 1730\n",
            "save_steps: 1250\n",
            "20220510 14:22:05 current learning_rate:0.00001000\n",
            "used_time: 0.20351314544677734\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1740, loss: 0.734461, acc: 0.625000\n",
            "steps: 1740\n",
            "save_steps: 1250\n",
            "20220510 14:22:07 current learning_rate:0.00001000\n",
            "used_time: 0.23033428192138672\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1750, loss: 0.090986, acc: 0.875000\n",
            "steps: 1750\n",
            "save_steps: 1250\n",
            "20220510 14:22:09 current learning_rate:0.00001000\n",
            "used_time: 0.24631977081298828\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1760, loss: 0.178599, acc: 0.625000\n",
            "steps: 1760\n",
            "save_steps: 1250\n",
            "20220510 14:22:11 current learning_rate:0.00001000\n",
            "used_time: 0.17296767234802246\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1770, loss: 0.733778, acc: 0.500000\n",
            "steps: 1770\n",
            "save_steps: 1250\n",
            "20220510 14:22:13 current learning_rate:0.00001000\n",
            "used_time: 0.2135477066040039\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1780, loss: 0.416117, acc: 0.625000\n",
            "steps: 1780\n",
            "save_steps: 1250\n",
            "20220510 14:22:14 current learning_rate:0.00001000\n",
            "used_time: 0.163283109664917\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1790, loss: 0.439221, acc: 0.500000\n",
            "steps: 1790\n",
            "save_steps: 1250\n",
            "20220510 14:22:16 current learning_rate:0.00001000\n",
            "used_time: 0.16907858848571777\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1800, loss: 0.060669, acc: 0.625000\n",
            "steps: 1800\n",
            "save_steps: 1250\n",
            "20220510 14:22:18 current learning_rate:0.00001000\n",
            "used_time: 0.18724608421325684\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1810, loss: 0.366868, acc: 0.625000\n",
            "steps: 1810\n",
            "save_steps: 1250\n",
            "20220510 14:22:20 current learning_rate:0.00001000\n",
            "used_time: 0.18708086013793945\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1820, loss: 0.213983, acc: 0.750000\n",
            "steps: 1820\n",
            "save_steps: 1250\n",
            "20220510 14:22:22 current learning_rate:0.00001000\n",
            "used_time: 0.18430566787719727\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1830, loss: 0.296409, acc: 0.375000\n",
            "steps: 1830\n",
            "save_steps: 1250\n",
            "20220510 14:22:24 current learning_rate:0.00001000\n",
            "used_time: 0.1903519630432129\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1840, loss: 0.206922, acc: 0.625000\n",
            "steps: 1840\n",
            "save_steps: 1250\n",
            "20220510 14:22:26 current learning_rate:0.00001000\n",
            "used_time: 0.19688749313354492\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1850, loss: 0.531337, acc: 0.625000\n",
            "steps: 1850\n",
            "save_steps: 1250\n",
            "20220510 14:22:28 current learning_rate:0.00001000\n",
            "used_time: 0.1774284839630127\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1860, loss: 0.287018, acc: 0.625000\n",
            "steps: 1860\n",
            "save_steps: 1250\n",
            "20220510 14:22:30 current learning_rate:0.00001000\n",
            "used_time: 0.19063639640808105\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1870, loss: 0.227843, acc: 0.500000\n",
            "steps: 1870\n",
            "save_steps: 1250\n",
            "20220510 14:22:32 current learning_rate:0.00001000\n",
            "used_time: 0.18828773498535156\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1880, loss: 0.338579, acc: 0.625000\n",
            "steps: 1880\n",
            "save_steps: 1250\n",
            "20220510 14:22:33 current learning_rate:0.00001000\n",
            "used_time: 0.1888113021850586\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1890, loss: 0.722708, acc: 0.875000\n",
            "steps: 1890\n",
            "save_steps: 1250\n",
            "20220510 14:22:35 current learning_rate:0.00001000\n",
            "used_time: 0.24962973594665527\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1900, loss: 0.022692, acc: 0.500000\n",
            "steps: 1900\n",
            "save_steps: 1250\n",
            "20220510 14:22:37 current learning_rate:0.00001000\n",
            "used_time: 0.18412113189697266\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1910, loss: 0.009228, acc: 0.875000\n",
            "steps: 1910\n",
            "save_steps: 1250\n",
            "20220510 14:22:39 current learning_rate:0.00001000\n",
            "used_time: 0.1770334243774414\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1920, loss: 0.871818, acc: 0.625000\n",
            "steps: 1920\n",
            "save_steps: 1250\n",
            "20220510 14:22:41 current learning_rate:0.00001000\n",
            "used_time: 0.17926788330078125\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1930, loss: 0.153762, acc: 0.750000\n",
            "steps: 1930\n",
            "save_steps: 1250\n",
            "20220510 14:22:43 current learning_rate:0.00001000\n",
            "used_time: 0.18338823318481445\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1940, loss: 1.615484, acc: 0.250000\n",
            "steps: 1940\n",
            "save_steps: 1250\n",
            "20220510 14:22:45 current learning_rate:0.00001000\n",
            "used_time: 0.1795673370361328\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1950, loss: 0.682875, acc: 0.750000\n",
            "steps: 1950\n",
            "save_steps: 1250\n",
            "20220510 14:22:47 current learning_rate:0.00001000\n",
            "used_time: 0.1728060245513916\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1960, loss: 0.525652, acc: 0.750000\n",
            "steps: 1960\n",
            "save_steps: 1250\n",
            "20220510 14:22:49 current learning_rate:0.00001000\n",
            "used_time: 0.1734170913696289\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1970, loss: 0.218594, acc: 0.625000\n",
            "steps: 1970\n",
            "save_steps: 1250\n",
            "20220510 14:22:51 current learning_rate:0.00001000\n",
            "used_time: 0.20149445533752441\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1980, loss: 1.272850, acc: 0.625000\n",
            "steps: 1980\n",
            "save_steps: 1250\n",
            "20220510 14:22:53 current learning_rate:0.00001000\n",
            "used_time: 0.19286394119262695\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1990, loss: 0.029848, acc: 0.500000\n",
            "steps: 1990\n",
            "save_steps: 1250\n",
            "20220510 14:22:55 current learning_rate:0.00001000\n",
            "used_time: 0.17731356620788574\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 2000, loss: 0.339052, acc: 0.875000\n",
            "steps: 2000\n",
            "save_steps: 1250\n",
            "Train-RCAC 0.9117147707979627\n",
            "20220510 14:22:57 current learning_rate:0.00001000\n",
            "used_time: 0.19133281707763672\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 2010, loss: 0.342988, acc: 0.625000\n",
            "steps: 2010\n",
            "save_steps: 1250\n",
            "20220510 14:22:59 current learning_rate:0.00001000\n",
            "used_time: 0.2065880298614502\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 2020, loss: 0.953851, acc: 0.875000\n",
            "steps: 2020\n",
            "save_steps: 1250\n",
            "20220510 14:23:01 current learning_rate:0.00001000\n",
            "used_time: 0.22954702377319336\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 2030, loss: 0.080295, acc: 0.750000\n",
            "steps: 2030\n",
            "save_steps: 1250\n",
            "20220510 14:23:02 current learning_rate:0.00001000\n",
            "used_time: 0.18890595436096191\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 2040, loss: 0.447078, acc: 0.875000\n",
            "steps: 2040\n",
            "save_steps: 1250\n",
            "20220510 14:23:04 current learning_rate:0.00001000\n",
            "used_time: 0.19114899635314941\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 2050, loss: 0.804447, acc: 0.875000\n",
            "steps: 2050\n",
            "save_steps: 1250\n",
            "20220510 14:23:06 current learning_rate:0.00001000\n",
            "used_time: 0.1950666904449463\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 2060, loss: 0.138571, acc: 0.625000\n",
            "steps: 2060\n",
            "save_steps: 1250\n",
            "20220510 14:23:08 current learning_rate:0.00001000\n",
            "used_time: 0.18666696548461914\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 2070, loss: 0.081922, acc: 0.625000\n",
            "steps: 2070\n",
            "save_steps: 1250\n",
            "20220510 14:23:10 current learning_rate:0.00001000\n",
            "used_time: 0.20813894271850586\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 2080, loss: 0.579417, acc: 0.625000\n",
            "steps: 2080\n",
            "save_steps: 1250\n",
            "20220510 14:23:12 current learning_rate:0.00001000\n",
            "used_time: 0.20744657516479492\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 2090, loss: 0.055341, acc: 0.875000\n",
            "steps: 2090\n",
            "save_steps: 1250\n",
            "20220510 14:23:14 current learning_rate:0.00001000\n",
            "used_time: 0.24247503280639648\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 2100, loss: 0.921876, acc: 0.625000\n",
            "steps: 2100\n",
            "save_steps: 1250\n",
            "20220510 14:23:16 current learning_rate:0.00001000\n",
            "used_time: 0.16515040397644043\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 2110, loss: 0.591519, acc: 0.875000\n",
            "steps: 2110\n",
            "save_steps: 1250\n",
            "20220510 14:23:18 current learning_rate:0.00001000\n",
            "used_time: 0.1875622272491455\n",
            "shuffle epoch 2\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2120, loss: 0.030401, acc: 0.750000\n",
            "steps: 2120\n",
            "save_steps: 1250\n",
            "20220510 14:23:20 current learning_rate:0.00001000\n",
            "used_time: 0.19123411178588867\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2130, loss: 0.283804, acc: 1.000000\n",
            "steps: 2130\n",
            "save_steps: 1250\n",
            "20220510 14:23:22 current learning_rate:0.00001000\n",
            "used_time: 0.20947670936584473\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2140, loss: 0.250419, acc: 0.625000\n",
            "steps: 2140\n",
            "save_steps: 1250\n",
            "20220510 14:23:24 current learning_rate:0.00001000\n",
            "used_time: 0.2156391143798828\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2150, loss: 0.158322, acc: 0.750000\n",
            "steps: 2150\n",
            "save_steps: 1250\n",
            "20220510 14:23:26 current learning_rate:0.00001000\n",
            "used_time: 0.1465930938720703\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2160, loss: 0.161202, acc: 0.500000\n",
            "steps: 2160\n",
            "save_steps: 1250\n",
            "20220510 14:23:28 current learning_rate:0.00001000\n",
            "used_time: 0.1973741054534912\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2170, loss: 0.137009, acc: 0.750000\n",
            "steps: 2170\n",
            "save_steps: 1250\n",
            "20220510 14:23:30 current learning_rate:0.00001000\n",
            "used_time: 0.2186877727508545\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2180, loss: 0.005820, acc: 0.750000\n",
            "steps: 2180\n",
            "save_steps: 1250\n",
            "20220510 14:23:31 current learning_rate:0.00001000\n",
            "used_time: 0.20844268798828125\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2190, loss: 0.002719, acc: 0.625000\n",
            "steps: 2190\n",
            "save_steps: 1250\n",
            "20220510 14:23:33 current learning_rate:0.00001000\n",
            "used_time: 0.19552397727966309\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2200, loss: 0.000604, acc: 0.625000\n",
            "steps: 2200\n",
            "save_steps: 1250\n",
            "20220510 14:23:35 current learning_rate:0.00001000\n",
            "used_time: 0.1803145408630371\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2210, loss: 0.000318, acc: 0.500000\n",
            "steps: 2210\n",
            "save_steps: 1250\n",
            "20220510 14:23:37 current learning_rate:0.00001000\n",
            "used_time: 0.2162036895751953\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2220, loss: 0.000288, acc: 0.375000\n",
            "steps: 2220\n",
            "save_steps: 1250\n",
            "20220510 14:23:39 current learning_rate:0.00001000\n",
            "used_time: 0.1757493019104004\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2230, loss: 0.000344, acc: 0.625000\n",
            "steps: 2230\n",
            "save_steps: 1250\n",
            "20220510 14:23:41 current learning_rate:0.00001000\n",
            "used_time: 0.16657567024230957\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2240, loss: 0.425084, acc: 0.625000\n",
            "steps: 2240\n",
            "save_steps: 1250\n",
            "20220510 14:23:43 current learning_rate:0.00001000\n",
            "used_time: 0.1638352870941162\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2250, loss: 0.055589, acc: 0.625000\n",
            "steps: 2250\n",
            "save_steps: 1250\n",
            "20220510 14:23:45 current learning_rate:0.00001000\n",
            "used_time: 0.18816924095153809\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2260, loss: 0.000852, acc: 0.375000\n",
            "steps: 2260\n",
            "save_steps: 1250\n",
            "20220510 14:23:47 current learning_rate:0.00001000\n",
            "used_time: 0.2361295223236084\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2270, loss: 0.000667, acc: 0.375000\n",
            "steps: 2270\n",
            "save_steps: 1250\n",
            "20220510 14:23:49 current learning_rate:0.00001000\n",
            "used_time: 0.20329737663269043\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2280, loss: 0.003171, acc: 0.750000\n",
            "steps: 2280\n",
            "save_steps: 1250\n",
            "20220510 14:23:51 current learning_rate:0.00001000\n",
            "used_time: 0.21271967887878418\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2290, loss: 0.051480, acc: 0.625000\n",
            "steps: 2290\n",
            "save_steps: 1250\n",
            "20220510 14:23:53 current learning_rate:0.00001000\n",
            "used_time: 0.20068597793579102\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2300, loss: 0.904761, acc: 0.625000\n",
            "steps: 2300\n",
            "save_steps: 1250\n",
            "20220510 14:23:54 current learning_rate:0.00001000\n",
            "used_time: 0.18322157859802246\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2310, loss: 0.008934, acc: 1.000000\n",
            "steps: 2310\n",
            "save_steps: 1250\n",
            "20220510 14:23:56 current learning_rate:0.00001000\n",
            "used_time: 0.17845630645751953\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2320, loss: 0.118087, acc: 0.875000\n",
            "steps: 2320\n",
            "save_steps: 1250\n",
            "20220510 14:23:58 current learning_rate:0.00001000\n",
            "used_time: 0.20889830589294434\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2330, loss: 0.013851, acc: 0.625000\n",
            "steps: 2330\n",
            "save_steps: 1250\n",
            "20220510 14:24:00 current learning_rate:0.00001000\n",
            "used_time: 0.18938899040222168\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2340, loss: 0.001256, acc: 0.625000\n",
            "steps: 2340\n",
            "save_steps: 1250\n",
            "20220510 14:24:02 current learning_rate:0.00001000\n",
            "used_time: 0.2047710418701172\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2350, loss: 0.008993, acc: 0.625000\n",
            "steps: 2350\n",
            "save_steps: 1250\n",
            "20220510 14:24:04 current learning_rate:0.00001000\n",
            "used_time: 0.24585986137390137\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2360, loss: 0.000270, acc: 0.750000\n",
            "steps: 2360\n",
            "save_steps: 1250\n",
            "20220510 14:24:06 current learning_rate:0.00001000\n",
            "used_time: 0.21364545822143555\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2370, loss: 0.564765, acc: 0.750000\n",
            "steps: 2370\n",
            "save_steps: 1250\n",
            "20220510 14:24:08 current learning_rate:0.00001000\n",
            "used_time: 0.21875500679016113\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2380, loss: 0.003716, acc: 0.625000\n",
            "steps: 2380\n",
            "save_steps: 1250\n",
            "20220510 14:24:10 current learning_rate:0.00001000\n",
            "used_time: 0.17447209358215332\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2390, loss: 0.008573, acc: 0.500000\n",
            "steps: 2390\n",
            "save_steps: 1250\n",
            "20220510 14:24:12 current learning_rate:0.00001000\n",
            "used_time: 0.19750046730041504\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2400, loss: 0.001011, acc: 0.875000\n",
            "steps: 2400\n",
            "save_steps: 1250\n",
            "20220510 14:24:14 current learning_rate:0.00001000\n",
            "used_time: 0.19685721397399902\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2410, loss: 0.654736, acc: 0.750000\n",
            "steps: 2410\n",
            "save_steps: 1250\n",
            "20220510 14:24:16 current learning_rate:0.00001000\n",
            "used_time: 0.1992049217224121\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2420, loss: 0.408210, acc: 0.250000\n",
            "steps: 2420\n",
            "save_steps: 1250\n",
            "20220510 14:24:18 current learning_rate:0.00001000\n",
            "used_time: 0.17336797714233398\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2430, loss: 0.167196, acc: 0.625000\n",
            "steps: 2430\n",
            "save_steps: 1250\n",
            "20220510 14:24:20 current learning_rate:0.00001000\n",
            "used_time: 0.17090058326721191\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2440, loss: 0.001203, acc: 0.750000\n",
            "steps: 2440\n",
            "save_steps: 1250\n",
            "20220510 14:24:22 current learning_rate:0.00001000\n",
            "used_time: 0.18857192993164062\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2450, loss: 0.001750, acc: 1.000000\n",
            "steps: 2450\n",
            "save_steps: 1250\n",
            "20220510 14:24:23 current learning_rate:0.00001000\n",
            "used_time: 0.19338464736938477\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2460, loss: 0.491126, acc: 0.750000\n",
            "steps: 2460\n",
            "save_steps: 1250\n",
            "20220510 14:24:25 current learning_rate:0.00001000\n",
            "used_time: 0.1788623332977295\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2470, loss: 0.102035, acc: 0.625000\n",
            "steps: 2470\n",
            "save_steps: 1250\n",
            "20220510 14:24:27 current learning_rate:0.00001000\n",
            "used_time: 0.17908024787902832\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2480, loss: 0.001610, acc: 0.625000\n",
            "steps: 2480\n",
            "save_steps: 1250\n",
            "20220510 14:24:29 current learning_rate:0.00001000\n",
            "used_time: 0.19319748878479004\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2490, loss: 0.001106, acc: 0.750000\n",
            "steps: 2490\n",
            "save_steps: 1250\n",
            "20220510 14:24:31 current learning_rate:0.00001000\n",
            "used_time: 0.19963788986206055\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2500, loss: 0.019134, acc: 0.875000\n",
            "steps: 2500\n",
            "save_steps: 1250\n",
            "Train-RCAC 0.9696969696969697\n",
            "20220510 14:24:33 current learning_rate:0.00001000\n",
            "save_path: output_hm/step_2500train\n",
            "used_time: 11.529366254806519\n",
            "############################WARNING################################### using init_pretraining_params, not init_checkpoint ###### meaning hyper param e.g. lr won't inherit from checkpoint#################################################################terminate called without an active exception\n",
            "W0510 14:24:45.534934   591 init.cc:216] Warning: PaddlePaddle catches a failure signal, it may not work properly\n",
            "W0510 14:24:45.534979   591 init.cc:218] You could check whether you killed PaddlePaddle thread/process accidentally or report the case to PaddlePaddle\n",
            "W0510 14:24:45.534987   591 init.cc:221] The detail failure signal is:\n",
            "\n",
            "W0510 14:24:45.534998   591 init.cc:224] *** Aborted at 1652192685 (unix time) try \"date -d @1652192685\" if you are using GNU date ***\n",
            "W0510 14:24:45.552605   591 init.cc:224] PC: @                0x0 (unknown)\n",
            "W0510 14:24:45.552860   591 init.cc:224] *** SIGABRT (@0x212) received by PID 530 (TID 0x7fe690d3f700) from PID 530; stack trace: ***\n",
            "W0510 14:24:45.554059   591 init.cc:224]     @     0x7fe835669f10 (unknown)\n",
            "W0510 14:24:45.556918   591 init.cc:224]     @     0x7fe835669e87 gsignal\n",
            "W0510 14:24:45.558490   591 init.cc:224]     @     0x7fe83566b7f1 abort\n",
            "W0510 14:24:45.562887   591 init.cc:224]     @     0x7fe834300957 (unknown)\n",
            "W0510 14:24:45.564532   591 init.cc:224]     @     0x7fe834306ae6 (unknown)\n",
            "W0510 14:24:45.574955   591 init.cc:224]     @     0x7fe834306b21 std::terminate()\n",
            "W0510 14:24:45.576550   591 init.cc:224]     @     0x7fe8343064ea __gxx_personality_v0\n",
            "W0510 14:24:45.578809   591 init.cc:224]     @     0x7fe833e46668 (unknown)\n",
            "W0510 14:24:45.580296   591 init.cc:224]     @     0x7fe833e46c5c _Unwind_ForcedUnwind\n",
            "W0510 14:24:45.581827   591 init.cc:224]     @     0x7fe83541d000 __GI___pthread_unwind\n",
            "W0510 14:24:45.582897   591 init.cc:224]     @     0x7fe835414ae5 __pthread_exit\n",
            "W0510 14:24:45.583961   591 init.cc:224]     @     0x7fe83575b364 pthread_exit\n",
            "W0510 14:24:45.584494   591 init.cc:224]     @           0x5e37d8 PyThread_exit_thread\n",
            "W0510 14:24:45.584656   591 init.cc:224]     @           0x47028a (unknown)\n",
            "W0510 14:24:45.595212   591 init.cc:224]     @     0x7fe7e240f019 pybind11::gil_scoped_release::~gil_scoped_release()\n",
            "W0510 14:24:45.596309   591 init.cc:224]     @     0x7fe7e24f73b6 _ZZN8pybind1112cpp_function10initializeIZN6paddle6pybind10BindReaderEPNS_6moduleEEUlRNS2_9operators6reader22LoDTensorBlockingQueueERKSt6vectorINS2_9framework9LoDTensorESaISC_EEE1_bIS9_SG_EINS_4nameENS_9is_methodENS_7siblingENS_10call_guardIINS_18gil_scoped_releaseEEEEEEEvOT_PFT0_DpT1_EDpRKT2_ENUlRNS_6detail13function_callEE1_4_FUNES11_\n",
            "W0510 14:24:45.599143   591 init.cc:224]     @     0x7fe7e242c829 pybind11::cpp_function::dispatcher()\n",
            "W0510 14:24:45.599301   591 init.cc:224]     @           0x593784 _PyMethodDef_RawFastCallKeywords\n",
            "W0510 14:24:45.599398   591 init.cc:224]     @           0x594731 _PyObject_FastCallKeywords\n",
            "W0510 14:24:45.599531   591 init.cc:224]     @           0x548cc1 (unknown)\n",
            "W0510 14:24:45.599598   591 init.cc:224]     @           0x51566f _PyEval_EvalFrameDefault\n",
            "W0510 14:24:45.599691   591 init.cc:224]     @           0x549e0e _PyEval_EvalCodeWithName\n",
            "W0510 14:24:45.599751   591 init.cc:224]     @           0x4bcb19 _PyFunction_FastCallDict\n",
            "W0510 14:24:45.599807   591 init.cc:224]     @           0x5134a6 _PyEval_EvalFrameDefault\n",
            "W0510 14:24:45.599922   591 init.cc:224]     @           0x593dd7 _PyFunction_FastCallKeywords\n",
            "W0510 14:24:45.599988   591 init.cc:224]     @           0x511e2c _PyEval_EvalFrameDefault\n",
            "W0510 14:24:45.600073   591 init.cc:224]     @           0x593dd7 _PyFunction_FastCallKeywords\n",
            "W0510 14:24:45.600138   591 init.cc:224]     @           0x511e2c _PyEval_EvalFrameDefault\n",
            "W0510 14:24:45.600196   591 init.cc:224]     @           0x4bc98a _PyFunction_FastCallDict\n",
            "W0510 14:24:45.600322   591 init.cc:224]     @           0x59c019 (unknown)\n",
            "W0510 14:24:45.600451   591 init.cc:224]     @           0x595ef6 PyObject_Call\n",
            "W0510 14:24:45.600572   591 init.cc:224]     @           0x5d5393 (unknown)\n",
            "/content/vilio/ernie-vil/run_finetuning.sh: line 64:   530 Aborted                 (core dumped) python /content/vilio/ernie-vil/finetune.py --use_cuda \"True\" --is_distributed \"False\" --use_fast_executor ${e_executor-\"True\"} --nccl_comm_num ${nccl_comm_num:-\"1\"} --batch_size $((BATCH_SIZE/gpu_cnt)) --do_train \"True\" --do_test \"False\" --task_name ${TASK_NAME} --vocab_path ${VOCAB_PATH} --task_group_json ${TASK_GROUP_JSON} --lr_scheduler ${lr_scheduler} --decay_steps ${decay_steps-\"\"} --lr_decay_ratio ${lr_decay_ratio-0.1} --num_train_steps ${num_train_steps} --checkpoints $output_model_path --save_steps ${SAVE_STEPS} --init_checkpoint ${PRETRAIN_MODELS} --ernie_config_path ${ERNIE_VIL_CONFIG} --learning_rate ${LR_RATE} --warmup_steps ${WARMUP_STEPS} --weight_decay ${WEIGHT_DECAY:-0} --max_seq_len ${MAX_LEN} --validation_steps ${VALID_STEPS} --skip_steps 10 --split ${SPLIT} --stop_steps ${STOP}\n",
            "-----------  Configuration Arguments -----------\n",
            "batch_size: 8\n",
            "checkpoints: checkpoints\n",
            "combine: False\n",
            "decay_steps: \n",
            "do_test: True\n",
            "do_train: False\n",
            "do_val: False\n",
            "epoch: 100\n",
            "ernie_config_path: /content/vilio/ernie-vil/data/erniesmall/ernie_vil_config.base.json\n",
            "exp: ES36\n",
            "feature_size: 2048\n",
            "fusion_method: sum\n",
            "hierarchical_allreduce_inter_nranks: 8\n",
            "init_checkpoint: /content/vilio/ernie-vil/output_hm/step_2500train\n",
            "is_distributed: False\n",
            "learning_rate: 0.0001\n",
            "lr_decay_dict_file: \n",
            "lr_decay_ratio: 0.1\n",
            "lr_scheduler: linear_warmup_decay\n",
            "max_img_len: 100\n",
            "max_seq_len: 128\n",
            "nccl_comm_num: 1\n",
            "num_features: 50\n",
            "num_train_steps: 1000000\n",
            "output_file: \n",
            "result_file: /content/vilio/ernie-vil/data/log\n",
            "save_steps: 100\n",
            "skip_steps: 10\n",
            "split: dev_seen\n",
            "stop_steps: 5000\n",
            "subtrain: False\n",
            "task_group_json: /content/vilio/ernie-vil/conf/hm/task_hm.json\n",
            "task_name: hm\n",
            "test_filelist: \n",
            "test_split: val\n",
            "train_filelist: \n",
            "use_cuda: True\n",
            "use_fast_executor: True\n",
            "use_fuse: False\n",
            "use_gpu: True\n",
            "use_hierarchical_allreduce: False\n",
            "valid_filelist: \n",
            "validation_steps: 6000\n",
            "verbose: False\n",
            "vocab_path: /content/vilio/ernie-vil/data/erniesmall/vocab.txt\n",
            "warmup_steps: 0\n",
            "weight_decay: 0.01\n",
            "------------------------------------------------\n",
            "finetuning tasks start\n",
            "attention_probs_dropout_prob: 0.1\n",
            "class_attr_size: 401\n",
            "class_size: 1601\n",
            "co_hidden_size: 1024\n",
            "co_intermediate_size: 1024\n",
            "co_num_attention_heads: 8\n",
            "hidden_act: gelu\n",
            "hidden_dropout_prob: 0.1\n",
            "hidden_size: 768\n",
            "initializer_range: 0.02\n",
            "max_position_embeddings: 512\n",
            "num_attention_heads: 12\n",
            "num_hidden_layers: 12\n",
            "sent_type_vocab_size: 4\n",
            "t_biattention_id: [6, 7, 8, 9, 10, 11]\n",
            "task_type_vocab_size: 16\n",
            "type_vocab_size: 2\n",
            "v_biattention_id: [0, 1, 2, 3, 4, 5]\n",
            "v_hidden_size: 1024\n",
            "v_intermediate_size: 1024\n",
            "v_num_attention_heads: 8\n",
            "vocab_size: 30522\n",
            "------------------------------------------------\n",
            "task:  [{'task': 'HM', 'num_choice': 1, 'annotations_jsonpath_train': '/content/vilio/ernie-vil/data/hm/train.jsonl', 'annotations_jsonpath_dev_seen': '/content/vilio/ernie-vil/data/hm/dev_seenlong.jsonl', 'annotations_jsonpath_traindev': '/content/vilio/ernie-vil/data/hm/traindev.jsonl', 'annotations_jsonpath_test_unseen': '/content/vilio/ernie-vil/data/hm/test_unseenlong.jsonl', 'annotations_jsonpath_test_seen': '/content/vilio/ernie-vil/data/hm/test_seenlong.jsonl', 'feature_lmdb_path': '/content/vilio/ernie-vil/data/hm/HM_img.tsv', 'gt_feature_lmdb_path': '/content/vilio/ernie-vil/data/hm/HM_gt_img.tsv', 'unisex_names_table': '/content/vilio/ernie-vil/data/vcr/unisex_names_table.csv', 'Proprocessor': 'PreprocessorBasic', 'tokenizer_name': 'FullTokenizer', 'fusion_method': 'mul', 'dropout_rate': 0.1, 'max_seq_len': 128, 'use_gt_fea': True, 'shufflekeep_across_task': True, 'shuffle_every_epoch': True, 'task_weight': 1.0, 'task_prefix': 'hm'}]\n",
            "2022-05-10 14:24:50,782-WARNING: paddle.fluid.layers.py_reader() may be deprecated in the near future. Please use paddle.fluid.io.DataLoader.from_generator() instead.\n",
            "theoretical memory usage: \n",
            "(3678.2632896423343, 3853.418684387207, 'MB')\n",
            "args.is_distributed: False\n",
            "W0510 14:24:51.686919   619 device_context.cc:252] Please NOTE: device: 0, CUDA Capability: 60, Driver API Version: 11.2, Runtime API Version: 9.0\n",
            "W0510 14:24:51.723721   619 device_context.cc:260] device: 0, cuDNN Version: 7.6.\n",
            "SPLIT: dev_seen\n",
            "Start to load Faster-RCNN detected objects from /content/vilio/ernie-vil/data/hm/HM_img.tsv\n",
            "Loaded 500 images in file /content/vilio/ernie-vil/data/hm/HM_img.tsv in 68 seconds.\n",
            "Start to load Faster-RCNN detected objects from /content/vilio/ernie-vil/data/hm/HM_gt_img.tsv\n",
            "Loaded 500 images in file /content/vilio/ernie-vil/data/hm/HM_gt_img.tsv in 49 seconds.\n",
            "Load 650 data from split(s) /content/vilio/ernie-vil/data/hm/dev_seenlong.jsonl.\n",
            "use gt featurre\n",
            "LEN:  650\n",
            "Load pretraining parameters from /content/vilio/ernie-vil/output_hm/step_2500train.\n",
            "testing on hm val split\n",
            "task name list :  ['mean_0.tmp_0', 'accuracy_0.tmp_0', 'arg_max_0.tmp_0', 'read_file_0.tmp_9', 'read_file_0.tmp_8', 'reshape2_120.tmp_0']\n",
            "cur_step: 10 cur_acc: 0.1125\n",
            "cur_step: 20 cur_acc: 0.31875\n",
            "cur_step: 30 cur_acc: 0.35833333333333334\n",
            "cur_step: 40 cur_acc: 0.43125\n",
            "cur_step: 50 cur_acc: 0.4675\n",
            "cur_step: 60 cur_acc: 0.49583333333333335\n",
            "cur_step: 70 cur_acc: 0.45714285714285713\n",
            "cur_step: 80 cur_acc: 0.4609375\n",
            "EXCEPTING\n",
            "LEN: 500 500\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 500 entries, 0 to 499\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   id      500 non-null    int64  \n",
            " 1   proba   500 non-null    float32\n",
            " 2   label   500 non-null    int64  \n",
            "dtypes: float32(1), int64(2)\n",
            "memory usage: 9.9 KB\n",
            "None\n",
            "average_acc: 0.4609375\n",
            "rocauc: 0.7756128715303365\n",
            "+ TASK_NAME=hm\n",
            "+ CONF_FILE=conf/hm/model_conf_hm\n",
            "+ VOCAB_PATH=/content/vilio/ernie-vil/data/erniesmall/vocab.txt\n",
            "+ ERNIE_VIL_CONFIG=/content/vilio/ernie-vil/data/erniesmall/ernie_vil_config.base.json\n",
            "+ PRETRAIN_MODELS=/content/vilio/ernie-vil/data/erniesmall/params\n",
            "+ SPLIT=traindev\n",
            "+ STOP=2500\n",
            "+ source conf/hm/model_conf_hm\n",
            "++ output_model_path=output_hm\n",
            "++ lr_scheduler=manual_warmup_decay\n",
            "++ decay_steps='13308;19962'\n",
            "++ lr_decay_ratio=0.1\n",
            "++ num_train_steps=5000\n",
            "++ SAVE_STEPS=1250\n",
            "++ WARMUP_STEPS=500\n",
            "++ BATCH_SIZE=8\n",
            "++ VALID_STEPS=20000\n",
            "++ LR_RATE=1e-5\n",
            "++ WEIGHT_DECAY=0.01\n",
            "++ MAX_LEN=128\n",
            "+ CUDA_VISIBLE_DEVICES=1\n",
            "+ export FLAGS_fast_eager_deletion_mode=1\n",
            "+ FLAGS_fast_eager_deletion_mode=1\n",
            "+ export FLAGS_eager_delete_tensor_gb=0.0\n",
            "+ FLAGS_eager_delete_tensor_gb=0.0\n",
            "+ export FLAGS_fraction_of_gpu_memory_to_use=0.98\n",
            "+ FLAGS_fraction_of_gpu_memory_to_use=0.98\n",
            "++ echo True\n",
            "++ tr '[A-Z]' '[a-z]'\n",
            "+ e_executor=true\n",
            "++ echo False\n",
            "++ tr '[A-Z]' '[a-z]'\n",
            "+ use_fuse=false\n",
            "+ [[ false == \\t\\r\\u\\e ]]\n",
            "+ TASK_GROUP_JSON=/content/vilio/ernie-vil/conf/hm/task_hm.json\n",
            "++ echo 1\n",
            "++ awk '-F\\t' '{len=split($0,vec,\",\");print len}'\n",
            "+ gpu_cnt=1\n",
            "+ echo gpu_cnt, 1\n",
            "gpu_cnt, 1\n",
            "+ python /content/vilio/ernie-vil/finetune.py --use_cuda True --is_distributed False --use_fast_executor true --nccl_comm_num 1 --batch_size 8 --do_train True --do_test False --task_name hm --vocab_path /content/vilio/ernie-vil/data/erniesmall/vocab.txt --task_group_json /content/vilio/ernie-vil/conf/hm/task_hm.json --lr_scheduler manual_warmup_decay --decay_steps '13308;19962' --lr_decay_ratio 0.1 --num_train_steps 5000 --checkpoints output_hm --save_steps 1250 --init_checkpoint /content/vilio/ernie-vil/data/erniesmall/params --ernie_config_path /content/vilio/ernie-vil/data/erniesmall/ernie_vil_config.base.json --learning_rate 1e-5 --warmup_steps 500 --weight_decay 0.01 --max_seq_len 128 --validation_steps 20000 --skip_steps 10 --split traindev --stop_steps 2500\n",
            "-----------  Configuration Arguments -----------\n",
            "batch_size: 8\n",
            "checkpoints: output_hm\n",
            "combine: False\n",
            "decay_steps: 13308;19962\n",
            "do_test: False\n",
            "do_train: True\n",
            "do_val: False\n",
            "epoch: 100\n",
            "ernie_config_path: /content/vilio/ernie-vil/data/erniesmall/ernie_vil_config.base.json\n",
            "exp: experiment\n",
            "feature_size: 2048\n",
            "fusion_method: sum\n",
            "hierarchical_allreduce_inter_nranks: 8\n",
            "init_checkpoint: /content/vilio/ernie-vil/data/erniesmall/params\n",
            "is_distributed: False\n",
            "learning_rate: 1e-05\n",
            "lr_decay_dict_file: \n",
            "lr_decay_ratio: 0.1\n",
            "lr_scheduler: manual_warmup_decay\n",
            "max_img_len: 100\n",
            "max_seq_len: 128\n",
            "nccl_comm_num: 1\n",
            "num_features: 50\n",
            "num_train_steps: 5000\n",
            "output_file: \n",
            "result_file: ./res_tmp\n",
            "save_steps: 1250\n",
            "skip_steps: 10\n",
            "split: traindev\n",
            "stop_steps: 2500\n",
            "subtrain: False\n",
            "task_group_json: /content/vilio/ernie-vil/conf/hm/task_hm.json\n",
            "task_name: hm\n",
            "test_filelist: \n",
            "test_split: test\n",
            "train_filelist: \n",
            "use_cuda: True\n",
            "use_fast_executor: True\n",
            "use_fuse: False\n",
            "use_gpu: True\n",
            "use_hierarchical_allreduce: False\n",
            "valid_filelist: \n",
            "validation_steps: 20000\n",
            "verbose: False\n",
            "vocab_path: /content/vilio/ernie-vil/data/erniesmall/vocab.txt\n",
            "warmup_steps: 500\n",
            "weight_decay: 0.01\n",
            "------------------------------------------------\n",
            "finetuning tasks start\n",
            "attention_probs_dropout_prob: 0.1\n",
            "class_attr_size: 401\n",
            "class_size: 1601\n",
            "co_hidden_size: 1024\n",
            "co_intermediate_size: 1024\n",
            "co_num_attention_heads: 8\n",
            "hidden_act: gelu\n",
            "hidden_dropout_prob: 0.1\n",
            "hidden_size: 768\n",
            "initializer_range: 0.02\n",
            "max_position_embeddings: 512\n",
            "num_attention_heads: 12\n",
            "num_hidden_layers: 12\n",
            "sent_type_vocab_size: 4\n",
            "t_biattention_id: [6, 7, 8, 9, 10, 11]\n",
            "task_type_vocab_size: 16\n",
            "type_vocab_size: 2\n",
            "v_biattention_id: [0, 1, 2, 3, 4, 5]\n",
            "v_hidden_size: 1024\n",
            "v_intermediate_size: 1024\n",
            "v_num_attention_heads: 8\n",
            "vocab_size: 30522\n",
            "------------------------------------------------\n",
            "task:  [{'task': 'HM', 'num_choice': 1, 'annotations_jsonpath_train': '/content/vilio/ernie-vil/data/hm/train.jsonl', 'annotations_jsonpath_dev_seen': '/content/vilio/ernie-vil/data/hm/dev_seenlong.jsonl', 'annotations_jsonpath_traindev': '/content/vilio/ernie-vil/data/hm/traindev.jsonl', 'annotations_jsonpath_test_unseen': '/content/vilio/ernie-vil/data/hm/test_unseenlong.jsonl', 'annotations_jsonpath_test_seen': '/content/vilio/ernie-vil/data/hm/test_seenlong.jsonl', 'feature_lmdb_path': '/content/vilio/ernie-vil/data/hm/HM_img.tsv', 'gt_feature_lmdb_path': '/content/vilio/ernie-vil/data/hm/HM_gt_img.tsv', 'unisex_names_table': '/content/vilio/ernie-vil/data/vcr/unisex_names_table.csv', 'Proprocessor': 'PreprocessorBasic', 'tokenizer_name': 'FullTokenizer', 'fusion_method': 'mul', 'dropout_rate': 0.1, 'max_seq_len': 128, 'use_gt_fea': True, 'shufflekeep_across_task': True, 'shuffle_every_epoch': True, 'task_weight': 1.0, 'task_prefix': 'hm'}]\n",
            "2022-05-10 14:27:11,270-WARNING: paddle.fluid.layers.py_reader() may be deprecated in the near future. Please use paddle.fluid.io.DataLoader.from_generator() instead.\n",
            "/usr/local/lib/python3.7/dist-packages/paddle/fluid/clip.py:779: UserWarning: Caution! 'set_gradient_clip' is not recommended and may be deprecated in future! We recommend a new strategy: set 'grad_clip' when initializing the 'optimizer'. This method can reduce the mistakes, please refer to documention of 'optimizer'.\n",
            "  warnings.warn(\"Caution! 'set_gradient_clip' is not recommended \"\n",
            "theoretical memory usage: \n",
            "(18209.21138906479, 19076.31669330597, 'MB')\n",
            "args.is_distributed: False\n",
            "W0510 14:27:15.685318   663 device_context.cc:252] Please NOTE: device: 0, CUDA Capability: 60, Driver API Version: 11.2, Runtime API Version: 9.0\n",
            "W0510 14:27:15.701696   663 device_context.cc:260] device: 0, cuDNN Version: 7.6.\n",
            "Load pretraining parameters from /content/vilio/ernie-vil/data/erniesmall/params.\n",
            "SPLIT: traindev\n",
            "Start to load Faster-RCNN detected objects from /content/vilio/ernie-vil/data/hm/HM_img.tsv\n",
            "Loaded 9096 images in file /content/vilio/ernie-vil/data/hm/HM_img.tsv in 85 seconds.\n",
            "Start to load Faster-RCNN detected objects from /content/vilio/ernie-vil/data/hm/HM_gt_img.tsv\n",
            "Loaded 9096 images in file /content/vilio/ernie-vil/data/hm/HM_gt_img.tsv in 61 seconds.\n",
            "Load 9596 data from split(s) /content/vilio/ernie-vil/data/hm/traindev.jsonl.\n",
            "use gt featurre\n",
            "LEN:  9596\n",
            "shuffle epoch 0\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 10, loss: 0.817918, acc: 0.750000\n",
            "steps: 10\n",
            "save_steps: 1250\n",
            "20220510 14:29:55 current learning_rate:0.00000018\n",
            "used_time: 0.18360352516174316\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 20, loss: 0.719890, acc: 0.500000\n",
            "steps: 20\n",
            "save_steps: 1250\n",
            "20220510 14:29:56 current learning_rate:0.00000038\n",
            "used_time: 0.16533327102661133\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 30, loss: 0.748483, acc: 0.625000\n",
            "steps: 30\n",
            "save_steps: 1250\n",
            "20220510 14:29:58 current learning_rate:0.00000058\n",
            "used_time: 0.18836426734924316\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 40, loss: 0.759308, acc: 0.750000\n",
            "steps: 40\n",
            "save_steps: 1250\n",
            "20220510 14:30:00 current learning_rate:0.00000078\n",
            "used_time: 0.21149063110351562\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 50, loss: 0.645504, acc: 0.750000\n",
            "steps: 50\n",
            "save_steps: 1250\n",
            "20220510 14:30:02 current learning_rate:0.00000098\n",
            "used_time: 0.18625950813293457\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 60, loss: 0.705465, acc: 0.875000\n",
            "steps: 60\n",
            "save_steps: 1250\n",
            "20220510 14:30:04 current learning_rate:0.00000118\n",
            "used_time: 0.19197559356689453\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 70, loss: 0.708006, acc: 0.875000\n",
            "steps: 70\n",
            "save_steps: 1250\n",
            "20220510 14:30:06 current learning_rate:0.00000138\n",
            "used_time: 0.2022075653076172\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 80, loss: 0.642013, acc: 0.750000\n",
            "steps: 80\n",
            "save_steps: 1250\n",
            "20220510 14:30:08 current learning_rate:0.00000158\n",
            "used_time: 0.1868605613708496\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 90, loss: 0.675895, acc: 0.500000\n",
            "steps: 90\n",
            "save_steps: 1250\n",
            "20220510 14:30:10 current learning_rate:0.00000178\n",
            "used_time: 0.1754627227783203\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 100, loss: 0.769921, acc: 0.375000\n",
            "steps: 100\n",
            "save_steps: 1250\n",
            "20220510 14:30:12 current learning_rate:0.00000198\n",
            "used_time: 0.17703604698181152\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 110, loss: 0.719142, acc: 0.500000\n",
            "steps: 110\n",
            "save_steps: 1250\n",
            "20220510 14:30:14 current learning_rate:0.00000218\n",
            "used_time: 0.1985180377960205\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 120, loss: 0.764049, acc: 0.500000\n",
            "steps: 120\n",
            "save_steps: 1250\n",
            "20220510 14:30:15 current learning_rate:0.00000238\n",
            "used_time: 0.17661833763122559\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 130, loss: 0.718538, acc: 0.500000\n",
            "steps: 130\n",
            "save_steps: 1250\n",
            "20220510 14:30:18 current learning_rate:0.00000258\n",
            "used_time: 0.22806882858276367\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 140, loss: 0.657310, acc: 0.625000\n",
            "steps: 140\n",
            "save_steps: 1250\n",
            "20220510 14:30:19 current learning_rate:0.00000278\n",
            "used_time: 0.20058059692382812\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 150, loss: 0.564034, acc: 0.875000\n",
            "steps: 150\n",
            "save_steps: 1250\n",
            "20220510 14:30:21 current learning_rate:0.00000298\n",
            "used_time: 0.1699385643005371\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 160, loss: 0.710390, acc: 0.500000\n",
            "steps: 160\n",
            "save_steps: 1250\n",
            "20220510 14:30:23 current learning_rate:0.00000318\n",
            "used_time: 0.17565274238586426\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 170, loss: 0.527188, acc: 0.875000\n",
            "steps: 170\n",
            "save_steps: 1250\n",
            "20220510 14:30:25 current learning_rate:0.00000338\n",
            "used_time: 0.246018648147583\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 180, loss: 0.549159, acc: 0.750000\n",
            "steps: 180\n",
            "save_steps: 1250\n",
            "20220510 14:30:27 current learning_rate:0.00000358\n",
            "used_time: 0.17149710655212402\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 190, loss: 0.645309, acc: 0.625000\n",
            "steps: 190\n",
            "save_steps: 1250\n",
            "20220510 14:30:29 current learning_rate:0.00000378\n",
            "used_time: 0.17259430885314941\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 200, loss: 0.561540, acc: 0.750000\n",
            "steps: 200\n",
            "save_steps: 1250\n",
            "20220510 14:30:31 current learning_rate:0.00000398\n",
            "used_time: 0.20690011978149414\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 210, loss: 0.622223, acc: 0.625000\n",
            "steps: 210\n",
            "save_steps: 1250\n",
            "20220510 14:30:33 current learning_rate:0.00000418\n",
            "used_time: 0.20981597900390625\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 220, loss: 0.531085, acc: 0.875000\n",
            "steps: 220\n",
            "save_steps: 1250\n",
            "20220510 14:30:35 current learning_rate:0.00000438\n",
            "used_time: 0.1876516342163086\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 230, loss: 0.697319, acc: 0.625000\n",
            "steps: 230\n",
            "save_steps: 1250\n",
            "20220510 14:30:37 current learning_rate:0.00000458\n",
            "used_time: 0.17321300506591797\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 240, loss: 0.641784, acc: 0.375000\n",
            "steps: 240\n",
            "save_steps: 1250\n",
            "20220510 14:30:39 current learning_rate:0.00000478\n",
            "used_time: 0.1807117462158203\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 250, loss: 0.559970, acc: 0.500000\n",
            "steps: 250\n",
            "save_steps: 1250\n",
            "20220510 14:30:41 current learning_rate:0.00000498\n",
            "used_time: 0.20145964622497559\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 260, loss: 0.861302, acc: 0.500000\n",
            "steps: 260\n",
            "save_steps: 1250\n",
            "20220510 14:30:42 current learning_rate:0.00000518\n",
            "used_time: 0.19977402687072754\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 270, loss: 0.532877, acc: 0.625000\n",
            "steps: 270\n",
            "save_steps: 1250\n",
            "20220510 14:30:44 current learning_rate:0.00000538\n",
            "used_time: 0.19564580917358398\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 280, loss: 0.789242, acc: 0.500000\n",
            "steps: 280\n",
            "save_steps: 1250\n",
            "20220510 14:30:46 current learning_rate:0.00000558\n",
            "used_time: 0.20193791389465332\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 290, loss: 0.736978, acc: 0.625000\n",
            "steps: 290\n",
            "save_steps: 1250\n",
            "20220510 14:30:48 current learning_rate:0.00000578\n",
            "used_time: 0.2004857063293457\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 300, loss: 0.619687, acc: 0.750000\n",
            "steps: 300\n",
            "save_steps: 1250\n",
            "20220510 14:30:50 current learning_rate:0.00000598\n",
            "used_time: 0.17681097984313965\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 310, loss: 0.506472, acc: 0.500000\n",
            "steps: 310\n",
            "save_steps: 1250\n",
            "20220510 14:30:52 current learning_rate:0.00000618\n",
            "used_time: 0.19681453704833984\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 320, loss: 0.602241, acc: 0.500000\n",
            "steps: 320\n",
            "save_steps: 1250\n",
            "20220510 14:30:54 current learning_rate:0.00000638\n",
            "used_time: 0.19210100173950195\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 330, loss: 0.856211, acc: 0.375000\n",
            "steps: 330\n",
            "save_steps: 1250\n",
            "20220510 14:30:56 current learning_rate:0.00000658\n",
            "used_time: 0.17303133010864258\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 340, loss: 0.720865, acc: 0.375000\n",
            "steps: 340\n",
            "save_steps: 1250\n",
            "20220510 14:30:58 current learning_rate:0.00000678\n",
            "used_time: 0.21900606155395508\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 350, loss: 0.718400, acc: 1.000000\n",
            "steps: 350\n",
            "save_steps: 1250\n",
            "20220510 14:31:00 current learning_rate:0.00000698\n",
            "used_time: 0.1975564956665039\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 360, loss: 0.544463, acc: 0.750000\n",
            "steps: 360\n",
            "save_steps: 1250\n",
            "20220510 14:31:02 current learning_rate:0.00000718\n",
            "used_time: 0.19276142120361328\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 370, loss: 0.687983, acc: 0.500000\n",
            "steps: 370\n",
            "save_steps: 1250\n",
            "20220510 14:31:04 current learning_rate:0.00000738\n",
            "used_time: 0.2391681671142578\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 380, loss: 0.520496, acc: 0.875000\n",
            "steps: 380\n",
            "save_steps: 1250\n",
            "20220510 14:31:06 current learning_rate:0.00000758\n",
            "used_time: 0.16966748237609863\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 390, loss: 0.428108, acc: 0.875000\n",
            "steps: 390\n",
            "save_steps: 1250\n",
            "20220510 14:31:08 current learning_rate:0.00000778\n",
            "used_time: 0.19674372673034668\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 400, loss: 0.491853, acc: 0.875000\n",
            "steps: 400\n",
            "save_steps: 1250\n",
            "20220510 14:31:09 current learning_rate:0.00000798\n",
            "used_time: 0.20459938049316406\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 410, loss: 0.626767, acc: 0.625000\n",
            "steps: 410\n",
            "save_steps: 1250\n",
            "20220510 14:31:11 current learning_rate:0.00000818\n",
            "used_time: 0.20551252365112305\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 420, loss: 0.646229, acc: 0.750000\n",
            "steps: 420\n",
            "save_steps: 1250\n",
            "20220510 14:31:13 current learning_rate:0.00000838\n",
            "used_time: 0.167649507522583\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 430, loss: 0.587955, acc: 0.750000\n",
            "steps: 430\n",
            "save_steps: 1250\n",
            "20220510 14:31:15 current learning_rate:0.00000858\n",
            "used_time: 0.19508028030395508\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 440, loss: 0.387171, acc: 0.750000\n",
            "steps: 440\n",
            "save_steps: 1250\n",
            "20220510 14:31:17 current learning_rate:0.00000878\n",
            "used_time: 0.16851186752319336\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 450, loss: 0.567992, acc: 0.750000\n",
            "steps: 450\n",
            "save_steps: 1250\n",
            "20220510 14:31:19 current learning_rate:0.00000898\n",
            "used_time: 0.19197821617126465\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 460, loss: 0.306868, acc: 0.750000\n",
            "steps: 460\n",
            "save_steps: 1250\n",
            "20220510 14:31:21 current learning_rate:0.00000918\n",
            "used_time: 0.16815757751464844\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 470, loss: 0.358068, acc: 0.625000\n",
            "steps: 470\n",
            "save_steps: 1250\n",
            "20220510 14:31:23 current learning_rate:0.00000938\n",
            "used_time: 0.1860494613647461\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 480, loss: 0.547186, acc: 0.625000\n",
            "steps: 480\n",
            "save_steps: 1250\n",
            "20220510 14:31:25 current learning_rate:0.00000958\n",
            "used_time: 0.17712736129760742\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 490, loss: 0.670926, acc: 0.750000\n",
            "steps: 490\n",
            "save_steps: 1250\n",
            "20220510 14:31:27 current learning_rate:0.00000978\n",
            "used_time: 0.1845409870147705\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 500, loss: 0.682445, acc: 0.625000\n",
            "steps: 500\n",
            "save_steps: 1250\n",
            "Train-RCAC 0.6388888888888888\n",
            "20220510 14:31:28 current learning_rate:0.00000998\n",
            "used_time: 0.1694643497467041\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 510, loss: 0.610842, acc: 0.625000\n",
            "steps: 510\n",
            "save_steps: 1250\n",
            "20220510 14:31:30 current learning_rate:0.00001000\n",
            "used_time: 0.2027573585510254\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 520, loss: 0.417760, acc: 0.750000\n",
            "steps: 520\n",
            "save_steps: 1250\n",
            "20220510 14:31:32 current learning_rate:0.00001000\n",
            "used_time: 0.16762113571166992\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 530, loss: 0.419142, acc: 0.625000\n",
            "steps: 530\n",
            "save_steps: 1250\n",
            "20220510 14:31:34 current learning_rate:0.00001000\n",
            "used_time: 0.1837315559387207\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 540, loss: 0.782144, acc: 0.500000\n",
            "steps: 540\n",
            "save_steps: 1250\n",
            "20220510 14:31:36 current learning_rate:0.00001000\n",
            "used_time: 0.18634819984436035\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 550, loss: 0.580759, acc: 0.750000\n",
            "steps: 550\n",
            "save_steps: 1250\n",
            "20220510 14:31:38 current learning_rate:0.00001000\n",
            "used_time: 0.17187905311584473\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 560, loss: 0.681228, acc: 0.500000\n",
            "steps: 560\n",
            "save_steps: 1250\n",
            "20220510 14:31:40 current learning_rate:0.00001000\n",
            "used_time: 0.17273569107055664\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 570, loss: 0.528373, acc: 0.625000\n",
            "steps: 570\n",
            "save_steps: 1250\n",
            "20220510 14:31:42 current learning_rate:0.00001000\n",
            "used_time: 0.2231004238128662\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 580, loss: 0.635829, acc: 0.625000\n",
            "steps: 580\n",
            "save_steps: 1250\n",
            "20220510 14:31:44 current learning_rate:0.00001000\n",
            "used_time: 0.21353578567504883\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 590, loss: 0.554305, acc: 0.625000\n",
            "steps: 590\n",
            "save_steps: 1250\n",
            "20220510 14:31:46 current learning_rate:0.00001000\n",
            "used_time: 0.19413447380065918\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 600, loss: 0.358710, acc: 0.875000\n",
            "steps: 600\n",
            "save_steps: 1250\n",
            "20220510 14:31:48 current learning_rate:0.00001000\n",
            "used_time: 0.20384001731872559\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 610, loss: 0.409654, acc: 0.500000\n",
            "steps: 610\n",
            "save_steps: 1250\n",
            "20220510 14:31:50 current learning_rate:0.00001000\n",
            "used_time: 0.19231557846069336\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 620, loss: 0.978015, acc: 0.750000\n",
            "steps: 620\n",
            "save_steps: 1250\n",
            "20220510 14:31:52 current learning_rate:0.00001000\n",
            "used_time: 0.18858098983764648\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 630, loss: 0.486064, acc: 0.375000\n",
            "steps: 630\n",
            "save_steps: 1250\n",
            "20220510 14:31:53 current learning_rate:0.00001000\n",
            "used_time: 0.20113682746887207\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 640, loss: 0.770005, acc: 0.750000\n",
            "steps: 640\n",
            "save_steps: 1250\n",
            "20220510 14:31:55 current learning_rate:0.00001000\n",
            "used_time: 0.1729428768157959\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 650, loss: 0.631849, acc: 0.625000\n",
            "steps: 650\n",
            "save_steps: 1250\n",
            "20220510 14:31:57 current learning_rate:0.00001000\n",
            "used_time: 0.18100547790527344\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 660, loss: 0.405232, acc: 0.750000\n",
            "steps: 660\n",
            "save_steps: 1250\n",
            "20220510 14:31:59 current learning_rate:0.00001000\n",
            "used_time: 0.18881702423095703\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 670, loss: 0.644762, acc: 0.375000\n",
            "steps: 670\n",
            "save_steps: 1250\n",
            "20220510 14:32:01 current learning_rate:0.00001000\n",
            "used_time: 0.18709349632263184\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 680, loss: 0.824504, acc: 0.375000\n",
            "steps: 680\n",
            "save_steps: 1250\n",
            "20220510 14:32:03 current learning_rate:0.00001000\n",
            "used_time: 0.24827909469604492\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 690, loss: 0.588110, acc: 0.625000\n",
            "steps: 690\n",
            "save_steps: 1250\n",
            "20220510 14:32:05 current learning_rate:0.00001000\n",
            "used_time: 0.19747090339660645\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 700, loss: 0.473106, acc: 0.875000\n",
            "steps: 700\n",
            "save_steps: 1250\n",
            "20220510 14:32:07 current learning_rate:0.00001000\n",
            "used_time: 0.16743230819702148\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 710, loss: 0.242186, acc: 0.875000\n",
            "steps: 710\n",
            "save_steps: 1250\n",
            "20220510 14:32:09 current learning_rate:0.00001000\n",
            "used_time: 0.2121870517730713\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 720, loss: 0.536098, acc: 0.625000\n",
            "steps: 720\n",
            "save_steps: 1250\n",
            "20220510 14:32:11 current learning_rate:0.00001000\n",
            "used_time: 0.20244669914245605\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 730, loss: 0.493766, acc: 0.250000\n",
            "steps: 730\n",
            "save_steps: 1250\n",
            "20220510 14:32:13 current learning_rate:0.00001000\n",
            "used_time: 0.20525836944580078\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 740, loss: 0.583036, acc: 0.625000\n",
            "steps: 740\n",
            "save_steps: 1250\n",
            "20220510 14:32:15 current learning_rate:0.00001000\n",
            "used_time: 0.20654773712158203\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 750, loss: 0.864139, acc: 0.500000\n",
            "steps: 750\n",
            "save_steps: 1250\n",
            "20220510 14:32:17 current learning_rate:0.00001000\n",
            "used_time: 0.18723177909851074\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 760, loss: 0.195378, acc: 0.625000\n",
            "steps: 760\n",
            "save_steps: 1250\n",
            "20220510 14:32:18 current learning_rate:0.00001000\n",
            "used_time: 0.18967175483703613\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 770, loss: 0.351083, acc: 0.750000\n",
            "steps: 770\n",
            "save_steps: 1250\n",
            "20220510 14:32:20 current learning_rate:0.00001000\n",
            "used_time: 0.2082841396331787\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 780, loss: 0.506973, acc: 0.500000\n",
            "steps: 780\n",
            "save_steps: 1250\n",
            "20220510 14:32:22 current learning_rate:0.00001000\n",
            "used_time: 0.1755049228668213\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 790, loss: 0.563036, acc: 0.750000\n",
            "steps: 790\n",
            "save_steps: 1250\n",
            "20220510 14:32:24 current learning_rate:0.00001000\n",
            "used_time: 0.20584392547607422\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 800, loss: 0.421537, acc: 0.875000\n",
            "steps: 800\n",
            "save_steps: 1250\n",
            "20220510 14:32:26 current learning_rate:0.00001000\n",
            "used_time: 0.17095494270324707\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 810, loss: 0.476959, acc: 0.750000\n",
            "steps: 810\n",
            "save_steps: 1250\n",
            "20220510 14:32:28 current learning_rate:0.00001000\n",
            "used_time: 0.19008994102478027\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 820, loss: 0.434170, acc: 0.500000\n",
            "steps: 820\n",
            "save_steps: 1250\n",
            "20220510 14:32:30 current learning_rate:0.00001000\n",
            "used_time: 0.2007148265838623\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 830, loss: 0.661411, acc: 0.500000\n",
            "steps: 830\n",
            "save_steps: 1250\n",
            "20220510 14:32:32 current learning_rate:0.00001000\n",
            "used_time: 0.17858362197875977\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 840, loss: 0.384834, acc: 0.625000\n",
            "steps: 840\n",
            "save_steps: 1250\n",
            "20220510 14:32:33 current learning_rate:0.00001000\n",
            "used_time: 0.19509148597717285\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 850, loss: 0.753288, acc: 0.375000\n",
            "steps: 850\n",
            "save_steps: 1250\n",
            "20220510 14:32:35 current learning_rate:0.00001000\n",
            "used_time: 0.2091670036315918\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 860, loss: 0.262980, acc: 0.750000\n",
            "steps: 860\n",
            "save_steps: 1250\n",
            "20220510 14:32:37 current learning_rate:0.00001000\n",
            "used_time: 0.1696004867553711\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 870, loss: 0.442448, acc: 0.750000\n",
            "steps: 870\n",
            "save_steps: 1250\n",
            "20220510 14:32:39 current learning_rate:0.00001000\n",
            "used_time: 0.18988823890686035\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 880, loss: 0.261799, acc: 0.875000\n",
            "steps: 880\n",
            "save_steps: 1250\n",
            "20220510 14:32:41 current learning_rate:0.00001000\n",
            "used_time: 0.18524765968322754\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 890, loss: 0.422418, acc: 0.625000\n",
            "steps: 890\n",
            "save_steps: 1250\n",
            "20220510 14:32:43 current learning_rate:0.00001000\n",
            "used_time: 0.21136736869812012\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 900, loss: 0.674024, acc: 0.375000\n",
            "steps: 900\n",
            "save_steps: 1250\n",
            "20220510 14:32:45 current learning_rate:0.00001000\n",
            "used_time: 0.17119169235229492\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 910, loss: 0.232300, acc: 0.875000\n",
            "steps: 910\n",
            "save_steps: 1250\n",
            "20220510 14:32:47 current learning_rate:0.00001000\n",
            "used_time: 0.1974658966064453\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 920, loss: 0.717189, acc: 0.500000\n",
            "steps: 920\n",
            "save_steps: 1250\n",
            "20220510 14:32:49 current learning_rate:0.00001000\n",
            "used_time: 0.18166756629943848\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 930, loss: 0.346800, acc: 0.875000\n",
            "steps: 930\n",
            "save_steps: 1250\n",
            "20220510 14:32:51 current learning_rate:0.00001000\n",
            "used_time: 0.2031259536743164\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 940, loss: 0.389981, acc: 0.625000\n",
            "steps: 940\n",
            "save_steps: 1250\n",
            "20220510 14:32:53 current learning_rate:0.00001000\n",
            "used_time: 0.20290303230285645\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 950, loss: 0.089098, acc: 0.750000\n",
            "steps: 950\n",
            "save_steps: 1250\n",
            "20220510 14:32:55 current learning_rate:0.00001000\n",
            "used_time: 0.20162677764892578\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 960, loss: 0.702429, acc: 0.375000\n",
            "steps: 960\n",
            "save_steps: 1250\n",
            "20220510 14:32:57 current learning_rate:0.00001000\n",
            "used_time: 0.20241117477416992\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 970, loss: 0.336526, acc: 0.375000\n",
            "steps: 970\n",
            "save_steps: 1250\n",
            "20220510 14:32:59 current learning_rate:0.00001000\n",
            "used_time: 0.20469021797180176\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 980, loss: 1.187663, acc: 0.375000\n",
            "steps: 980\n",
            "save_steps: 1250\n",
            "20220510 14:33:01 current learning_rate:0.00001000\n",
            "used_time: 0.1662600040435791\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 990, loss: 0.584797, acc: 0.875000\n",
            "steps: 990\n",
            "save_steps: 1250\n",
            "20220510 14:33:02 current learning_rate:0.00001000\n",
            "used_time: 0.24463725090026855\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1000, loss: 0.302085, acc: 0.875000\n",
            "steps: 1000\n",
            "save_steps: 1250\n",
            "Train-RCAC 0.9388083735909823\n",
            "20220510 14:33:04 current learning_rate:0.00001000\n",
            "used_time: 0.1681346893310547\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1010, loss: 0.609503, acc: 0.500000\n",
            "steps: 1010\n",
            "save_steps: 1250\n",
            "20220510 14:33:06 current learning_rate:0.00001000\n",
            "used_time: 0.2122640609741211\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1020, loss: 0.836993, acc: 0.500000\n",
            "steps: 1020\n",
            "save_steps: 1250\n",
            "20220510 14:33:08 current learning_rate:0.00001000\n",
            "used_time: 0.19553089141845703\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1030, loss: 0.520131, acc: 0.375000\n",
            "steps: 1030\n",
            "save_steps: 1250\n",
            "20220510 14:33:10 current learning_rate:0.00001000\n",
            "used_time: 0.22894954681396484\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1040, loss: 0.670118, acc: 0.375000\n",
            "steps: 1040\n",
            "save_steps: 1250\n",
            "20220510 14:33:12 current learning_rate:0.00001000\n",
            "used_time: 0.21000432968139648\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1050, loss: 0.337296, acc: 0.625000\n",
            "steps: 1050\n",
            "save_steps: 1250\n",
            "20220510 14:33:14 current learning_rate:0.00001000\n",
            "used_time: 0.21893811225891113\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1060, loss: 0.446287, acc: 0.750000\n",
            "steps: 1060\n",
            "save_steps: 1250\n",
            "20220510 14:33:16 current learning_rate:0.00001000\n",
            "used_time: 0.17868328094482422\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1070, loss: 1.200327, acc: 0.500000\n",
            "steps: 1070\n",
            "save_steps: 1250\n",
            "20220510 14:33:18 current learning_rate:0.00001000\n",
            "used_time: 0.1570138931274414\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1080, loss: 0.520198, acc: 0.500000\n",
            "steps: 1080\n",
            "save_steps: 1250\n",
            "20220510 14:33:20 current learning_rate:0.00001000\n",
            "used_time: 0.207780122756958\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1090, loss: 0.347964, acc: 0.625000\n",
            "steps: 1090\n",
            "save_steps: 1250\n",
            "20220510 14:33:22 current learning_rate:0.00001000\n",
            "used_time: 0.25655627250671387\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1100, loss: 0.593197, acc: 0.500000\n",
            "steps: 1100\n",
            "save_steps: 1250\n",
            "20220510 14:33:24 current learning_rate:0.00001000\n",
            "used_time: 0.16961956024169922\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1110, loss: 0.502060, acc: 0.875000\n",
            "steps: 1110\n",
            "save_steps: 1250\n",
            "20220510 14:33:26 current learning_rate:0.00001000\n",
            "used_time: 0.1840195655822754\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1120, loss: 0.524946, acc: 0.500000\n",
            "steps: 1120\n",
            "save_steps: 1250\n",
            "20220510 14:33:28 current learning_rate:0.00001000\n",
            "used_time: 0.19079828262329102\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1130, loss: 0.520113, acc: 0.875000\n",
            "steps: 1130\n",
            "save_steps: 1250\n",
            "20220510 14:33:29 current learning_rate:0.00001000\n",
            "used_time: 0.17635679244995117\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1140, loss: 0.293127, acc: 0.500000\n",
            "steps: 1140\n",
            "save_steps: 1250\n",
            "20220510 14:33:31 current learning_rate:0.00001000\n",
            "used_time: 0.20833921432495117\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1150, loss: 0.377138, acc: 0.625000\n",
            "steps: 1150\n",
            "save_steps: 1250\n",
            "20220510 14:33:33 current learning_rate:0.00001000\n",
            "used_time: 0.18427777290344238\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1160, loss: 0.820924, acc: 0.625000\n",
            "steps: 1160\n",
            "save_steps: 1250\n",
            "20220510 14:33:35 current learning_rate:0.00001000\n",
            "used_time: 0.21801376342773438\n",
            "shuffle epoch 1\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1170, loss: 0.426803, acc: 0.625000\n",
            "steps: 1170\n",
            "save_steps: 1250\n",
            "20220510 14:33:37 current learning_rate:0.00001000\n",
            "used_time: 0.1827850341796875\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1180, loss: 0.680800, acc: 0.750000\n",
            "steps: 1180\n",
            "save_steps: 1250\n",
            "20220510 14:33:39 current learning_rate:0.00001000\n",
            "used_time: 0.19042301177978516\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1190, loss: 0.289837, acc: 0.375000\n",
            "steps: 1190\n",
            "save_steps: 1250\n",
            "20220510 14:33:41 current learning_rate:0.00001000\n",
            "used_time: 0.20371508598327637\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1200, loss: 0.601781, acc: 0.500000\n",
            "steps: 1200\n",
            "save_steps: 1250\n",
            "20220510 14:33:43 current learning_rate:0.00001000\n",
            "used_time: 0.12467384338378906\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1210, loss: 0.626437, acc: 0.750000\n",
            "steps: 1210\n",
            "save_steps: 1250\n",
            "20220510 14:33:45 current learning_rate:0.00001000\n",
            "used_time: 0.19193387031555176\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1220, loss: 0.324562, acc: 0.375000\n",
            "steps: 1220\n",
            "save_steps: 1250\n",
            "20220510 14:33:47 current learning_rate:0.00001000\n",
            "used_time: 0.197770357131958\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1230, loss: 1.286929, acc: 0.500000\n",
            "steps: 1230\n",
            "save_steps: 1250\n",
            "20220510 14:33:48 current learning_rate:0.00001000\n",
            "used_time: 0.18404912948608398\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1240, loss: 0.728173, acc: 0.625000\n",
            "steps: 1240\n",
            "save_steps: 1250\n",
            "20220510 14:33:50 current learning_rate:0.00001000\n",
            "used_time: 0.1874077320098877\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1250, loss: 0.197113, acc: 0.750000\n",
            "steps: 1250\n",
            "save_steps: 1250\n",
            "20220510 14:33:52 current learning_rate:0.00001000\n",
            "save_path: output_hm/step_1250traindev\n",
            "used_time: 11.497514486312866\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1260, loss: 0.763421, acc: 0.750000\n",
            "steps: 1260\n",
            "save_steps: 1250\n",
            "20220510 14:34:05 current learning_rate:0.00001000\n",
            "used_time: 0.17470121383666992\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1270, loss: 0.469210, acc: 0.875000\n",
            "steps: 1270\n",
            "save_steps: 1250\n",
            "20220510 14:34:07 current learning_rate:0.00001000\n",
            "used_time: 0.19280791282653809\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1280, loss: 0.530916, acc: 0.625000\n",
            "steps: 1280\n",
            "save_steps: 1250\n",
            "20220510 14:34:09 current learning_rate:0.00001000\n",
            "used_time: 0.17992162704467773\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1290, loss: 0.779818, acc: 0.250000\n",
            "steps: 1290\n",
            "save_steps: 1250\n",
            "20220510 14:34:11 current learning_rate:0.00001000\n",
            "used_time: 0.18166732788085938\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1300, loss: 0.275375, acc: 0.750000\n",
            "steps: 1300\n",
            "save_steps: 1250\n",
            "20220510 14:34:13 current learning_rate:0.00001000\n",
            "used_time: 0.17360448837280273\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1310, loss: 0.238858, acc: 0.500000\n",
            "steps: 1310\n",
            "save_steps: 1250\n",
            "20220510 14:34:15 current learning_rate:0.00001000\n",
            "used_time: 0.18013477325439453\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1320, loss: 0.480867, acc: 0.625000\n",
            "steps: 1320\n",
            "save_steps: 1250\n",
            "20220510 14:34:17 current learning_rate:0.00001000\n",
            "used_time: 0.1864917278289795\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1330, loss: 0.119664, acc: 0.875000\n",
            "steps: 1330\n",
            "save_steps: 1250\n",
            "20220510 14:34:19 current learning_rate:0.00001000\n",
            "used_time: 0.21209192276000977\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1340, loss: 0.113483, acc: 0.875000\n",
            "steps: 1340\n",
            "save_steps: 1250\n",
            "20220510 14:34:21 current learning_rate:0.00001000\n",
            "used_time: 0.17078137397766113\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1350, loss: 0.217144, acc: 0.625000\n",
            "steps: 1350\n",
            "save_steps: 1250\n",
            "20220510 14:34:23 current learning_rate:0.00001000\n",
            "used_time: 0.1838393211364746\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1360, loss: 0.232278, acc: 0.375000\n",
            "steps: 1360\n",
            "save_steps: 1250\n",
            "20220510 14:34:25 current learning_rate:0.00001000\n",
            "used_time: 0.1728513240814209\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1370, loss: 0.270063, acc: 0.625000\n",
            "steps: 1370\n",
            "save_steps: 1250\n",
            "20220510 14:34:27 current learning_rate:0.00001000\n",
            "used_time: 0.17983031272888184\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1380, loss: 0.672549, acc: 0.750000\n",
            "steps: 1380\n",
            "save_steps: 1250\n",
            "20220510 14:34:28 current learning_rate:0.00001000\n",
            "used_time: 0.17391681671142578\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1390, loss: 0.202483, acc: 0.375000\n",
            "steps: 1390\n",
            "save_steps: 1250\n",
            "20220510 14:34:30 current learning_rate:0.00001000\n",
            "used_time: 0.19106841087341309\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1400, loss: 0.345490, acc: 0.625000\n",
            "steps: 1400\n",
            "save_steps: 1250\n",
            "20220510 14:34:32 current learning_rate:0.00001000\n",
            "used_time: 0.19591927528381348\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1410, loss: 0.322649, acc: 0.750000\n",
            "steps: 1410\n",
            "save_steps: 1250\n",
            "20220510 14:34:34 current learning_rate:0.00001000\n",
            "used_time: 0.17658352851867676\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1420, loss: 0.047323, acc: 0.750000\n",
            "steps: 1420\n",
            "save_steps: 1250\n",
            "20220510 14:34:36 current learning_rate:0.00001000\n",
            "used_time: 0.19098234176635742\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1430, loss: 1.105719, acc: 0.500000\n",
            "steps: 1430\n",
            "save_steps: 1250\n",
            "20220510 14:34:38 current learning_rate:0.00001000\n",
            "used_time: 0.18314242362976074\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1440, loss: 0.871096, acc: 0.500000\n",
            "steps: 1440\n",
            "save_steps: 1250\n",
            "20220510 14:34:40 current learning_rate:0.00001000\n",
            "used_time: 0.18512487411499023\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1450, loss: 0.501329, acc: 0.500000\n",
            "steps: 1450\n",
            "save_steps: 1250\n",
            "20220510 14:34:42 current learning_rate:0.00001000\n",
            "used_time: 0.19363617897033691\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1460, loss: 0.224814, acc: 0.875000\n",
            "steps: 1460\n",
            "save_steps: 1250\n",
            "20220510 14:34:44 current learning_rate:0.00001000\n",
            "used_time: 0.23581433296203613\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1470, loss: 0.491183, acc: 0.500000\n",
            "steps: 1470\n",
            "save_steps: 1250\n",
            "20220510 14:34:46 current learning_rate:0.00001000\n",
            "used_time: 0.21909213066101074\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1480, loss: 0.288394, acc: 0.750000\n",
            "steps: 1480\n",
            "save_steps: 1250\n",
            "20220510 14:34:48 current learning_rate:0.00001000\n",
            "used_time: 0.20132040977478027\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1490, loss: 0.454455, acc: 0.625000\n",
            "steps: 1490\n",
            "save_steps: 1250\n",
            "20220510 14:34:49 current learning_rate:0.00001000\n",
            "used_time: 0.1840682029724121\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1500, loss: 0.313954, acc: 0.250000\n",
            "steps: 1500\n",
            "save_steps: 1250\n",
            "Train-RCAC 0.865874363327674\n",
            "20220510 14:34:51 current learning_rate:0.00001000\n",
            "used_time: 0.21018147468566895\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1510, loss: 0.398372, acc: 0.375000\n",
            "steps: 1510\n",
            "save_steps: 1250\n",
            "20220510 14:34:53 current learning_rate:0.00001000\n",
            "used_time: 0.19713950157165527\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1520, loss: 0.774035, acc: 0.375000\n",
            "steps: 1520\n",
            "save_steps: 1250\n",
            "20220510 14:34:55 current learning_rate:0.00001000\n",
            "used_time: 0.19394779205322266\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1530, loss: 0.367102, acc: 0.625000\n",
            "steps: 1530\n",
            "save_steps: 1250\n",
            "20220510 14:34:57 current learning_rate:0.00001000\n",
            "used_time: 0.2365875244140625\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1540, loss: 0.482557, acc: 0.625000\n",
            "steps: 1540\n",
            "save_steps: 1250\n",
            "20220510 14:34:59 current learning_rate:0.00001000\n",
            "used_time: 0.17327666282653809\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1550, loss: 1.200114, acc: 0.500000\n",
            "steps: 1550\n",
            "save_steps: 1250\n",
            "20220510 14:35:01 current learning_rate:0.00001000\n",
            "used_time: 0.17121624946594238\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1560, loss: 0.218496, acc: 0.875000\n",
            "steps: 1560\n",
            "save_steps: 1250\n",
            "20220510 14:35:03 current learning_rate:0.00001000\n",
            "used_time: 0.18601202964782715\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1570, loss: 0.187448, acc: 0.500000\n",
            "steps: 1570\n",
            "save_steps: 1250\n",
            "20220510 14:35:05 current learning_rate:0.00001000\n",
            "used_time: 0.2027592658996582\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1580, loss: 0.782438, acc: 0.500000\n",
            "steps: 1580\n",
            "save_steps: 1250\n",
            "20220510 14:35:07 current learning_rate:0.00001000\n",
            "used_time: 0.1782393455505371\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1590, loss: 0.412965, acc: 0.500000\n",
            "steps: 1590\n",
            "save_steps: 1250\n",
            "20220510 14:35:09 current learning_rate:0.00001000\n",
            "used_time: 0.19614720344543457\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1600, loss: 0.643450, acc: 0.750000\n",
            "steps: 1600\n",
            "save_steps: 1250\n",
            "20220510 14:35:11 current learning_rate:0.00001000\n",
            "used_time: 0.17673087120056152\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1610, loss: 0.674156, acc: 0.625000\n",
            "steps: 1610\n",
            "save_steps: 1250\n",
            "20220510 14:35:13 current learning_rate:0.00001000\n",
            "used_time: 0.17321300506591797\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1620, loss: 0.259350, acc: 0.750000\n",
            "steps: 1620\n",
            "save_steps: 1250\n",
            "20220510 14:35:15 current learning_rate:0.00001000\n",
            "used_time: 0.17173504829406738\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1630, loss: 0.463978, acc: 0.500000\n",
            "steps: 1630\n",
            "save_steps: 1250\n",
            "20220510 14:35:17 current learning_rate:0.00001000\n",
            "used_time: 0.20148801803588867\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1640, loss: 0.454403, acc: 0.750000\n",
            "steps: 1640\n",
            "save_steps: 1250\n",
            "20220510 14:35:18 current learning_rate:0.00001000\n",
            "used_time: 0.1762862205505371\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1650, loss: 0.901195, acc: 0.625000\n",
            "steps: 1650\n",
            "save_steps: 1250\n",
            "20220510 14:35:21 current learning_rate:0.00001000\n",
            "used_time: 0.2088172435760498\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1660, loss: 0.330377, acc: 0.375000\n",
            "steps: 1660\n",
            "save_steps: 1250\n",
            "20220510 14:35:22 current learning_rate:0.00001000\n",
            "used_time: 0.20250749588012695\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1670, loss: 0.822464, acc: 0.625000\n",
            "steps: 1670\n",
            "save_steps: 1250\n",
            "20220510 14:35:24 current learning_rate:0.00001000\n",
            "used_time: 0.2016286849975586\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1680, loss: 0.314527, acc: 0.625000\n",
            "steps: 1680\n",
            "save_steps: 1250\n",
            "20220510 14:35:26 current learning_rate:0.00001000\n",
            "used_time: 0.17638874053955078\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1690, loss: 0.684720, acc: 0.500000\n",
            "steps: 1690\n",
            "save_steps: 1250\n",
            "20220510 14:35:28 current learning_rate:0.00001000\n",
            "used_time: 0.21408462524414062\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1700, loss: 0.262633, acc: 0.250000\n",
            "steps: 1700\n",
            "save_steps: 1250\n",
            "20220510 14:35:30 current learning_rate:0.00001000\n",
            "used_time: 0.18568682670593262\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1710, loss: 0.168449, acc: 0.500000\n",
            "steps: 1710\n",
            "save_steps: 1250\n",
            "20220510 14:35:32 current learning_rate:0.00001000\n",
            "used_time: 0.19387149810791016\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1720, loss: 0.155290, acc: 0.750000\n",
            "steps: 1720\n",
            "save_steps: 1250\n",
            "20220510 14:35:34 current learning_rate:0.00001000\n",
            "used_time: 0.1801919937133789\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1730, loss: 0.174653, acc: 0.750000\n",
            "steps: 1730\n",
            "save_steps: 1250\n",
            "20220510 14:35:36 current learning_rate:0.00001000\n",
            "used_time: 0.19307756423950195\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1740, loss: 0.360188, acc: 0.375000\n",
            "steps: 1740\n",
            "save_steps: 1250\n",
            "20220510 14:35:38 current learning_rate:0.00001000\n",
            "used_time: 0.2107710838317871\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1750, loss: 0.479612, acc: 0.625000\n",
            "steps: 1750\n",
            "save_steps: 1250\n",
            "20220510 14:35:40 current learning_rate:0.00001000\n",
            "used_time: 0.17181062698364258\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1760, loss: 0.315819, acc: 0.625000\n",
            "steps: 1760\n",
            "save_steps: 1250\n",
            "20220510 14:35:42 current learning_rate:0.00001000\n",
            "used_time: 0.18868112564086914\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1770, loss: 0.066552, acc: 0.625000\n",
            "steps: 1770\n",
            "save_steps: 1250\n",
            "20220510 14:35:43 current learning_rate:0.00001000\n",
            "used_time: 0.18982505798339844\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1780, loss: 0.646696, acc: 0.750000\n",
            "steps: 1780\n",
            "save_steps: 1250\n",
            "20220510 14:35:45 current learning_rate:0.00001000\n",
            "used_time: 0.16492700576782227\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1790, loss: 0.414655, acc: 0.500000\n",
            "steps: 1790\n",
            "save_steps: 1250\n",
            "20220510 14:35:47 current learning_rate:0.00001000\n",
            "used_time: 0.21720504760742188\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1800, loss: 0.971221, acc: 0.875000\n",
            "steps: 1800\n",
            "save_steps: 1250\n",
            "20220510 14:35:49 current learning_rate:0.00001000\n",
            "used_time: 0.196425199508667\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1810, loss: 0.772765, acc: 0.875000\n",
            "steps: 1810\n",
            "save_steps: 1250\n",
            "20220510 14:35:51 current learning_rate:0.00001000\n",
            "used_time: 0.1906731128692627\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1820, loss: 0.077465, acc: 0.625000\n",
            "steps: 1820\n",
            "save_steps: 1250\n",
            "20220510 14:35:53 current learning_rate:0.00001000\n",
            "used_time: 0.17363667488098145\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1830, loss: 0.877759, acc: 0.500000\n",
            "steps: 1830\n",
            "save_steps: 1250\n",
            "20220510 14:35:55 current learning_rate:0.00001000\n",
            "used_time: 0.17391347885131836\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1840, loss: 1.510092, acc: 0.375000\n",
            "steps: 1840\n",
            "save_steps: 1250\n",
            "20220510 14:35:57 current learning_rate:0.00001000\n",
            "used_time: 0.19386816024780273\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1850, loss: 0.323446, acc: 0.500000\n",
            "steps: 1850\n",
            "save_steps: 1250\n",
            "20220510 14:35:59 current learning_rate:0.00001000\n",
            "used_time: 0.21584534645080566\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1860, loss: 0.132096, acc: 0.750000\n",
            "steps: 1860\n",
            "save_steps: 1250\n",
            "20220510 14:36:01 current learning_rate:0.00001000\n",
            "used_time: 0.17998623847961426\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1870, loss: 0.364529, acc: 0.500000\n",
            "steps: 1870\n",
            "save_steps: 1250\n",
            "20220510 14:36:03 current learning_rate:0.00001000\n",
            "used_time: 0.18930339813232422\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1880, loss: 0.531247, acc: 0.750000\n",
            "steps: 1880\n",
            "save_steps: 1250\n",
            "20220510 14:36:05 current learning_rate:0.00001000\n",
            "used_time: 0.18903398513793945\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1890, loss: 0.338851, acc: 0.625000\n",
            "steps: 1890\n",
            "save_steps: 1250\n",
            "20220510 14:36:07 current learning_rate:0.00001000\n",
            "used_time: 0.214371919631958\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1900, loss: 0.290547, acc: 0.750000\n",
            "steps: 1900\n",
            "save_steps: 1250\n",
            "20220510 14:36:09 current learning_rate:0.00001000\n",
            "used_time: 0.2197895050048828\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1910, loss: 0.614124, acc: 0.625000\n",
            "steps: 1910\n",
            "save_steps: 1250\n",
            "20220510 14:36:11 current learning_rate:0.00001000\n",
            "used_time: 0.19459247589111328\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1920, loss: 0.170517, acc: 0.625000\n",
            "steps: 1920\n",
            "save_steps: 1250\n",
            "20220510 14:36:13 current learning_rate:0.00001000\n",
            "used_time: 0.1726853847503662\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1930, loss: 0.358863, acc: 0.625000\n",
            "steps: 1930\n",
            "save_steps: 1250\n",
            "20220510 14:36:15 current learning_rate:0.00001000\n",
            "used_time: 0.20111632347106934\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1940, loss: 0.075298, acc: 0.500000\n",
            "steps: 1940\n",
            "save_steps: 1250\n",
            "20220510 14:36:16 current learning_rate:0.00001000\n",
            "used_time: 0.17458128929138184\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1950, loss: 1.196295, acc: 0.875000\n",
            "steps: 1950\n",
            "save_steps: 1250\n",
            "20220510 14:36:18 current learning_rate:0.00001000\n",
            "used_time: 0.22621679306030273\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1960, loss: 0.198208, acc: 0.625000\n",
            "steps: 1960\n",
            "save_steps: 1250\n",
            "20220510 14:36:20 current learning_rate:0.00001000\n",
            "used_time: 0.1884763240814209\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1970, loss: 0.274495, acc: 0.500000\n",
            "steps: 1970\n",
            "save_steps: 1250\n",
            "20220510 14:36:22 current learning_rate:0.00001000\n",
            "used_time: 0.19435691833496094\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1980, loss: 0.097073, acc: 0.375000\n",
            "steps: 1980\n",
            "save_steps: 1250\n",
            "20220510 14:36:24 current learning_rate:0.00001000\n",
            "used_time: 0.20658397674560547\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1990, loss: 0.573102, acc: 0.625000\n",
            "steps: 1990\n",
            "save_steps: 1250\n",
            "20220510 14:36:26 current learning_rate:0.00001000\n",
            "used_time: 0.18853044509887695\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2000, loss: 0.696688, acc: 0.500000\n",
            "steps: 2000\n",
            "save_steps: 1250\n",
            "Train-RCAC 0.7866666666666666\n",
            "20220510 14:36:28 current learning_rate:0.00001000\n",
            "used_time: 0.17841148376464844\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2010, loss: 0.109112, acc: 0.625000\n",
            "steps: 2010\n",
            "save_steps: 1250\n",
            "20220510 14:36:30 current learning_rate:0.00001000\n",
            "used_time: 0.1976485252380371\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2020, loss: 0.034041, acc: 0.750000\n",
            "steps: 2020\n",
            "save_steps: 1250\n",
            "20220510 14:36:32 current learning_rate:0.00001000\n",
            "used_time: 0.18698954582214355\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2030, loss: 0.549387, acc: 0.500000\n",
            "steps: 2030\n",
            "save_steps: 1250\n",
            "20220510 14:36:34 current learning_rate:0.00001000\n",
            "used_time: 0.21100592613220215\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2040, loss: 1.103270, acc: 0.625000\n",
            "steps: 2040\n",
            "save_steps: 1250\n",
            "20220510 14:36:36 current learning_rate:0.00001000\n",
            "used_time: 0.18937325477600098\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2050, loss: 0.268762, acc: 0.625000\n",
            "steps: 2050\n",
            "save_steps: 1250\n",
            "20220510 14:36:38 current learning_rate:0.00001000\n",
            "used_time: 0.2057797908782959\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2060, loss: 0.139136, acc: 0.875000\n",
            "steps: 2060\n",
            "save_steps: 1250\n",
            "20220510 14:36:40 current learning_rate:0.00001000\n",
            "used_time: 0.2296462059020996\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2070, loss: 0.423496, acc: 0.625000\n",
            "steps: 2070\n",
            "save_steps: 1250\n",
            "20220510 14:36:42 current learning_rate:0.00001000\n",
            "used_time: 0.2086780071258545\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2080, loss: 0.154864, acc: 0.625000\n",
            "steps: 2080\n",
            "save_steps: 1250\n",
            "20220510 14:36:43 current learning_rate:0.00001000\n",
            "used_time: 0.19992733001708984\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2090, loss: 0.392092, acc: 0.625000\n",
            "steps: 2090\n",
            "save_steps: 1250\n",
            "20220510 14:36:45 current learning_rate:0.00001000\n",
            "used_time: 0.22375988960266113\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2100, loss: 0.282412, acc: 0.750000\n",
            "steps: 2100\n",
            "save_steps: 1250\n",
            "20220510 14:36:47 current learning_rate:0.00001000\n",
            "used_time: 0.17447757720947266\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2110, loss: 0.633162, acc: 0.625000\n",
            "steps: 2110\n",
            "save_steps: 1250\n",
            "20220510 14:36:49 current learning_rate:0.00001000\n",
            "used_time: 0.16456127166748047\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2120, loss: 0.148115, acc: 0.625000\n",
            "steps: 2120\n",
            "save_steps: 1250\n",
            "20220510 14:36:51 current learning_rate:0.00001000\n",
            "used_time: 0.19291305541992188\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2130, loss: 0.394854, acc: 0.750000\n",
            "steps: 2130\n",
            "save_steps: 1250\n",
            "20220510 14:36:53 current learning_rate:0.00001000\n",
            "used_time: 0.20109248161315918\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2140, loss: 0.822538, acc: 0.875000\n",
            "steps: 2140\n",
            "save_steps: 1250\n",
            "20220510 14:36:55 current learning_rate:0.00001000\n",
            "used_time: 0.1814255714416504\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2150, loss: 0.191302, acc: 0.500000\n",
            "steps: 2150\n",
            "save_steps: 1250\n",
            "20220510 14:36:57 current learning_rate:0.00001000\n",
            "used_time: 0.17792248725891113\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2160, loss: 0.456067, acc: 0.625000\n",
            "steps: 2160\n",
            "save_steps: 1250\n",
            "20220510 14:36:59 current learning_rate:0.00001000\n",
            "used_time: 0.23879122734069824\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2170, loss: 0.451328, acc: 0.375000\n",
            "steps: 2170\n",
            "save_steps: 1250\n",
            "20220510 14:37:01 current learning_rate:0.00001000\n",
            "used_time: 0.17693114280700684\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2180, loss: 0.531638, acc: 0.875000\n",
            "steps: 2180\n",
            "save_steps: 1250\n",
            "20220510 14:37:03 current learning_rate:0.00001000\n",
            "used_time: 0.23554730415344238\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2190, loss: 1.125858, acc: 0.500000\n",
            "steps: 2190\n",
            "save_steps: 1250\n",
            "20220510 14:37:04 current learning_rate:0.00001000\n",
            "used_time: 0.17196059226989746\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2200, loss: 0.484098, acc: 0.625000\n",
            "steps: 2200\n",
            "save_steps: 1250\n",
            "20220510 14:37:06 current learning_rate:0.00001000\n",
            "used_time: 0.19248700141906738\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2210, loss: 1.070058, acc: 0.500000\n",
            "steps: 2210\n",
            "save_steps: 1250\n",
            "20220510 14:37:08 current learning_rate:0.00001000\n",
            "used_time: 0.18442249298095703\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2220, loss: 0.283106, acc: 0.250000\n",
            "steps: 2220\n",
            "save_steps: 1250\n",
            "20220510 14:37:10 current learning_rate:0.00001000\n",
            "used_time: 0.18660426139831543\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2230, loss: 0.648276, acc: 0.625000\n",
            "steps: 2230\n",
            "save_steps: 1250\n",
            "20220510 14:37:12 current learning_rate:0.00001000\n",
            "used_time: 0.19061064720153809\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2240, loss: 0.275575, acc: 0.625000\n",
            "steps: 2240\n",
            "save_steps: 1250\n",
            "20220510 14:37:14 current learning_rate:0.00001000\n",
            "used_time: 0.1740419864654541\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2250, loss: 0.211565, acc: 0.625000\n",
            "steps: 2250\n",
            "save_steps: 1250\n",
            "20220510 14:37:16 current learning_rate:0.00001000\n",
            "used_time: 0.19322443008422852\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2260, loss: 0.283278, acc: 0.625000\n",
            "steps: 2260\n",
            "save_steps: 1250\n",
            "20220510 14:37:18 current learning_rate:0.00001000\n",
            "used_time: 0.176011323928833\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2270, loss: 0.101046, acc: 0.500000\n",
            "steps: 2270\n",
            "save_steps: 1250\n",
            "20220510 14:37:20 current learning_rate:0.00001000\n",
            "used_time: 0.20288300514221191\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2280, loss: 0.560976, acc: 0.500000\n",
            "steps: 2280\n",
            "save_steps: 1250\n",
            "20220510 14:37:22 current learning_rate:0.00001000\n",
            "used_time: 0.17099833488464355\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2290, loss: 0.935166, acc: 0.875000\n",
            "steps: 2290\n",
            "save_steps: 1250\n",
            "20220510 14:37:23 current learning_rate:0.00001000\n",
            "used_time: 0.17535185813903809\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2300, loss: 0.790522, acc: 0.500000\n",
            "steps: 2300\n",
            "save_steps: 1250\n",
            "20220510 14:37:25 current learning_rate:0.00001000\n",
            "used_time: 0.2003951072692871\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2310, loss: 0.418038, acc: 0.625000\n",
            "steps: 2310\n",
            "save_steps: 1250\n",
            "20220510 14:37:27 current learning_rate:0.00001000\n",
            "used_time: 0.17628979682922363\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2320, loss: 0.442907, acc: 0.625000\n",
            "steps: 2320\n",
            "save_steps: 1250\n",
            "20220510 14:37:29 current learning_rate:0.00001000\n",
            "used_time: 0.18900370597839355\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2330, loss: 0.164195, acc: 0.875000\n",
            "steps: 2330\n",
            "save_steps: 1250\n",
            "20220510 14:37:31 current learning_rate:0.00001000\n",
            "used_time: 0.212357759475708\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2340, loss: 0.019004, acc: 0.625000\n",
            "steps: 2340\n",
            "save_steps: 1250\n",
            "20220510 14:37:33 current learning_rate:0.00001000\n",
            "used_time: 0.21090006828308105\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2350, loss: 0.123570, acc: 0.750000\n",
            "steps: 2350\n",
            "save_steps: 1250\n",
            "20220510 14:37:35 current learning_rate:0.00001000\n",
            "used_time: 0.19759774208068848\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2360, loss: 0.938655, acc: 0.625000\n",
            "steps: 2360\n",
            "save_steps: 1250\n",
            "20220510 14:37:37 current learning_rate:0.00001000\n",
            "used_time: 0.16857242584228516\n",
            "shuffle epoch 2\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2370, loss: 0.262877, acc: 0.500000\n",
            "steps: 2370\n",
            "save_steps: 1250\n",
            "20220510 14:37:39 current learning_rate:0.00001000\n",
            "used_time: 0.18712735176086426\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2380, loss: 1.008398, acc: 0.500000\n",
            "steps: 2380\n",
            "save_steps: 1250\n",
            "20220510 14:37:41 current learning_rate:0.00001000\n",
            "used_time: 0.18409276008605957\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2390, loss: 0.161995, acc: 0.500000\n",
            "steps: 2390\n",
            "save_steps: 1250\n",
            "20220510 14:37:43 current learning_rate:0.00001000\n",
            "used_time: 0.19710302352905273\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2400, loss: 0.402731, acc: 0.750000\n",
            "steps: 2400\n",
            "save_steps: 1250\n",
            "20220510 14:37:45 current learning_rate:0.00001000\n",
            "used_time: 0.1347825527191162\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2410, loss: 0.125385, acc: 0.750000\n",
            "steps: 2410\n",
            "save_steps: 1250\n",
            "20220510 14:37:47 current learning_rate:0.00001000\n",
            "used_time: 0.2201099395751953\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2420, loss: 0.142735, acc: 0.500000\n",
            "steps: 2420\n",
            "save_steps: 1250\n",
            "20220510 14:37:49 current learning_rate:0.00001000\n",
            "used_time: 0.20003366470336914\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2430, loss: 0.082331, acc: 0.625000\n",
            "steps: 2430\n",
            "save_steps: 1250\n",
            "20220510 14:37:50 current learning_rate:0.00001000\n",
            "used_time: 0.19591832160949707\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2440, loss: 0.016100, acc: 0.500000\n",
            "steps: 2440\n",
            "save_steps: 1250\n",
            "20220510 14:37:52 current learning_rate:0.00001000\n",
            "used_time: 0.19082427024841309\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2450, loss: 0.216820, acc: 0.750000\n",
            "steps: 2450\n",
            "save_steps: 1250\n",
            "20220510 14:37:54 current learning_rate:0.00001000\n",
            "used_time: 0.21028614044189453\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2460, loss: 0.524608, acc: 0.875000\n",
            "steps: 2460\n",
            "save_steps: 1250\n",
            "20220510 14:37:56 current learning_rate:0.00001000\n",
            "used_time: 0.184403657913208\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2470, loss: 0.922346, acc: 0.875000\n",
            "steps: 2470\n",
            "save_steps: 1250\n",
            "20220510 14:37:58 current learning_rate:0.00001000\n",
            "used_time: 0.17110180854797363\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2480, loss: 0.817751, acc: 0.500000\n",
            "steps: 2480\n",
            "save_steps: 1250\n",
            "20220510 14:38:00 current learning_rate:0.00001000\n",
            "used_time: 0.1733083724975586\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2490, loss: 0.018360, acc: 0.625000\n",
            "steps: 2490\n",
            "save_steps: 1250\n",
            "20220510 14:38:02 current learning_rate:0.00001000\n",
            "used_time: 0.2116084098815918\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2500, loss: 0.019853, acc: 0.625000\n",
            "steps: 2500\n",
            "save_steps: 1250\n",
            "Train-RCAC 0.8971428571428571\n",
            "20220510 14:38:04 current learning_rate:0.00001000\n",
            "save_path: output_hm/step_2500traindev\n",
            "used_time: 11.438059568405151\n",
            "############################WARNING################################### using init_pretraining_params, not init_checkpoint ###### meaning hyper param e.g. lr won't inherit from checkpoint#################################################################terminate called without an active exception\n",
            "W0510 14:38:16.172601   700 init.cc:216] Warning: PaddlePaddle catches a failure signal, it may not work properly\n",
            "W0510 14:38:16.172749   700 init.cc:218] You could check whether you killed PaddlePaddle thread/process accidentally or report the case to PaddlePaddle\n",
            "W0510 14:38:16.172762   700 init.cc:221] The detail failure signal is:\n",
            "\n",
            "W0510 14:38:16.172771   700 init.cc:224] *** Aborted at 1652193496 (unix time) try \"date -d @1652193496\" if you are using GNU date ***\n",
            "W0510 14:38:16.174731   700 init.cc:224] PC: @                0x0 (unknown)\n",
            "W0510 14:38:16.175730   700 init.cc:224] *** SIGABRT (@0x297) received by PID 663 (TID 0x7f4bf79bf700) from PID 663; stack trace: ***\n",
            "W0510 14:38:16.177539   700 init.cc:224]     @     0x7f4d9c3d2f10 (unknown)\n",
            "W0510 14:38:16.179011   700 init.cc:224]     @     0x7f4d9c3d2e87 gsignal\n",
            "W0510 14:38:16.180452   700 init.cc:224]     @     0x7f4d9c3d47f1 abort\n",
            "W0510 14:38:16.182025   700 init.cc:224]     @     0x7f4d9b069957 (unknown)\n",
            "W0510 14:38:16.183686   700 init.cc:224]     @     0x7f4d9b06fae6 (unknown)\n",
            "W0510 14:38:16.185220   700 init.cc:224]     @     0x7f4d9b06fb21 std::terminate()\n",
            "W0510 14:38:16.186715   700 init.cc:224]     @     0x7f4d9b06f4ea __gxx_personality_v0\n",
            "W0510 14:38:16.188153   700 init.cc:224]     @     0x7f4d9abaf668 (unknown)\n",
            "W0510 14:38:16.189611   700 init.cc:224]     @     0x7f4d9abafc5c _Unwind_ForcedUnwind\n",
            "W0510 14:38:16.191113   700 init.cc:224]     @     0x7f4d9c186000 __GI___pthread_unwind\n",
            "W0510 14:38:16.192574   700 init.cc:224]     @     0x7f4d9c17dae5 __pthread_exit\n",
            "W0510 14:38:16.194317   700 init.cc:224]     @     0x7f4d9c4c4364 pthread_exit\n",
            "W0510 14:38:16.194458   700 init.cc:224]     @           0x5e37d8 PyThread_exit_thread\n",
            "W0510 14:38:16.194584   700 init.cc:224]     @           0x47028a (unknown)\n",
            "W0510 14:38:16.199313   700 init.cc:224]     @     0x7f4d49178019 pybind11::gil_scoped_release::~gil_scoped_release()\n",
            "W0510 14:38:16.200430   700 init.cc:224]     @     0x7f4d492603b6 _ZZN8pybind1112cpp_function10initializeIZN6paddle6pybind10BindReaderEPNS_6moduleEEUlRNS2_9operators6reader22LoDTensorBlockingQueueERKSt6vectorINS2_9framework9LoDTensorESaISC_EEE1_bIS9_SG_EINS_4nameENS_9is_methodENS_7siblingENS_10call_guardIINS_18gil_scoped_releaseEEEEEEEvOT_PFT0_DpT1_EDpRKT2_ENUlRNS_6detail13function_callEE1_4_FUNES11_\n",
            "W0510 14:38:16.202998   700 init.cc:224]     @     0x7f4d49195829 pybind11::cpp_function::dispatcher()\n",
            "W0510 14:38:16.203150   700 init.cc:224]     @           0x593784 _PyMethodDef_RawFastCallKeywords\n",
            "W0510 14:38:16.203241   700 init.cc:224]     @           0x594731 _PyObject_FastCallKeywords\n",
            "W0510 14:38:16.203364   700 init.cc:224]     @           0x548cc1 (unknown)\n",
            "W0510 14:38:16.203435   700 init.cc:224]     @           0x51566f _PyEval_EvalFrameDefault\n",
            "W0510 14:38:16.203522   700 init.cc:224]     @           0x549e0e _PyEval_EvalCodeWithName\n",
            "W0510 14:38:16.203580   700 init.cc:224]     @           0x4bcb19 _PyFunction_FastCallDict\n",
            "W0510 14:38:16.203636   700 init.cc:224]     @           0x5134a6 _PyEval_EvalFrameDefault\n",
            "W0510 14:38:16.203719   700 init.cc:224]     @           0x593dd7 _PyFunction_FastCallKeywords\n",
            "W0510 14:38:16.203774   700 init.cc:224]     @           0x511e2c _PyEval_EvalFrameDefault\n",
            "W0510 14:38:16.203857   700 init.cc:224]     @           0x593dd7 _PyFunction_FastCallKeywords\n",
            "W0510 14:38:16.203936   700 init.cc:224]     @           0x511e2c _PyEval_EvalFrameDefault\n",
            "W0510 14:38:16.203999   700 init.cc:224]     @           0x4bc98a _PyFunction_FastCallDict\n",
            "W0510 14:38:16.204124   700 init.cc:224]     @           0x59c019 (unknown)\n",
            "W0510 14:38:16.204244   700 init.cc:224]     @           0x595ef6 PyObject_Call\n",
            "W0510 14:38:16.204382   700 init.cc:224]     @           0x5d5393 (unknown)\n",
            "/content/vilio/ernie-vil/run_finetuning.sh: line 64:   663 Aborted                 (core dumped) python /content/vilio/ernie-vil/finetune.py --use_cuda \"True\" --is_distributed \"False\" --use_fast_executor ${e_executor-\"True\"} --nccl_comm_num ${nccl_comm_num:-\"1\"} --batch_size $((BATCH_SIZE/gpu_cnt)) --do_train \"True\" --do_test \"False\" --task_name ${TASK_NAME} --vocab_path ${VOCAB_PATH} --task_group_json ${TASK_GROUP_JSON} --lr_scheduler ${lr_scheduler} --decay_steps ${decay_steps-\"\"} --lr_decay_ratio ${lr_decay_ratio-0.1} --num_train_steps ${num_train_steps} --checkpoints $output_model_path --save_steps ${SAVE_STEPS} --init_checkpoint ${PRETRAIN_MODELS} --ernie_config_path ${ERNIE_VIL_CONFIG} --learning_rate ${LR_RATE} --warmup_steps ${WARMUP_STEPS} --weight_decay ${WEIGHT_DECAY:-0} --max_seq_len ${MAX_LEN} --validation_steps ${VALID_STEPS} --skip_steps 10 --split ${SPLIT} --stop_steps ${STOP}\n",
            "-----------  Configuration Arguments -----------\n",
            "batch_size: 8\n",
            "checkpoints: checkpoints\n",
            "combine: False\n",
            "decay_steps: \n",
            "do_test: True\n",
            "do_train: False\n",
            "do_val: False\n",
            "epoch: 100\n",
            "ernie_config_path: /content/vilio/ernie-vil/data/erniesmall/ernie_vil_config.base.json\n",
            "exp: ES36\n",
            "feature_size: 2048\n",
            "fusion_method: sum\n",
            "hierarchical_allreduce_inter_nranks: 8\n",
            "init_checkpoint: /content/vilio/ernie-vil/output_hm/step_2500traindev\n",
            "is_distributed: False\n",
            "learning_rate: 0.0001\n",
            "lr_decay_dict_file: \n",
            "lr_decay_ratio: 0.1\n",
            "lr_scheduler: linear_warmup_decay\n",
            "max_img_len: 100\n",
            "max_seq_len: 128\n",
            "nccl_comm_num: 1\n",
            "num_features: 50\n",
            "num_train_steps: 1000000\n",
            "output_file: \n",
            "result_file: /content/vilio/ernie-vil/data/log\n",
            "save_steps: 100\n",
            "skip_steps: 10\n",
            "split: test_seen\n",
            "stop_steps: 5000\n",
            "subtrain: False\n",
            "task_group_json: /content/vilio/ernie-vil/conf/hm/task_hm.json\n",
            "task_name: hm\n",
            "test_filelist: \n",
            "test_split: val\n",
            "train_filelist: \n",
            "use_cuda: True\n",
            "use_fast_executor: True\n",
            "use_fuse: False\n",
            "use_gpu: True\n",
            "use_hierarchical_allreduce: False\n",
            "valid_filelist: \n",
            "validation_steps: 6000\n",
            "verbose: False\n",
            "vocab_path: /content/vilio/ernie-vil/data/erniesmall/vocab.txt\n",
            "warmup_steps: 0\n",
            "weight_decay: 0.01\n",
            "------------------------------------------------\n",
            "finetuning tasks start\n",
            "attention_probs_dropout_prob: 0.1\n",
            "class_attr_size: 401\n",
            "class_size: 1601\n",
            "co_hidden_size: 1024\n",
            "co_intermediate_size: 1024\n",
            "co_num_attention_heads: 8\n",
            "hidden_act: gelu\n",
            "hidden_dropout_prob: 0.1\n",
            "hidden_size: 768\n",
            "initializer_range: 0.02\n",
            "max_position_embeddings: 512\n",
            "num_attention_heads: 12\n",
            "num_hidden_layers: 12\n",
            "sent_type_vocab_size: 4\n",
            "t_biattention_id: [6, 7, 8, 9, 10, 11]\n",
            "task_type_vocab_size: 16\n",
            "type_vocab_size: 2\n",
            "v_biattention_id: [0, 1, 2, 3, 4, 5]\n",
            "v_hidden_size: 1024\n",
            "v_intermediate_size: 1024\n",
            "v_num_attention_heads: 8\n",
            "vocab_size: 30522\n",
            "------------------------------------------------\n",
            "task:  [{'task': 'HM', 'num_choice': 1, 'annotations_jsonpath_train': '/content/vilio/ernie-vil/data/hm/train.jsonl', 'annotations_jsonpath_dev_seen': '/content/vilio/ernie-vil/data/hm/dev_seenlong.jsonl', 'annotations_jsonpath_traindev': '/content/vilio/ernie-vil/data/hm/traindev.jsonl', 'annotations_jsonpath_test_unseen': '/content/vilio/ernie-vil/data/hm/test_unseenlong.jsonl', 'annotations_jsonpath_test_seen': '/content/vilio/ernie-vil/data/hm/test_seenlong.jsonl', 'feature_lmdb_path': '/content/vilio/ernie-vil/data/hm/HM_img.tsv', 'gt_feature_lmdb_path': '/content/vilio/ernie-vil/data/hm/HM_gt_img.tsv', 'unisex_names_table': '/content/vilio/ernie-vil/data/vcr/unisex_names_table.csv', 'Proprocessor': 'PreprocessorBasic', 'tokenizer_name': 'FullTokenizer', 'fusion_method': 'mul', 'dropout_rate': 0.1, 'max_seq_len': 128, 'use_gt_fea': True, 'shufflekeep_across_task': True, 'shuffle_every_epoch': True, 'task_weight': 1.0, 'task_prefix': 'hm'}]\n",
            "2022-05-10 14:38:19,950-WARNING: paddle.fluid.layers.py_reader() may be deprecated in the near future. Please use paddle.fluid.io.DataLoader.from_generator() instead.\n",
            "theoretical memory usage: \n",
            "(3678.2632896423343, 3853.418684387207, 'MB')\n",
            "args.is_distributed: False\n",
            "W0510 14:38:20.834539   728 device_context.cc:252] Please NOTE: device: 0, CUDA Capability: 60, Driver API Version: 11.2, Runtime API Version: 9.0\n",
            "W0510 14:38:20.846027   728 device_context.cc:260] device: 0, cuDNN Version: 7.6.\n",
            "SPLIT: test_seen\n",
            "Start to load Faster-RCNN detected objects from /content/vilio/ernie-vil/data/hm/HM_img.tsv\n",
            "Loaded 1000 images in file /content/vilio/ernie-vil/data/hm/HM_img.tsv in 71 seconds.\n",
            "Start to load Faster-RCNN detected objects from /content/vilio/ernie-vil/data/hm/HM_gt_img.tsv\n",
            "Loaded 1000 images in file /content/vilio/ernie-vil/data/hm/HM_gt_img.tsv in 50 seconds.\n",
            "Load 1300 data from split(s) /content/vilio/ernie-vil/data/hm/test_seenlong.jsonl.\n",
            "use gt featurre\n",
            "LEN:  1300\n",
            "Load pretraining parameters from /content/vilio/ernie-vil/output_hm/step_2500traindev.\n",
            "testing on hm val split\n",
            "task name list :  ['mean_0.tmp_0', 'accuracy_0.tmp_0', 'arg_max_0.tmp_0', 'read_file_0.tmp_9', 'read_file_0.tmp_8', 'reshape2_120.tmp_0']\n",
            "cur_step: 10 cur_acc: 0.9875\n",
            "cur_step: 20 cur_acc: 0.99375\n",
            "cur_step: 30 cur_acc: 0.9958333333333333\n",
            "cur_step: 40 cur_acc: 0.996875\n",
            "cur_step: 50 cur_acc: 0.9975\n",
            "cur_step: 60 cur_acc: 0.9979166666666667\n",
            "cur_step: 70 cur_acc: 0.9982142857142857\n",
            "cur_step: 80 cur_acc: 0.9984375\n",
            "cur_step: 90 cur_acc: 0.9986111111111111\n",
            "cur_step: 100 cur_acc: 0.99875\n",
            "cur_step: 110 cur_acc: 0.9988636363636364\n",
            "cur_step: 120 cur_acc: 0.9989583333333333\n",
            "cur_step: 130 cur_acc: 0.9980769230769231\n",
            "cur_step: 140 cur_acc: 0.9982142857142857\n",
            "cur_step: 150 cur_acc: 0.9983333333333333\n",
            "cur_step: 160 cur_acc: 0.9984375\n",
            "EXCEPTING\n",
            "LEN: 1000 1000\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   id      1000 non-null   int64  \n",
            " 1   proba   1000 non-null   float32\n",
            " 2   label   1000 non-null   int64  \n",
            "dtypes: float32(1), int64(2)\n",
            "memory usage: 19.7 KB\n",
            "None\n",
            "average_acc: 0.9984375\n",
            "rocauc: 0.9100156494522691\n",
            "-----------  Configuration Arguments -----------\n",
            "batch_size: 8\n",
            "checkpoints: checkpoints\n",
            "combine: False\n",
            "decay_steps: \n",
            "do_test: True\n",
            "do_train: False\n",
            "do_val: False\n",
            "epoch: 100\n",
            "ernie_config_path: /content/vilio/ernie-vil/data/erniesmall/ernie_vil_config.base.json\n",
            "exp: ES36\n",
            "feature_size: 2048\n",
            "fusion_method: sum\n",
            "hierarchical_allreduce_inter_nranks: 8\n",
            "init_checkpoint: /content/vilio/ernie-vil/output_hm/step_2500traindev\n",
            "is_distributed: False\n",
            "learning_rate: 0.0001\n",
            "lr_decay_dict_file: \n",
            "lr_decay_ratio: 0.1\n",
            "lr_scheduler: linear_warmup_decay\n",
            "max_img_len: 100\n",
            "max_seq_len: 128\n",
            "nccl_comm_num: 1\n",
            "num_features: 50\n",
            "num_train_steps: 1000000\n",
            "output_file: \n",
            "result_file: /content/vilio/ernie-vil/data/log\n",
            "save_steps: 100\n",
            "skip_steps: 10\n",
            "split: test_unseen\n",
            "stop_steps: 5000\n",
            "subtrain: False\n",
            "task_group_json: /content/vilio/ernie-vil/conf/hm/task_hm.json\n",
            "task_name: hm\n",
            "test_filelist: \n",
            "test_split: val\n",
            "train_filelist: \n",
            "use_cuda: True\n",
            "use_fast_executor: True\n",
            "use_fuse: False\n",
            "use_gpu: True\n",
            "use_hierarchical_allreduce: False\n",
            "valid_filelist: \n",
            "validation_steps: 6000\n",
            "verbose: False\n",
            "vocab_path: /content/vilio/ernie-vil/data/erniesmall/vocab.txt\n",
            "warmup_steps: 0\n",
            "weight_decay: 0.01\n",
            "------------------------------------------------\n",
            "finetuning tasks start\n",
            "attention_probs_dropout_prob: 0.1\n",
            "class_attr_size: 401\n",
            "class_size: 1601\n",
            "co_hidden_size: 1024\n",
            "co_intermediate_size: 1024\n",
            "co_num_attention_heads: 8\n",
            "hidden_act: gelu\n",
            "hidden_dropout_prob: 0.1\n",
            "hidden_size: 768\n",
            "initializer_range: 0.02\n",
            "max_position_embeddings: 512\n",
            "num_attention_heads: 12\n",
            "num_hidden_layers: 12\n",
            "sent_type_vocab_size: 4\n",
            "t_biattention_id: [6, 7, 8, 9, 10, 11]\n",
            "task_type_vocab_size: 16\n",
            "type_vocab_size: 2\n",
            "v_biattention_id: [0, 1, 2, 3, 4, 5]\n",
            "v_hidden_size: 1024\n",
            "v_intermediate_size: 1024\n",
            "v_num_attention_heads: 8\n",
            "vocab_size: 30522\n",
            "------------------------------------------------\n",
            "task:  [{'task': 'HM', 'num_choice': 1, 'annotations_jsonpath_train': '/content/vilio/ernie-vil/data/hm/train.jsonl', 'annotations_jsonpath_dev_seen': '/content/vilio/ernie-vil/data/hm/dev_seenlong.jsonl', 'annotations_jsonpath_traindev': '/content/vilio/ernie-vil/data/hm/traindev.jsonl', 'annotations_jsonpath_test_unseen': '/content/vilio/ernie-vil/data/hm/test_unseenlong.jsonl', 'annotations_jsonpath_test_seen': '/content/vilio/ernie-vil/data/hm/test_seenlong.jsonl', 'feature_lmdb_path': '/content/vilio/ernie-vil/data/hm/HM_img.tsv', 'gt_feature_lmdb_path': '/content/vilio/ernie-vil/data/hm/HM_gt_img.tsv', 'unisex_names_table': '/content/vilio/ernie-vil/data/vcr/unisex_names_table.csv', 'Proprocessor': 'PreprocessorBasic', 'tokenizer_name': 'FullTokenizer', 'fusion_method': 'mul', 'dropout_rate': 0.1, 'max_seq_len': 128, 'use_gt_fea': True, 'shufflekeep_across_task': True, 'shuffle_every_epoch': True, 'task_weight': 1.0, 'task_prefix': 'hm'}]\n",
            "2022-05-10 14:40:52,914-WARNING: paddle.fluid.layers.py_reader() may be deprecated in the near future. Please use paddle.fluid.io.DataLoader.from_generator() instead.\n",
            "theoretical memory usage: \n",
            "(3678.2632896423343, 3853.418684387207, 'MB')\n",
            "args.is_distributed: False\n",
            "W0510 14:40:53.800643   773 device_context.cc:252] Please NOTE: device: 0, CUDA Capability: 60, Driver API Version: 11.2, Runtime API Version: 9.0\n",
            "W0510 14:40:53.811951   773 device_context.cc:260] device: 0, cuDNN Version: 7.6.\n",
            "SPLIT: test_unseen\n",
            "Start to load Faster-RCNN detected objects from /content/vilio/ernie-vil/data/hm/HM_img.tsv\n",
            "Loaded 2000 images in file /content/vilio/ernie-vil/data/hm/HM_img.tsv in 72 seconds.\n",
            "Start to load Faster-RCNN detected objects from /content/vilio/ernie-vil/data/hm/HM_gt_img.tsv\n",
            "Loaded 2000 images in file /content/vilio/ernie-vil/data/hm/HM_gt_img.tsv in 52 seconds.\n",
            "Load 2600 data from split(s) /content/vilio/ernie-vil/data/hm/test_unseenlong.jsonl.\n",
            "use gt featurre\n",
            "LEN:  2600\n",
            "Load pretraining parameters from /content/vilio/ernie-vil/output_hm/step_2500traindev.\n",
            "testing on hm val split\n",
            "task name list :  ['mean_0.tmp_0', 'accuracy_0.tmp_0', 'arg_max_0.tmp_0', 'read_file_0.tmp_9', 'read_file_0.tmp_8', 'reshape2_120.tmp_0']\n",
            "cur_step: 10 cur_acc: 0.9875\n",
            "cur_step: 20 cur_acc: 0.99375\n",
            "cur_step: 30 cur_acc: 0.9958333333333333\n",
            "cur_step: 40 cur_acc: 0.996875\n",
            "cur_step: 50 cur_acc: 0.9975\n",
            "cur_step: 60 cur_acc: 0.9979166666666667\n",
            "cur_step: 70 cur_acc: 0.9982142857142857\n",
            "cur_step: 80 cur_acc: 0.9984375\n",
            "cur_step: 90 cur_acc: 0.9986111111111111\n",
            "cur_step: 100 cur_acc: 0.99875\n",
            "cur_step: 110 cur_acc: 0.9988636363636364\n",
            "cur_step: 120 cur_acc: 0.9989583333333333\n",
            "cur_step: 130 cur_acc: 0.9990384615384615\n",
            "cur_step: 140 cur_acc: 0.9991071428571429\n",
            "cur_step: 150 cur_acc: 0.9991666666666666\n",
            "cur_step: 160 cur_acc: 0.99921875\n",
            "cur_step: 170 cur_acc: 0.9992647058823529\n",
            "cur_step: 180 cur_acc: 0.9993055555555556\n",
            "cur_step: 190 cur_acc: 0.9993421052631579\n",
            "cur_step: 200 cur_acc: 0.999375\n",
            "cur_step: 210 cur_acc: 0.9994047619047619\n",
            "cur_step: 220 cur_acc: 0.9994318181818181\n",
            "cur_step: 230 cur_acc: 0.9994565217391305\n",
            "cur_step: 240 cur_acc: 0.9994791666666667\n",
            "cur_step: 250 cur_acc: 0.9995\n",
            "cur_step: 260 cur_acc: 0.9990384615384615\n",
            "cur_step: 270 cur_acc: 0.9990740740740741\n",
            "cur_step: 280 cur_acc: 0.9991071428571429\n",
            "cur_step: 290 cur_acc: 0.9991379310344828\n",
            "cur_step: 300 cur_acc: 0.9991666666666666\n",
            "cur_step: 310 cur_acc: 0.9991935483870967\n",
            "cur_step: 320 cur_acc: 0.99921875\n",
            "EXCEPTING\n",
            "LEN: 2000 2000\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2000 entries, 0 to 1999\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   id      2000 non-null   int64  \n",
            " 1   proba   2000 non-null   float32\n",
            " 2   label   2000 non-null   int64  \n",
            "dtypes: float32(1), int64(2)\n",
            "memory usage: 39.2 KB\n",
            "None\n",
            "average_acc: 0.99921875\n",
            "rocauc: 0.19624706802189207\n",
            "CPU times: user 11.9 s, sys: 1.61 s, total: 13.5 s\n",
            "Wall time: 34min 59s\n"
          ]
        }
      ],
      "source": [
        "# second round\n",
        "\n",
        "%%time\n",
        "!bash /content/vilio/ernie-vil/bash/training/ES/hm_ES36.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results record\n",
        "* The results should be stored in `/content/vilio/ernie-vil/data/hm` as `.csv` file."
      ],
      "metadata": {
        "id": "CDu9x_tvia6F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!bash /content/vilio/ernie-vil/bash/training/ES/hm_ES.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPPXt4rQiQU1",
        "outputId": "ae8b04a6-7f45-4927-ff3b-43dd44f87462"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mSe han truncado las últimas 5000 líneas del flujo de salida.\u001b[0m\n",
            "steps: 950\n",
            "save_steps: 1250\n",
            "20220510 16:33:55 current learning_rate:0.00001000\n",
            "used_time: 0.18418645858764648\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 960, loss: 0.133864, acc: 0.625000\n",
            "steps: 960\n",
            "save_steps: 1250\n",
            "20220510 16:33:56 current learning_rate:0.00001000\n",
            "used_time: 0.18204236030578613\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 970, loss: 0.340891, acc: 0.375000\n",
            "steps: 970\n",
            "save_steps: 1250\n",
            "20220510 16:33:58 current learning_rate:0.00001000\n",
            "used_time: 0.20531797409057617\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 980, loss: 0.989595, acc: 0.875000\n",
            "steps: 980\n",
            "save_steps: 1250\n",
            "20220510 16:34:00 current learning_rate:0.00001000\n",
            "used_time: 0.1721208095550537\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 990, loss: 0.626693, acc: 0.750000\n",
            "steps: 990\n",
            "save_steps: 1250\n",
            "20220510 16:34:02 current learning_rate:0.00001000\n",
            "used_time: 0.2057342529296875\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1000, loss: 0.541029, acc: 0.750000\n",
            "steps: 1000\n",
            "save_steps: 1250\n",
            "Train-RCAC 0.6611226611226612\n",
            "20220510 16:34:04 current learning_rate:0.00001000\n",
            "used_time: 0.27676844596862793\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1010, loss: 0.456983, acc: 0.750000\n",
            "steps: 1010\n",
            "save_steps: 1250\n",
            "20220510 16:34:06 current learning_rate:0.00001000\n",
            "used_time: 0.19103765487670898\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1020, loss: 0.430524, acc: 0.625000\n",
            "steps: 1020\n",
            "save_steps: 1250\n",
            "20220510 16:34:08 current learning_rate:0.00001000\n",
            "used_time: 0.1604008674621582\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1030, loss: 0.140680, acc: 1.000000\n",
            "steps: 1030\n",
            "save_steps: 1250\n",
            "20220510 16:34:10 current learning_rate:0.00001000\n",
            "used_time: 0.1673734188079834\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1040, loss: 0.430822, acc: 0.500000\n",
            "steps: 1040\n",
            "save_steps: 1250\n",
            "20220510 16:34:12 current learning_rate:0.00001000\n",
            "used_time: 0.18700933456420898\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1050, loss: 0.543694, acc: 0.875000\n",
            "steps: 1050\n",
            "save_steps: 1250\n",
            "20220510 16:34:14 current learning_rate:0.00001000\n",
            "used_time: 0.21722030639648438\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1060, loss: 1.315256, acc: 0.250000\n",
            "steps: 1060\n",
            "save_steps: 1250\n",
            "20220510 16:34:16 current learning_rate:0.00001000\n",
            "used_time: 0.1896684169769287\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1070, loss: 0.573207, acc: 0.625000\n",
            "steps: 1070\n",
            "save_steps: 1250\n",
            "20220510 16:34:18 current learning_rate:0.00001000\n",
            "used_time: 0.19035768508911133\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1080, loss: 0.193270, acc: 0.750000\n",
            "steps: 1080\n",
            "save_steps: 1250\n",
            "20220510 16:34:20 current learning_rate:0.00001000\n",
            "used_time: 0.19441652297973633\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1090, loss: 0.074117, acc: 0.750000\n",
            "steps: 1090\n",
            "save_steps: 1250\n",
            "20220510 16:34:22 current learning_rate:0.00001000\n",
            "used_time: 0.2008984088897705\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1100, loss: 0.582124, acc: 0.500000\n",
            "steps: 1100\n",
            "save_steps: 1250\n",
            "20220510 16:34:23 current learning_rate:0.00001000\n",
            "used_time: 0.18702483177185059\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1110, loss: 0.132777, acc: 0.375000\n",
            "steps: 1110\n",
            "save_steps: 1250\n",
            "20220510 16:34:25 current learning_rate:0.00001000\n",
            "used_time: 0.20605254173278809\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1120, loss: 0.163013, acc: 0.875000\n",
            "steps: 1120\n",
            "save_steps: 1250\n",
            "20220510 16:34:27 current learning_rate:0.00001000\n",
            "used_time: 0.17632246017456055\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1130, loss: 0.331746, acc: 0.750000\n",
            "steps: 1130\n",
            "save_steps: 1250\n",
            "20220510 16:34:29 current learning_rate:0.00001000\n",
            "used_time: 0.19679594039916992\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1140, loss: 0.118028, acc: 1.000000\n",
            "steps: 1140\n",
            "save_steps: 1250\n",
            "20220510 16:34:31 current learning_rate:0.00001000\n",
            "used_time: 0.19444870948791504\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1150, loss: 0.374832, acc: 0.750000\n",
            "steps: 1150\n",
            "save_steps: 1250\n",
            "20220510 16:34:33 current learning_rate:0.00001000\n",
            "used_time: 0.20799589157104492\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1160, loss: 0.762277, acc: 0.500000\n",
            "steps: 1160\n",
            "save_steps: 1250\n",
            "20220510 16:34:35 current learning_rate:0.00001000\n",
            "used_time: 0.20166778564453125\n",
            "shuffle epoch 1\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1170, loss: 0.926038, acc: 0.625000\n",
            "steps: 1170\n",
            "save_steps: 1250\n",
            "20220510 16:34:37 current learning_rate:0.00001000\n",
            "used_time: 0.21282005310058594\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1180, loss: 0.397716, acc: 0.750000\n",
            "steps: 1180\n",
            "save_steps: 1250\n",
            "20220510 16:34:39 current learning_rate:0.00001000\n",
            "used_time: 0.18357396125793457\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1190, loss: 0.500716, acc: 0.375000\n",
            "steps: 1190\n",
            "save_steps: 1250\n",
            "20220510 16:34:41 current learning_rate:0.00001000\n",
            "used_time: 0.1907341480255127\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1200, loss: 0.704154, acc: 0.500000\n",
            "steps: 1200\n",
            "save_steps: 1250\n",
            "20220510 16:34:43 current learning_rate:0.00001000\n",
            "used_time: 0.1452326774597168\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1210, loss: 0.353209, acc: 0.500000\n",
            "steps: 1210\n",
            "save_steps: 1250\n",
            "20220510 16:34:45 current learning_rate:0.00001000\n",
            "used_time: 0.20224857330322266\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1220, loss: 0.094475, acc: 0.875000\n",
            "steps: 1220\n",
            "save_steps: 1250\n",
            "20220510 16:34:47 current learning_rate:0.00001000\n",
            "used_time: 0.20847582817077637\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1230, loss: 0.481884, acc: 0.625000\n",
            "steps: 1230\n",
            "save_steps: 1250\n",
            "20220510 16:34:49 current learning_rate:0.00001000\n",
            "used_time: 0.18349456787109375\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1240, loss: 0.086667, acc: 0.750000\n",
            "steps: 1240\n",
            "save_steps: 1250\n",
            "20220510 16:34:51 current learning_rate:0.00001000\n",
            "used_time: 0.167039155960083\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1250, loss: 0.107039, acc: 0.125000\n",
            "steps: 1250\n",
            "save_steps: 1250\n",
            "20220510 16:34:53 current learning_rate:0.00001000\n",
            "save_path: output_hm/step_1250traindev\n",
            "used_time: 11.801190853118896\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1260, loss: 0.184862, acc: 0.625000\n",
            "steps: 1260\n",
            "save_steps: 1250\n",
            "20220510 16:35:06 current learning_rate:0.00001000\n",
            "used_time: 0.2095341682434082\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1270, loss: 0.653638, acc: 0.625000\n",
            "steps: 1270\n",
            "save_steps: 1250\n",
            "20220510 16:35:08 current learning_rate:0.00001000\n",
            "used_time: 0.1919240951538086\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1280, loss: 0.278816, acc: 0.375000\n",
            "steps: 1280\n",
            "save_steps: 1250\n",
            "20220510 16:35:10 current learning_rate:0.00001000\n",
            "used_time: 0.21698474884033203\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1290, loss: 0.182966, acc: 0.875000\n",
            "steps: 1290\n",
            "save_steps: 1250\n",
            "20220510 16:35:12 current learning_rate:0.00001000\n",
            "used_time: 0.18162107467651367\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1300, loss: 0.420128, acc: 0.500000\n",
            "steps: 1300\n",
            "save_steps: 1250\n",
            "20220510 16:35:14 current learning_rate:0.00001000\n",
            "used_time: 0.18326663970947266\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1310, loss: 0.484841, acc: 0.625000\n",
            "steps: 1310\n",
            "save_steps: 1250\n",
            "20220510 16:35:16 current learning_rate:0.00001000\n",
            "used_time: 0.18474674224853516\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1320, loss: 0.237874, acc: 0.500000\n",
            "steps: 1320\n",
            "save_steps: 1250\n",
            "20220510 16:35:18 current learning_rate:0.00001000\n",
            "used_time: 0.17362546920776367\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1330, loss: 0.491960, acc: 0.875000\n",
            "steps: 1330\n",
            "save_steps: 1250\n",
            "20220510 16:35:20 current learning_rate:0.00001000\n",
            "used_time: 0.21135234832763672\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1340, loss: 0.240869, acc: 0.875000\n",
            "steps: 1340\n",
            "save_steps: 1250\n",
            "20220510 16:35:22 current learning_rate:0.00001000\n",
            "used_time: 0.19891953468322754\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1350, loss: 0.110352, acc: 0.625000\n",
            "steps: 1350\n",
            "save_steps: 1250\n",
            "20220510 16:35:23 current learning_rate:0.00001000\n",
            "used_time: 0.22176051139831543\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1360, loss: 0.218621, acc: 0.625000\n",
            "steps: 1360\n",
            "save_steps: 1250\n",
            "20220510 16:35:25 current learning_rate:0.00001000\n",
            "used_time: 0.17473220825195312\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1370, loss: 0.435073, acc: 0.500000\n",
            "steps: 1370\n",
            "save_steps: 1250\n",
            "20220510 16:35:27 current learning_rate:0.00001000\n",
            "used_time: 0.19245100021362305\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1380, loss: 0.332580, acc: 0.500000\n",
            "steps: 1380\n",
            "save_steps: 1250\n",
            "20220510 16:35:29 current learning_rate:0.00001000\n",
            "used_time: 0.2042529582977295\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1390, loss: 0.400903, acc: 0.500000\n",
            "steps: 1390\n",
            "save_steps: 1250\n",
            "20220510 16:35:31 current learning_rate:0.00001000\n",
            "used_time: 0.16977834701538086\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1400, loss: 0.480296, acc: 0.625000\n",
            "steps: 1400\n",
            "save_steps: 1250\n",
            "20220510 16:35:33 current learning_rate:0.00001000\n",
            "used_time: 0.1996452808380127\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1410, loss: 0.334595, acc: 0.625000\n",
            "steps: 1410\n",
            "save_steps: 1250\n",
            "20220510 16:35:35 current learning_rate:0.00001000\n",
            "used_time: 0.21230363845825195\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1420, loss: 0.802474, acc: 0.375000\n",
            "steps: 1420\n",
            "save_steps: 1250\n",
            "20220510 16:35:37 current learning_rate:0.00001000\n",
            "used_time: 0.2111680507659912\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1430, loss: 0.048999, acc: 0.375000\n",
            "steps: 1430\n",
            "save_steps: 1250\n",
            "20220510 16:35:39 current learning_rate:0.00001000\n",
            "used_time: 0.19676828384399414\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1440, loss: 0.028555, acc: 0.875000\n",
            "steps: 1440\n",
            "save_steps: 1250\n",
            "20220510 16:35:41 current learning_rate:0.00001000\n",
            "used_time: 0.20236802101135254\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1450, loss: 0.381299, acc: 0.375000\n",
            "steps: 1450\n",
            "save_steps: 1250\n",
            "20220510 16:35:43 current learning_rate:0.00001000\n",
            "used_time: 0.20387744903564453\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1460, loss: 0.333518, acc: 0.375000\n",
            "steps: 1460\n",
            "save_steps: 1250\n",
            "20220510 16:35:45 current learning_rate:0.00001000\n",
            "used_time: 0.18913602828979492\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1470, loss: 0.742203, acc: 0.750000\n",
            "steps: 1470\n",
            "save_steps: 1250\n",
            "20220510 16:35:47 current learning_rate:0.00001000\n",
            "used_time: 0.18772530555725098\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1480, loss: 0.158888, acc: 0.625000\n",
            "steps: 1480\n",
            "save_steps: 1250\n",
            "20220510 16:35:48 current learning_rate:0.00001000\n",
            "used_time: 0.19855284690856934\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1490, loss: 0.738177, acc: 0.500000\n",
            "steps: 1490\n",
            "save_steps: 1250\n",
            "20220510 16:35:50 current learning_rate:0.00001000\n",
            "used_time: 0.22680449485778809\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1500, loss: 0.337993, acc: 0.625000\n",
            "steps: 1500\n",
            "save_steps: 1250\n",
            "Train-RCAC 0.9340277777777778\n",
            "20220510 16:35:52 current learning_rate:0.00001000\n",
            "used_time: 0.17722535133361816\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1510, loss: 0.238998, acc: 0.625000\n",
            "steps: 1510\n",
            "save_steps: 1250\n",
            "20220510 16:35:54 current learning_rate:0.00001000\n",
            "used_time: 0.19329452514648438\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1520, loss: 0.051353, acc: 0.875000\n",
            "steps: 1520\n",
            "save_steps: 1250\n",
            "20220510 16:35:56 current learning_rate:0.00001000\n",
            "used_time: 0.17913031578063965\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1530, loss: 0.440134, acc: 0.625000\n",
            "steps: 1530\n",
            "save_steps: 1250\n",
            "20220510 16:35:58 current learning_rate:0.00001000\n",
            "used_time: 0.22327876091003418\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1540, loss: 0.023907, acc: 0.875000\n",
            "steps: 1540\n",
            "save_steps: 1250\n",
            "20220510 16:36:00 current learning_rate:0.00001000\n",
            "used_time: 0.18697023391723633\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1550, loss: 0.068415, acc: 0.625000\n",
            "steps: 1550\n",
            "save_steps: 1250\n",
            "20220510 16:36:02 current learning_rate:0.00001000\n",
            "used_time: 0.18477320671081543\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1560, loss: 0.185215, acc: 0.500000\n",
            "steps: 1560\n",
            "save_steps: 1250\n",
            "20220510 16:36:04 current learning_rate:0.00001000\n",
            "used_time: 0.1987476348876953\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1570, loss: 0.071480, acc: 0.750000\n",
            "steps: 1570\n",
            "save_steps: 1250\n",
            "20220510 16:36:06 current learning_rate:0.00001000\n",
            "used_time: 0.21625447273254395\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1580, loss: 0.476759, acc: 0.500000\n",
            "steps: 1580\n",
            "save_steps: 1250\n",
            "20220510 16:36:08 current learning_rate:0.00001000\n",
            "used_time: 0.19803452491760254\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1590, loss: 0.329488, acc: 0.250000\n",
            "steps: 1590\n",
            "save_steps: 1250\n",
            "20220510 16:36:10 current learning_rate:0.00001000\n",
            "used_time: 0.19285941123962402\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1600, loss: 0.340540, acc: 0.500000\n",
            "steps: 1600\n",
            "save_steps: 1250\n",
            "20220510 16:36:11 current learning_rate:0.00001000\n",
            "used_time: 0.18690848350524902\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1610, loss: 0.328142, acc: 1.000000\n",
            "steps: 1610\n",
            "save_steps: 1250\n",
            "20220510 16:36:13 current learning_rate:0.00001000\n",
            "used_time: 0.1799182891845703\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1620, loss: 0.367155, acc: 0.500000\n",
            "steps: 1620\n",
            "save_steps: 1250\n",
            "20220510 16:36:15 current learning_rate:0.00001000\n",
            "used_time: 0.20407581329345703\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1630, loss: 0.105703, acc: 0.625000\n",
            "steps: 1630\n",
            "save_steps: 1250\n",
            "20220510 16:36:17 current learning_rate:0.00001000\n",
            "used_time: 0.19454002380371094\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1640, loss: 0.095225, acc: 0.750000\n",
            "steps: 1640\n",
            "save_steps: 1250\n",
            "20220510 16:36:19 current learning_rate:0.00001000\n",
            "used_time: 0.1857891082763672\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1650, loss: 0.029308, acc: 0.750000\n",
            "steps: 1650\n",
            "save_steps: 1250\n",
            "20220510 16:36:21 current learning_rate:0.00001000\n",
            "used_time: 0.21912789344787598\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1660, loss: 0.338237, acc: 0.250000\n",
            "steps: 1660\n",
            "save_steps: 1250\n",
            "20220510 16:36:23 current learning_rate:0.00001000\n",
            "used_time: 0.23864984512329102\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1670, loss: 0.481681, acc: 0.750000\n",
            "steps: 1670\n",
            "save_steps: 1250\n",
            "20220510 16:36:25 current learning_rate:0.00001000\n",
            "used_time: 0.2024843692779541\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1680, loss: 0.382205, acc: 0.625000\n",
            "steps: 1680\n",
            "save_steps: 1250\n",
            "20220510 16:36:27 current learning_rate:0.00001000\n",
            "used_time: 0.18036246299743652\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1690, loss: 0.351140, acc: 0.625000\n",
            "steps: 1690\n",
            "save_steps: 1250\n",
            "20220510 16:36:29 current learning_rate:0.00001000\n",
            "used_time: 0.2252655029296875\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1700, loss: 0.057615, acc: 0.875000\n",
            "steps: 1700\n",
            "save_steps: 1250\n",
            "20220510 16:36:31 current learning_rate:0.00001000\n",
            "used_time: 0.18845367431640625\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1710, loss: 0.537590, acc: 0.500000\n",
            "steps: 1710\n",
            "save_steps: 1250\n",
            "20220510 16:36:33 current learning_rate:0.00001000\n",
            "used_time: 0.1905977725982666\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1720, loss: 0.038216, acc: 0.750000\n",
            "steps: 1720\n",
            "save_steps: 1250\n",
            "20220510 16:36:35 current learning_rate:0.00001000\n",
            "used_time: 0.1926102638244629\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1730, loss: 0.086012, acc: 0.625000\n",
            "steps: 1730\n",
            "save_steps: 1250\n",
            "20220510 16:36:37 current learning_rate:0.00001000\n",
            "used_time: 0.19282245635986328\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1740, loss: 0.438444, acc: 0.625000\n",
            "steps: 1740\n",
            "save_steps: 1250\n",
            "20220510 16:36:39 current learning_rate:0.00001000\n",
            "used_time: 0.16350126266479492\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1750, loss: 0.502536, acc: 0.375000\n",
            "steps: 1750\n",
            "save_steps: 1250\n",
            "20220510 16:36:41 current learning_rate:0.00001000\n",
            "used_time: 0.2064650058746338\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1760, loss: 1.068268, acc: 0.625000\n",
            "steps: 1760\n",
            "save_steps: 1250\n",
            "20220510 16:36:43 current learning_rate:0.00001000\n",
            "used_time: 0.18968987464904785\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1770, loss: 0.024474, acc: 0.875000\n",
            "steps: 1770\n",
            "save_steps: 1250\n",
            "20220510 16:36:44 current learning_rate:0.00001000\n",
            "used_time: 0.22626233100891113\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1780, loss: 0.164075, acc: 0.750000\n",
            "steps: 1780\n",
            "save_steps: 1250\n",
            "20220510 16:36:46 current learning_rate:0.00001000\n",
            "used_time: 0.1937541961669922\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1790, loss: 1.194207, acc: 0.500000\n",
            "steps: 1790\n",
            "save_steps: 1250\n",
            "20220510 16:36:48 current learning_rate:0.00001000\n",
            "used_time: 0.21689105033874512\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1800, loss: 1.010344, acc: 0.625000\n",
            "steps: 1800\n",
            "save_steps: 1250\n",
            "20220510 16:36:50 current learning_rate:0.00001000\n",
            "used_time: 0.18023967742919922\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1810, loss: 0.018122, acc: 0.750000\n",
            "steps: 1810\n",
            "save_steps: 1250\n",
            "20220510 16:36:52 current learning_rate:0.00001000\n",
            "used_time: 0.19543814659118652\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1820, loss: 0.367352, acc: 0.750000\n",
            "steps: 1820\n",
            "save_steps: 1250\n",
            "20220510 16:36:54 current learning_rate:0.00001000\n",
            "used_time: 0.20059490203857422\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1830, loss: 0.143138, acc: 1.000000\n",
            "steps: 1830\n",
            "save_steps: 1250\n",
            "20220510 16:36:56 current learning_rate:0.00001000\n",
            "used_time: 0.1727590560913086\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1840, loss: 0.572659, acc: 0.250000\n",
            "steps: 1840\n",
            "save_steps: 1250\n",
            "20220510 16:36:58 current learning_rate:0.00001000\n",
            "used_time: 0.18776202201843262\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1850, loss: 0.703343, acc: 0.375000\n",
            "steps: 1850\n",
            "save_steps: 1250\n",
            "20220510 16:37:00 current learning_rate:0.00001000\n",
            "used_time: 0.20108985900878906\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1860, loss: 0.135579, acc: 0.625000\n",
            "steps: 1860\n",
            "save_steps: 1250\n",
            "20220510 16:37:02 current learning_rate:0.00001000\n",
            "used_time: 0.19110679626464844\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1870, loss: 0.275791, acc: 0.750000\n",
            "steps: 1870\n",
            "save_steps: 1250\n",
            "20220510 16:37:04 current learning_rate:0.00001000\n",
            "used_time: 0.19027018547058105\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1880, loss: 0.016489, acc: 0.750000\n",
            "steps: 1880\n",
            "save_steps: 1250\n",
            "20220510 16:37:06 current learning_rate:0.00001000\n",
            "used_time: 0.1812739372253418\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1890, loss: 0.484716, acc: 0.750000\n",
            "steps: 1890\n",
            "save_steps: 1250\n",
            "20220510 16:37:08 current learning_rate:0.00001000\n",
            "used_time: 0.1884152889251709\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1900, loss: 0.167842, acc: 0.375000\n",
            "steps: 1900\n",
            "save_steps: 1250\n",
            "20220510 16:37:09 current learning_rate:0.00001000\n",
            "used_time: 0.1834242343902588\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1910, loss: 0.038413, acc: 0.375000\n",
            "steps: 1910\n",
            "save_steps: 1250\n",
            "20220510 16:37:11 current learning_rate:0.00001000\n",
            "used_time: 0.1918637752532959\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1920, loss: 0.400439, acc: 0.875000\n",
            "steps: 1920\n",
            "save_steps: 1250\n",
            "20220510 16:37:13 current learning_rate:0.00001000\n",
            "used_time: 0.1716139316558838\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1930, loss: 0.433483, acc: 0.500000\n",
            "steps: 1930\n",
            "save_steps: 1250\n",
            "20220510 16:37:15 current learning_rate:0.00001000\n",
            "used_time: 0.1902759075164795\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1940, loss: 0.893052, acc: 0.625000\n",
            "steps: 1940\n",
            "save_steps: 1250\n",
            "20220510 16:37:17 current learning_rate:0.00001000\n",
            "used_time: 0.18289780616760254\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1950, loss: 0.488321, acc: 0.750000\n",
            "steps: 1950\n",
            "save_steps: 1250\n",
            "20220510 16:37:19 current learning_rate:0.00001000\n",
            "used_time: 0.19915556907653809\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1960, loss: 0.087540, acc: 0.375000\n",
            "steps: 1960\n",
            "save_steps: 1250\n",
            "20220510 16:37:21 current learning_rate:0.00001000\n",
            "used_time: 0.22056961059570312\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1970, loss: 0.047816, acc: 0.875000\n",
            "steps: 1970\n",
            "save_steps: 1250\n",
            "20220510 16:37:23 current learning_rate:0.00001000\n",
            "used_time: 0.21239805221557617\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1980, loss: 0.976147, acc: 0.500000\n",
            "steps: 1980\n",
            "save_steps: 1250\n",
            "20220510 16:37:25 current learning_rate:0.00001000\n",
            "used_time: 0.17654085159301758\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1990, loss: 0.991379, acc: 0.625000\n",
            "steps: 1990\n",
            "save_steps: 1250\n",
            "20220510 16:37:27 current learning_rate:0.00001000\n",
            "used_time: 0.21075654029846191\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2000, loss: 0.603953, acc: 0.625000\n",
            "steps: 2000\n",
            "save_steps: 1250\n",
            "Train-RCAC 0.9599358974358974\n",
            "20220510 16:37:29 current learning_rate:0.00001000\n",
            "used_time: 0.19037628173828125\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2010, loss: 0.041192, acc: 0.625000\n",
            "steps: 2010\n",
            "save_steps: 1250\n",
            "20220510 16:37:31 current learning_rate:0.00001000\n",
            "used_time: 0.19720244407653809\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2020, loss: 0.296332, acc: 0.750000\n",
            "steps: 2020\n",
            "save_steps: 1250\n",
            "20220510 16:37:32 current learning_rate:0.00001000\n",
            "used_time: 0.17673587799072266\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2030, loss: 0.032758, acc: 0.625000\n",
            "steps: 2030\n",
            "save_steps: 1250\n",
            "20220510 16:37:34 current learning_rate:0.00001000\n",
            "used_time: 0.1959981918334961\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2040, loss: 0.531457, acc: 0.750000\n",
            "steps: 2040\n",
            "save_steps: 1250\n",
            "20220510 16:37:36 current learning_rate:0.00001000\n",
            "used_time: 0.17012262344360352\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2050, loss: 0.631293, acc: 0.625000\n",
            "steps: 2050\n",
            "save_steps: 1250\n",
            "20220510 16:37:38 current learning_rate:0.00001000\n",
            "used_time: 0.1837480068206787\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2060, loss: 0.412852, acc: 0.875000\n",
            "steps: 2060\n",
            "save_steps: 1250\n",
            "20220510 16:37:40 current learning_rate:0.00001000\n",
            "used_time: 0.18832063674926758\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2070, loss: 0.127529, acc: 0.875000\n",
            "steps: 2070\n",
            "save_steps: 1250\n",
            "20220510 16:37:42 current learning_rate:0.00001000\n",
            "used_time: 0.18295526504516602\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2080, loss: 0.549528, acc: 0.375000\n",
            "steps: 2080\n",
            "save_steps: 1250\n",
            "20220510 16:37:44 current learning_rate:0.00001000\n",
            "used_time: 0.19031739234924316\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2090, loss: 0.662237, acc: 0.625000\n",
            "steps: 2090\n",
            "save_steps: 1250\n",
            "20220510 16:37:46 current learning_rate:0.00001000\n",
            "used_time: 0.21755719184875488\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2100, loss: 0.549307, acc: 0.500000\n",
            "steps: 2100\n",
            "save_steps: 1250\n",
            "20220510 16:37:48 current learning_rate:0.00001000\n",
            "used_time: 0.18863296508789062\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2110, loss: 0.400629, acc: 0.250000\n",
            "steps: 2110\n",
            "save_steps: 1250\n",
            "20220510 16:37:50 current learning_rate:0.00001000\n",
            "used_time: 0.22725415229797363\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2120, loss: 0.173319, acc: 0.875000\n",
            "steps: 2120\n",
            "save_steps: 1250\n",
            "20220510 16:37:52 current learning_rate:0.00001000\n",
            "used_time: 0.1887805461883545\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2130, loss: 0.319577, acc: 0.375000\n",
            "steps: 2130\n",
            "save_steps: 1250\n",
            "20220510 16:37:54 current learning_rate:0.00001000\n",
            "used_time: 0.1949784755706787\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2140, loss: 0.507649, acc: 0.750000\n",
            "steps: 2140\n",
            "save_steps: 1250\n",
            "20220510 16:37:56 current learning_rate:0.00001000\n",
            "used_time: 0.23734498023986816\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2150, loss: 0.074584, acc: 0.375000\n",
            "steps: 2150\n",
            "save_steps: 1250\n",
            "20220510 16:37:58 current learning_rate:0.00001000\n",
            "used_time: 0.18523764610290527\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2160, loss: 0.273368, acc: 0.875000\n",
            "steps: 2160\n",
            "save_steps: 1250\n",
            "20220510 16:38:00 current learning_rate:0.00001000\n",
            "used_time: 0.1740589141845703\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2170, loss: 0.263283, acc: 0.500000\n",
            "steps: 2170\n",
            "save_steps: 1250\n",
            "20220510 16:38:02 current learning_rate:0.00001000\n",
            "used_time: 0.18920493125915527\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2180, loss: 0.502629, acc: 0.750000\n",
            "steps: 2180\n",
            "save_steps: 1250\n",
            "20220510 16:38:04 current learning_rate:0.00001000\n",
            "used_time: 0.18878579139709473\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2190, loss: 0.294114, acc: 0.625000\n",
            "steps: 2190\n",
            "save_steps: 1250\n",
            "20220510 16:38:06 current learning_rate:0.00001000\n",
            "used_time: 0.1917867660522461\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2200, loss: 0.407484, acc: 0.875000\n",
            "steps: 2200\n",
            "save_steps: 1250\n",
            "20220510 16:38:07 current learning_rate:0.00001000\n",
            "used_time: 0.1747751235961914\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2210, loss: 0.530859, acc: 0.750000\n",
            "steps: 2210\n",
            "save_steps: 1250\n",
            "20220510 16:38:09 current learning_rate:0.00001000\n",
            "used_time: 0.192474365234375\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2220, loss: 0.481544, acc: 0.750000\n",
            "steps: 2220\n",
            "save_steps: 1250\n",
            "20220510 16:38:11 current learning_rate:0.00001000\n",
            "used_time: 0.18730473518371582\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2230, loss: 0.038533, acc: 0.625000\n",
            "steps: 2230\n",
            "save_steps: 1250\n",
            "20220510 16:38:13 current learning_rate:0.00001000\n",
            "used_time: 0.17637968063354492\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2240, loss: 0.025809, acc: 0.250000\n",
            "steps: 2240\n",
            "save_steps: 1250\n",
            "20220510 16:38:15 current learning_rate:0.00001000\n",
            "used_time: 0.21153712272644043\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2250, loss: 0.361797, acc: 0.500000\n",
            "steps: 2250\n",
            "save_steps: 1250\n",
            "20220510 16:38:17 current learning_rate:0.00001000\n",
            "used_time: 0.22465753555297852\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2260, loss: 0.793275, acc: 0.750000\n",
            "steps: 2260\n",
            "save_steps: 1250\n",
            "20220510 16:38:19 current learning_rate:0.00001000\n",
            "used_time: 0.1941523551940918\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2270, loss: 1.176667, acc: 0.500000\n",
            "steps: 2270\n",
            "save_steps: 1250\n",
            "20220510 16:38:21 current learning_rate:0.00001000\n",
            "used_time: 0.1725177764892578\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2280, loss: 0.523463, acc: 0.625000\n",
            "steps: 2280\n",
            "save_steps: 1250\n",
            "20220510 16:38:23 current learning_rate:0.00001000\n",
            "used_time: 0.20201730728149414\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2290, loss: 0.797157, acc: 0.625000\n",
            "steps: 2290\n",
            "save_steps: 1250\n",
            "20220510 16:38:25 current learning_rate:0.00001000\n",
            "used_time: 0.17530274391174316\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2300, loss: 0.466791, acc: 0.750000\n",
            "steps: 2300\n",
            "save_steps: 1250\n",
            "20220510 16:38:27 current learning_rate:0.00001000\n",
            "used_time: 0.2009434700012207\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2310, loss: 0.419092, acc: 0.625000\n",
            "steps: 2310\n",
            "save_steps: 1250\n",
            "20220510 16:38:29 current learning_rate:0.00001000\n",
            "used_time: 0.2153770923614502\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2320, loss: 0.514669, acc: 0.625000\n",
            "steps: 2320\n",
            "save_steps: 1250\n",
            "20220510 16:38:31 current learning_rate:0.00001000\n",
            "used_time: 0.22263193130493164\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2330, loss: 0.066996, acc: 0.500000\n",
            "steps: 2330\n",
            "save_steps: 1250\n",
            "20220510 16:38:32 current learning_rate:0.00001000\n",
            "used_time: 0.18045306205749512\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2340, loss: 0.328634, acc: 0.750000\n",
            "steps: 2340\n",
            "save_steps: 1250\n",
            "20220510 16:38:34 current learning_rate:0.00001000\n",
            "used_time: 0.18089079856872559\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2350, loss: 0.291359, acc: 0.625000\n",
            "steps: 2350\n",
            "save_steps: 1250\n",
            "20220510 16:38:36 current learning_rate:0.00001000\n",
            "used_time: 0.20168638229370117\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2360, loss: 1.421769, acc: 0.375000\n",
            "steps: 2360\n",
            "save_steps: 1250\n",
            "20220510 16:38:38 current learning_rate:0.00001000\n",
            "used_time: 0.19858360290527344\n",
            "shuffle epoch 2\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2370, loss: 0.952960, acc: 1.000000\n",
            "steps: 2370\n",
            "save_steps: 1250\n",
            "20220510 16:38:40 current learning_rate:0.00001000\n",
            "used_time: 0.18518424034118652\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2380, loss: 0.007902, acc: 0.625000\n",
            "steps: 2380\n",
            "save_steps: 1250\n",
            "20220510 16:38:42 current learning_rate:0.00001000\n",
            "used_time: 0.17760801315307617\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2390, loss: 0.029476, acc: 0.750000\n",
            "steps: 2390\n",
            "save_steps: 1250\n",
            "20220510 16:38:44 current learning_rate:0.00001000\n",
            "used_time: 0.191941499710083\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2400, loss: 0.044332, acc: 0.750000\n",
            "steps: 2400\n",
            "save_steps: 1250\n",
            "20220510 16:38:46 current learning_rate:0.00001000\n",
            "used_time: 0.15354371070861816\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2410, loss: 0.019244, acc: 0.500000\n",
            "steps: 2410\n",
            "save_steps: 1250\n",
            "20220510 16:38:48 current learning_rate:0.00001000\n",
            "used_time: 0.20888829231262207\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2420, loss: 0.077484, acc: 0.625000\n",
            "steps: 2420\n",
            "save_steps: 1250\n",
            "20220510 16:38:50 current learning_rate:0.00001000\n",
            "used_time: 0.19523286819458008\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2430, loss: 0.022896, acc: 0.750000\n",
            "steps: 2430\n",
            "save_steps: 1250\n",
            "20220510 16:38:52 current learning_rate:0.00001000\n",
            "used_time: 0.19683480262756348\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2440, loss: 0.008437, acc: 0.125000\n",
            "steps: 2440\n",
            "save_steps: 1250\n",
            "20220510 16:38:53 current learning_rate:0.00001000\n",
            "used_time: 0.20791244506835938\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2450, loss: 0.014849, acc: 0.500000\n",
            "steps: 2450\n",
            "save_steps: 1250\n",
            "20220510 16:38:55 current learning_rate:0.00001000\n",
            "used_time: 0.20727849006652832\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2460, loss: 0.033999, acc: 0.500000\n",
            "steps: 2460\n",
            "save_steps: 1250\n",
            "20220510 16:38:57 current learning_rate:0.00001000\n",
            "used_time: 0.21377158164978027\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2470, loss: 0.010492, acc: 0.625000\n",
            "steps: 2470\n",
            "save_steps: 1250\n",
            "20220510 16:38:59 current learning_rate:0.00001000\n",
            "used_time: 0.18817496299743652\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2480, loss: 0.372991, acc: 0.875000\n",
            "steps: 2480\n",
            "save_steps: 1250\n",
            "20220510 16:39:01 current learning_rate:0.00001000\n",
            "used_time: 0.21503829956054688\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2490, loss: 0.002015, acc: 0.750000\n",
            "steps: 2490\n",
            "save_steps: 1250\n",
            "20220510 16:39:03 current learning_rate:0.00001000\n",
            "used_time: 0.21256351470947266\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2500, loss: 0.017882, acc: 0.500000\n",
            "steps: 2500\n",
            "save_steps: 1250\n",
            "Train-RCAC 0.8816666666666667\n",
            "20220510 16:39:05 current learning_rate:0.00001000\n",
            "save_path: output_hm/step_2500traindev\n",
            "used_time: 11.977226972579956\n",
            "############################WARNING################################### using init_pretraining_params, not init_checkpoint ###### meaning hyper param e.g. lr won't inherit from checkpoint#################################################################terminate called without an active exception\n",
            "W0510 16:39:17.675513  1825 init.cc:216] Warning: PaddlePaddle catches a failure signal, it may not work properly\n",
            "W0510 16:39:17.675549  1825 init.cc:218] You could check whether you killed PaddlePaddle thread/process accidentally or report the case to PaddlePaddle\n",
            "W0510 16:39:17.675555  1825 init.cc:221] The detail failure signal is:\n",
            "\n",
            "W0510 16:39:17.675565  1825 init.cc:224] *** Aborted at 1652200757 (unix time) try \"date -d @1652200757\" if you are using GNU date ***\n",
            "W0510 16:39:17.677736  1825 init.cc:224] PC: @                0x0 (unknown)\n",
            "W0510 16:39:17.678062  1825 init.cc:224] *** SIGABRT (@0x6f7) received by PID 1783 (TID 0x7f250dd3f700) from PID 1783; stack trace: ***\n",
            "W0510 16:39:17.679806  1825 init.cc:224]     @     0x7f26b2763f10 (unknown)\n",
            "W0510 16:39:17.681485  1825 init.cc:224]     @     0x7f26b2763e87 gsignal\n",
            "W0510 16:39:17.684538  1825 init.cc:224]     @     0x7f26b27657f1 abort\n",
            "W0510 16:39:17.686352  1825 init.cc:224]     @     0x7f26b13fa957 (unknown)\n",
            "W0510 16:39:17.688045  1825 init.cc:224]     @     0x7f26b1400ae6 (unknown)\n",
            "W0510 16:39:17.689535  1825 init.cc:224]     @     0x7f26b1400b21 std::terminate()\n",
            "W0510 16:39:17.691044  1825 init.cc:224]     @     0x7f26b14004ea __gxx_personality_v0\n",
            "W0510 16:39:17.692520  1825 init.cc:224]     @     0x7f26b0f40668 (unknown)\n",
            "W0510 16:39:17.694029  1825 init.cc:224]     @     0x7f26b0f40c5c _Unwind_ForcedUnwind\n",
            "W0510 16:39:17.695557  1825 init.cc:224]     @     0x7f26b2517000 __GI___pthread_unwind\n",
            "W0510 16:39:17.697170  1825 init.cc:224]     @     0x7f26b250eae5 __pthread_exit\n",
            "W0510 16:39:17.698772  1825 init.cc:224]     @     0x7f26b2855364 pthread_exit\n",
            "W0510 16:39:17.698930  1825 init.cc:224]     @           0x5e37d8 PyThread_exit_thread\n",
            "W0510 16:39:17.699069  1825 init.cc:224]     @           0x47028a (unknown)\n",
            "W0510 16:39:17.703771  1825 init.cc:224]     @     0x7f265f509019 pybind11::gil_scoped_release::~gil_scoped_release()\n",
            "W0510 16:39:17.704950  1825 init.cc:224]     @     0x7f265f5f13b6 _ZZN8pybind1112cpp_function10initializeIZN6paddle6pybind10BindReaderEPNS_6moduleEEUlRNS2_9operators6reader22LoDTensorBlockingQueueERKSt6vectorINS2_9framework9LoDTensorESaISC_EEE1_bIS9_SG_EINS_4nameENS_9is_methodENS_7siblingENS_10call_guardIINS_18gil_scoped_releaseEEEEEEEvOT_PFT0_DpT1_EDpRKT2_ENUlRNS_6detail13function_callEE1_4_FUNES11_\n",
            "W0510 16:39:17.707662  1825 init.cc:224]     @     0x7f265f526829 pybind11::cpp_function::dispatcher()\n",
            "W0510 16:39:17.707818  1825 init.cc:224]     @           0x593784 _PyMethodDef_RawFastCallKeywords\n",
            "W0510 16:39:17.707934  1825 init.cc:224]     @           0x594731 _PyObject_FastCallKeywords\n",
            "W0510 16:39:17.708068  1825 init.cc:224]     @           0x548cc1 (unknown)\n",
            "W0510 16:39:17.708173  1825 init.cc:224]     @           0x51566f _PyEval_EvalFrameDefault\n",
            "W0510 16:39:17.708267  1825 init.cc:224]     @           0x549e0e _PyEval_EvalCodeWithName\n",
            "W0510 16:39:17.708328  1825 init.cc:224]     @           0x4bcb19 _PyFunction_FastCallDict\n",
            "W0510 16:39:17.708385  1825 init.cc:224]     @           0x5134a6 _PyEval_EvalFrameDefault\n",
            "W0510 16:39:17.708472  1825 init.cc:224]     @           0x593dd7 _PyFunction_FastCallKeywords\n",
            "W0510 16:39:17.708531  1825 init.cc:224]     @           0x511e2c _PyEval_EvalFrameDefault\n",
            "W0510 16:39:17.708616  1825 init.cc:224]     @           0x593dd7 _PyFunction_FastCallKeywords\n",
            "W0510 16:39:17.708674  1825 init.cc:224]     @           0x511e2c _PyEval_EvalFrameDefault\n",
            "W0510 16:39:17.708732  1825 init.cc:224]     @           0x4bc98a _PyFunction_FastCallDict\n",
            "W0510 16:39:17.708858  1825 init.cc:224]     @           0x59c019 (unknown)\n",
            "W0510 16:39:17.709017  1825 init.cc:224]     @           0x595ef6 PyObject_Call\n",
            "W0510 16:39:17.709147  1825 init.cc:224]     @           0x5d5393 (unknown)\n",
            "run_finetuning.sh: line 64:  1783 Aborted                 (core dumped) python /content/vilio/ernie-vil/finetune.py --use_cuda \"True\" --is_distributed \"False\" --use_fast_executor ${e_executor-\"True\"} --nccl_comm_num ${nccl_comm_num:-\"1\"} --batch_size $((BATCH_SIZE/gpu_cnt)) --do_train \"True\" --do_test \"False\" --task_name ${TASK_NAME} --vocab_path ${VOCAB_PATH} --task_group_json ${TASK_GROUP_JSON} --lr_scheduler ${lr_scheduler} --decay_steps ${decay_steps-\"\"} --lr_decay_ratio ${lr_decay_ratio-0.1} --num_train_steps ${num_train_steps} --checkpoints $output_model_path --save_steps ${SAVE_STEPS} --init_checkpoint ${PRETRAIN_MODELS} --ernie_config_path ${ERNIE_VIL_CONFIG} --learning_rate ${LR_RATE} --warmup_steps ${WARMUP_STEPS} --weight_decay ${WEIGHT_DECAY:-0} --max_seq_len ${MAX_LEN} --validation_steps ${VALID_STEPS} --skip_steps 10 --split ${SPLIT} --stop_steps ${STOP}\n",
            "-----------  Configuration Arguments -----------\n",
            "batch_size: 8\n",
            "checkpoints: checkpoints\n",
            "combine: False\n",
            "decay_steps: \n",
            "do_test: True\n",
            "do_train: False\n",
            "do_val: False\n",
            "epoch: 100\n",
            "ernie_config_path: /content/vilio/ernie-vil/data/erniesmall/ernie_vil_config.base.json\n",
            "exp: ES72\n",
            "feature_size: 2048\n",
            "fusion_method: sum\n",
            "hierarchical_allreduce_inter_nranks: 8\n",
            "init_checkpoint: /content/vilio/ernie-vil/output_hm/step_2500traindev\n",
            "is_distributed: False\n",
            "learning_rate: 0.0001\n",
            "lr_decay_dict_file: \n",
            "lr_decay_ratio: 0.1\n",
            "lr_scheduler: linear_warmup_decay\n",
            "max_img_len: 100\n",
            "max_seq_len: 128\n",
            "nccl_comm_num: 1\n",
            "num_features: 50\n",
            "num_train_steps: 1000000\n",
            "output_file: \n",
            "result_file: /content/vilio/ernie-vil/data/log\n",
            "save_steps: 100\n",
            "skip_steps: 10\n",
            "split: test_seen\n",
            "stop_steps: 5000\n",
            "subtrain: False\n",
            "task_group_json: /content/vilio/ernie-vil/conf/hm/task_hm.json\n",
            "task_name: hm\n",
            "test_filelist: \n",
            "test_split: val\n",
            "train_filelist: \n",
            "use_cuda: True\n",
            "use_fast_executor: True\n",
            "use_fuse: False\n",
            "use_gpu: True\n",
            "use_hierarchical_allreduce: False\n",
            "valid_filelist: \n",
            "validation_steps: 6000\n",
            "verbose: False\n",
            "vocab_path: /content/vilio/ernie-vil/data/erniesmall/vocab.txt\n",
            "warmup_steps: 0\n",
            "weight_decay: 0.01\n",
            "------------------------------------------------\n",
            "finetuning tasks start\n",
            "attention_probs_dropout_prob: 0.1\n",
            "class_attr_size: 401\n",
            "class_size: 1601\n",
            "co_hidden_size: 1024\n",
            "co_intermediate_size: 1024\n",
            "co_num_attention_heads: 8\n",
            "hidden_act: gelu\n",
            "hidden_dropout_prob: 0.1\n",
            "hidden_size: 768\n",
            "initializer_range: 0.02\n",
            "max_position_embeddings: 512\n",
            "num_attention_heads: 12\n",
            "num_hidden_layers: 12\n",
            "sent_type_vocab_size: 4\n",
            "t_biattention_id: [6, 7, 8, 9, 10, 11]\n",
            "task_type_vocab_size: 16\n",
            "type_vocab_size: 2\n",
            "v_biattention_id: [0, 1, 2, 3, 4, 5]\n",
            "v_hidden_size: 1024\n",
            "v_intermediate_size: 1024\n",
            "v_num_attention_heads: 8\n",
            "vocab_size: 30522\n",
            "------------------------------------------------\n",
            "task:  [{'task': 'HM', 'num_choice': 1, 'annotations_jsonpath_train': '/content/vilio/ernie-vil/data/hm/train.jsonl', 'annotations_jsonpath_dev_seen': '/content/vilio/ernie-vil/data/hm/dev_seenlong.jsonl', 'annotations_jsonpath_traindev': '/content/vilio/ernie-vil/data/hm/traindev.jsonl', 'annotations_jsonpath_test_unseen': '/content/vilio/ernie-vil/data/hm/test_unseenlong.jsonl', 'annotations_jsonpath_test_seen': '/content/vilio/ernie-vil/data/hm/test_seenlong.jsonl', 'feature_lmdb_path': '/content/vilio/ernie-vil/data/hm/HM_img.tsv', 'gt_feature_lmdb_path': '/content/vilio/ernie-vil/data/hm/HM_gt_img.tsv', 'unisex_names_table': '/content/vilio/ernie-vil/data/vcr/unisex_names_table.csv', 'Proprocessor': 'PreprocessorBasic', 'tokenizer_name': 'FullTokenizer', 'fusion_method': 'mul', 'dropout_rate': 0.1, 'max_seq_len': 128, 'use_gt_fea': True, 'shufflekeep_across_task': True, 'shuffle_every_epoch': True, 'task_weight': 1.0, 'task_prefix': 'hm'}]\n",
            "2022-05-10 16:39:21,297-WARNING: paddle.fluid.layers.py_reader() may be deprecated in the near future. Please use paddle.fluid.io.DataLoader.from_generator() instead.\n",
            "theoretical memory usage: \n",
            "(3678.2632896423343, 3853.418684387207, 'MB')\n",
            "args.is_distributed: False\n",
            "W0510 16:39:22.200713  1945 device_context.cc:252] Please NOTE: device: 0, CUDA Capability: 60, Driver API Version: 11.2, Runtime API Version: 9.0\n",
            "W0510 16:39:22.213882  1945 device_context.cc:260] device: 0, cuDNN Version: 7.6.\n",
            "SPLIT: test_seen\n",
            "Start to load Faster-RCNN detected objects from /content/vilio/ernie-vil/data/hm/HM_img.tsv\n",
            "Loaded 1000 images in file /content/vilio/ernie-vil/data/hm/HM_img.tsv in 70 seconds.\n",
            "Start to load Faster-RCNN detected objects from /content/vilio/ernie-vil/data/hm/HM_gt_img.tsv\n",
            "Loaded 1000 images in file /content/vilio/ernie-vil/data/hm/HM_gt_img.tsv in 50 seconds.\n",
            "Load 1300 data from split(s) /content/vilio/ernie-vil/data/hm/test_seenlong.jsonl.\n",
            "use gt featurre\n",
            "LEN:  1300\n",
            "Load pretraining parameters from /content/vilio/ernie-vil/output_hm/step_2500traindev.\n",
            "testing on hm val split\n",
            "task name list :  ['mean_0.tmp_0', 'accuracy_0.tmp_0', 'arg_max_0.tmp_0', 'read_file_0.tmp_9', 'read_file_0.tmp_8', 'reshape2_120.tmp_0']\n",
            "cur_step: 10 cur_acc: 0.9875\n",
            "cur_step: 20 cur_acc: 0.99375\n",
            "cur_step: 30 cur_acc: 0.9958333333333333\n",
            "cur_step: 40 cur_acc: 0.996875\n",
            "cur_step: 50 cur_acc: 0.9975\n",
            "cur_step: 60 cur_acc: 0.9979166666666667\n",
            "cur_step: 70 cur_acc: 0.9982142857142857\n",
            "cur_step: 80 cur_acc: 0.9984375\n",
            "cur_step: 90 cur_acc: 0.9986111111111111\n",
            "cur_step: 100 cur_acc: 0.99875\n",
            "cur_step: 110 cur_acc: 0.9988636363636364\n",
            "cur_step: 120 cur_acc: 0.9989583333333333\n",
            "cur_step: 130 cur_acc: 0.9980769230769231\n",
            "cur_step: 140 cur_acc: 0.9982142857142857\n",
            "cur_step: 150 cur_acc: 0.9983333333333333\n",
            "cur_step: 160 cur_acc: 0.9984375\n",
            "EXCEPTING\n",
            "LEN: 1000 1000\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   id      1000 non-null   int64  \n",
            " 1   proba   1000 non-null   float32\n",
            " 2   label   1000 non-null   int64  \n",
            "dtypes: float32(1), int64(2)\n",
            "memory usage: 19.7 KB\n",
            "None\n",
            "average_acc: 0.9984375\n",
            "rocauc: 0.7981220657276996\n",
            "-----------  Configuration Arguments -----------\n",
            "batch_size: 8\n",
            "checkpoints: checkpoints\n",
            "combine: False\n",
            "decay_steps: \n",
            "do_test: True\n",
            "do_train: False\n",
            "do_val: False\n",
            "epoch: 100\n",
            "ernie_config_path: /content/vilio/ernie-vil/data/erniesmall/ernie_vil_config.base.json\n",
            "exp: ES72\n",
            "feature_size: 2048\n",
            "fusion_method: sum\n",
            "hierarchical_allreduce_inter_nranks: 8\n",
            "init_checkpoint: /content/vilio/ernie-vil/output_hm/step_2500traindev\n",
            "is_distributed: False\n",
            "learning_rate: 0.0001\n",
            "lr_decay_dict_file: \n",
            "lr_decay_ratio: 0.1\n",
            "lr_scheduler: linear_warmup_decay\n",
            "max_img_len: 100\n",
            "max_seq_len: 128\n",
            "nccl_comm_num: 1\n",
            "num_features: 50\n",
            "num_train_steps: 1000000\n",
            "output_file: \n",
            "result_file: /content/vilio/ernie-vil/data/log\n",
            "save_steps: 100\n",
            "skip_steps: 10\n",
            "split: test_unseen\n",
            "stop_steps: 5000\n",
            "subtrain: False\n",
            "task_group_json: /content/vilio/ernie-vil/conf/hm/task_hm.json\n",
            "task_name: hm\n",
            "test_filelist: \n",
            "test_split: val\n",
            "train_filelist: \n",
            "use_cuda: True\n",
            "use_fast_executor: True\n",
            "use_fuse: False\n",
            "use_gpu: True\n",
            "use_hierarchical_allreduce: False\n",
            "valid_filelist: \n",
            "validation_steps: 6000\n",
            "verbose: False\n",
            "vocab_path: /content/vilio/ernie-vil/data/erniesmall/vocab.txt\n",
            "warmup_steps: 0\n",
            "weight_decay: 0.01\n",
            "------------------------------------------------\n",
            "finetuning tasks start\n",
            "attention_probs_dropout_prob: 0.1\n",
            "class_attr_size: 401\n",
            "class_size: 1601\n",
            "co_hidden_size: 1024\n",
            "co_intermediate_size: 1024\n",
            "co_num_attention_heads: 8\n",
            "hidden_act: gelu\n",
            "hidden_dropout_prob: 0.1\n",
            "hidden_size: 768\n",
            "initializer_range: 0.02\n",
            "max_position_embeddings: 512\n",
            "num_attention_heads: 12\n",
            "num_hidden_layers: 12\n",
            "sent_type_vocab_size: 4\n",
            "t_biattention_id: [6, 7, 8, 9, 10, 11]\n",
            "task_type_vocab_size: 16\n",
            "type_vocab_size: 2\n",
            "v_biattention_id: [0, 1, 2, 3, 4, 5]\n",
            "v_hidden_size: 1024\n",
            "v_intermediate_size: 1024\n",
            "v_num_attention_heads: 8\n",
            "vocab_size: 30522\n",
            "------------------------------------------------\n",
            "task:  [{'task': 'HM', 'num_choice': 1, 'annotations_jsonpath_train': '/content/vilio/ernie-vil/data/hm/train.jsonl', 'annotations_jsonpath_dev_seen': '/content/vilio/ernie-vil/data/hm/dev_seenlong.jsonl', 'annotations_jsonpath_traindev': '/content/vilio/ernie-vil/data/hm/traindev.jsonl', 'annotations_jsonpath_test_unseen': '/content/vilio/ernie-vil/data/hm/test_unseenlong.jsonl', 'annotations_jsonpath_test_seen': '/content/vilio/ernie-vil/data/hm/test_seenlong.jsonl', 'feature_lmdb_path': '/content/vilio/ernie-vil/data/hm/HM_img.tsv', 'gt_feature_lmdb_path': '/content/vilio/ernie-vil/data/hm/HM_gt_img.tsv', 'unisex_names_table': '/content/vilio/ernie-vil/data/vcr/unisex_names_table.csv', 'Proprocessor': 'PreprocessorBasic', 'tokenizer_name': 'FullTokenizer', 'fusion_method': 'mul', 'dropout_rate': 0.1, 'max_seq_len': 128, 'use_gt_fea': True, 'shufflekeep_across_task': True, 'shuffle_every_epoch': True, 'task_weight': 1.0, 'task_prefix': 'hm'}]\n",
            "2022-05-10 16:41:53,125-WARNING: paddle.fluid.layers.py_reader() may be deprecated in the near future. Please use paddle.fluid.io.DataLoader.from_generator() instead.\n",
            "theoretical memory usage: \n",
            "(3678.2632896423343, 3853.418684387207, 'MB')\n",
            "args.is_distributed: False\n",
            "W0510 16:41:53.999891  2021 device_context.cc:252] Please NOTE: device: 0, CUDA Capability: 60, Driver API Version: 11.2, Runtime API Version: 9.0\n",
            "W0510 16:41:54.012580  2021 device_context.cc:260] device: 0, cuDNN Version: 7.6.\n",
            "SPLIT: test_unseen\n",
            "Start to load Faster-RCNN detected objects from /content/vilio/ernie-vil/data/hm/HM_img.tsv\n",
            "Loaded 2000 images in file /content/vilio/ernie-vil/data/hm/HM_img.tsv in 72 seconds.\n",
            "Start to load Faster-RCNN detected objects from /content/vilio/ernie-vil/data/hm/HM_gt_img.tsv\n",
            "Loaded 2000 images in file /content/vilio/ernie-vil/data/hm/HM_gt_img.tsv in 51 seconds.\n",
            "Load 2600 data from split(s) /content/vilio/ernie-vil/data/hm/test_unseenlong.jsonl.\n",
            "use gt featurre\n",
            "LEN:  2600\n",
            "Load pretraining parameters from /content/vilio/ernie-vil/output_hm/step_2500traindev.\n",
            "testing on hm val split\n",
            "task name list :  ['mean_0.tmp_0', 'accuracy_0.tmp_0', 'arg_max_0.tmp_0', 'read_file_0.tmp_9', 'read_file_0.tmp_8', 'reshape2_120.tmp_0']\n",
            "cur_step: 10 cur_acc: 0.9875\n",
            "cur_step: 20 cur_acc: 0.99375\n",
            "cur_step: 30 cur_acc: 0.9958333333333333\n",
            "cur_step: 40 cur_acc: 0.996875\n",
            "cur_step: 50 cur_acc: 0.9975\n",
            "cur_step: 60 cur_acc: 0.9979166666666667\n",
            "cur_step: 70 cur_acc: 0.9982142857142857\n",
            "cur_step: 80 cur_acc: 0.9984375\n",
            "cur_step: 90 cur_acc: 0.9986111111111111\n",
            "cur_step: 100 cur_acc: 0.99875\n",
            "cur_step: 110 cur_acc: 0.9988636363636364\n",
            "cur_step: 120 cur_acc: 0.9989583333333333\n",
            "cur_step: 130 cur_acc: 0.9990384615384615\n",
            "cur_step: 140 cur_acc: 0.9991071428571429\n",
            "cur_step: 150 cur_acc: 0.9991666666666666\n",
            "cur_step: 160 cur_acc: 0.99921875\n",
            "cur_step: 170 cur_acc: 0.9992647058823529\n",
            "cur_step: 180 cur_acc: 0.9993055555555556\n",
            "cur_step: 190 cur_acc: 0.9993421052631579\n",
            "cur_step: 200 cur_acc: 0.999375\n",
            "cur_step: 210 cur_acc: 0.9994047619047619\n",
            "cur_step: 220 cur_acc: 0.9994318181818181\n",
            "cur_step: 230 cur_acc: 0.9994565217391305\n",
            "cur_step: 240 cur_acc: 0.9994791666666667\n",
            "cur_step: 250 cur_acc: 0.9995\n",
            "cur_step: 260 cur_acc: 0.9990384615384615\n",
            "cur_step: 270 cur_acc: 0.9990740740740741\n",
            "cur_step: 280 cur_acc: 0.9991071428571429\n",
            "cur_step: 290 cur_acc: 0.9991379310344828\n",
            "cur_step: 300 cur_acc: 0.9991666666666666\n",
            "cur_step: 310 cur_acc: 0.9991935483870967\n",
            "cur_step: 320 cur_acc: 0.99921875\n",
            "EXCEPTING\n",
            "LEN: 2000 2000\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2000 entries, 0 to 1999\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   id      2000 non-null   int64  \n",
            " 1   proba   2000 non-null   float32\n",
            " 2   label   2000 non-null   int64  \n",
            "dtypes: float32(1), int64(2)\n",
            "memory usage: 39.2 KB\n",
            "None\n",
            "average_acc: 0.99921875\n",
            "rocauc: 0.5930414386239249\n",
            "mv: cannot stat '/content/vilio/ernie-vil/data/hm/hm_vgattr10100.tsv': No such file or directory\n",
            "mv: cannot stat '/content/vilio/ernie-vil/data/hm/hm_vgattr7272.tsv': No such file or directory\n",
            "+ TASK_NAME=hm\n",
            "+ CONF_FILE=conf/hm/model_conf_hm\n",
            "+ VOCAB_PATH=/content/vilio/ernie-vil/data/erniesmallvcr/vocab.txt\n",
            "+ ERNIE_VIL_CONFIG=/content/vilio/ernie-vil/data/erniesmallvcr/ernie_vil_config.base.json\n",
            "+ PRETRAIN_MODELS=/content/vilio/ernie-vil/data/erniesmallvcr/params\n",
            "+ SPLIT=train\n",
            "+ STOP=2500\n",
            "+ source conf/hm/model_conf_hm\n",
            "++ output_model_path=output_hm\n",
            "++ lr_scheduler=manual_warmup_decay\n",
            "++ decay_steps='13308;19962'\n",
            "++ lr_decay_ratio=0.1\n",
            "++ num_train_steps=5000\n",
            "++ SAVE_STEPS=1250\n",
            "++ WARMUP_STEPS=500\n",
            "++ BATCH_SIZE=8\n",
            "++ VALID_STEPS=20000\n",
            "++ LR_RATE=1e-5\n",
            "++ WEIGHT_DECAY=0.01\n",
            "++ MAX_LEN=128\n",
            "+ CUDA_VISIBLE_DEVICES=1\n",
            "+ export FLAGS_fast_eager_deletion_mode=1\n",
            "+ FLAGS_fast_eager_deletion_mode=1\n",
            "+ export FLAGS_eager_delete_tensor_gb=0.0\n",
            "+ FLAGS_eager_delete_tensor_gb=0.0\n",
            "+ export FLAGS_fraction_of_gpu_memory_to_use=0.98\n",
            "+ FLAGS_fraction_of_gpu_memory_to_use=0.98\n",
            "++ echo True\n",
            "++ tr '[A-Z]' '[a-z]'\n",
            "+ e_executor=true\n",
            "++ echo False\n",
            "++ tr '[A-Z]' '[a-z]'\n",
            "+ use_fuse=false\n",
            "+ [[ false == \\t\\r\\u\\e ]]\n",
            "+ TASK_GROUP_JSON=/content/vilio/ernie-vil/conf/hm/task_hm.json\n",
            "++ echo 1\n",
            "++ awk '-F\\t' '{len=split($0,vec,\",\");print len}'\n",
            "+ gpu_cnt=1\n",
            "+ echo gpu_cnt, 1\n",
            "gpu_cnt, 1\n",
            "+ python /content/vilio/ernie-vil/finetune.py --use_cuda True --is_distributed False --use_fast_executor true --nccl_comm_num 1 --batch_size 8 --do_train True --do_test False --task_name hm --vocab_path /content/vilio/ernie-vil/data/erniesmallvcr/vocab.txt --task_group_json /content/vilio/ernie-vil/conf/hm/task_hm.json --lr_scheduler manual_warmup_decay --decay_steps '13308;19962' --lr_decay_ratio 0.1 --num_train_steps 5000 --checkpoints output_hm --save_steps 1250 --init_checkpoint /content/vilio/ernie-vil/data/erniesmallvcr/params --ernie_config_path /content/vilio/ernie-vil/data/erniesmallvcr/ernie_vil_config.base.json --learning_rate 1e-5 --warmup_steps 500 --weight_decay 0.01 --max_seq_len 128 --validation_steps 20000 --skip_steps 10 --split train --stop_steps 2500\n",
            "-----------  Configuration Arguments -----------\n",
            "batch_size: 8\n",
            "checkpoints: output_hm\n",
            "combine: False\n",
            "decay_steps: 13308;19962\n",
            "do_test: False\n",
            "do_train: True\n",
            "do_val: False\n",
            "epoch: 100\n",
            "ernie_config_path: /content/vilio/ernie-vil/data/erniesmallvcr/ernie_vil_config.base.json\n",
            "exp: experiment\n",
            "feature_size: 2048\n",
            "fusion_method: sum\n",
            "hierarchical_allreduce_inter_nranks: 8\n",
            "init_checkpoint: /content/vilio/ernie-vil/data/erniesmallvcr/params\n",
            "is_distributed: False\n",
            "learning_rate: 1e-05\n",
            "lr_decay_dict_file: \n",
            "lr_decay_ratio: 0.1\n",
            "lr_scheduler: manual_warmup_decay\n",
            "max_img_len: 100\n",
            "max_seq_len: 128\n",
            "nccl_comm_num: 1\n",
            "num_features: 50\n",
            "num_train_steps: 5000\n",
            "output_file: \n",
            "result_file: ./res_tmp\n",
            "save_steps: 1250\n",
            "skip_steps: 10\n",
            "split: train\n",
            "stop_steps: 2500\n",
            "subtrain: False\n",
            "task_group_json: /content/vilio/ernie-vil/conf/hm/task_hm.json\n",
            "task_name: hm\n",
            "test_filelist: \n",
            "test_split: test\n",
            "train_filelist: \n",
            "use_cuda: True\n",
            "use_fast_executor: True\n",
            "use_fuse: False\n",
            "use_gpu: True\n",
            "use_hierarchical_allreduce: False\n",
            "valid_filelist: \n",
            "validation_steps: 20000\n",
            "verbose: False\n",
            "vocab_path: /content/vilio/ernie-vil/data/erniesmallvcr/vocab.txt\n",
            "warmup_steps: 500\n",
            "weight_decay: 0.01\n",
            "------------------------------------------------\n",
            "finetuning tasks start\n",
            "attention_probs_dropout_prob: 0.1\n",
            "class_attr_size: 401\n",
            "class_size: 1601\n",
            "co_hidden_size: 1024\n",
            "co_intermediate_size: 1024\n",
            "co_num_attention_heads: 8\n",
            "hidden_act: gelu\n",
            "hidden_dropout_prob: 0.1\n",
            "hidden_size: 768\n",
            "initializer_range: 0.02\n",
            "max_position_embeddings: 512\n",
            "num_attention_heads: 12\n",
            "num_hidden_layers: 12\n",
            "sent_type_vocab_size: 4\n",
            "t_biattention_id: [6, 7, 8, 9, 10, 11]\n",
            "task_type_vocab_size: 16\n",
            "type_vocab_size: 2\n",
            "v_biattention_id: [0, 1, 2, 3, 4, 5]\n",
            "v_hidden_size: 1024\n",
            "v_intermediate_size: 1024\n",
            "v_num_attention_heads: 8\n",
            "vocab_size: 30522\n",
            "------------------------------------------------\n",
            "task:  [{'task': 'HM', 'num_choice': 1, 'annotations_jsonpath_train': '/content/vilio/ernie-vil/data/hm/train.jsonl', 'annotations_jsonpath_dev_seen': '/content/vilio/ernie-vil/data/hm/dev_seenlong.jsonl', 'annotations_jsonpath_traindev': '/content/vilio/ernie-vil/data/hm/traindev.jsonl', 'annotations_jsonpath_test_unseen': '/content/vilio/ernie-vil/data/hm/test_unseenlong.jsonl', 'annotations_jsonpath_test_seen': '/content/vilio/ernie-vil/data/hm/test_seenlong.jsonl', 'feature_lmdb_path': '/content/vilio/ernie-vil/data/hm/HM_img.tsv', 'gt_feature_lmdb_path': '/content/vilio/ernie-vil/data/hm/HM_gt_img.tsv', 'unisex_names_table': '/content/vilio/ernie-vil/data/vcr/unisex_names_table.csv', 'Proprocessor': 'PreprocessorBasic', 'tokenizer_name': 'FullTokenizer', 'fusion_method': 'mul', 'dropout_rate': 0.1, 'max_seq_len': 128, 'use_gt_fea': True, 'shufflekeep_across_task': True, 'shuffle_every_epoch': True, 'task_weight': 1.0, 'task_prefix': 'hm'}]\n",
            "2022-05-10 16:44:47,554-WARNING: paddle.fluid.layers.py_reader() may be deprecated in the near future. Please use paddle.fluid.io.DataLoader.from_generator() instead.\n",
            "/usr/local/lib/python3.7/dist-packages/paddle/fluid/clip.py:779: UserWarning: Caution! 'set_gradient_clip' is not recommended and may be deprecated in future! We recommend a new strategy: set 'grad_clip' when initializing the 'optimizer'. This method can reduce the mistakes, please refer to documention of 'optimizer'.\n",
            "  warnings.warn(\"Caution! 'set_gradient_clip' is not recommended \"\n",
            "theoretical memory usage: \n",
            "(18209.21138906479, 19076.31669330597, 'MB')\n",
            "args.is_distributed: False\n",
            "W0510 16:44:51.897806  2093 device_context.cc:252] Please NOTE: device: 0, CUDA Capability: 60, Driver API Version: 11.2, Runtime API Version: 9.0\n",
            "W0510 16:44:51.910136  2093 device_context.cc:260] device: 0, cuDNN Version: 7.6.\n",
            "Load pretraining parameters from /content/vilio/ernie-vil/data/erniesmallvcr/params.\n",
            "SPLIT: train\n",
            "Start to load Faster-RCNN detected objects from /content/vilio/ernie-vil/data/hm/HM_img.tsv\n",
            "Loaded 8596 images in file /content/vilio/ernie-vil/data/hm/HM_img.tsv in 84 seconds.\n",
            "Start to load Faster-RCNN detected objects from /content/vilio/ernie-vil/data/hm/HM_gt_img.tsv\n",
            "Loaded 8596 images in file /content/vilio/ernie-vil/data/hm/HM_gt_img.tsv in 60 seconds.\n",
            "Load 8596 data from split(s) /content/vilio/ernie-vil/data/hm/train.jsonl.\n",
            "use gt featurre\n",
            "LEN:  8596\n",
            "shuffle epoch 0\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 10, loss: 0.663511, acc: 0.875000\n",
            "steps: 10\n",
            "save_steps: 1250\n",
            "20220510 16:47:28 current learning_rate:0.00000018\n",
            "used_time: 0.20260334014892578\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 20, loss: 0.705539, acc: 0.625000\n",
            "steps: 20\n",
            "save_steps: 1250\n",
            "20220510 16:47:30 current learning_rate:0.00000038\n",
            "used_time: 0.1899430751800537\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 30, loss: 0.682549, acc: 0.625000\n",
            "steps: 30\n",
            "save_steps: 1250\n",
            "20220510 16:47:32 current learning_rate:0.00000058\n",
            "used_time: 0.17704439163208008\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 40, loss: 0.666253, acc: 0.750000\n",
            "steps: 40\n",
            "save_steps: 1250\n",
            "20220510 16:47:34 current learning_rate:0.00000078\n",
            "used_time: 0.17494559288024902\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 50, loss: 0.664188, acc: 0.625000\n",
            "steps: 50\n",
            "save_steps: 1250\n",
            "20220510 16:47:36 current learning_rate:0.00000098\n",
            "used_time: 0.21557235717773438\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 60, loss: 0.651500, acc: 0.750000\n",
            "steps: 60\n",
            "save_steps: 1250\n",
            "20220510 16:47:38 current learning_rate:0.00000118\n",
            "used_time: 0.20227575302124023\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 70, loss: 0.712183, acc: 0.500000\n",
            "steps: 70\n",
            "save_steps: 1250\n",
            "20220510 16:47:40 current learning_rate:0.00000138\n",
            "used_time: 0.19678258895874023\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 80, loss: 0.570555, acc: 1.000000\n",
            "steps: 80\n",
            "save_steps: 1250\n",
            "20220510 16:47:42 current learning_rate:0.00000158\n",
            "used_time: 0.19595098495483398\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 90, loss: 0.798992, acc: 0.125000\n",
            "steps: 90\n",
            "save_steps: 1250\n",
            "20220510 16:47:44 current learning_rate:0.00000178\n",
            "used_time: 0.2011415958404541\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 100, loss: 0.677605, acc: 0.500000\n",
            "steps: 100\n",
            "save_steps: 1250\n",
            "20220510 16:47:46 current learning_rate:0.00000198\n",
            "used_time: 0.17644119262695312\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 110, loss: 0.764142, acc: 0.375000\n",
            "steps: 110\n",
            "save_steps: 1250\n",
            "20220510 16:47:48 current learning_rate:0.00000218\n",
            "used_time: 0.18611359596252441\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 120, loss: 0.703232, acc: 0.500000\n",
            "steps: 120\n",
            "save_steps: 1250\n",
            "20220510 16:47:50 current learning_rate:0.00000238\n",
            "used_time: 0.20150065422058105\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 130, loss: 0.649690, acc: 0.750000\n",
            "steps: 130\n",
            "save_steps: 1250\n",
            "20220510 16:47:52 current learning_rate:0.00000258\n",
            "used_time: 0.2008202075958252\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 140, loss: 0.662850, acc: 0.625000\n",
            "steps: 140\n",
            "save_steps: 1250\n",
            "20220510 16:47:53 current learning_rate:0.00000278\n",
            "used_time: 0.17136502265930176\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 150, loss: 0.651795, acc: 0.625000\n",
            "steps: 150\n",
            "save_steps: 1250\n",
            "20220510 16:47:55 current learning_rate:0.00000298\n",
            "used_time: 0.20296716690063477\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 160, loss: 0.567018, acc: 0.750000\n",
            "steps: 160\n",
            "save_steps: 1250\n",
            "20220510 16:47:57 current learning_rate:0.00000318\n",
            "used_time: 0.20145916938781738\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 170, loss: 0.600136, acc: 0.750000\n",
            "steps: 170\n",
            "save_steps: 1250\n",
            "20220510 16:47:59 current learning_rate:0.00000338\n",
            "used_time: 0.2172410488128662\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 180, loss: 0.515510, acc: 0.875000\n",
            "steps: 180\n",
            "save_steps: 1250\n",
            "20220510 16:48:01 current learning_rate:0.00000358\n",
            "used_time: 0.17132234573364258\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 190, loss: 0.685293, acc: 0.500000\n",
            "steps: 190\n",
            "save_steps: 1250\n",
            "20220510 16:48:03 current learning_rate:0.00000378\n",
            "used_time: 0.20563197135925293\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 200, loss: 0.606859, acc: 0.750000\n",
            "steps: 200\n",
            "save_steps: 1250\n",
            "20220510 16:48:05 current learning_rate:0.00000398\n",
            "used_time: 0.1899869441986084\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 210, loss: 0.684531, acc: 0.500000\n",
            "steps: 210\n",
            "save_steps: 1250\n",
            "20220510 16:48:07 current learning_rate:0.00000418\n",
            "used_time: 0.21191668510437012\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 220, loss: 0.603395, acc: 0.750000\n",
            "steps: 220\n",
            "save_steps: 1250\n",
            "20220510 16:48:09 current learning_rate:0.00000438\n",
            "used_time: 0.17682576179504395\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 230, loss: 0.612372, acc: 0.500000\n",
            "steps: 230\n",
            "save_steps: 1250\n",
            "20220510 16:48:11 current learning_rate:0.00000458\n",
            "used_time: 0.2161705493927002\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 240, loss: 0.459277, acc: 1.000000\n",
            "steps: 240\n",
            "save_steps: 1250\n",
            "20220510 16:48:13 current learning_rate:0.00000478\n",
            "used_time: 0.17748069763183594\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 250, loss: 0.562125, acc: 0.625000\n",
            "steps: 250\n",
            "save_steps: 1250\n",
            "20220510 16:48:15 current learning_rate:0.00000498\n",
            "used_time: 0.21708154678344727\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 260, loss: 0.497326, acc: 0.875000\n",
            "steps: 260\n",
            "save_steps: 1250\n",
            "20220510 16:48:17 current learning_rate:0.00000518\n",
            "used_time: 0.2410898208618164\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 270, loss: 0.665067, acc: 0.625000\n",
            "steps: 270\n",
            "save_steps: 1250\n",
            "20220510 16:48:19 current learning_rate:0.00000538\n",
            "used_time: 0.21385693550109863\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 280, loss: 0.414725, acc: 0.750000\n",
            "steps: 280\n",
            "save_steps: 1250\n",
            "20220510 16:48:21 current learning_rate:0.00000558\n",
            "used_time: 0.1846141815185547\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 290, loss: 0.405107, acc: 0.875000\n",
            "steps: 290\n",
            "save_steps: 1250\n",
            "20220510 16:48:23 current learning_rate:0.00000578\n",
            "used_time: 0.20575380325317383\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 300, loss: 0.816349, acc: 0.625000\n",
            "steps: 300\n",
            "save_steps: 1250\n",
            "20220510 16:48:25 current learning_rate:0.00000598\n",
            "used_time: 0.18817758560180664\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 310, loss: 0.797287, acc: 0.250000\n",
            "steps: 310\n",
            "save_steps: 1250\n",
            "20220510 16:48:27 current learning_rate:0.00000618\n",
            "used_time: 0.2080230712890625\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 320, loss: 0.268772, acc: 0.875000\n",
            "steps: 320\n",
            "save_steps: 1250\n",
            "20220510 16:48:28 current learning_rate:0.00000638\n",
            "used_time: 0.19807124137878418\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 330, loss: 0.439782, acc: 0.750000\n",
            "steps: 330\n",
            "save_steps: 1250\n",
            "20220510 16:48:30 current learning_rate:0.00000658\n",
            "used_time: 0.2081453800201416\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 340, loss: 0.490512, acc: 0.625000\n",
            "steps: 340\n",
            "save_steps: 1250\n",
            "20220510 16:48:32 current learning_rate:0.00000678\n",
            "used_time: 0.20350360870361328\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 350, loss: 0.371677, acc: 0.625000\n",
            "steps: 350\n",
            "save_steps: 1250\n",
            "20220510 16:48:34 current learning_rate:0.00000698\n",
            "used_time: 0.1971902847290039\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 360, loss: 0.371071, acc: 0.750000\n",
            "steps: 360\n",
            "save_steps: 1250\n",
            "20220510 16:48:36 current learning_rate:0.00000718\n",
            "used_time: 0.1744823455810547\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 370, loss: 0.550465, acc: 0.500000\n",
            "steps: 370\n",
            "save_steps: 1250\n",
            "20220510 16:48:38 current learning_rate:0.00000738\n",
            "used_time: 0.19310235977172852\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 380, loss: 0.466722, acc: 0.750000\n",
            "steps: 380\n",
            "save_steps: 1250\n",
            "20220510 16:48:40 current learning_rate:0.00000758\n",
            "used_time: 0.20328426361083984\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 390, loss: 0.286998, acc: 0.750000\n",
            "steps: 390\n",
            "save_steps: 1250\n",
            "20220510 16:48:42 current learning_rate:0.00000778\n",
            "used_time: 0.17566633224487305\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 400, loss: 0.506848, acc: 0.625000\n",
            "steps: 400\n",
            "save_steps: 1250\n",
            "20220510 16:48:44 current learning_rate:0.00000798\n",
            "used_time: 0.19370555877685547\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 410, loss: 0.506933, acc: 0.750000\n",
            "steps: 410\n",
            "save_steps: 1250\n",
            "20220510 16:48:46 current learning_rate:0.00000818\n",
            "used_time: 0.1739485263824463\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 420, loss: 0.353105, acc: 0.625000\n",
            "steps: 420\n",
            "save_steps: 1250\n",
            "20220510 16:48:48 current learning_rate:0.00000838\n",
            "used_time: 0.17221355438232422\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 430, loss: 0.876172, acc: 0.500000\n",
            "steps: 430\n",
            "save_steps: 1250\n",
            "20220510 16:48:50 current learning_rate:0.00000858\n",
            "used_time: 0.2029285430908203\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 440, loss: 0.414608, acc: 0.500000\n",
            "steps: 440\n",
            "save_steps: 1250\n",
            "20220510 16:48:52 current learning_rate:0.00000878\n",
            "used_time: 0.20610547065734863\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 450, loss: 0.432602, acc: 0.625000\n",
            "steps: 450\n",
            "save_steps: 1250\n",
            "20220510 16:48:54 current learning_rate:0.00000898\n",
            "used_time: 0.18201851844787598\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 460, loss: 0.411352, acc: 0.875000\n",
            "steps: 460\n",
            "save_steps: 1250\n",
            "20220510 16:48:56 current learning_rate:0.00000918\n",
            "used_time: 0.16476058959960938\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 470, loss: 0.463620, acc: 0.500000\n",
            "steps: 470\n",
            "save_steps: 1250\n",
            "20220510 16:48:57 current learning_rate:0.00000938\n",
            "used_time: 0.19410085678100586\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 480, loss: 0.710175, acc: 0.750000\n",
            "steps: 480\n",
            "save_steps: 1250\n",
            "20220510 16:48:59 current learning_rate:0.00000958\n",
            "used_time: 0.21152877807617188\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 490, loss: 0.393129, acc: 0.750000\n",
            "steps: 490\n",
            "save_steps: 1250\n",
            "20220510 16:49:01 current learning_rate:0.00000978\n",
            "used_time: 0.19412851333618164\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 500, loss: 0.633641, acc: 0.625000\n",
            "steps: 500\n",
            "save_steps: 1250\n",
            "Train-RCAC 0.696969696969697\n",
            "20220510 16:49:03 current learning_rate:0.00000998\n",
            "used_time: 0.19548702239990234\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 510, loss: 0.498538, acc: 0.750000\n",
            "steps: 510\n",
            "save_steps: 1250\n",
            "20220510 16:49:05 current learning_rate:0.00001000\n",
            "used_time: 0.252439022064209\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 520, loss: 0.452788, acc: 0.375000\n",
            "steps: 520\n",
            "save_steps: 1250\n",
            "20220510 16:49:07 current learning_rate:0.00001000\n",
            "used_time: 0.20772147178649902\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 530, loss: 0.566717, acc: 0.750000\n",
            "steps: 530\n",
            "save_steps: 1250\n",
            "20220510 16:49:09 current learning_rate:0.00001000\n",
            "used_time: 0.19236302375793457\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 540, loss: 0.593390, acc: 0.625000\n",
            "steps: 540\n",
            "save_steps: 1250\n",
            "20220510 16:49:11 current learning_rate:0.00001000\n",
            "used_time: 0.2101285457611084\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 550, loss: 0.642591, acc: 0.625000\n",
            "steps: 550\n",
            "save_steps: 1250\n",
            "20220510 16:49:13 current learning_rate:0.00001000\n",
            "used_time: 0.17699503898620605\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 560, loss: 0.633923, acc: 0.750000\n",
            "steps: 560\n",
            "save_steps: 1250\n",
            "20220510 16:49:15 current learning_rate:0.00001000\n",
            "used_time: 0.18451333045959473\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 570, loss: 0.393060, acc: 0.625000\n",
            "steps: 570\n",
            "save_steps: 1250\n",
            "20220510 16:49:17 current learning_rate:0.00001000\n",
            "used_time: 0.2137298583984375\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 580, loss: 0.496588, acc: 0.375000\n",
            "steps: 580\n",
            "save_steps: 1250\n",
            "20220510 16:49:19 current learning_rate:0.00001000\n",
            "used_time: 0.19008278846740723\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 590, loss: 0.481174, acc: 0.625000\n",
            "steps: 590\n",
            "save_steps: 1250\n",
            "20220510 16:49:21 current learning_rate:0.00001000\n",
            "used_time: 0.17075109481811523\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 600, loss: 0.504653, acc: 0.875000\n",
            "steps: 600\n",
            "save_steps: 1250\n",
            "20220510 16:49:23 current learning_rate:0.00001000\n",
            "used_time: 0.20189237594604492\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 610, loss: 0.474804, acc: 0.750000\n",
            "steps: 610\n",
            "save_steps: 1250\n",
            "20220510 16:49:25 current learning_rate:0.00001000\n",
            "used_time: 0.19002842903137207\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 620, loss: 0.442353, acc: 0.750000\n",
            "steps: 620\n",
            "save_steps: 1250\n",
            "20220510 16:49:27 current learning_rate:0.00001000\n",
            "used_time: 0.1882762908935547\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 630, loss: 0.443147, acc: 0.625000\n",
            "steps: 630\n",
            "save_steps: 1250\n",
            "20220510 16:49:29 current learning_rate:0.00001000\n",
            "used_time: 0.19442462921142578\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 640, loss: 0.580915, acc: 0.625000\n",
            "steps: 640\n",
            "save_steps: 1250\n",
            "20220510 16:49:30 current learning_rate:0.00001000\n",
            "used_time: 0.17152786254882812\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 650, loss: 0.481534, acc: 0.375000\n",
            "steps: 650\n",
            "save_steps: 1250\n",
            "20220510 16:49:32 current learning_rate:0.00001000\n",
            "used_time: 0.21848392486572266\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 660, loss: 0.290813, acc: 0.750000\n",
            "steps: 660\n",
            "save_steps: 1250\n",
            "20220510 16:49:34 current learning_rate:0.00001000\n",
            "used_time: 0.17119550704956055\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 670, loss: 0.690585, acc: 0.500000\n",
            "steps: 670\n",
            "save_steps: 1250\n",
            "20220510 16:49:36 current learning_rate:0.00001000\n",
            "used_time: 0.1834712028503418\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 680, loss: 1.029840, acc: 0.500000\n",
            "steps: 680\n",
            "save_steps: 1250\n",
            "20220510 16:49:38 current learning_rate:0.00001000\n",
            "used_time: 0.196868896484375\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 690, loss: 0.531940, acc: 0.375000\n",
            "steps: 690\n",
            "save_steps: 1250\n",
            "20220510 16:49:40 current learning_rate:0.00001000\n",
            "used_time: 0.19991493225097656\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 700, loss: 0.201518, acc: 1.000000\n",
            "steps: 700\n",
            "save_steps: 1250\n",
            "20220510 16:49:42 current learning_rate:0.00001000\n",
            "used_time: 0.16954588890075684\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 710, loss: 0.256365, acc: 0.750000\n",
            "steps: 710\n",
            "save_steps: 1250\n",
            "20220510 16:49:44 current learning_rate:0.00001000\n",
            "used_time: 0.18894553184509277\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 720, loss: 0.369689, acc: 0.625000\n",
            "steps: 720\n",
            "save_steps: 1250\n",
            "20220510 16:49:46 current learning_rate:0.00001000\n",
            "used_time: 0.18603801727294922\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 730, loss: 0.300714, acc: 0.375000\n",
            "steps: 730\n",
            "save_steps: 1250\n",
            "20220510 16:49:48 current learning_rate:0.00001000\n",
            "used_time: 0.24392223358154297\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 740, loss: 0.424589, acc: 0.875000\n",
            "steps: 740\n",
            "save_steps: 1250\n",
            "20220510 16:49:50 current learning_rate:0.00001000\n",
            "used_time: 0.18607473373413086\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 750, loss: 0.820429, acc: 0.375000\n",
            "steps: 750\n",
            "save_steps: 1250\n",
            "20220510 16:49:52 current learning_rate:0.00001000\n",
            "used_time: 0.21474838256835938\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 760, loss: 0.841763, acc: 0.625000\n",
            "steps: 760\n",
            "save_steps: 1250\n",
            "20220510 16:49:54 current learning_rate:0.00001000\n",
            "used_time: 0.1875596046447754\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 770, loss: 0.157630, acc: 0.750000\n",
            "steps: 770\n",
            "save_steps: 1250\n",
            "20220510 16:49:55 current learning_rate:0.00001000\n",
            "used_time: 0.2023622989654541\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 780, loss: 0.582750, acc: 0.875000\n",
            "steps: 780\n",
            "save_steps: 1250\n",
            "20220510 16:49:57 current learning_rate:0.00001000\n",
            "used_time: 0.18846416473388672\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 790, loss: 0.662587, acc: 0.750000\n",
            "steps: 790\n",
            "save_steps: 1250\n",
            "20220510 16:49:59 current learning_rate:0.00001000\n",
            "used_time: 0.17784619331359863\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 800, loss: 0.335076, acc: 0.625000\n",
            "steps: 800\n",
            "save_steps: 1250\n",
            "20220510 16:50:01 current learning_rate:0.00001000\n",
            "used_time: 0.16610193252563477\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 810, loss: 0.813700, acc: 0.625000\n",
            "steps: 810\n",
            "save_steps: 1250\n",
            "20220510 16:50:03 current learning_rate:0.00001000\n",
            "used_time: 0.20896387100219727\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 820, loss: 0.789098, acc: 0.875000\n",
            "steps: 820\n",
            "save_steps: 1250\n",
            "20220510 16:50:05 current learning_rate:0.00001000\n",
            "used_time: 0.17869019508361816\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 830, loss: 0.586888, acc: 0.750000\n",
            "steps: 830\n",
            "save_steps: 1250\n",
            "20220510 16:50:07 current learning_rate:0.00001000\n",
            "used_time: 0.1700146198272705\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 840, loss: 0.345681, acc: 0.625000\n",
            "steps: 840\n",
            "save_steps: 1250\n",
            "20220510 16:50:09 current learning_rate:0.00001000\n",
            "used_time: 0.1937870979309082\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 850, loss: 0.526561, acc: 0.250000\n",
            "steps: 850\n",
            "save_steps: 1250\n",
            "20220510 16:50:11 current learning_rate:0.00001000\n",
            "used_time: 0.2170581817626953\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 860, loss: 0.572331, acc: 0.375000\n",
            "steps: 860\n",
            "save_steps: 1250\n",
            "20220510 16:50:13 current learning_rate:0.00001000\n",
            "used_time: 0.1737196445465088\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 870, loss: 0.632863, acc: 0.625000\n",
            "steps: 870\n",
            "save_steps: 1250\n",
            "20220510 16:50:15 current learning_rate:0.00001000\n",
            "used_time: 0.16919755935668945\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 880, loss: 0.531835, acc: 0.625000\n",
            "steps: 880\n",
            "save_steps: 1250\n",
            "20220510 16:50:17 current learning_rate:0.00001000\n",
            "used_time: 0.1735248565673828\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 890, loss: 0.443480, acc: 0.625000\n",
            "steps: 890\n",
            "save_steps: 1250\n",
            "20220510 16:50:18 current learning_rate:0.00001000\n",
            "used_time: 0.18974065780639648\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 900, loss: 0.480714, acc: 0.750000\n",
            "steps: 900\n",
            "save_steps: 1250\n",
            "20220510 16:50:20 current learning_rate:0.00001000\n",
            "used_time: 0.16847848892211914\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 910, loss: 0.565338, acc: 0.750000\n",
            "steps: 910\n",
            "save_steps: 1250\n",
            "20220510 16:50:22 current learning_rate:0.00001000\n",
            "used_time: 0.22099661827087402\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 920, loss: 0.361801, acc: 0.750000\n",
            "steps: 920\n",
            "save_steps: 1250\n",
            "20220510 16:50:24 current learning_rate:0.00001000\n",
            "used_time: 0.1798839569091797\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 930, loss: 0.589615, acc: 0.750000\n",
            "steps: 930\n",
            "save_steps: 1250\n",
            "20220510 16:50:26 current learning_rate:0.00001000\n",
            "used_time: 0.20445680618286133\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 940, loss: 0.080195, acc: 1.000000\n",
            "steps: 940\n",
            "save_steps: 1250\n",
            "20220510 16:50:28 current learning_rate:0.00001000\n",
            "used_time: 0.1888725757598877\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 950, loss: 0.373001, acc: 0.625000\n",
            "steps: 950\n",
            "save_steps: 1250\n",
            "20220510 16:50:30 current learning_rate:0.00001000\n",
            "used_time: 0.2158675193786621\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 960, loss: 0.654598, acc: 0.875000\n",
            "steps: 960\n",
            "save_steps: 1250\n",
            "20220510 16:50:32 current learning_rate:0.00001000\n",
            "used_time: 0.19928908348083496\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 970, loss: 0.154462, acc: 0.625000\n",
            "steps: 970\n",
            "save_steps: 1250\n",
            "20220510 16:50:34 current learning_rate:0.00001000\n",
            "used_time: 0.2124156951904297\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 980, loss: 0.699819, acc: 0.500000\n",
            "steps: 980\n",
            "save_steps: 1250\n",
            "20220510 16:50:36 current learning_rate:0.00001000\n",
            "used_time: 0.21383357048034668\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 990, loss: 0.430112, acc: 0.375000\n",
            "steps: 990\n",
            "save_steps: 1250\n",
            "20220510 16:50:38 current learning_rate:0.00001000\n",
            "used_time: 0.2890157699584961\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1000, loss: 0.576157, acc: 0.500000\n",
            "steps: 1000\n",
            "save_steps: 1250\n",
            "Train-RCAC 0.9104761904761904\n",
            "20220510 16:50:40 current learning_rate:0.00001000\n",
            "used_time: 0.19243621826171875\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1010, loss: 0.307633, acc: 0.625000\n",
            "steps: 1010\n",
            "save_steps: 1250\n",
            "20220510 16:50:42 current learning_rate:0.00001000\n",
            "used_time: 0.2239987850189209\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1020, loss: 0.428594, acc: 0.875000\n",
            "steps: 1020\n",
            "save_steps: 1250\n",
            "20220510 16:50:44 current learning_rate:0.00001000\n",
            "used_time: 0.1635589599609375\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1030, loss: 0.569175, acc: 0.375000\n",
            "steps: 1030\n",
            "save_steps: 1250\n",
            "20220510 16:50:45 current learning_rate:0.00001000\n",
            "used_time: 0.19941377639770508\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1040, loss: 0.639484, acc: 0.625000\n",
            "steps: 1040\n",
            "save_steps: 1250\n",
            "20220510 16:50:47 current learning_rate:0.00001000\n",
            "used_time: 0.17911648750305176\n",
            "shuffle epoch 1\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1050, loss: 0.634396, acc: 0.750000\n",
            "steps: 1050\n",
            "save_steps: 1250\n",
            "20220510 16:50:49 current learning_rate:0.00001000\n",
            "used_time: 0.21608281135559082\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1060, loss: 0.720560, acc: 0.500000\n",
            "steps: 1060\n",
            "save_steps: 1250\n",
            "20220510 16:50:51 current learning_rate:0.00001000\n",
            "used_time: 0.21044707298278809\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1070, loss: 0.766944, acc: 0.625000\n",
            "steps: 1070\n",
            "save_steps: 1250\n",
            "20220510 16:50:53 current learning_rate:0.00001000\n",
            "used_time: 0.20680522918701172\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1080, loss: 0.660015, acc: 0.250000\n",
            "steps: 1080\n",
            "save_steps: 1250\n",
            "20220510 16:50:55 current learning_rate:0.00001000\n",
            "used_time: 0.17470216751098633\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1090, loss: 0.275730, acc: 0.750000\n",
            "steps: 1090\n",
            "save_steps: 1250\n",
            "20220510 16:50:57 current learning_rate:0.00001000\n",
            "used_time: 0.1868574619293213\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1100, loss: 0.272792, acc: 0.625000\n",
            "steps: 1100\n",
            "save_steps: 1250\n",
            "20220510 16:50:59 current learning_rate:0.00001000\n",
            "used_time: 0.21176624298095703\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1110, loss: 0.143782, acc: 0.500000\n",
            "steps: 1110\n",
            "save_steps: 1250\n",
            "20220510 16:51:01 current learning_rate:0.00001000\n",
            "used_time: 0.19233012199401855\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1120, loss: 0.143585, acc: 0.625000\n",
            "steps: 1120\n",
            "save_steps: 1250\n",
            "20220510 16:51:03 current learning_rate:0.00001000\n",
            "used_time: 0.26490211486816406\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1130, loss: 0.116913, acc: 0.875000\n",
            "steps: 1130\n",
            "save_steps: 1250\n",
            "20220510 16:51:05 current learning_rate:0.00001000\n",
            "used_time: 0.201338529586792\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1140, loss: 0.483352, acc: 0.750000\n",
            "steps: 1140\n",
            "save_steps: 1250\n",
            "20220510 16:51:07 current learning_rate:0.00001000\n",
            "used_time: 0.22765874862670898\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1150, loss: 0.278302, acc: 0.750000\n",
            "steps: 1150\n",
            "save_steps: 1250\n",
            "20220510 16:51:09 current learning_rate:0.00001000\n",
            "used_time: 0.17456316947937012\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1160, loss: 0.167364, acc: 1.000000\n",
            "steps: 1160\n",
            "save_steps: 1250\n",
            "20220510 16:51:11 current learning_rate:0.00001000\n",
            "used_time: 0.2070317268371582\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1170, loss: 0.144775, acc: 0.875000\n",
            "steps: 1170\n",
            "save_steps: 1250\n",
            "20220510 16:51:13 current learning_rate:0.00001000\n",
            "used_time: 0.21517467498779297\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1180, loss: 0.337436, acc: 0.500000\n",
            "steps: 1180\n",
            "save_steps: 1250\n",
            "20220510 16:51:15 current learning_rate:0.00001000\n",
            "used_time: 0.2139432430267334\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1190, loss: 0.193537, acc: 0.375000\n",
            "steps: 1190\n",
            "save_steps: 1250\n",
            "20220510 16:51:17 current learning_rate:0.00001000\n",
            "used_time: 0.1747729778289795\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1200, loss: 0.401792, acc: 0.375000\n",
            "steps: 1200\n",
            "save_steps: 1250\n",
            "20220510 16:51:19 current learning_rate:0.00001000\n",
            "used_time: 0.1873633861541748\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1210, loss: 0.226123, acc: 0.500000\n",
            "steps: 1210\n",
            "save_steps: 1250\n",
            "20220510 16:51:20 current learning_rate:0.00001000\n",
            "used_time: 0.21869397163391113\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1220, loss: 0.435763, acc: 0.750000\n",
            "steps: 1220\n",
            "save_steps: 1250\n",
            "20220510 16:51:22 current learning_rate:0.00001000\n",
            "used_time: 0.1871950626373291\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1230, loss: 0.081263, acc: 1.000000\n",
            "steps: 1230\n",
            "save_steps: 1250\n",
            "20220510 16:51:24 current learning_rate:0.00001000\n",
            "used_time: 0.17642974853515625\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1240, loss: 0.696976, acc: 0.750000\n",
            "steps: 1240\n",
            "save_steps: 1250\n",
            "20220510 16:51:26 current learning_rate:0.00001000\n",
            "used_time: 0.17667078971862793\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1250, loss: 0.105421, acc: 0.500000\n",
            "steps: 1250\n",
            "save_steps: 1250\n",
            "20220510 16:51:28 current learning_rate:0.00001000\n",
            "save_path: output_hm/step_1250train\n",
            "used_time: 11.912997007369995\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1260, loss: 0.426584, acc: 0.875000\n",
            "steps: 1260\n",
            "save_steps: 1250\n",
            "20220510 16:51:42 current learning_rate:0.00001000\n",
            "used_time: 0.18900370597839355\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1270, loss: 0.177459, acc: 1.000000\n",
            "steps: 1270\n",
            "save_steps: 1250\n",
            "20220510 16:51:44 current learning_rate:0.00001000\n",
            "used_time: 0.20939397811889648\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1280, loss: 0.278266, acc: 0.500000\n",
            "steps: 1280\n",
            "save_steps: 1250\n",
            "20220510 16:51:46 current learning_rate:0.00001000\n",
            "used_time: 0.19019842147827148\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1290, loss: 0.096314, acc: 0.875000\n",
            "steps: 1290\n",
            "save_steps: 1250\n",
            "20220510 16:51:48 current learning_rate:0.00001000\n",
            "used_time: 0.1898353099822998\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1300, loss: 0.203588, acc: 0.625000\n",
            "steps: 1300\n",
            "save_steps: 1250\n",
            "20220510 16:51:50 current learning_rate:0.00001000\n",
            "used_time: 0.18500280380249023\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1310, loss: 0.919169, acc: 0.250000\n",
            "steps: 1310\n",
            "save_steps: 1250\n",
            "20220510 16:51:51 current learning_rate:0.00001000\n",
            "used_time: 0.18825745582580566\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1320, loss: 0.346457, acc: 0.500000\n",
            "steps: 1320\n",
            "save_steps: 1250\n",
            "20220510 16:51:53 current learning_rate:0.00001000\n",
            "used_time: 0.19831395149230957\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1330, loss: 0.537889, acc: 0.875000\n",
            "steps: 1330\n",
            "save_steps: 1250\n",
            "20220510 16:51:55 current learning_rate:0.00001000\n",
            "used_time: 0.18376970291137695\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1340, loss: 0.088718, acc: 0.625000\n",
            "steps: 1340\n",
            "save_steps: 1250\n",
            "20220510 16:51:57 current learning_rate:0.00001000\n",
            "used_time: 0.17882323265075684\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1350, loss: 0.346780, acc: 0.750000\n",
            "steps: 1350\n",
            "save_steps: 1250\n",
            "20220510 16:51:59 current learning_rate:0.00001000\n",
            "used_time: 0.19510841369628906\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1360, loss: 0.412841, acc: 0.750000\n",
            "steps: 1360\n",
            "save_steps: 1250\n",
            "20220510 16:52:01 current learning_rate:0.00001000\n",
            "used_time: 0.20597100257873535\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1370, loss: 0.483951, acc: 0.500000\n",
            "steps: 1370\n",
            "save_steps: 1250\n",
            "20220510 16:52:03 current learning_rate:0.00001000\n",
            "used_time: 0.17742061614990234\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1380, loss: 0.264269, acc: 0.750000\n",
            "steps: 1380\n",
            "save_steps: 1250\n",
            "20220510 16:52:05 current learning_rate:0.00001000\n",
            "used_time: 0.20951271057128906\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1390, loss: 0.101702, acc: 0.750000\n",
            "steps: 1390\n",
            "save_steps: 1250\n",
            "20220510 16:52:07 current learning_rate:0.00001000\n",
            "used_time: 0.1869668960571289\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1400, loss: 0.811080, acc: 0.875000\n",
            "steps: 1400\n",
            "save_steps: 1250\n",
            "20220510 16:52:09 current learning_rate:0.00001000\n",
            "used_time: 0.23075270652770996\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1410, loss: 0.207138, acc: 0.375000\n",
            "steps: 1410\n",
            "save_steps: 1250\n",
            "20220510 16:52:11 current learning_rate:0.00001000\n",
            "used_time: 0.20093059539794922\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1420, loss: 0.424343, acc: 0.875000\n",
            "steps: 1420\n",
            "save_steps: 1250\n",
            "20220510 16:52:13 current learning_rate:0.00001000\n",
            "used_time: 0.17735576629638672\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1430, loss: 0.061267, acc: 0.750000\n",
            "steps: 1430\n",
            "save_steps: 1250\n",
            "20220510 16:52:15 current learning_rate:0.00001000\n",
            "used_time: 0.17846155166625977\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1440, loss: 0.786396, acc: 0.500000\n",
            "steps: 1440\n",
            "save_steps: 1250\n",
            "20220510 16:52:17 current learning_rate:0.00001000\n",
            "used_time: 0.20525503158569336\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1450, loss: 0.250653, acc: 0.375000\n",
            "steps: 1450\n",
            "save_steps: 1250\n",
            "20220510 16:52:19 current learning_rate:0.00001000\n",
            "used_time: 0.19887518882751465\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1460, loss: 0.122546, acc: 0.750000\n",
            "steps: 1460\n",
            "save_steps: 1250\n",
            "20220510 16:52:21 current learning_rate:0.00001000\n",
            "used_time: 0.17436599731445312\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1470, loss: 0.061553, acc: 0.500000\n",
            "steps: 1470\n",
            "save_steps: 1250\n",
            "20220510 16:52:23 current learning_rate:0.00001000\n",
            "used_time: 0.18928956985473633\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1480, loss: 0.206811, acc: 0.625000\n",
            "steps: 1480\n",
            "save_steps: 1250\n",
            "20220510 16:52:24 current learning_rate:0.00001000\n",
            "used_time: 0.18794798851013184\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1490, loss: 0.753969, acc: 0.500000\n",
            "steps: 1490\n",
            "save_steps: 1250\n",
            "20220510 16:52:26 current learning_rate:0.00001000\n",
            "used_time: 0.22872424125671387\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1500, loss: 0.015010, acc: 0.875000\n",
            "steps: 1500\n",
            "save_steps: 1250\n",
            "Train-RCAC 0.9473684210526316\n",
            "20220510 16:52:28 current learning_rate:0.00001000\n",
            "used_time: 0.1862020492553711\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1510, loss: 0.583068, acc: 0.625000\n",
            "steps: 1510\n",
            "save_steps: 1250\n",
            "20220510 16:52:30 current learning_rate:0.00001000\n",
            "used_time: 0.1971275806427002\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1520, loss: 0.113999, acc: 0.500000\n",
            "steps: 1520\n",
            "save_steps: 1250\n",
            "20220510 16:52:32 current learning_rate:0.00001000\n",
            "used_time: 0.20338034629821777\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1530, loss: 0.240950, acc: 0.625000\n",
            "steps: 1530\n",
            "save_steps: 1250\n",
            "20220510 16:52:34 current learning_rate:0.00001000\n",
            "used_time: 0.24014973640441895\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1540, loss: 0.209398, acc: 0.500000\n",
            "steps: 1540\n",
            "save_steps: 1250\n",
            "20220510 16:52:36 current learning_rate:0.00001000\n",
            "used_time: 0.18694853782653809\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1550, loss: 0.536770, acc: 0.625000\n",
            "steps: 1550\n",
            "save_steps: 1250\n",
            "20220510 16:52:38 current learning_rate:0.00001000\n",
            "used_time: 0.17091774940490723\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1560, loss: 0.563623, acc: 0.750000\n",
            "steps: 1560\n",
            "save_steps: 1250\n",
            "20220510 16:52:40 current learning_rate:0.00001000\n",
            "used_time: 0.20293807983398438\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1570, loss: 0.355830, acc: 0.625000\n",
            "steps: 1570\n",
            "save_steps: 1250\n",
            "20220510 16:52:42 current learning_rate:0.00001000\n",
            "used_time: 0.22507262229919434\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1580, loss: 0.140923, acc: 0.750000\n",
            "steps: 1580\n",
            "save_steps: 1250\n",
            "20220510 16:52:44 current learning_rate:0.00001000\n",
            "used_time: 0.19786596298217773\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1590, loss: 0.054521, acc: 0.750000\n",
            "steps: 1590\n",
            "save_steps: 1250\n",
            "20220510 16:52:46 current learning_rate:0.00001000\n",
            "used_time: 0.21576905250549316\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1600, loss: 0.847488, acc: 0.500000\n",
            "steps: 1600\n",
            "save_steps: 1250\n",
            "20220510 16:52:48 current learning_rate:0.00001000\n",
            "used_time: 0.24892902374267578\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1610, loss: 0.452231, acc: 0.625000\n",
            "steps: 1610\n",
            "save_steps: 1250\n",
            "20220510 16:52:50 current learning_rate:0.00001000\n",
            "used_time: 0.19564604759216309\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1620, loss: 0.799446, acc: 0.625000\n",
            "steps: 1620\n",
            "save_steps: 1250\n",
            "20220510 16:52:52 current learning_rate:0.00001000\n",
            "used_time: 0.17407512664794922\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1630, loss: 0.105594, acc: 0.625000\n",
            "steps: 1630\n",
            "save_steps: 1250\n",
            "20220510 16:52:54 current learning_rate:0.00001000\n",
            "used_time: 0.19443750381469727\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1640, loss: 0.150352, acc: 0.875000\n",
            "steps: 1640\n",
            "save_steps: 1250\n",
            "20220510 16:52:56 current learning_rate:0.00001000\n",
            "used_time: 0.18797039985656738\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1650, loss: 0.158955, acc: 0.500000\n",
            "steps: 1650\n",
            "save_steps: 1250\n",
            "20220510 16:52:58 current learning_rate:0.00001000\n",
            "used_time: 0.23615360260009766\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1660, loss: 0.951724, acc: 0.375000\n",
            "steps: 1660\n",
            "save_steps: 1250\n",
            "20220510 16:53:00 current learning_rate:0.00001000\n",
            "used_time: 0.16464018821716309\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1670, loss: 0.325295, acc: 0.625000\n",
            "steps: 1670\n",
            "save_steps: 1250\n",
            "20220510 16:53:02 current learning_rate:0.00001000\n",
            "used_time: 0.18780899047851562\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1680, loss: 0.573599, acc: 0.500000\n",
            "steps: 1680\n",
            "save_steps: 1250\n",
            "20220510 16:53:03 current learning_rate:0.00001000\n",
            "used_time: 0.19555091857910156\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1690, loss: 0.349101, acc: 0.625000\n",
            "steps: 1690\n",
            "save_steps: 1250\n",
            "20220510 16:53:05 current learning_rate:0.00001000\n",
            "used_time: 0.20649933815002441\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1700, loss: 0.138217, acc: 0.500000\n",
            "steps: 1700\n",
            "save_steps: 1250\n",
            "20220510 16:53:07 current learning_rate:0.00001000\n",
            "used_time: 0.19797015190124512\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1710, loss: 0.559949, acc: 0.250000\n",
            "steps: 1710\n",
            "save_steps: 1250\n",
            "20220510 16:53:09 current learning_rate:0.00001000\n",
            "used_time: 0.20852279663085938\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1720, loss: 0.675926, acc: 0.250000\n",
            "steps: 1720\n",
            "save_steps: 1250\n",
            "20220510 16:53:11 current learning_rate:0.00001000\n",
            "used_time: 0.19456052780151367\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1730, loss: 0.312676, acc: 0.625000\n",
            "steps: 1730\n",
            "save_steps: 1250\n",
            "20220510 16:53:13 current learning_rate:0.00001000\n",
            "used_time: 0.19225478172302246\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1740, loss: 0.136735, acc: 0.625000\n",
            "steps: 1740\n",
            "save_steps: 1250\n",
            "20220510 16:53:15 current learning_rate:0.00001000\n",
            "used_time: 0.20140695571899414\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1750, loss: 0.223836, acc: 0.625000\n",
            "steps: 1750\n",
            "save_steps: 1250\n",
            "20220510 16:53:17 current learning_rate:0.00001000\n",
            "used_time: 0.20250225067138672\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1760, loss: 0.283982, acc: 0.500000\n",
            "steps: 1760\n",
            "save_steps: 1250\n",
            "20220510 16:53:19 current learning_rate:0.00001000\n",
            "used_time: 0.20332860946655273\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1770, loss: 0.473793, acc: 0.375000\n",
            "steps: 1770\n",
            "save_steps: 1250\n",
            "20220510 16:53:21 current learning_rate:0.00001000\n",
            "used_time: 0.2192072868347168\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1780, loss: 0.826418, acc: 0.625000\n",
            "steps: 1780\n",
            "save_steps: 1250\n",
            "20220510 16:53:23 current learning_rate:0.00001000\n",
            "used_time: 0.17580723762512207\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1790, loss: 0.315341, acc: 0.625000\n",
            "steps: 1790\n",
            "save_steps: 1250\n",
            "20220510 16:53:24 current learning_rate:0.00001000\n",
            "used_time: 0.18785881996154785\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1800, loss: 0.670179, acc: 0.625000\n",
            "steps: 1800\n",
            "save_steps: 1250\n",
            "20220510 16:53:26 current learning_rate:0.00001000\n",
            "used_time: 0.19519281387329102\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1810, loss: 0.221589, acc: 0.750000\n",
            "steps: 1810\n",
            "save_steps: 1250\n",
            "20220510 16:53:28 current learning_rate:0.00001000\n",
            "used_time: 0.1899876594543457\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1820, loss: 0.342357, acc: 0.625000\n",
            "steps: 1820\n",
            "save_steps: 1250\n",
            "20220510 16:53:30 current learning_rate:0.00001000\n",
            "used_time: 0.17767667770385742\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1830, loss: 0.181921, acc: 0.875000\n",
            "steps: 1830\n",
            "save_steps: 1250\n",
            "20220510 16:53:32 current learning_rate:0.00001000\n",
            "used_time: 0.18160033226013184\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1840, loss: 0.370680, acc: 0.625000\n",
            "steps: 1840\n",
            "save_steps: 1250\n",
            "20220510 16:53:34 current learning_rate:0.00001000\n",
            "used_time: 0.18506813049316406\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1850, loss: 0.130486, acc: 0.625000\n",
            "steps: 1850\n",
            "save_steps: 1250\n",
            "20220510 16:53:36 current learning_rate:0.00001000\n",
            "used_time: 0.21256494522094727\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1860, loss: 0.613126, acc: 0.375000\n",
            "steps: 1860\n",
            "save_steps: 1250\n",
            "20220510 16:53:38 current learning_rate:0.00001000\n",
            "used_time: 0.2025761604309082\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1870, loss: 0.285462, acc: 0.625000\n",
            "steps: 1870\n",
            "save_steps: 1250\n",
            "20220510 16:53:40 current learning_rate:0.00001000\n",
            "used_time: 0.19257473945617676\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1880, loss: 0.137981, acc: 0.500000\n",
            "steps: 1880\n",
            "save_steps: 1250\n",
            "20220510 16:53:42 current learning_rate:0.00001000\n",
            "used_time: 0.18725347518920898\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1890, loss: 0.064998, acc: 0.375000\n",
            "steps: 1890\n",
            "save_steps: 1250\n",
            "20220510 16:53:44 current learning_rate:0.00001000\n",
            "used_time: 0.21582365036010742\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1900, loss: 0.192784, acc: 0.750000\n",
            "steps: 1900\n",
            "save_steps: 1250\n",
            "20220510 16:53:46 current learning_rate:0.00001000\n",
            "used_time: 0.1850132942199707\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1910, loss: 0.300656, acc: 0.625000\n",
            "steps: 1910\n",
            "save_steps: 1250\n",
            "20220510 16:53:48 current learning_rate:0.00001000\n",
            "used_time: 0.1711418628692627\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1920, loss: 0.651161, acc: 0.375000\n",
            "steps: 1920\n",
            "save_steps: 1250\n",
            "20220510 16:53:50 current learning_rate:0.00001000\n",
            "used_time: 0.19020676612854004\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1930, loss: 0.293901, acc: 0.375000\n",
            "steps: 1930\n",
            "save_steps: 1250\n",
            "20220510 16:53:52 current learning_rate:0.00001000\n",
            "used_time: 0.19490289688110352\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1940, loss: 0.519122, acc: 0.875000\n",
            "steps: 1940\n",
            "save_steps: 1250\n",
            "20220510 16:53:54 current learning_rate:0.00001000\n",
            "used_time: 0.16727280616760254\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1950, loss: 0.090480, acc: 0.875000\n",
            "steps: 1950\n",
            "save_steps: 1250\n",
            "20220510 16:53:55 current learning_rate:0.00001000\n",
            "used_time: 0.20596814155578613\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1960, loss: 0.065655, acc: 0.500000\n",
            "steps: 1960\n",
            "save_steps: 1250\n",
            "20220510 16:53:57 current learning_rate:0.00001000\n",
            "used_time: 0.18631362915039062\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1970, loss: 0.213678, acc: 0.625000\n",
            "steps: 1970\n",
            "save_steps: 1250\n",
            "20220510 16:53:59 current learning_rate:0.00001000\n",
            "used_time: 0.20581316947937012\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1980, loss: 0.306872, acc: 0.750000\n",
            "steps: 1980\n",
            "save_steps: 1250\n",
            "20220510 16:54:01 current learning_rate:0.00001000\n",
            "used_time: 0.19769692420959473\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 1990, loss: 0.119723, acc: 0.500000\n",
            "steps: 1990\n",
            "save_steps: 1250\n",
            "20220510 16:54:03 current learning_rate:0.00001000\n",
            "used_time: 0.17305350303649902\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 2000, loss: 0.214402, acc: 0.750000\n",
            "steps: 2000\n",
            "save_steps: 1250\n",
            "Train-RCAC 0.8676470588235294\n",
            "20220510 16:54:05 current learning_rate:0.00001000\n",
            "used_time: 0.17836213111877441\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 2010, loss: 0.678083, acc: 0.250000\n",
            "steps: 2010\n",
            "save_steps: 1250\n",
            "20220510 16:54:07 current learning_rate:0.00001000\n",
            "used_time: 0.21346664428710938\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 2020, loss: 0.340982, acc: 0.750000\n",
            "steps: 2020\n",
            "save_steps: 1250\n",
            "20220510 16:54:09 current learning_rate:0.00001000\n",
            "used_time: 0.19044017791748047\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 2030, loss: 0.046782, acc: 0.625000\n",
            "steps: 2030\n",
            "save_steps: 1250\n",
            "20220510 16:54:11 current learning_rate:0.00001000\n",
            "used_time: 0.1944742202758789\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 2040, loss: 1.290361, acc: 0.375000\n",
            "steps: 2040\n",
            "save_steps: 1250\n",
            "20220510 16:54:13 current learning_rate:0.00001000\n",
            "used_time: 0.176896333694458\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 2050, loss: 0.109009, acc: 0.625000\n",
            "steps: 2050\n",
            "save_steps: 1250\n",
            "20220510 16:54:15 current learning_rate:0.00001000\n",
            "used_time: 0.1968221664428711\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 2060, loss: 0.514474, acc: 0.750000\n",
            "steps: 2060\n",
            "save_steps: 1250\n",
            "20220510 16:54:17 current learning_rate:0.00001000\n",
            "used_time: 0.2068023681640625\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 2070, loss: 0.192072, acc: 1.000000\n",
            "steps: 2070\n",
            "save_steps: 1250\n",
            "20220510 16:54:19 current learning_rate:0.00001000\n",
            "used_time: 0.16504907608032227\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 2080, loss: 0.453456, acc: 0.625000\n",
            "steps: 2080\n",
            "save_steps: 1250\n",
            "20220510 16:54:21 current learning_rate:0.00001000\n",
            "used_time: 0.17879581451416016\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 2090, loss: 0.510936, acc: 0.750000\n",
            "steps: 2090\n",
            "save_steps: 1250\n",
            "20220510 16:54:23 current learning_rate:0.00001000\n",
            "used_time: 0.21320819854736328\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 2100, loss: 0.132928, acc: 0.875000\n",
            "steps: 2100\n",
            "save_steps: 1250\n",
            "20220510 16:54:24 current learning_rate:0.00001000\n",
            "used_time: 0.15585851669311523\n",
            "feed_queue size 30\n",
            "epoch: 1, progress: 0/0, step: 2110, loss: 0.009349, acc: 0.625000\n",
            "steps: 2110\n",
            "save_steps: 1250\n",
            "20220510 16:54:26 current learning_rate:0.00001000\n",
            "used_time: 0.2293238639831543\n",
            "shuffle epoch 2\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2120, loss: 0.373758, acc: 0.500000\n",
            "steps: 2120\n",
            "save_steps: 1250\n",
            "20220510 16:54:28 current learning_rate:0.00001000\n",
            "used_time: 0.1781010627746582\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2130, loss: 0.010686, acc: 0.375000\n",
            "steps: 2130\n",
            "save_steps: 1250\n",
            "20220510 16:54:30 current learning_rate:0.00001000\n",
            "used_time: 0.22414565086364746\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2140, loss: 0.020577, acc: 0.500000\n",
            "steps: 2140\n",
            "save_steps: 1250\n",
            "20220510 16:54:32 current learning_rate:0.00001000\n",
            "used_time: 0.17917203903198242\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2150, loss: 0.240509, acc: 1.000000\n",
            "steps: 2150\n",
            "save_steps: 1250\n",
            "20220510 16:54:34 current learning_rate:0.00001000\n",
            "used_time: 0.1392686367034912\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2160, loss: 0.007704, acc: 1.000000\n",
            "steps: 2160\n",
            "save_steps: 1250\n",
            "20220510 16:54:36 current learning_rate:0.00001000\n",
            "used_time: 0.1952347755432129\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2170, loss: 0.069292, acc: 0.500000\n",
            "steps: 2170\n",
            "save_steps: 1250\n",
            "20220510 16:54:38 current learning_rate:0.00001000\n",
            "used_time: 0.19354557991027832\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2180, loss: 0.020176, acc: 0.625000\n",
            "steps: 2180\n",
            "save_steps: 1250\n",
            "20220510 16:54:40 current learning_rate:0.00001000\n",
            "used_time: 0.17832517623901367\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2190, loss: 0.186664, acc: 0.625000\n",
            "steps: 2190\n",
            "save_steps: 1250\n",
            "20220510 16:54:42 current learning_rate:0.00001000\n",
            "used_time: 0.18519115447998047\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2200, loss: 0.380849, acc: 0.500000\n",
            "steps: 2200\n",
            "save_steps: 1250\n",
            "20220510 16:54:44 current learning_rate:0.00001000\n",
            "used_time: 0.21783661842346191\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2210, loss: 0.008308, acc: 0.625000\n",
            "steps: 2210\n",
            "save_steps: 1250\n",
            "20220510 16:54:46 current learning_rate:0.00001000\n",
            "used_time: 0.18910551071166992\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2220, loss: 0.006062, acc: 0.625000\n",
            "steps: 2220\n",
            "save_steps: 1250\n",
            "20220510 16:54:47 current learning_rate:0.00001000\n",
            "used_time: 0.2115650177001953\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2230, loss: 0.003099, acc: 0.750000\n",
            "steps: 2230\n",
            "save_steps: 1250\n",
            "20220510 16:54:49 current learning_rate:0.00001000\n",
            "used_time: 0.19033241271972656\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2240, loss: 0.000791, acc: 0.750000\n",
            "steps: 2240\n",
            "save_steps: 1250\n",
            "20220510 16:54:51 current learning_rate:0.00001000\n",
            "used_time: 0.19721007347106934\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2250, loss: 0.211904, acc: 0.875000\n",
            "steps: 2250\n",
            "save_steps: 1250\n",
            "20220510 16:54:53 current learning_rate:0.00001000\n",
            "used_time: 0.18268036842346191\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2260, loss: 0.001770, acc: 1.000000\n",
            "steps: 2260\n",
            "save_steps: 1250\n",
            "20220510 16:54:55 current learning_rate:0.00001000\n",
            "used_time: 0.2193894386291504\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2270, loss: 0.075785, acc: 0.625000\n",
            "steps: 2270\n",
            "save_steps: 1250\n",
            "20220510 16:54:57 current learning_rate:0.00001000\n",
            "used_time: 0.21317243576049805\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2280, loss: 0.837660, acc: 0.500000\n",
            "steps: 2280\n",
            "save_steps: 1250\n",
            "20220510 16:54:59 current learning_rate:0.00001000\n",
            "used_time: 0.2042253017425537\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2290, loss: 0.001315, acc: 0.875000\n",
            "steps: 2290\n",
            "save_steps: 1250\n",
            "20220510 16:55:01 current learning_rate:0.00001000\n",
            "used_time: 0.19785499572753906\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2300, loss: 0.041696, acc: 0.500000\n",
            "steps: 2300\n",
            "save_steps: 1250\n",
            "20220510 16:55:03 current learning_rate:0.00001000\n",
            "used_time: 0.1886301040649414\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2310, loss: 0.007573, acc: 0.625000\n",
            "steps: 2310\n",
            "save_steps: 1250\n",
            "20220510 16:55:05 current learning_rate:0.00001000\n",
            "used_time: 0.28357386589050293\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2320, loss: 0.006275, acc: 0.750000\n",
            "steps: 2320\n",
            "save_steps: 1250\n",
            "20220510 16:55:07 current learning_rate:0.00001000\n",
            "used_time: 0.1935873031616211\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2330, loss: 0.001494, acc: 0.625000\n",
            "steps: 2330\n",
            "save_steps: 1250\n",
            "20220510 16:55:09 current learning_rate:0.00001000\n",
            "used_time: 0.18793272972106934\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2340, loss: 0.002956, acc: 0.625000\n",
            "steps: 2340\n",
            "save_steps: 1250\n",
            "20220510 16:55:11 current learning_rate:0.00001000\n",
            "used_time: 0.19800758361816406\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2350, loss: 0.322335, acc: 0.750000\n",
            "steps: 2350\n",
            "save_steps: 1250\n",
            "20220510 16:55:12 current learning_rate:0.00001000\n",
            "used_time: 0.19005680084228516\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2360, loss: 0.326181, acc: 0.375000\n",
            "steps: 2360\n",
            "save_steps: 1250\n",
            "20220510 16:55:14 current learning_rate:0.00001000\n",
            "used_time: 0.19982647895812988\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2370, loss: 0.001003, acc: 0.625000\n",
            "steps: 2370\n",
            "save_steps: 1250\n",
            "20220510 16:55:16 current learning_rate:0.00001000\n",
            "used_time: 0.19709420204162598\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2380, loss: 0.015802, acc: 0.875000\n",
            "steps: 2380\n",
            "save_steps: 1250\n",
            "20220510 16:55:18 current learning_rate:0.00001000\n",
            "used_time: 0.2056431770324707\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2390, loss: 0.221579, acc: 0.500000\n",
            "steps: 2390\n",
            "save_steps: 1250\n",
            "20220510 16:55:20 current learning_rate:0.00001000\n",
            "used_time: 0.20780014991760254\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2400, loss: 0.000493, acc: 0.625000\n",
            "steps: 2400\n",
            "save_steps: 1250\n",
            "20220510 16:55:22 current learning_rate:0.00001000\n",
            "used_time: 0.21256756782531738\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2410, loss: 0.001929, acc: 0.750000\n",
            "steps: 2410\n",
            "save_steps: 1250\n",
            "20220510 16:55:24 current learning_rate:0.00001000\n",
            "used_time: 0.22363972663879395\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2420, loss: 0.003833, acc: 0.500000\n",
            "steps: 2420\n",
            "save_steps: 1250\n",
            "20220510 16:55:26 current learning_rate:0.00001000\n",
            "used_time: 0.19649171829223633\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2430, loss: 0.029009, acc: 0.625000\n",
            "steps: 2430\n",
            "save_steps: 1250\n",
            "20220510 16:55:28 current learning_rate:0.00001000\n",
            "used_time: 0.17240452766418457\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2440, loss: 0.014565, acc: 0.875000\n",
            "steps: 2440\n",
            "save_steps: 1250\n",
            "20220510 16:55:30 current learning_rate:0.00001000\n",
            "used_time: 0.1920936107635498\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2450, loss: 0.005749, acc: 0.750000\n",
            "steps: 2450\n",
            "save_steps: 1250\n",
            "20220510 16:55:32 current learning_rate:0.00001000\n",
            "used_time: 0.19480299949645996\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2460, loss: 0.562916, acc: 0.625000\n",
            "steps: 2460\n",
            "save_steps: 1250\n",
            "20220510 16:55:34 current learning_rate:0.00001000\n",
            "used_time: 0.18360066413879395\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2470, loss: 0.008306, acc: 0.500000\n",
            "steps: 2470\n",
            "save_steps: 1250\n",
            "20220510 16:55:36 current learning_rate:0.00001000\n",
            "used_time: 0.1755073070526123\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2480, loss: 0.006417, acc: 0.875000\n",
            "steps: 2480\n",
            "save_steps: 1250\n",
            "20220510 16:55:38 current learning_rate:0.00001000\n",
            "used_time: 0.17455053329467773\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2490, loss: 0.017394, acc: 0.625000\n",
            "steps: 2490\n",
            "save_steps: 1250\n",
            "20220510 16:55:40 current learning_rate:0.00001000\n",
            "used_time: 0.2446606159210205\n",
            "feed_queue size 30\n",
            "epoch: 2, progress: 0/0, step: 2500, loss: 0.312985, acc: 0.750000\n",
            "steps: 2500\n",
            "save_steps: 1250\n",
            "Train-RCAC 0.9883449883449884\n",
            "20220510 16:55:42 current learning_rate:0.00001000\n",
            "save_path: output_hm/step_2500train\n",
            "used_time: 11.8459153175354\n",
            "############################WARNING################################### using init_pretraining_params, not init_checkpoint ###### meaning hyper param e.g. lr won't inherit from checkpoint#################################################################terminate called without an active exception\n",
            "W0510 16:55:54.669538  2131 init.cc:216] Warning: PaddlePaddle catches a failure signal, it may not work properly\n",
            "W0510 16:55:54.669576  2131 init.cc:218] You could check whether you killed PaddlePaddle thread/process accidentally or report the case to PaddlePaddle\n",
            "W0510 16:55:54.669584  2131 init.cc:221] The detail failure signal is:\n",
            "\n",
            "W0510 16:55:54.669593  2131 init.cc:224] *** Aborted at 1652201754 (unix time) try \"date -d @1652201754\" if you are using GNU date ***\n",
            "W0510 16:55:54.671566  2131 init.cc:224] PC: @                0x0 (unknown)\n",
            "W0510 16:55:54.674158  2131 init.cc:224] *** SIGABRT (@0x82d) received by PID 2093 (TID 0x7efe69bbf700) from PID 2093; stack trace: ***\n",
            "W0510 16:55:54.676617  2131 init.cc:224]     @     0x7f000df86f10 (unknown)\n",
            "W0510 16:55:54.678838  2131 init.cc:224]     @     0x7f000df86e87 gsignal\n",
            "W0510 16:55:54.684650  2131 init.cc:224]     @     0x7f000df887f1 abort\n",
            "W0510 16:55:54.686331  2131 init.cc:224]     @     0x7f000cc1d957 (unknown)\n",
            "W0510 16:55:54.688006  2131 init.cc:224]     @     0x7f000cc23ae6 (unknown)\n",
            "W0510 16:55:54.689512  2131 init.cc:224]     @     0x7f000cc23b21 std::terminate()\n",
            "W0510 16:55:54.691010  2131 init.cc:224]     @     0x7f000cc234ea __gxx_personality_v0\n",
            "W0510 16:55:54.692457  2131 init.cc:224]     @     0x7f000c763668 (unknown)\n",
            "W0510 16:55:54.693941  2131 init.cc:224]     @     0x7f000c763c5c _Unwind_ForcedUnwind\n",
            "W0510 16:55:54.695654  2131 init.cc:224]     @     0x7f000dd3a000 __GI___pthread_unwind\n",
            "W0510 16:55:54.697160  2131 init.cc:224]     @     0x7f000dd31ae5 __pthread_exit\n",
            "W0510 16:55:54.698709  2131 init.cc:224]     @     0x7f000e078364 pthread_exit\n",
            "W0510 16:55:54.698843  2131 init.cc:224]     @           0x5e37d8 PyThread_exit_thread\n",
            "W0510 16:55:54.699003  2131 init.cc:224]     @           0x47028a (unknown)\n",
            "W0510 16:55:54.703941  2131 init.cc:224]     @     0x7effbad2c019 pybind11::gil_scoped_release::~gil_scoped_release()\n",
            "W0510 16:55:54.705117  2131 init.cc:224]     @     0x7effbae143b6 _ZZN8pybind1112cpp_function10initializeIZN6paddle6pybind10BindReaderEPNS_6moduleEEUlRNS2_9operators6reader22LoDTensorBlockingQueueERKSt6vectorINS2_9framework9LoDTensorESaISC_EEE1_bIS9_SG_EINS_4nameENS_9is_methodENS_7siblingENS_10call_guardIINS_18gil_scoped_releaseEEEEEEEvOT_PFT0_DpT1_EDpRKT2_ENUlRNS_6detail13function_callEE1_4_FUNES11_\n",
            "W0510 16:55:54.707940  2131 init.cc:224]     @     0x7effbad49829 pybind11::cpp_function::dispatcher()\n",
            "W0510 16:55:54.708101  2131 init.cc:224]     @           0x593784 _PyMethodDef_RawFastCallKeywords\n",
            "W0510 16:55:54.708200  2131 init.cc:224]     @           0x594731 _PyObject_FastCallKeywords\n",
            "W0510 16:55:54.708328  2131 init.cc:224]     @           0x548cc1 (unknown)\n",
            "W0510 16:55:54.708393  2131 init.cc:224]     @           0x51566f _PyEval_EvalFrameDefault\n",
            "W0510 16:55:54.708487  2131 init.cc:224]     @           0x549e0e _PyEval_EvalCodeWithName\n",
            "W0510 16:55:54.708549  2131 init.cc:224]     @           0x4bcb19 _PyFunction_FastCallDict\n",
            "W0510 16:55:54.708606  2131 init.cc:224]     @           0x5134a6 _PyEval_EvalFrameDefault\n",
            "W0510 16:55:54.708693  2131 init.cc:224]     @           0x593dd7 _PyFunction_FastCallKeywords\n",
            "W0510 16:55:54.708750  2131 init.cc:224]     @           0x511e2c _PyEval_EvalFrameDefault\n",
            "W0510 16:55:54.708834  2131 init.cc:224]     @           0x593dd7 _PyFunction_FastCallKeywords\n",
            "W0510 16:55:54.708927  2131 init.cc:224]     @           0x511e2c _PyEval_EvalFrameDefault\n",
            "W0510 16:55:54.708992  2131 init.cc:224]     @           0x4bc98a _PyFunction_FastCallDict\n",
            "W0510 16:55:54.709128  2131 init.cc:224]     @           0x59c019 (unknown)\n",
            "W0510 16:55:54.709254  2131 init.cc:224]     @           0x595ef6 PyObject_Call\n",
            "W0510 16:55:54.709381  2131 init.cc:224]     @           0x5d5393 (unknown)\n",
            "run_finetuning.sh: line 64:  2093 Aborted                 (core dumped) python /content/vilio/ernie-vil/finetune.py --use_cuda \"True\" --is_distributed \"False\" --use_fast_executor ${e_executor-\"True\"} --nccl_comm_num ${nccl_comm_num:-\"1\"} --batch_size $((BATCH_SIZE/gpu_cnt)) --do_train \"True\" --do_test \"False\" --task_name ${TASK_NAME} --vocab_path ${VOCAB_PATH} --task_group_json ${TASK_GROUP_JSON} --lr_scheduler ${lr_scheduler} --decay_steps ${decay_steps-\"\"} --lr_decay_ratio ${lr_decay_ratio-0.1} --num_train_steps ${num_train_steps} --checkpoints $output_model_path --save_steps ${SAVE_STEPS} --init_checkpoint ${PRETRAIN_MODELS} --ernie_config_path ${ERNIE_VIL_CONFIG} --learning_rate ${LR_RATE} --warmup_steps ${WARMUP_STEPS} --weight_decay ${WEIGHT_DECAY:-0} --max_seq_len ${MAX_LEN} --validation_steps ${VALID_STEPS} --skip_steps 10 --split ${SPLIT} --stop_steps ${STOP}\n",
            "-----------  Configuration Arguments -----------\n",
            "batch_size: 8\n",
            "checkpoints: checkpoints\n",
            "combine: False\n",
            "decay_steps: \n",
            "do_test: True\n",
            "do_train: False\n",
            "do_val: False\n",
            "epoch: 100\n",
            "ernie_config_path: /content/vilio/ernie-vil/data/erniesmallvcr/ernie_vil_config.base.json\n",
            "exp: ESVCR72\n",
            "feature_size: 2048\n",
            "fusion_method: sum\n",
            "hierarchical_allreduce_inter_nranks: 8\n",
            "init_checkpoint: /content/vilio/ernie-vil/output_hm/step_2500train\n",
            "is_distributed: False\n",
            "learning_rate: 0.0001\n",
            "lr_decay_dict_file: \n",
            "lr_decay_ratio: 0.1\n",
            "lr_scheduler: linear_warmup_decay\n",
            "max_img_len: 100\n",
            "max_seq_len: 128\n",
            "nccl_comm_num: 1\n",
            "num_features: 50\n",
            "num_train_steps: 1000000\n",
            "output_file: \n",
            "result_file: /content/vilio/ernie-vil/data/log\n",
            "save_steps: 100\n",
            "skip_steps: 10\n",
            "split: dev_seen\n",
            "stop_steps: 5000\n",
            "subtrain: False\n",
            "task_group_json: /content/vilio/ernie-vil/conf/hm/task_hm.json\n",
            "task_name: hm\n",
            "test_filelist: \n",
            "test_split: val\n",
            "train_filelist: \n",
            "use_cuda: True\n",
            "use_fast_executor: True\n",
            "use_fuse: False\n",
            "use_gpu: True\n",
            "use_hierarchical_allreduce: False\n",
            "valid_filelist: \n",
            "validation_steps: 6000\n",
            "verbose: False\n",
            "vocab_path: /content/vilio/ernie-vil/data/erniesmallvcr/vocab.txt\n",
            "warmup_steps: 0\n",
            "weight_decay: 0.01\n",
            "------------------------------------------------\n",
            "finetuning tasks start\n",
            "attention_probs_dropout_prob: 0.1\n",
            "class_attr_size: 401\n",
            "class_size: 1601\n",
            "co_hidden_size: 1024\n",
            "co_intermediate_size: 1024\n",
            "co_num_attention_heads: 8\n",
            "hidden_act: gelu\n",
            "hidden_dropout_prob: 0.1\n",
            "hidden_size: 768\n",
            "initializer_range: 0.02\n",
            "max_position_embeddings: 512\n",
            "num_attention_heads: 12\n",
            "num_hidden_layers: 12\n",
            "sent_type_vocab_size: 4\n",
            "t_biattention_id: [6, 7, 8, 9, 10, 11]\n",
            "task_type_vocab_size: 16\n",
            "type_vocab_size: 2\n",
            "v_biattention_id: [0, 1, 2, 3, 4, 5]\n",
            "v_hidden_size: 1024\n",
            "v_intermediate_size: 1024\n",
            "v_num_attention_heads: 8\n",
            "vocab_size: 30522\n",
            "------------------------------------------------\n",
            "task:  [{'task': 'HM', 'num_choice': 1, 'annotations_jsonpath_train': '/content/vilio/ernie-vil/data/hm/train.jsonl', 'annotations_jsonpath_dev_seen': '/content/vilio/ernie-vil/data/hm/dev_seenlong.jsonl', 'annotations_jsonpath_traindev': '/content/vilio/ernie-vil/data/hm/traindev.jsonl', 'annotations_jsonpath_test_unseen': '/content/vilio/ernie-vil/data/hm/test_unseenlong.jsonl', 'annotations_jsonpath_test_seen': '/content/vilio/ernie-vil/data/hm/test_seenlong.jsonl', 'feature_lmdb_path': '/content/vilio/ernie-vil/data/hm/HM_img.tsv', 'gt_feature_lmdb_path': '/content/vilio/ernie-vil/data/hm/HM_gt_img.tsv', 'unisex_names_table': '/content/vilio/ernie-vil/data/vcr/unisex_names_table.csv', 'Proprocessor': 'PreprocessorBasic', 'tokenizer_name': 'FullTokenizer', 'fusion_method': 'mul', 'dropout_rate': 0.1, 'max_seq_len': 128, 'use_gt_fea': True, 'shufflekeep_across_task': True, 'shuffle_every_epoch': True, 'task_weight': 1.0, 'task_prefix': 'hm'}]\n",
            "2022-05-10 16:55:58,349-WARNING: paddle.fluid.layers.py_reader() may be deprecated in the near future. Please use paddle.fluid.io.DataLoader.from_generator() instead.\n",
            "theoretical memory usage: \n",
            "(3678.2632896423343, 3853.418684387207, 'MB')\n",
            "args.is_distributed: False\n",
            "W0510 16:55:59.220381  2155 device_context.cc:252] Please NOTE: device: 0, CUDA Capability: 60, Driver API Version: 11.2, Runtime API Version: 9.0\n",
            "W0510 16:55:59.234472  2155 device_context.cc:260] device: 0, cuDNN Version: 7.6.\n",
            "SPLIT: dev_seen\n",
            "Start to load Faster-RCNN detected objects from /content/vilio/ernie-vil/data/hm/HM_img.tsv\n",
            "Loaded 500 images in file /content/vilio/ernie-vil/data/hm/HM_img.tsv in 69 seconds.\n",
            "Start to load Faster-RCNN detected objects from /content/vilio/ernie-vil/data/hm/HM_gt_img.tsv\n",
            "Loaded 500 images in file /content/vilio/ernie-vil/data/hm/HM_gt_img.tsv in 50 seconds.\n",
            "Load 650 data from split(s) /content/vilio/ernie-vil/data/hm/dev_seenlong.jsonl.\n",
            "use gt featurre\n",
            "LEN:  650\n",
            "Load pretraining parameters from /content/vilio/ernie-vil/output_hm/step_2500train.\n",
            "testing on hm val split\n",
            "task name list :  ['mean_0.tmp_0', 'accuracy_0.tmp_0', 'arg_max_0.tmp_0', 'read_file_0.tmp_9', 'read_file_0.tmp_8', 'reshape2_120.tmp_0']\n",
            "cur_step: 10 cur_acc: 0.1125\n",
            "cur_step: 20 cur_acc: 0.31875\n",
            "cur_step: 30 cur_acc: 0.35833333333333334\n",
            "cur_step: 40 cur_acc: 0.43125\n",
            "cur_step: 50 cur_acc: 0.4675\n",
            "cur_step: 60 cur_acc: 0.49583333333333335\n",
            "cur_step: 70 cur_acc: 0.45714285714285713\n",
            "cur_step: 80 cur_acc: 0.4609375\n",
            "EXCEPTING\n",
            "LEN: 500 500\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 500 entries, 0 to 499\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   id      500 non-null    int64  \n",
            " 1   proba   500 non-null    float32\n",
            " 2   label   500 non-null    int64  \n",
            "dtypes: float32(1), int64(2)\n",
            "memory usage: 9.9 KB\n",
            "None\n",
            "average_acc: 0.4609375\n",
            "rocauc: 0.7612085482682388\n",
            "+ TASK_NAME=hm\n",
            "+ CONF_FILE=conf/hm/model_conf_hm\n",
            "+ VOCAB_PATH=/content/vilio/ernie-vil/data/erniesmallvcr/vocab.txt\n",
            "+ ERNIE_VIL_CONFIG=/content/vilio/ernie-vil/data/erniesmallvcr/ernie_vil_config.base.json\n",
            "+ PRETRAIN_MODELS=/content/vilio/ernie-vil/data/erniesmallvcr/params\n",
            "+ SPLIT=traindev\n",
            "+ STOP=2500\n",
            "+ source conf/hm/model_conf_hm\n",
            "++ output_model_path=output_hm\n",
            "++ lr_scheduler=manual_warmup_decay\n",
            "++ decay_steps='13308;19962'\n",
            "++ lr_decay_ratio=0.1\n",
            "++ num_train_steps=5000\n",
            "++ SAVE_STEPS=1250\n",
            "++ WARMUP_STEPS=500\n",
            "++ BATCH_SIZE=8\n",
            "++ VALID_STEPS=20000\n",
            "++ LR_RATE=1e-5\n",
            "++ WEIGHT_DECAY=0.01\n",
            "++ MAX_LEN=128\n",
            "+ CUDA_VISIBLE_DEVICES=1\n",
            "+ export FLAGS_fast_eager_deletion_mode=1\n",
            "+ FLAGS_fast_eager_deletion_mode=1\n",
            "+ export FLAGS_eager_delete_tensor_gb=0.0\n",
            "+ FLAGS_eager_delete_tensor_gb=0.0\n",
            "+ export FLAGS_fraction_of_gpu_memory_to_use=0.98\n",
            "+ FLAGS_fraction_of_gpu_memory_to_use=0.98\n",
            "++ echo True\n",
            "++ tr '[A-Z]' '[a-z]'\n",
            "+ e_executor=true\n",
            "++ echo False\n",
            "++ tr '[A-Z]' '[a-z]'\n",
            "+ use_fuse=false\n",
            "+ [[ false == \\t\\r\\u\\e ]]\n",
            "+ TASK_GROUP_JSON=/content/vilio/ernie-vil/conf/hm/task_hm.json\n",
            "++ echo 1\n",
            "++ awk '-F\\t' '{len=split($0,vec,\",\");print len}'\n",
            "+ gpu_cnt=1\n",
            "+ echo gpu_cnt, 1\n",
            "gpu_cnt, 1\n",
            "+ python /content/vilio/ernie-vil/finetune.py --use_cuda True --is_distributed False --use_fast_executor true --nccl_comm_num 1 --batch_size 8 --do_train True --do_test False --task_name hm --vocab_path /content/vilio/ernie-vil/data/erniesmallvcr/vocab.txt --task_group_json /content/vilio/ernie-vil/conf/hm/task_hm.json --lr_scheduler manual_warmup_decay --decay_steps '13308;19962' --lr_decay_ratio 0.1 --num_train_steps 5000 --checkpoints output_hm --save_steps 1250 --init_checkpoint /content/vilio/ernie-vil/data/erniesmallvcr/params --ernie_config_path /content/vilio/ernie-vil/data/erniesmallvcr/ernie_vil_config.base.json --learning_rate 1e-5 --warmup_steps 500 --weight_decay 0.01 --max_seq_len 128 --validation_steps 20000 --skip_steps 10 --split traindev --stop_steps 2500\n",
            "-----------  Configuration Arguments -----------\n",
            "batch_size: 8\n",
            "checkpoints: output_hm\n",
            "combine: False\n",
            "decay_steps: 13308;19962\n",
            "do_test: False\n",
            "do_train: True\n",
            "do_val: False\n",
            "epoch: 100\n",
            "ernie_config_path: /content/vilio/ernie-vil/data/erniesmallvcr/ernie_vil_config.base.json\n",
            "exp: experiment\n",
            "feature_size: 2048\n",
            "fusion_method: sum\n",
            "hierarchical_allreduce_inter_nranks: 8\n",
            "init_checkpoint: /content/vilio/ernie-vil/data/erniesmallvcr/params\n",
            "is_distributed: False\n",
            "learning_rate: 1e-05\n",
            "lr_decay_dict_file: \n",
            "lr_decay_ratio: 0.1\n",
            "lr_scheduler: manual_warmup_decay\n",
            "max_img_len: 100\n",
            "max_seq_len: 128\n",
            "nccl_comm_num: 1\n",
            "num_features: 50\n",
            "num_train_steps: 5000\n",
            "output_file: \n",
            "result_file: ./res_tmp\n",
            "save_steps: 1250\n",
            "skip_steps: 10\n",
            "split: traindev\n",
            "stop_steps: 2500\n",
            "subtrain: False\n",
            "task_group_json: /content/vilio/ernie-vil/conf/hm/task_hm.json\n",
            "task_name: hm\n",
            "test_filelist: \n",
            "test_split: test\n",
            "train_filelist: \n",
            "use_cuda: True\n",
            "use_fast_executor: True\n",
            "use_fuse: False\n",
            "use_gpu: True\n",
            "use_hierarchical_allreduce: False\n",
            "valid_filelist: \n",
            "validation_steps: 20000\n",
            "verbose: False\n",
            "vocab_path: /content/vilio/ernie-vil/data/erniesmallvcr/vocab.txt\n",
            "warmup_steps: 500\n",
            "weight_decay: 0.01\n",
            "------------------------------------------------\n",
            "finetuning tasks start\n",
            "attention_probs_dropout_prob: 0.1\n",
            "class_attr_size: 401\n",
            "class_size: 1601\n",
            "co_hidden_size: 1024\n",
            "co_intermediate_size: 1024\n",
            "co_num_attention_heads: 8\n",
            "hidden_act: gelu\n",
            "hidden_dropout_prob: 0.1\n",
            "hidden_size: 768\n",
            "initializer_range: 0.02\n",
            "max_position_embeddings: 512\n",
            "num_attention_heads: 12\n",
            "num_hidden_layers: 12\n",
            "sent_type_vocab_size: 4\n",
            "t_biattention_id: [6, 7, 8, 9, 10, 11]\n",
            "task_type_vocab_size: 16\n",
            "type_vocab_size: 2\n",
            "v_biattention_id: [0, 1, 2, 3, 4, 5]\n",
            "v_hidden_size: 1024\n",
            "v_intermediate_size: 1024\n",
            "v_num_attention_heads: 8\n",
            "vocab_size: 30522\n",
            "------------------------------------------------\n",
            "task:  [{'task': 'HM', 'num_choice': 1, 'annotations_jsonpath_train': '/content/vilio/ernie-vil/data/hm/train.jsonl', 'annotations_jsonpath_dev_seen': '/content/vilio/ernie-vil/data/hm/dev_seenlong.jsonl', 'annotations_jsonpath_traindev': '/content/vilio/ernie-vil/data/hm/traindev.jsonl', 'annotations_jsonpath_test_unseen': '/content/vilio/ernie-vil/data/hm/test_unseenlong.jsonl', 'annotations_jsonpath_test_seen': '/content/vilio/ernie-vil/data/hm/test_seenlong.jsonl', 'feature_lmdb_path': '/content/vilio/ernie-vil/data/hm/HM_img.tsv', 'gt_feature_lmdb_path': '/content/vilio/ernie-vil/data/hm/HM_gt_img.tsv', 'unisex_names_table': '/content/vilio/ernie-vil/data/vcr/unisex_names_table.csv', 'Proprocessor': 'PreprocessorBasic', 'tokenizer_name': 'FullTokenizer', 'fusion_method': 'mul', 'dropout_rate': 0.1, 'max_seq_len': 128, 'use_gt_fea': True, 'shufflekeep_across_task': True, 'shuffle_every_epoch': True, 'task_weight': 1.0, 'task_prefix': 'hm'}]\n",
            "2022-05-10 16:58:19,315-WARNING: paddle.fluid.layers.py_reader() may be deprecated in the near future. Please use paddle.fluid.io.DataLoader.from_generator() instead.\n",
            "/usr/local/lib/python3.7/dist-packages/paddle/fluid/clip.py:779: UserWarning: Caution! 'set_gradient_clip' is not recommended and may be deprecated in future! We recommend a new strategy: set 'grad_clip' when initializing the 'optimizer'. This method can reduce the mistakes, please refer to documention of 'optimizer'.\n",
            "  warnings.warn(\"Caution! 'set_gradient_clip' is not recommended \"\n",
            "theoretical memory usage: \n",
            "(18209.21138906479, 19076.31669330597, 'MB')\n",
            "args.is_distributed: False\n",
            "W0510 16:58:23.730206  2204 device_context.cc:252] Please NOTE: device: 0, CUDA Capability: 60, Driver API Version: 11.2, Runtime API Version: 9.0\n",
            "W0510 16:58:23.742429  2204 device_context.cc:260] device: 0, cuDNN Version: 7.6.\n",
            "Load pretraining parameters from /content/vilio/ernie-vil/data/erniesmallvcr/params.\n",
            "SPLIT: traindev\n",
            "Start to load Faster-RCNN detected objects from /content/vilio/ernie-vil/data/hm/HM_img.tsv\n",
            "Loaded 9096 images in file /content/vilio/ernie-vil/data/hm/HM_img.tsv in 85 seconds.\n",
            "Start to load Faster-RCNN detected objects from /content/vilio/ernie-vil/data/hm/HM_gt_img.tsv\n",
            "Loaded 9096 images in file /content/vilio/ernie-vil/data/hm/HM_gt_img.tsv in 61 seconds.\n",
            "Load 9596 data from split(s) /content/vilio/ernie-vil/data/hm/traindev.jsonl.\n",
            "use gt featurre\n",
            "LEN:  9596\n",
            "shuffle epoch 0\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 10, loss: 0.696133, acc: 0.625000\n",
            "steps: 10\n",
            "save_steps: 1250\n",
            "20220510 17:01:03 current learning_rate:0.00000018\n",
            "used_time: 0.1932692527770996\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 20, loss: 0.698328, acc: 0.625000\n",
            "steps: 20\n",
            "save_steps: 1250\n",
            "20220510 17:01:05 current learning_rate:0.00000038\n",
            "used_time: 0.1945357322692871\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 30, loss: 0.692209, acc: 0.750000\n",
            "steps: 30\n",
            "save_steps: 1250\n",
            "20220510 17:01:07 current learning_rate:0.00000058\n",
            "used_time: 0.17371177673339844\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 40, loss: 0.700597, acc: 0.625000\n",
            "steps: 40\n",
            "save_steps: 1250\n",
            "20220510 17:01:08 current learning_rate:0.00000078\n",
            "used_time: 0.1759495735168457\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 50, loss: 0.711558, acc: 0.375000\n",
            "steps: 50\n",
            "save_steps: 1250\n",
            "20220510 17:01:10 current learning_rate:0.00000098\n",
            "used_time: 0.23297357559204102\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 60, loss: 0.688532, acc: 0.625000\n",
            "steps: 60\n",
            "save_steps: 1250\n",
            "20220510 17:01:12 current learning_rate:0.00000118\n",
            "used_time: 0.18570542335510254\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 70, loss: 0.672760, acc: 0.500000\n",
            "steps: 70\n",
            "save_steps: 1250\n",
            "20220510 17:01:14 current learning_rate:0.00000138\n",
            "used_time: 0.18124055862426758\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 80, loss: 0.644847, acc: 0.750000\n",
            "steps: 80\n",
            "save_steps: 1250\n",
            "20220510 17:01:16 current learning_rate:0.00000158\n",
            "used_time: 0.1933581829071045\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 90, loss: 0.668882, acc: 0.625000\n",
            "steps: 90\n",
            "save_steps: 1250\n",
            "20220510 17:01:18 current learning_rate:0.00000178\n",
            "used_time: 0.18055486679077148\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 100, loss: 0.696990, acc: 0.625000\n",
            "steps: 100\n",
            "save_steps: 1250\n",
            "20220510 17:01:20 current learning_rate:0.00000198\n",
            "used_time: 0.18479490280151367\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 110, loss: 0.768048, acc: 0.375000\n",
            "steps: 110\n",
            "save_steps: 1250\n",
            "20220510 17:01:22 current learning_rate:0.00000218\n",
            "used_time: 0.20073580741882324\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 120, loss: 0.735997, acc: 0.500000\n",
            "steps: 120\n",
            "save_steps: 1250\n",
            "20220510 17:01:24 current learning_rate:0.00000238\n",
            "used_time: 0.1953415870666504\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 130, loss: 0.744080, acc: 0.375000\n",
            "steps: 130\n",
            "save_steps: 1250\n",
            "20220510 17:01:25 current learning_rate:0.00000258\n",
            "used_time: 0.20162057876586914\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 140, loss: 0.601652, acc: 0.750000\n",
            "steps: 140\n",
            "save_steps: 1250\n",
            "20220510 17:01:27 current learning_rate:0.00000278\n",
            "used_time: 0.2068498134613037\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 150, loss: 0.729513, acc: 0.500000\n",
            "steps: 150\n",
            "save_steps: 1250\n",
            "20220510 17:01:29 current learning_rate:0.00000298\n",
            "used_time: 0.18491435050964355\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 160, loss: 0.700120, acc: 0.500000\n",
            "steps: 160\n",
            "save_steps: 1250\n",
            "20220510 17:01:31 current learning_rate:0.00000318\n",
            "used_time: 0.25234341621398926\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 170, loss: 0.656085, acc: 0.750000\n",
            "steps: 170\n",
            "save_steps: 1250\n",
            "20220510 17:01:33 current learning_rate:0.00000338\n",
            "used_time: 0.19211483001708984\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 180, loss: 0.662197, acc: 0.625000\n",
            "steps: 180\n",
            "save_steps: 1250\n",
            "20220510 17:01:35 current learning_rate:0.00000358\n",
            "used_time: 0.17405200004577637\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 190, loss: 0.576108, acc: 0.750000\n",
            "steps: 190\n",
            "save_steps: 1250\n",
            "20220510 17:01:37 current learning_rate:0.00000378\n",
            "used_time: 0.19074583053588867\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 200, loss: 0.672731, acc: 0.625000\n",
            "steps: 200\n",
            "save_steps: 1250\n",
            "20220510 17:01:39 current learning_rate:0.00000398\n",
            "used_time: 0.19125103950500488\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 210, loss: 0.674920, acc: 0.625000\n",
            "steps: 210\n",
            "save_steps: 1250\n",
            "20220510 17:01:41 current learning_rate:0.00000418\n",
            "used_time: 0.1741011142730713\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 220, loss: 0.542697, acc: 0.750000\n",
            "steps: 220\n",
            "save_steps: 1250\n",
            "20220510 17:01:43 current learning_rate:0.00000438\n",
            "used_time: 0.1854259967803955\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 230, loss: 0.799976, acc: 0.250000\n",
            "steps: 230\n",
            "save_steps: 1250\n",
            "20220510 17:01:45 current learning_rate:0.00000458\n",
            "used_time: 0.2186129093170166\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 240, loss: 0.785446, acc: 0.375000\n",
            "steps: 240\n",
            "save_steps: 1250\n",
            "20220510 17:01:46 current learning_rate:0.00000478\n",
            "used_time: 0.1962447166442871\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 250, loss: 0.771286, acc: 0.500000\n",
            "steps: 250\n",
            "save_steps: 1250\n",
            "20220510 17:01:48 current learning_rate:0.00000498\n",
            "used_time: 0.2155301570892334\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 260, loss: 0.559192, acc: 0.750000\n",
            "steps: 260\n",
            "save_steps: 1250\n",
            "20220510 17:01:50 current learning_rate:0.00000518\n",
            "used_time: 0.16629958152770996\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 270, loss: 0.721183, acc: 0.500000\n",
            "steps: 270\n",
            "save_steps: 1250\n",
            "20220510 17:01:52 current learning_rate:0.00000538\n",
            "used_time: 0.19005680084228516\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 280, loss: 0.616709, acc: 0.625000\n",
            "steps: 280\n",
            "save_steps: 1250\n",
            "20220510 17:01:54 current learning_rate:0.00000558\n",
            "used_time: 0.1919994354248047\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 290, loss: 0.596411, acc: 0.375000\n",
            "steps: 290\n",
            "save_steps: 1250\n",
            "20220510 17:01:56 current learning_rate:0.00000578\n",
            "used_time: 0.1820387840270996\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 300, loss: 0.766902, acc: 0.375000\n",
            "steps: 300\n",
            "save_steps: 1250\n",
            "20220510 17:01:58 current learning_rate:0.00000598\n",
            "used_time: 0.1781454086303711\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 310, loss: 0.234798, acc: 0.875000\n",
            "steps: 310\n",
            "save_steps: 1250\n",
            "20220510 17:02:00 current learning_rate:0.00000618\n",
            "used_time: 0.15614795684814453\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 320, loss: 0.617881, acc: 0.500000\n",
            "steps: 320\n",
            "save_steps: 1250\n",
            "20220510 17:02:02 current learning_rate:0.00000638\n",
            "used_time: 0.1715562343597412\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 330, loss: 0.504939, acc: 0.625000\n",
            "steps: 330\n",
            "save_steps: 1250\n",
            "20220510 17:02:04 current learning_rate:0.00000658\n",
            "used_time: 0.20269036293029785\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 340, loss: 0.485364, acc: 0.500000\n",
            "steps: 340\n",
            "save_steps: 1250\n",
            "20220510 17:02:06 current learning_rate:0.00000678\n",
            "used_time: 0.2082676887512207\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 350, loss: 0.264691, acc: 0.875000\n",
            "steps: 350\n",
            "save_steps: 1250\n",
            "20220510 17:02:08 current learning_rate:0.00000698\n",
            "used_time: 0.173264741897583\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 360, loss: 0.204638, acc: 0.750000\n",
            "steps: 360\n",
            "save_steps: 1250\n",
            "20220510 17:02:09 current learning_rate:0.00000718\n",
            "used_time: 0.19345593452453613\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 370, loss: 0.589874, acc: 0.625000\n",
            "steps: 370\n",
            "save_steps: 1250\n",
            "20220510 17:02:11 current learning_rate:0.00000738\n",
            "used_time: 0.20139861106872559\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 380, loss: 0.745767, acc: 0.500000\n",
            "steps: 380\n",
            "save_steps: 1250\n",
            "20220510 17:02:13 current learning_rate:0.00000758\n",
            "used_time: 0.25159192085266113\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 390, loss: 0.327841, acc: 0.750000\n",
            "steps: 390\n",
            "save_steps: 1250\n",
            "20220510 17:02:15 current learning_rate:0.00000778\n",
            "used_time: 0.1864025592803955\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 400, loss: 0.548214, acc: 0.750000\n",
            "steps: 400\n",
            "save_steps: 1250\n",
            "20220510 17:02:17 current learning_rate:0.00000798\n",
            "used_time: 0.17002487182617188\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 410, loss: 1.213575, acc: 0.125000\n",
            "steps: 410\n",
            "save_steps: 1250\n",
            "20220510 17:02:19 current learning_rate:0.00000818\n",
            "used_time: 0.20458984375\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 420, loss: 0.766672, acc: 0.625000\n",
            "steps: 420\n",
            "save_steps: 1250\n",
            "20220510 17:02:21 current learning_rate:0.00000838\n",
            "used_time: 0.1922740936279297\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 430, loss: 0.548448, acc: 0.625000\n",
            "steps: 430\n",
            "save_steps: 1250\n",
            "20220510 17:02:23 current learning_rate:0.00000858\n",
            "used_time: 0.1937108039855957\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 440, loss: 0.609443, acc: 0.625000\n",
            "steps: 440\n",
            "save_steps: 1250\n",
            "20220510 17:02:25 current learning_rate:0.00000878\n",
            "used_time: 0.16855788230895996\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 450, loss: 0.773908, acc: 0.875000\n",
            "steps: 450\n",
            "save_steps: 1250\n",
            "20220510 17:02:27 current learning_rate:0.00000898\n",
            "used_time: 0.18935537338256836\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 460, loss: 0.404871, acc: 0.750000\n",
            "steps: 460\n",
            "save_steps: 1250\n",
            "20220510 17:02:29 current learning_rate:0.00000918\n",
            "used_time: 0.19283676147460938\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 470, loss: 0.347001, acc: 0.875000\n",
            "steps: 470\n",
            "save_steps: 1250\n",
            "20220510 17:02:31 current learning_rate:0.00000938\n",
            "used_time: 0.19796061515808105\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 480, loss: 0.207914, acc: 0.875000\n",
            "steps: 480\n",
            "save_steps: 1250\n",
            "20220510 17:02:33 current learning_rate:0.00000958\n",
            "used_time: 0.1730945110321045\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 490, loss: 0.420468, acc: 0.500000\n",
            "steps: 490\n",
            "save_steps: 1250\n",
            "20220510 17:02:35 current learning_rate:0.00000978\n",
            "used_time: 0.1936790943145752\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 500, loss: 0.574109, acc: 0.625000\n",
            "steps: 500\n",
            "save_steps: 1250\n",
            "Train-RCAC 0.7175324675324676\n",
            "20220510 17:02:36 current learning_rate:0.00000998\n",
            "used_time: 0.17429876327514648\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 510, loss: 1.060756, acc: 0.500000\n",
            "steps: 510\n",
            "save_steps: 1250\n",
            "20220510 17:02:38 current learning_rate:0.00001000\n",
            "used_time: 0.19115757942199707\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 520, loss: 0.439971, acc: 0.625000\n",
            "steps: 520\n",
            "save_steps: 1250\n",
            "20220510 17:02:40 current learning_rate:0.00001000\n",
            "used_time: 0.1600186824798584\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 530, loss: 0.524170, acc: 0.625000\n",
            "steps: 530\n",
            "save_steps: 1250\n",
            "20220510 17:02:42 current learning_rate:0.00001000\n",
            "used_time: 0.19823551177978516\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 540, loss: 0.493020, acc: 0.750000\n",
            "steps: 540\n",
            "save_steps: 1250\n",
            "20220510 17:02:44 current learning_rate:0.00001000\n",
            "used_time: 0.1717054843902588\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 550, loss: 0.482827, acc: 0.625000\n",
            "steps: 550\n",
            "save_steps: 1250\n",
            "20220510 17:02:46 current learning_rate:0.00001000\n",
            "used_time: 0.28060221672058105\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 560, loss: 1.052514, acc: 0.750000\n",
            "steps: 560\n",
            "save_steps: 1250\n",
            "20220510 17:02:48 current learning_rate:0.00001000\n",
            "used_time: 0.17252826690673828\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 570, loss: 0.642625, acc: 0.625000\n",
            "steps: 570\n",
            "save_steps: 1250\n",
            "20220510 17:02:50 current learning_rate:0.00001000\n",
            "used_time: 0.21520519256591797\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 580, loss: 0.774940, acc: 0.625000\n",
            "steps: 580\n",
            "save_steps: 1250\n",
            "20220510 17:02:52 current learning_rate:0.00001000\n",
            "used_time: 0.16283345222473145\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 590, loss: 0.434680, acc: 0.625000\n",
            "steps: 590\n",
            "save_steps: 1250\n",
            "20220510 17:02:54 current learning_rate:0.00001000\n",
            "used_time: 0.21522808074951172\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 600, loss: 0.690052, acc: 0.500000\n",
            "steps: 600\n",
            "save_steps: 1250\n",
            "20220510 17:02:56 current learning_rate:0.00001000\n",
            "used_time: 0.18329906463623047\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 610, loss: 0.797483, acc: 0.625000\n",
            "steps: 610\n",
            "save_steps: 1250\n",
            "20220510 17:02:57 current learning_rate:0.00001000\n",
            "used_time: 0.21584606170654297\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 620, loss: 0.882971, acc: 1.000000\n",
            "steps: 620\n",
            "save_steps: 1250\n",
            "20220510 17:02:59 current learning_rate:0.00001000\n",
            "used_time: 0.18736577033996582\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 630, loss: 0.488239, acc: 0.750000\n",
            "steps: 630\n",
            "save_steps: 1250\n",
            "20220510 17:03:01 current learning_rate:0.00001000\n",
            "used_time: 0.1971755027770996\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 640, loss: 0.599259, acc: 0.625000\n",
            "steps: 640\n",
            "save_steps: 1250\n",
            "20220510 17:03:03 current learning_rate:0.00001000\n",
            "used_time: 0.16682171821594238\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 650, loss: 0.451414, acc: 0.500000\n",
            "steps: 650\n",
            "save_steps: 1250\n",
            "20220510 17:03:05 current learning_rate:0.00001000\n",
            "used_time: 0.22051215171813965\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 660, loss: 0.575273, acc: 0.750000\n",
            "steps: 660\n",
            "save_steps: 1250\n",
            "20220510 17:03:07 current learning_rate:0.00001000\n",
            "used_time: 0.18847084045410156\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 670, loss: 0.578637, acc: 0.250000\n",
            "steps: 670\n",
            "save_steps: 1250\n",
            "20220510 17:03:09 current learning_rate:0.00001000\n",
            "used_time: 0.17174172401428223\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 680, loss: 0.919227, acc: 0.750000\n",
            "steps: 680\n",
            "save_steps: 1250\n",
            "20220510 17:03:11 current learning_rate:0.00001000\n",
            "used_time: 0.1843430995941162\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 690, loss: 0.508344, acc: 0.750000\n",
            "steps: 690\n",
            "save_steps: 1250\n",
            "20220510 17:03:13 current learning_rate:0.00001000\n",
            "used_time: 0.2048649787902832\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 700, loss: 0.348209, acc: 0.625000\n",
            "steps: 700\n",
            "save_steps: 1250\n",
            "20220510 17:03:15 current learning_rate:0.00001000\n",
            "used_time: 0.19471025466918945\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 710, loss: 0.344940, acc: 0.750000\n",
            "steps: 710\n",
            "save_steps: 1250\n",
            "20220510 17:03:17 current learning_rate:0.00001000\n",
            "used_time: 0.20800042152404785\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 720, loss: 0.757621, acc: 0.500000\n",
            "steps: 720\n",
            "save_steps: 1250\n",
            "20220510 17:03:19 current learning_rate:0.00001000\n",
            "used_time: 0.20026922225952148\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 730, loss: 0.675464, acc: 0.625000\n",
            "steps: 730\n",
            "save_steps: 1250\n",
            "20220510 17:03:21 current learning_rate:0.00001000\n",
            "used_time: 0.22493934631347656\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 740, loss: 0.660258, acc: 0.625000\n",
            "steps: 740\n",
            "save_steps: 1250\n",
            "20220510 17:03:23 current learning_rate:0.00001000\n",
            "used_time: 0.19337201118469238\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 750, loss: 0.457744, acc: 1.000000\n",
            "steps: 750\n",
            "save_steps: 1250\n",
            "20220510 17:03:24 current learning_rate:0.00001000\n",
            "used_time: 0.18836379051208496\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 760, loss: 0.393522, acc: 0.625000\n",
            "steps: 760\n",
            "save_steps: 1250\n",
            "20220510 17:03:26 current learning_rate:0.00001000\n",
            "used_time: 0.19674110412597656\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 770, loss: 0.577039, acc: 0.500000\n",
            "steps: 770\n",
            "save_steps: 1250\n",
            "20220510 17:03:28 current learning_rate:0.00001000\n",
            "used_time: 0.21779513359069824\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 780, loss: 0.659482, acc: 0.625000\n",
            "steps: 780\n",
            "save_steps: 1250\n",
            "20220510 17:03:30 current learning_rate:0.00001000\n",
            "used_time: 0.19186973571777344\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 790, loss: 1.118600, acc: 0.625000\n",
            "steps: 790\n",
            "save_steps: 1250\n",
            "20220510 17:03:32 current learning_rate:0.00001000\n",
            "used_time: 0.18338370323181152\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 800, loss: 0.329962, acc: 1.000000\n",
            "steps: 800\n",
            "save_steps: 1250\n",
            "20220510 17:03:34 current learning_rate:0.00001000\n",
            "used_time: 0.16211724281311035\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 810, loss: 0.611854, acc: 0.625000\n",
            "steps: 810\n",
            "save_steps: 1250\n",
            "20220510 17:03:36 current learning_rate:0.00001000\n",
            "used_time: 0.19460797309875488\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 820, loss: 0.237395, acc: 0.875000\n",
            "steps: 820\n",
            "save_steps: 1250\n",
            "20220510 17:03:38 current learning_rate:0.00001000\n",
            "used_time: 0.21439504623413086\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 830, loss: 0.227755, acc: 0.750000\n",
            "steps: 830\n",
            "save_steps: 1250\n",
            "20220510 17:03:40 current learning_rate:0.00001000\n",
            "used_time: 0.21042990684509277\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 840, loss: 0.713946, acc: 0.500000\n",
            "steps: 840\n",
            "save_steps: 1250\n",
            "20220510 17:03:42 current learning_rate:0.00001000\n",
            "used_time: 0.19124245643615723\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 850, loss: 0.419473, acc: 0.625000\n",
            "steps: 850\n",
            "save_steps: 1250\n",
            "20220510 17:03:44 current learning_rate:0.00001000\n",
            "used_time: 0.21352767944335938\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 860, loss: 0.451994, acc: 0.875000\n",
            "steps: 860\n",
            "save_steps: 1250\n",
            "20220510 17:03:46 current learning_rate:0.00001000\n",
            "used_time: 0.17984509468078613\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 870, loss: 0.266287, acc: 0.750000\n",
            "steps: 870\n",
            "save_steps: 1250\n",
            "20220510 17:03:48 current learning_rate:0.00001000\n",
            "used_time: 0.17355680465698242\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 880, loss: 0.845893, acc: 0.500000\n",
            "steps: 880\n",
            "save_steps: 1250\n",
            "20220510 17:03:50 current learning_rate:0.00001000\n",
            "used_time: 0.1721196174621582\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 890, loss: 0.394483, acc: 0.625000\n",
            "steps: 890\n",
            "save_steps: 1250\n",
            "20220510 17:03:52 current learning_rate:0.00001000\n",
            "used_time: 0.18623042106628418\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 900, loss: 0.516993, acc: 0.250000\n",
            "steps: 900\n",
            "save_steps: 1250\n",
            "20220510 17:03:54 current learning_rate:0.00001000\n",
            "used_time: 0.1942143440246582\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 910, loss: 0.708569, acc: 0.625000\n",
            "steps: 910\n",
            "save_steps: 1250\n",
            "20220510 17:03:56 current learning_rate:0.00001000\n",
            "used_time: 0.17344212532043457\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 920, loss: 1.009703, acc: 0.500000\n",
            "steps: 920\n",
            "save_steps: 1250\n",
            "20220510 17:03:57 current learning_rate:0.00001000\n",
            "used_time: 0.2095177173614502\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 930, loss: 0.536685, acc: 0.875000\n",
            "steps: 930\n",
            "save_steps: 1250\n",
            "20220510 17:03:59 current learning_rate:0.00001000\n",
            "used_time: 0.19692277908325195\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 940, loss: 0.384224, acc: 0.625000\n",
            "steps: 940\n",
            "save_steps: 1250\n",
            "20220510 17:04:01 current learning_rate:0.00001000\n",
            "used_time: 0.19305181503295898\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 950, loss: 0.452638, acc: 0.500000\n",
            "steps: 950\n",
            "save_steps: 1250\n",
            "20220510 17:04:03 current learning_rate:0.00001000\n",
            "used_time: 0.17245125770568848\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 960, loss: 0.810157, acc: 0.875000\n",
            "steps: 960\n",
            "save_steps: 1250\n",
            "20220510 17:04:05 current learning_rate:0.00001000\n",
            "used_time: 0.17573118209838867\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 970, loss: 0.496606, acc: 0.625000\n",
            "steps: 970\n",
            "save_steps: 1250\n",
            "20220510 17:04:07 current learning_rate:0.00001000\n",
            "used_time: 0.18634986877441406\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 980, loss: 0.986320, acc: 0.250000\n",
            "steps: 980\n",
            "save_steps: 1250\n",
            "20220510 17:04:09 current learning_rate:0.00001000\n",
            "used_time: 0.18575644493103027\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 990, loss: 0.310310, acc: 0.500000\n",
            "steps: 990\n",
            "save_steps: 1250\n",
            "20220510 17:04:11 current learning_rate:0.00001000\n",
            "used_time: 0.1897280216217041\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1000, loss: 0.839654, acc: 0.375000\n",
            "steps: 1000\n",
            "save_steps: 1250\n",
            "Train-RCAC 0.6616666666666667\n",
            "20220510 17:04:13 current learning_rate:0.00001000\n",
            "used_time: 0.19257473945617676\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1010, loss: 0.361017, acc: 0.750000\n",
            "steps: 1010\n",
            "save_steps: 1250\n",
            "20220510 17:04:15 current learning_rate:0.00001000\n",
            "used_time: 0.18397235870361328\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1020, loss: 0.756197, acc: 0.375000\n",
            "steps: 1020\n",
            "save_steps: 1250\n",
            "20220510 17:04:17 current learning_rate:0.00001000\n",
            "used_time: 0.18281006813049316\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1030, loss: 0.654956, acc: 0.500000\n",
            "steps: 1030\n",
            "save_steps: 1250\n",
            "20220510 17:04:19 current learning_rate:0.00001000\n",
            "used_time: 0.1833510398864746\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1040, loss: 0.420954, acc: 0.750000\n",
            "steps: 1040\n",
            "save_steps: 1250\n",
            "20220510 17:04:20 current learning_rate:0.00001000\n",
            "used_time: 0.20075178146362305\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1050, loss: 0.281203, acc: 0.625000\n",
            "steps: 1050\n",
            "save_steps: 1250\n",
            "20220510 17:04:22 current learning_rate:0.00001000\n",
            "used_time: 0.18971681594848633\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1060, loss: 0.445764, acc: 0.750000\n",
            "steps: 1060\n",
            "save_steps: 1250\n",
            "20220510 17:04:24 current learning_rate:0.00001000\n",
            "used_time: 0.2227942943572998\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1070, loss: 0.485685, acc: 0.625000\n",
            "steps: 1070\n",
            "save_steps: 1250\n",
            "20220510 17:04:26 current learning_rate:0.00001000\n",
            "used_time: 0.22288918495178223\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1080, loss: 0.542270, acc: 0.750000\n",
            "steps: 1080\n",
            "save_steps: 1250\n",
            "20220510 17:04:28 current learning_rate:0.00001000\n",
            "used_time: 0.183851957321167\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1090, loss: 0.290697, acc: 0.625000\n",
            "steps: 1090\n",
            "save_steps: 1250\n",
            "20220510 17:04:30 current learning_rate:0.00001000\n",
            "used_time: 0.19597840309143066\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1100, loss: 0.729936, acc: 0.625000\n",
            "steps: 1100\n",
            "save_steps: 1250\n",
            "20220510 17:04:32 current learning_rate:0.00001000\n",
            "used_time: 0.1679682731628418\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1110, loss: 0.529367, acc: 0.750000\n",
            "steps: 1110\n",
            "save_steps: 1250\n",
            "20220510 17:04:34 current learning_rate:0.00001000\n",
            "used_time: 0.18674778938293457\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1120, loss: 0.509932, acc: 0.875000\n",
            "steps: 1120\n",
            "save_steps: 1250\n",
            "20220510 17:04:36 current learning_rate:0.00001000\n",
            "used_time: 0.21324753761291504\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1130, loss: 0.617921, acc: 0.625000\n",
            "steps: 1130\n",
            "save_steps: 1250\n",
            "20220510 17:04:37 current learning_rate:0.00001000\n",
            "used_time: 0.19925665855407715\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1140, loss: 0.719349, acc: 0.750000\n",
            "steps: 1140\n",
            "save_steps: 1250\n",
            "20220510 17:04:40 current learning_rate:0.00001000\n",
            "used_time: 0.20269560813903809\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1150, loss: 0.257231, acc: 0.750000\n",
            "steps: 1150\n",
            "save_steps: 1250\n",
            "20220510 17:04:42 current learning_rate:0.00001000\n",
            "used_time: 0.18318915367126465\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1160, loss: 0.790592, acc: 0.375000\n",
            "steps: 1160\n",
            "save_steps: 1250\n",
            "20220510 17:04:44 current learning_rate:0.00001000\n",
            "used_time: 0.20342683792114258\n",
            "shuffle epoch 1\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1170, loss: 0.179638, acc: 0.875000\n",
            "steps: 1170\n",
            "save_steps: 1250\n",
            "20220510 17:04:45 current learning_rate:0.00001000\n",
            "used_time: 0.20739293098449707\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1180, loss: 0.213368, acc: 0.375000\n",
            "steps: 1180\n",
            "save_steps: 1250\n",
            "20220510 17:04:47 current learning_rate:0.00001000\n",
            "used_time: 0.19790911674499512\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1190, loss: 0.603615, acc: 0.625000\n",
            "steps: 1190\n",
            "save_steps: 1250\n",
            "20220510 17:04:49 current learning_rate:0.00001000\n",
            "used_time: 0.2093808650970459\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1200, loss: 0.221383, acc: 0.500000\n",
            "steps: 1200\n",
            "save_steps: 1250\n",
            "20220510 17:04:51 current learning_rate:0.00001000\n",
            "used_time: 0.14082884788513184\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1210, loss: 0.313495, acc: 0.625000\n",
            "steps: 1210\n",
            "save_steps: 1250\n",
            "20220510 17:04:53 current learning_rate:0.00001000\n",
            "used_time: 0.19281291961669922\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1220, loss: 0.410911, acc: 0.625000\n",
            "steps: 1220\n",
            "save_steps: 1250\n",
            "20220510 17:04:55 current learning_rate:0.00001000\n",
            "used_time: 0.16876006126403809\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1230, loss: 0.343917, acc: 0.875000\n",
            "steps: 1230\n",
            "save_steps: 1250\n",
            "20220510 17:04:57 current learning_rate:0.00001000\n",
            "used_time: 0.19939970970153809\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1240, loss: 0.759914, acc: 0.625000\n",
            "steps: 1240\n",
            "save_steps: 1250\n",
            "20220510 17:04:59 current learning_rate:0.00001000\n",
            "used_time: 0.19694232940673828\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1250, loss: 0.283625, acc: 0.500000\n",
            "steps: 1250\n",
            "save_steps: 1250\n",
            "20220510 17:05:00 current learning_rate:0.00001000\n",
            "save_path: output_hm/step_1250traindev\n",
            "used_time: 11.846973657608032\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1260, loss: 0.651365, acc: 0.750000\n",
            "steps: 1260\n",
            "save_steps: 1250\n",
            "20220510 17:05:14 current learning_rate:0.00001000\n",
            "used_time: 0.1838231086730957\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1270, loss: 0.185360, acc: 0.625000\n",
            "steps: 1270\n",
            "save_steps: 1250\n",
            "20220510 17:05:16 current learning_rate:0.00001000\n",
            "used_time: 0.2044050693511963\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1280, loss: 0.251608, acc: 0.375000\n",
            "steps: 1280\n",
            "save_steps: 1250\n",
            "20220510 17:05:18 current learning_rate:0.00001000\n",
            "used_time: 0.17038607597351074\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1290, loss: 0.474318, acc: 0.750000\n",
            "steps: 1290\n",
            "save_steps: 1250\n",
            "20220510 17:05:20 current learning_rate:0.00001000\n",
            "used_time: 0.20000982284545898\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1300, loss: 0.340320, acc: 0.750000\n",
            "steps: 1300\n",
            "save_steps: 1250\n",
            "20220510 17:05:21 current learning_rate:0.00001000\n",
            "used_time: 0.16805338859558105\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1310, loss: 0.233399, acc: 0.750000\n",
            "steps: 1310\n",
            "save_steps: 1250\n",
            "20220510 17:05:23 current learning_rate:0.00001000\n",
            "used_time: 0.19436264038085938\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1320, loss: 0.402736, acc: 0.750000\n",
            "steps: 1320\n",
            "save_steps: 1250\n",
            "20220510 17:05:25 current learning_rate:0.00001000\n",
            "used_time: 0.21047425270080566\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1330, loss: 0.109598, acc: 0.625000\n",
            "steps: 1330\n",
            "save_steps: 1250\n",
            "20220510 17:05:27 current learning_rate:0.00001000\n",
            "used_time: 0.19350504875183105\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1340, loss: 0.399349, acc: 0.750000\n",
            "steps: 1340\n",
            "save_steps: 1250\n",
            "20220510 17:05:29 current learning_rate:0.00001000\n",
            "used_time: 0.2078399658203125\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1350, loss: 0.577973, acc: 0.750000\n",
            "steps: 1350\n",
            "save_steps: 1250\n",
            "20220510 17:05:31 current learning_rate:0.00001000\n",
            "used_time: 0.19638895988464355\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1360, loss: 0.015110, acc: 1.000000\n",
            "steps: 1360\n",
            "save_steps: 1250\n",
            "20220510 17:05:33 current learning_rate:0.00001000\n",
            "used_time: 0.15861940383911133\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1370, loss: 0.079425, acc: 0.750000\n",
            "steps: 1370\n",
            "save_steps: 1250\n",
            "20220510 17:05:35 current learning_rate:0.00001000\n",
            "used_time: 0.18924832344055176\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1380, loss: 0.352605, acc: 0.500000\n",
            "steps: 1380\n",
            "save_steps: 1250\n",
            "20220510 17:05:37 current learning_rate:0.00001000\n",
            "used_time: 0.18108439445495605\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1390, loss: 0.186868, acc: 0.750000\n",
            "steps: 1390\n",
            "save_steps: 1250\n",
            "20220510 17:05:39 current learning_rate:0.00001000\n",
            "used_time: 0.1937243938446045\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1400, loss: 0.251928, acc: 0.500000\n",
            "steps: 1400\n",
            "save_steps: 1250\n",
            "20220510 17:05:40 current learning_rate:0.00001000\n",
            "used_time: 0.21202516555786133\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1410, loss: 0.375916, acc: 0.750000\n",
            "steps: 1410\n",
            "save_steps: 1250\n",
            "20220510 17:05:42 current learning_rate:0.00001000\n",
            "used_time: 0.21177887916564941\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1420, loss: 0.165135, acc: 0.750000\n",
            "steps: 1420\n",
            "save_steps: 1250\n",
            "20220510 17:05:44 current learning_rate:0.00001000\n",
            "used_time: 0.19505953788757324\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1430, loss: 0.508343, acc: 0.625000\n",
            "steps: 1430\n",
            "save_steps: 1250\n",
            "20220510 17:05:46 current learning_rate:0.00001000\n",
            "used_time: 0.21521902084350586\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1440, loss: 0.345644, acc: 0.875000\n",
            "steps: 1440\n",
            "save_steps: 1250\n",
            "20220510 17:05:48 current learning_rate:0.00001000\n",
            "used_time: 0.19291329383850098\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1450, loss: 0.047199, acc: 0.750000\n",
            "steps: 1450\n",
            "save_steps: 1250\n",
            "20220510 17:05:50 current learning_rate:0.00001000\n",
            "used_time: 0.2726290225982666\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1460, loss: 0.512405, acc: 0.875000\n",
            "steps: 1460\n",
            "save_steps: 1250\n",
            "20220510 17:05:52 current learning_rate:0.00001000\n",
            "used_time: 0.19637727737426758\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1470, loss: 0.300627, acc: 0.375000\n",
            "steps: 1470\n",
            "save_steps: 1250\n",
            "20220510 17:05:54 current learning_rate:0.00001000\n",
            "used_time: 0.18953776359558105\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1480, loss: 0.064084, acc: 0.625000\n",
            "steps: 1480\n",
            "save_steps: 1250\n",
            "20220510 17:05:56 current learning_rate:0.00001000\n",
            "used_time: 0.17645549774169922\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1490, loss: 0.655473, acc: 0.375000\n",
            "steps: 1490\n",
            "save_steps: 1250\n",
            "20220510 17:05:58 current learning_rate:0.00001000\n",
            "used_time: 0.23014044761657715\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1500, loss: 0.383193, acc: 0.500000\n",
            "steps: 1500\n",
            "save_steps: 1250\n",
            "Train-RCAC 0.8110516934046346\n",
            "20220510 17:06:00 current learning_rate:0.00001000\n",
            "used_time: 0.17729520797729492\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1510, loss: 0.038620, acc: 0.750000\n",
            "steps: 1510\n",
            "save_steps: 1250\n",
            "20220510 17:06:02 current learning_rate:0.00001000\n",
            "used_time: 0.17886853218078613\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1520, loss: 0.375826, acc: 0.750000\n",
            "steps: 1520\n",
            "save_steps: 1250\n",
            "20220510 17:06:04 current learning_rate:0.00001000\n",
            "used_time: 0.21359753608703613\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1530, loss: 0.038383, acc: 0.625000\n",
            "steps: 1530\n",
            "save_steps: 1250\n",
            "20220510 17:06:05 current learning_rate:0.00001000\n",
            "used_time: 0.18695616722106934\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1540, loss: 0.206381, acc: 0.500000\n",
            "steps: 1540\n",
            "save_steps: 1250\n",
            "20220510 17:06:07 current learning_rate:0.00001000\n",
            "used_time: 0.19270992279052734\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1550, loss: 0.511158, acc: 0.750000\n",
            "steps: 1550\n",
            "save_steps: 1250\n",
            "20220510 17:06:09 current learning_rate:0.00001000\n",
            "used_time: 0.16806244850158691\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1560, loss: 0.154533, acc: 0.625000\n",
            "steps: 1560\n",
            "save_steps: 1250\n",
            "20220510 17:06:11 current learning_rate:0.00001000\n",
            "used_time: 0.17551755905151367\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1570, loss: 0.082706, acc: 0.625000\n",
            "steps: 1570\n",
            "save_steps: 1250\n",
            "20220510 17:06:13 current learning_rate:0.00001000\n",
            "used_time: 0.18722319602966309\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1580, loss: 0.109063, acc: 0.500000\n",
            "steps: 1580\n",
            "save_steps: 1250\n",
            "20220510 17:06:15 current learning_rate:0.00001000\n",
            "used_time: 0.1747279167175293\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1590, loss: 0.726444, acc: 0.625000\n",
            "steps: 1590\n",
            "save_steps: 1250\n",
            "20220510 17:06:17 current learning_rate:0.00001000\n",
            "used_time: 0.17984795570373535\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1600, loss: 0.135302, acc: 0.625000\n",
            "steps: 1600\n",
            "save_steps: 1250\n",
            "20220510 17:06:19 current learning_rate:0.00001000\n",
            "used_time: 0.19169974327087402\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1610, loss: 0.402993, acc: 0.500000\n",
            "steps: 1610\n",
            "save_steps: 1250\n",
            "20220510 17:06:21 current learning_rate:0.00001000\n",
            "used_time: 0.19556474685668945\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1620, loss: 0.078521, acc: 0.625000\n",
            "steps: 1620\n",
            "save_steps: 1250\n",
            "20220510 17:06:23 current learning_rate:0.00001000\n",
            "used_time: 0.19504547119140625\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1630, loss: 0.219994, acc: 0.500000\n",
            "steps: 1630\n",
            "save_steps: 1250\n",
            "20220510 17:06:25 current learning_rate:0.00001000\n",
            "used_time: 0.19894766807556152\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1640, loss: 0.286777, acc: 0.875000\n",
            "steps: 1640\n",
            "save_steps: 1250\n",
            "20220510 17:06:26 current learning_rate:0.00001000\n",
            "used_time: 0.1879746913909912\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1650, loss: 0.321231, acc: 0.750000\n",
            "steps: 1650\n",
            "save_steps: 1250\n",
            "20220510 17:06:28 current learning_rate:0.00001000\n",
            "used_time: 0.17142844200134277\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1660, loss: 0.501733, acc: 0.500000\n",
            "steps: 1660\n",
            "save_steps: 1250\n",
            "20220510 17:06:30 current learning_rate:0.00001000\n",
            "used_time: 0.19871902465820312\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1670, loss: 0.892689, acc: 0.375000\n",
            "steps: 1670\n",
            "save_steps: 1250\n",
            "20220510 17:06:32 current learning_rate:0.00001000\n",
            "used_time: 0.15949630737304688\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1680, loss: 0.249897, acc: 0.875000\n",
            "steps: 1680\n",
            "save_steps: 1250\n",
            "20220510 17:06:34 current learning_rate:0.00001000\n",
            "used_time: 0.192702054977417\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1690, loss: 0.303964, acc: 0.875000\n",
            "steps: 1690\n",
            "save_steps: 1250\n",
            "20220510 17:06:36 current learning_rate:0.00001000\n",
            "used_time: 0.19537019729614258\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1700, loss: 0.270134, acc: 0.750000\n",
            "steps: 1700\n",
            "save_steps: 1250\n",
            "20220510 17:06:38 current learning_rate:0.00001000\n",
            "used_time: 0.20754408836364746\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1710, loss: 0.072656, acc: 0.625000\n",
            "steps: 1710\n",
            "save_steps: 1250\n",
            "20220510 17:06:40 current learning_rate:0.00001000\n",
            "used_time: 0.18563222885131836\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1720, loss: 0.283314, acc: 0.750000\n",
            "steps: 1720\n",
            "save_steps: 1250\n",
            "20220510 17:06:42 current learning_rate:0.00001000\n",
            "used_time: 0.26576876640319824\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1730, loss: 0.513943, acc: 0.625000\n",
            "steps: 1730\n",
            "save_steps: 1250\n",
            "20220510 17:06:44 current learning_rate:0.00001000\n",
            "used_time: 0.21289563179016113\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1740, loss: 0.131736, acc: 0.625000\n",
            "steps: 1740\n",
            "save_steps: 1250\n",
            "20220510 17:06:46 current learning_rate:0.00001000\n",
            "used_time: 0.20457720756530762\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1750, loss: 0.437208, acc: 0.625000\n",
            "steps: 1750\n",
            "save_steps: 1250\n",
            "20220510 17:06:48 current learning_rate:0.00001000\n",
            "used_time: 0.1902022361755371\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1760, loss: 0.421938, acc: 0.500000\n",
            "steps: 1760\n",
            "save_steps: 1250\n",
            "20220510 17:06:49 current learning_rate:0.00001000\n",
            "used_time: 0.17169642448425293\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1770, loss: 0.370783, acc: 0.625000\n",
            "steps: 1770\n",
            "save_steps: 1250\n",
            "20220510 17:06:51 current learning_rate:0.00001000\n",
            "used_time: 0.22401094436645508\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1780, loss: 0.428416, acc: 0.625000\n",
            "steps: 1780\n",
            "save_steps: 1250\n",
            "20220510 17:06:53 current learning_rate:0.00001000\n",
            "used_time: 0.16376590728759766\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1790, loss: 0.178748, acc: 0.625000\n",
            "steps: 1790\n",
            "save_steps: 1250\n",
            "20220510 17:06:55 current learning_rate:0.00001000\n",
            "used_time: 0.1875455379486084\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1800, loss: 0.400868, acc: 1.000000\n",
            "steps: 1800\n",
            "save_steps: 1250\n",
            "20220510 17:06:57 current learning_rate:0.00001000\n",
            "used_time: 0.17714929580688477\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1810, loss: 0.643403, acc: 0.500000\n",
            "steps: 1810\n",
            "save_steps: 1250\n",
            "20220510 17:06:59 current learning_rate:0.00001000\n",
            "used_time: 0.18302607536315918\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1820, loss: 0.615194, acc: 0.750000\n",
            "steps: 1820\n",
            "save_steps: 1250\n",
            "20220510 17:07:01 current learning_rate:0.00001000\n",
            "used_time: 0.19388508796691895\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1830, loss: 0.385797, acc: 0.625000\n",
            "steps: 1830\n",
            "save_steps: 1250\n",
            "20220510 17:07:03 current learning_rate:0.00001000\n",
            "used_time: 0.20380711555480957\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1840, loss: 0.242699, acc: 0.625000\n",
            "steps: 1840\n",
            "save_steps: 1250\n",
            "20220510 17:07:05 current learning_rate:0.00001000\n",
            "used_time: 0.20620441436767578\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1850, loss: 0.201416, acc: 0.750000\n",
            "steps: 1850\n",
            "save_steps: 1250\n",
            "20220510 17:07:07 current learning_rate:0.00001000\n",
            "used_time: 0.23595166206359863\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1860, loss: 0.360811, acc: 0.375000\n",
            "steps: 1860\n",
            "save_steps: 1250\n",
            "20220510 17:07:09 current learning_rate:0.00001000\n",
            "used_time: 0.19820904731750488\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1870, loss: 0.049891, acc: 0.875000\n",
            "steps: 1870\n",
            "save_steps: 1250\n",
            "20220510 17:07:11 current learning_rate:0.00001000\n",
            "used_time: 0.18081903457641602\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1880, loss: 0.519868, acc: 0.750000\n",
            "steps: 1880\n",
            "save_steps: 1250\n",
            "20220510 17:07:13 current learning_rate:0.00001000\n",
            "used_time: 0.19318866729736328\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1890, loss: 0.375343, acc: 0.375000\n",
            "steps: 1890\n",
            "save_steps: 1250\n",
            "20220510 17:07:15 current learning_rate:0.00001000\n",
            "used_time: 0.18036985397338867\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1900, loss: 0.340971, acc: 0.875000\n",
            "steps: 1900\n",
            "save_steps: 1250\n",
            "20220510 17:07:17 current learning_rate:0.00001000\n",
            "used_time: 0.18274664878845215\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1910, loss: 0.132569, acc: 0.750000\n",
            "steps: 1910\n",
            "save_steps: 1250\n",
            "20220510 17:07:19 current learning_rate:0.00001000\n",
            "used_time: 0.18575525283813477\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1920, loss: 1.012097, acc: 0.625000\n",
            "steps: 1920\n",
            "save_steps: 1250\n",
            "20220510 17:07:21 current learning_rate:0.00001000\n",
            "used_time: 0.2204608917236328\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1930, loss: 0.442235, acc: 1.000000\n",
            "steps: 1930\n",
            "save_steps: 1250\n",
            "20220510 17:07:23 current learning_rate:0.00001000\n",
            "used_time: 0.20150136947631836\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1940, loss: 0.413316, acc: 0.375000\n",
            "steps: 1940\n",
            "save_steps: 1250\n",
            "20220510 17:07:24 current learning_rate:0.00001000\n",
            "used_time: 0.1862342357635498\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1950, loss: 0.251611, acc: 0.375000\n",
            "steps: 1950\n",
            "save_steps: 1250\n",
            "20220510 17:07:26 current learning_rate:0.00001000\n",
            "used_time: 0.2305903434753418\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1960, loss: 0.347297, acc: 0.750000\n",
            "steps: 1960\n",
            "save_steps: 1250\n",
            "20220510 17:07:28 current learning_rate:0.00001000\n",
            "used_time: 0.19637608528137207\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1970, loss: 0.210378, acc: 0.500000\n",
            "steps: 1970\n",
            "save_steps: 1250\n",
            "20220510 17:07:30 current learning_rate:0.00001000\n",
            "used_time: 0.2056446075439453\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1980, loss: 0.813258, acc: 0.500000\n",
            "steps: 1980\n",
            "save_steps: 1250\n",
            "20220510 17:07:32 current learning_rate:0.00001000\n",
            "used_time: 0.21153926849365234\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 1990, loss: 0.151611, acc: 0.625000\n",
            "steps: 1990\n",
            "save_steps: 1250\n",
            "20220510 17:07:34 current learning_rate:0.00001000\n",
            "used_time: 0.2070484161376953\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2000, loss: 0.232267, acc: 0.625000\n",
            "steps: 2000\n",
            "save_steps: 1250\n",
            "Train-RCAC 0.8360071301247771\n",
            "20220510 17:07:36 current learning_rate:0.00001000\n",
            "used_time: 0.20737171173095703\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2010, loss: 0.063151, acc: 0.750000\n",
            "steps: 2010\n",
            "save_steps: 1250\n",
            "20220510 17:07:38 current learning_rate:0.00001000\n",
            "used_time: 0.20062923431396484\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2020, loss: 0.495280, acc: 0.750000\n",
            "steps: 2020\n",
            "save_steps: 1250\n",
            "20220510 17:07:40 current learning_rate:0.00001000\n",
            "used_time: 0.1700916290283203\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2030, loss: 0.032571, acc: 0.250000\n",
            "steps: 2030\n",
            "save_steps: 1250\n",
            "20220510 17:07:42 current learning_rate:0.00001000\n",
            "used_time: 0.22127556800842285\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2040, loss: 1.182105, acc: 0.500000\n",
            "steps: 2040\n",
            "save_steps: 1250\n",
            "20220510 17:07:44 current learning_rate:0.00001000\n",
            "used_time: 0.18022847175598145\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2050, loss: 0.478327, acc: 0.500000\n",
            "steps: 2050\n",
            "save_steps: 1250\n",
            "20220510 17:07:46 current learning_rate:0.00001000\n",
            "used_time: 0.18265771865844727\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2060, loss: 0.379474, acc: 0.625000\n",
            "steps: 2060\n",
            "save_steps: 1250\n",
            "20220510 17:07:48 current learning_rate:0.00001000\n",
            "used_time: 0.20981526374816895\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2070, loss: 0.692444, acc: 0.500000\n",
            "steps: 2070\n",
            "save_steps: 1250\n",
            "20220510 17:07:50 current learning_rate:0.00001000\n",
            "used_time: 0.17052698135375977\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2080, loss: 0.405543, acc: 0.500000\n",
            "steps: 2080\n",
            "save_steps: 1250\n",
            "20220510 17:07:52 current learning_rate:0.00001000\n",
            "used_time: 0.1701037883758545\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2090, loss: 0.520003, acc: 0.375000\n",
            "steps: 2090\n",
            "save_steps: 1250\n",
            "20220510 17:07:53 current learning_rate:0.00001000\n",
            "used_time: 0.21781086921691895\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2100, loss: 0.607521, acc: 0.625000\n",
            "steps: 2100\n",
            "save_steps: 1250\n",
            "20220510 17:07:55 current learning_rate:0.00001000\n",
            "used_time: 0.19745898246765137\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2110, loss: 0.339932, acc: 1.000000\n",
            "steps: 2110\n",
            "save_steps: 1250\n",
            "20220510 17:07:57 current learning_rate:0.00001000\n",
            "used_time: 0.1944108009338379\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2120, loss: 0.248407, acc: 0.625000\n",
            "steps: 2120\n",
            "save_steps: 1250\n",
            "20220510 17:07:59 current learning_rate:0.00001000\n",
            "used_time: 0.16150546073913574\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2130, loss: 0.483134, acc: 0.500000\n",
            "steps: 2130\n",
            "save_steps: 1250\n",
            "20220510 17:08:01 current learning_rate:0.00001000\n",
            "used_time: 0.20961856842041016\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2140, loss: 0.178859, acc: 0.750000\n",
            "steps: 2140\n",
            "save_steps: 1250\n",
            "20220510 17:08:03 current learning_rate:0.00001000\n",
            "used_time: 0.17545533180236816\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2150, loss: 0.272736, acc: 0.750000\n",
            "steps: 2150\n",
            "save_steps: 1250\n",
            "20220510 17:08:05 current learning_rate:0.00001000\n",
            "used_time: 0.18950271606445312\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2160, loss: 0.719867, acc: 0.375000\n",
            "steps: 2160\n",
            "save_steps: 1250\n",
            "20220510 17:08:07 current learning_rate:0.00001000\n",
            "used_time: 0.1872246265411377\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2170, loss: 0.109748, acc: 0.750000\n",
            "steps: 2170\n",
            "save_steps: 1250\n",
            "20220510 17:08:09 current learning_rate:0.00001000\n",
            "used_time: 0.2003166675567627\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2180, loss: 0.120515, acc: 1.000000\n",
            "steps: 2180\n",
            "save_steps: 1250\n",
            "20220510 17:08:11 current learning_rate:0.00001000\n",
            "used_time: 0.17642498016357422\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2190, loss: 0.161406, acc: 0.625000\n",
            "steps: 2190\n",
            "save_steps: 1250\n",
            "20220510 17:08:13 current learning_rate:0.00001000\n",
            "used_time: 0.20350861549377441\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2200, loss: 0.254931, acc: 0.500000\n",
            "steps: 2200\n",
            "save_steps: 1250\n",
            "20220510 17:08:15 current learning_rate:0.00001000\n",
            "used_time: 0.186476469039917\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2210, loss: 0.114783, acc: 0.500000\n",
            "steps: 2210\n",
            "save_steps: 1250\n",
            "20220510 17:08:17 current learning_rate:0.00001000\n",
            "used_time: 0.181807279586792\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2220, loss: 0.088610, acc: 0.750000\n",
            "steps: 2220\n",
            "save_steps: 1250\n",
            "20220510 17:08:19 current learning_rate:0.00001000\n",
            "used_time: 0.18956828117370605\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2230, loss: 0.507616, acc: 0.625000\n",
            "steps: 2230\n",
            "save_steps: 1250\n",
            "20220510 17:08:21 current learning_rate:0.00001000\n",
            "used_time: 0.21154332160949707\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2240, loss: 1.039439, acc: 0.875000\n",
            "steps: 2240\n",
            "save_steps: 1250\n",
            "20220510 17:08:23 current learning_rate:0.00001000\n",
            "used_time: 0.18934130668640137\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2250, loss: 0.235600, acc: 0.375000\n",
            "steps: 2250\n",
            "save_steps: 1250\n",
            "20220510 17:08:24 current learning_rate:0.00001000\n",
            "used_time: 0.20437097549438477\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2260, loss: 0.401363, acc: 0.750000\n",
            "steps: 2260\n",
            "save_steps: 1250\n",
            "20220510 17:08:26 current learning_rate:0.00001000\n",
            "used_time: 0.2007889747619629\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2270, loss: 0.380528, acc: 0.625000\n",
            "steps: 2270\n",
            "save_steps: 1250\n",
            "20220510 17:08:28 current learning_rate:0.00001000\n",
            "used_time: 0.18716883659362793\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2280, loss: 0.515069, acc: 0.000000\n",
            "steps: 2280\n",
            "save_steps: 1250\n",
            "20220510 17:08:30 current learning_rate:0.00001000\n",
            "used_time: 0.1966702938079834\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2290, loss: 0.423638, acc: 0.625000\n",
            "steps: 2290\n",
            "save_steps: 1250\n",
            "20220510 17:08:32 current learning_rate:0.00001000\n",
            "used_time: 0.2253890037536621\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2300, loss: 0.539350, acc: 0.750000\n",
            "steps: 2300\n",
            "save_steps: 1250\n",
            "20220510 17:08:34 current learning_rate:0.00001000\n",
            "used_time: 0.21933960914611816\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2310, loss: 0.077691, acc: 0.750000\n",
            "steps: 2310\n",
            "save_steps: 1250\n",
            "20220510 17:08:36 current learning_rate:0.00001000\n",
            "used_time: 0.17206835746765137\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2320, loss: 0.133080, acc: 0.500000\n",
            "steps: 2320\n",
            "save_steps: 1250\n",
            "20220510 17:08:38 current learning_rate:0.00001000\n",
            "used_time: 0.19767355918884277\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2330, loss: 0.589343, acc: 0.250000\n",
            "steps: 2330\n",
            "save_steps: 1250\n",
            "20220510 17:08:40 current learning_rate:0.00001000\n",
            "used_time: 0.2192089557647705\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2340, loss: 0.574863, acc: 0.750000\n",
            "steps: 2340\n",
            "save_steps: 1250\n",
            "20220510 17:08:42 current learning_rate:0.00001000\n",
            "used_time: 0.19221925735473633\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2350, loss: 0.648718, acc: 0.625000\n",
            "steps: 2350\n",
            "save_steps: 1250\n",
            "20220510 17:08:44 current learning_rate:0.00001000\n",
            "used_time: 0.16870427131652832\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2360, loss: 0.310333, acc: 0.625000\n",
            "steps: 2360\n",
            "save_steps: 1250\n",
            "20220510 17:08:46 current learning_rate:0.00001000\n",
            "used_time: 0.1900041103363037\n",
            "shuffle epoch 2\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2370, loss: 0.177939, acc: 0.625000\n",
            "steps: 2370\n",
            "save_steps: 1250\n",
            "20220510 17:08:48 current learning_rate:0.00001000\n",
            "used_time: 0.2046823501586914\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2380, loss: 0.474844, acc: 0.625000\n",
            "steps: 2380\n",
            "save_steps: 1250\n",
            "20220510 17:08:50 current learning_rate:0.00001000\n",
            "used_time: 0.1993422508239746\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2390, loss: 0.339291, acc: 0.625000\n",
            "steps: 2390\n",
            "save_steps: 1250\n",
            "20220510 17:08:52 current learning_rate:0.00001000\n",
            "used_time: 0.18585443496704102\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2400, loss: 0.963940, acc: 0.500000\n",
            "steps: 2400\n",
            "save_steps: 1250\n",
            "20220510 17:08:54 current learning_rate:0.00001000\n",
            "used_time: 0.1486814022064209\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2410, loss: 0.094708, acc: 0.375000\n",
            "steps: 2410\n",
            "save_steps: 1250\n",
            "20220510 17:08:55 current learning_rate:0.00001000\n",
            "used_time: 0.2211475372314453\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2420, loss: 0.093124, acc: 0.750000\n",
            "steps: 2420\n",
            "save_steps: 1250\n",
            "20220510 17:08:57 current learning_rate:0.00001000\n",
            "used_time: 0.19266080856323242\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2430, loss: 0.001126, acc: 1.000000\n",
            "steps: 2430\n",
            "save_steps: 1250\n",
            "20220510 17:08:59 current learning_rate:0.00001000\n",
            "used_time: 0.19365406036376953\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2440, loss: 0.490900, acc: 0.500000\n",
            "steps: 2440\n",
            "save_steps: 1250\n",
            "20220510 17:09:01 current learning_rate:0.00001000\n",
            "used_time: 0.2059478759765625\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2450, loss: 0.877994, acc: 0.750000\n",
            "steps: 2450\n",
            "save_steps: 1250\n",
            "20220510 17:09:03 current learning_rate:0.00001000\n",
            "used_time: 0.23053812980651855\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2460, loss: 0.719428, acc: 0.625000\n",
            "steps: 2460\n",
            "save_steps: 1250\n",
            "20220510 17:09:05 current learning_rate:0.00001000\n",
            "used_time: 0.1978614330291748\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2470, loss: 0.035798, acc: 0.500000\n",
            "steps: 2470\n",
            "save_steps: 1250\n",
            "20220510 17:09:07 current learning_rate:0.00001000\n",
            "used_time: 0.18293237686157227\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2480, loss: 0.001716, acc: 0.625000\n",
            "steps: 2480\n",
            "save_steps: 1250\n",
            "20220510 17:09:09 current learning_rate:0.00001000\n",
            "used_time: 0.20639944076538086\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2490, loss: 0.178792, acc: 0.875000\n",
            "steps: 2490\n",
            "save_steps: 1250\n",
            "20220510 17:09:11 current learning_rate:0.00001000\n",
            "used_time: 0.18400311470031738\n",
            "feed_queue size 30\n",
            "epoch: 0, progress: 0/0, step: 2500, loss: 0.182831, acc: 0.625000\n",
            "steps: 2500\n",
            "save_steps: 1250\n",
            "Train-RCAC 0.9771428571428571\n",
            "20220510 17:09:13 current learning_rate:0.00001000\n",
            "save_path: output_hm/step_2500traindev\n",
            "used_time: 11.801098346710205\n",
            "############################WARNING################################### using init_pretraining_params, not init_checkpoint ###### meaning hyper param e.g. lr won't inherit from checkpoint#################################################################terminate called without an active exception\n",
            "W0510 17:09:25.497597  2244 init.cc:216] Warning: PaddlePaddle catches a failure signal, it may not work properly\n",
            "W0510 17:09:25.497637  2244 init.cc:218] You could check whether you killed PaddlePaddle thread/process accidentally or report the case to PaddlePaddle\n",
            "W0510 17:09:25.497644  2244 init.cc:221] The detail failure signal is:\n",
            "\n",
            "W0510 17:09:25.497655  2244 init.cc:224] *** Aborted at 1652202565 (unix time) try \"date -d @1652202565\" if you are using GNU date ***\n",
            "W0510 17:09:25.499621  2244 init.cc:224] PC: @                0x0 (unknown)\n",
            "W0510 17:09:25.499944  2244 init.cc:224] *** SIGABRT (@0x89c) received by PID 2204 (TID 0x7f053cbbf700) from PID 2204; stack trace: ***\n",
            "W0510 17:09:25.501636  2244 init.cc:224]     @     0x7f06e15b6f10 (unknown)\n",
            "W0510 17:09:25.503129  2244 init.cc:224]     @     0x7f06e15b6e87 gsignal\n",
            "W0510 17:09:25.504781  2244 init.cc:224]     @     0x7f06e15b87f1 abort\n",
            "W0510 17:09:25.506356  2244 init.cc:224]     @     0x7f06e024d957 (unknown)\n",
            "W0510 17:09:25.507941  2244 init.cc:224]     @     0x7f06e0253ae6 (unknown)\n",
            "W0510 17:09:25.509358  2244 init.cc:224]     @     0x7f06e0253b21 std::terminate()\n",
            "W0510 17:09:25.510931  2244 init.cc:224]     @     0x7f06e02534ea __gxx_personality_v0\n",
            "W0510 17:09:25.512455  2244 init.cc:224]     @     0x7f06dfd93668 (unknown)\n",
            "W0510 17:09:25.513931  2244 init.cc:224]     @     0x7f06dfd93c5c _Unwind_ForcedUnwind\n",
            "W0510 17:09:25.515442  2244 init.cc:224]     @     0x7f06e136a000 __GI___pthread_unwind\n",
            "W0510 17:09:25.516960  2244 init.cc:224]     @     0x7f06e1361ae5 __pthread_exit\n",
            "W0510 17:09:25.518508  2244 init.cc:224]     @     0x7f06e16a8364 pthread_exit\n",
            "W0510 17:09:25.518640  2244 init.cc:224]     @           0x5e37d8 PyThread_exit_thread\n",
            "W0510 17:09:25.518764  2244 init.cc:224]     @           0x47028a (unknown)\n",
            "W0510 17:09:25.523913  2244 init.cc:224]     @     0x7f068e35c019 pybind11::gil_scoped_release::~gil_scoped_release()\n",
            "W0510 17:09:25.525003  2244 init.cc:224]     @     0x7f068e4443b6 _ZZN8pybind1112cpp_function10initializeIZN6paddle6pybind10BindReaderEPNS_6moduleEEUlRNS2_9operators6reader22LoDTensorBlockingQueueERKSt6vectorINS2_9framework9LoDTensorESaISC_EEE1_bIS9_SG_EINS_4nameENS_9is_methodENS_7siblingENS_10call_guardIINS_18gil_scoped_releaseEEEEEEEvOT_PFT0_DpT1_EDpRKT2_ENUlRNS_6detail13function_callEE1_4_FUNES11_\n",
            "W0510 17:09:25.527806  2244 init.cc:224]     @     0x7f068e379829 pybind11::cpp_function::dispatcher()\n",
            "W0510 17:09:25.527982  2244 init.cc:224]     @           0x593784 _PyMethodDef_RawFastCallKeywords\n",
            "W0510 17:09:25.528084  2244 init.cc:224]     @           0x594731 _PyObject_FastCallKeywords\n",
            "W0510 17:09:25.528213  2244 init.cc:224]     @           0x548cc1 (unknown)\n",
            "W0510 17:09:25.528277  2244 init.cc:224]     @           0x51566f _PyEval_EvalFrameDefault\n",
            "W0510 17:09:25.528378  2244 init.cc:224]     @           0x549e0e _PyEval_EvalCodeWithName\n",
            "W0510 17:09:25.528442  2244 init.cc:224]     @           0x4bcb19 _PyFunction_FastCallDict\n",
            "W0510 17:09:25.528499  2244 init.cc:224]     @           0x5134a6 _PyEval_EvalFrameDefault\n",
            "W0510 17:09:25.528585  2244 init.cc:224]     @           0x593dd7 _PyFunction_FastCallKeywords\n",
            "W0510 17:09:25.528642  2244 init.cc:224]     @           0x511e2c _PyEval_EvalFrameDefault\n",
            "W0510 17:09:25.528726  2244 init.cc:224]     @           0x593dd7 _PyFunction_FastCallKeywords\n",
            "W0510 17:09:25.528781  2244 init.cc:224]     @           0x511e2c _PyEval_EvalFrameDefault\n",
            "W0510 17:09:25.528842  2244 init.cc:224]     @           0x4bc98a _PyFunction_FastCallDict\n",
            "W0510 17:09:25.529039  2244 init.cc:224]     @           0x59c019 (unknown)\n",
            "W0510 17:09:25.529177  2244 init.cc:224]     @           0x595ef6 PyObject_Call\n",
            "W0510 17:09:25.529306  2244 init.cc:224]     @           0x5d5393 (unknown)\n",
            "run_finetuning.sh: line 64:  2204 Aborted                 (core dumped) python /content/vilio/ernie-vil/finetune.py --use_cuda \"True\" --is_distributed \"False\" --use_fast_executor ${e_executor-\"True\"} --nccl_comm_num ${nccl_comm_num:-\"1\"} --batch_size $((BATCH_SIZE/gpu_cnt)) --do_train \"True\" --do_test \"False\" --task_name ${TASK_NAME} --vocab_path ${VOCAB_PATH} --task_group_json ${TASK_GROUP_JSON} --lr_scheduler ${lr_scheduler} --decay_steps ${decay_steps-\"\"} --lr_decay_ratio ${lr_decay_ratio-0.1} --num_train_steps ${num_train_steps} --checkpoints $output_model_path --save_steps ${SAVE_STEPS} --init_checkpoint ${PRETRAIN_MODELS} --ernie_config_path ${ERNIE_VIL_CONFIG} --learning_rate ${LR_RATE} --warmup_steps ${WARMUP_STEPS} --weight_decay ${WEIGHT_DECAY:-0} --max_seq_len ${MAX_LEN} --validation_steps ${VALID_STEPS} --skip_steps 10 --split ${SPLIT} --stop_steps ${STOP}\n",
            "-----------  Configuration Arguments -----------\n",
            "batch_size: 8\n",
            "checkpoints: checkpoints\n",
            "combine: False\n",
            "decay_steps: \n",
            "do_test: True\n",
            "do_train: False\n",
            "do_val: False\n",
            "epoch: 100\n",
            "ernie_config_path: /content/vilio/ernie-vil/data/erniesmallvcr/ernie_vil_config.base.json\n",
            "exp: ESVCR72\n",
            "feature_size: 2048\n",
            "fusion_method: sum\n",
            "hierarchical_allreduce_inter_nranks: 8\n",
            "init_checkpoint: /content/vilio/ernie-vil/output_hm/step_2500traindev\n",
            "is_distributed: False\n",
            "learning_rate: 0.0001\n",
            "lr_decay_dict_file: \n",
            "lr_decay_ratio: 0.1\n",
            "lr_scheduler: linear_warmup_decay\n",
            "max_img_len: 100\n",
            "max_seq_len: 128\n",
            "nccl_comm_num: 1\n",
            "num_features: 50\n",
            "num_train_steps: 1000000\n",
            "output_file: \n",
            "result_file: /content/vilio/ernie-vil/data/log\n",
            "save_steps: 100\n",
            "skip_steps: 10\n",
            "split: test_seen\n",
            "stop_steps: 5000\n",
            "subtrain: False\n",
            "task_group_json: /content/vilio/ernie-vil/conf/hm/task_hm.json\n",
            "task_name: hm\n",
            "test_filelist: \n",
            "test_split: val\n",
            "train_filelist: \n",
            "use_cuda: True\n",
            "use_fast_executor: True\n",
            "use_fuse: False\n",
            "use_gpu: True\n",
            "use_hierarchical_allreduce: False\n",
            "valid_filelist: \n",
            "validation_steps: 6000\n",
            "verbose: False\n",
            "vocab_path: /content/vilio/ernie-vil/data/erniesmallvcr/vocab.txt\n",
            "warmup_steps: 0\n",
            "weight_decay: 0.01\n",
            "------------------------------------------------\n",
            "finetuning tasks start\n",
            "attention_probs_dropout_prob: 0.1\n",
            "class_attr_size: 401\n",
            "class_size: 1601\n",
            "co_hidden_size: 1024\n",
            "co_intermediate_size: 1024\n",
            "co_num_attention_heads: 8\n",
            "hidden_act: gelu\n",
            "hidden_dropout_prob: 0.1\n",
            "hidden_size: 768\n",
            "initializer_range: 0.02\n",
            "max_position_embeddings: 512\n",
            "num_attention_heads: 12\n",
            "num_hidden_layers: 12\n",
            "sent_type_vocab_size: 4\n",
            "t_biattention_id: [6, 7, 8, 9, 10, 11]\n",
            "task_type_vocab_size: 16\n",
            "type_vocab_size: 2\n",
            "v_biattention_id: [0, 1, 2, 3, 4, 5]\n",
            "v_hidden_size: 1024\n",
            "v_intermediate_size: 1024\n",
            "v_num_attention_heads: 8\n",
            "vocab_size: 30522\n",
            "------------------------------------------------\n",
            "task:  [{'task': 'HM', 'num_choice': 1, 'annotations_jsonpath_train': '/content/vilio/ernie-vil/data/hm/train.jsonl', 'annotations_jsonpath_dev_seen': '/content/vilio/ernie-vil/data/hm/dev_seenlong.jsonl', 'annotations_jsonpath_traindev': '/content/vilio/ernie-vil/data/hm/traindev.jsonl', 'annotations_jsonpath_test_unseen': '/content/vilio/ernie-vil/data/hm/test_unseenlong.jsonl', 'annotations_jsonpath_test_seen': '/content/vilio/ernie-vil/data/hm/test_seenlong.jsonl', 'feature_lmdb_path': '/content/vilio/ernie-vil/data/hm/HM_img.tsv', 'gt_feature_lmdb_path': '/content/vilio/ernie-vil/data/hm/HM_gt_img.tsv', 'unisex_names_table': '/content/vilio/ernie-vil/data/vcr/unisex_names_table.csv', 'Proprocessor': 'PreprocessorBasic', 'tokenizer_name': 'FullTokenizer', 'fusion_method': 'mul', 'dropout_rate': 0.1, 'max_seq_len': 128, 'use_gt_fea': True, 'shufflekeep_across_task': True, 'shuffle_every_epoch': True, 'task_weight': 1.0, 'task_prefix': 'hm'}]\n",
            "2022-05-10 17:09:29,202-WARNING: paddle.fluid.layers.py_reader() may be deprecated in the near future. Please use paddle.fluid.io.DataLoader.from_generator() instead.\n",
            "theoretical memory usage: \n",
            "(3678.2632896423343, 3853.418684387207, 'MB')\n",
            "args.is_distributed: False\n",
            "W0510 17:09:30.130308  2296 device_context.cc:252] Please NOTE: device: 0, CUDA Capability: 60, Driver API Version: 11.2, Runtime API Version: 9.0\n",
            "W0510 17:09:30.143103  2296 device_context.cc:260] device: 0, cuDNN Version: 7.6.\n",
            "SPLIT: test_seen\n",
            "Start to load Faster-RCNN detected objects from /content/vilio/ernie-vil/data/hm/HM_img.tsv\n",
            "Loaded 1000 images in file /content/vilio/ernie-vil/data/hm/HM_img.tsv in 70 seconds.\n",
            "Start to load Faster-RCNN detected objects from /content/vilio/ernie-vil/data/hm/HM_gt_img.tsv\n",
            "Loaded 1000 images in file /content/vilio/ernie-vil/data/hm/HM_gt_img.tsv in 50 seconds.\n",
            "Load 1300 data from split(s) /content/vilio/ernie-vil/data/hm/test_seenlong.jsonl.\n",
            "use gt featurre\n",
            "LEN:  1300\n",
            "Load pretraining parameters from /content/vilio/ernie-vil/output_hm/step_2500traindev.\n",
            "testing on hm val split\n",
            "task name list :  ['mean_0.tmp_0', 'accuracy_0.tmp_0', 'arg_max_0.tmp_0', 'read_file_0.tmp_9', 'read_file_0.tmp_8', 'reshape2_120.tmp_0']\n",
            "cur_step: 10 cur_acc: 0.9875\n",
            "cur_step: 20 cur_acc: 0.99375\n",
            "cur_step: 30 cur_acc: 0.9958333333333333\n",
            "cur_step: 40 cur_acc: 0.996875\n",
            "cur_step: 50 cur_acc: 0.9975\n",
            "cur_step: 60 cur_acc: 0.9979166666666667\n",
            "cur_step: 70 cur_acc: 0.9982142857142857\n",
            "cur_step: 80 cur_acc: 0.9984375\n",
            "cur_step: 90 cur_acc: 0.9986111111111111\n",
            "cur_step: 100 cur_acc: 0.99875\n",
            "cur_step: 110 cur_acc: 0.9988636363636364\n",
            "cur_step: 120 cur_acc: 0.9989583333333333\n",
            "cur_step: 130 cur_acc: 0.9980769230769231\n",
            "cur_step: 140 cur_acc: 0.9982142857142857\n",
            "cur_step: 150 cur_acc: 0.9983333333333333\n",
            "cur_step: 160 cur_acc: 0.9984375\n",
            "EXCEPTING\n",
            "LEN: 1000 1000\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   id      1000 non-null   int64  \n",
            " 1   proba   1000 non-null   float32\n",
            " 2   label   1000 non-null   int64  \n",
            "dtypes: float32(1), int64(2)\n",
            "memory usage: 19.7 KB\n",
            "None\n",
            "average_acc: 0.9984375\n",
            "rocauc: 0.6431924882629108\n",
            "-----------  Configuration Arguments -----------\n",
            "batch_size: 8\n",
            "checkpoints: checkpoints\n",
            "combine: False\n",
            "decay_steps: \n",
            "do_test: True\n",
            "do_train: False\n",
            "do_val: False\n",
            "epoch: 100\n",
            "ernie_config_path: /content/vilio/ernie-vil/data/erniesmallvcr/ernie_vil_config.base.json\n",
            "exp: ESVCR72\n",
            "feature_size: 2048\n",
            "fusion_method: sum\n",
            "hierarchical_allreduce_inter_nranks: 8\n",
            "init_checkpoint: /content/vilio/ernie-vil/output_hm/step_2500traindev\n",
            "is_distributed: False\n",
            "learning_rate: 0.0001\n",
            "lr_decay_dict_file: \n",
            "lr_decay_ratio: 0.1\n",
            "lr_scheduler: linear_warmup_decay\n",
            "max_img_len: 100\n",
            "max_seq_len: 128\n",
            "nccl_comm_num: 1\n",
            "num_features: 50\n",
            "num_train_steps: 1000000\n",
            "output_file: \n",
            "result_file: /content/vilio/ernie-vil/data/log\n",
            "save_steps: 100\n",
            "skip_steps: 10\n",
            "split: test_unseen\n",
            "stop_steps: 5000\n",
            "subtrain: False\n",
            "task_group_json: /content/vilio/ernie-vil/conf/hm/task_hm.json\n",
            "task_name: hm\n",
            "test_filelist: \n",
            "test_split: val\n",
            "train_filelist: \n",
            "use_cuda: True\n",
            "use_fast_executor: True\n",
            "use_fuse: False\n",
            "use_gpu: True\n",
            "use_hierarchical_allreduce: False\n",
            "valid_filelist: \n",
            "validation_steps: 6000\n",
            "verbose: False\n",
            "vocab_path: /content/vilio/ernie-vil/data/erniesmallvcr/vocab.txt\n",
            "warmup_steps: 0\n",
            "weight_decay: 0.01\n",
            "------------------------------------------------\n",
            "finetuning tasks start\n",
            "attention_probs_dropout_prob: 0.1\n",
            "class_attr_size: 401\n",
            "class_size: 1601\n",
            "co_hidden_size: 1024\n",
            "co_intermediate_size: 1024\n",
            "co_num_attention_heads: 8\n",
            "hidden_act: gelu\n",
            "hidden_dropout_prob: 0.1\n",
            "hidden_size: 768\n",
            "initializer_range: 0.02\n",
            "max_position_embeddings: 512\n",
            "num_attention_heads: 12\n",
            "num_hidden_layers: 12\n",
            "sent_type_vocab_size: 4\n",
            "t_biattention_id: [6, 7, 8, 9, 10, 11]\n",
            "task_type_vocab_size: 16\n",
            "type_vocab_size: 2\n",
            "v_biattention_id: [0, 1, 2, 3, 4, 5]\n",
            "v_hidden_size: 1024\n",
            "v_intermediate_size: 1024\n",
            "v_num_attention_heads: 8\n",
            "vocab_size: 30522\n",
            "------------------------------------------------\n",
            "task:  [{'task': 'HM', 'num_choice': 1, 'annotations_jsonpath_train': '/content/vilio/ernie-vil/data/hm/train.jsonl', 'annotations_jsonpath_dev_seen': '/content/vilio/ernie-vil/data/hm/dev_seenlong.jsonl', 'annotations_jsonpath_traindev': '/content/vilio/ernie-vil/data/hm/traindev.jsonl', 'annotations_jsonpath_test_unseen': '/content/vilio/ernie-vil/data/hm/test_unseenlong.jsonl', 'annotations_jsonpath_test_seen': '/content/vilio/ernie-vil/data/hm/test_seenlong.jsonl', 'feature_lmdb_path': '/content/vilio/ernie-vil/data/hm/HM_img.tsv', 'gt_feature_lmdb_path': '/content/vilio/ernie-vil/data/hm/HM_gt_img.tsv', 'unisex_names_table': '/content/vilio/ernie-vil/data/vcr/unisex_names_table.csv', 'Proprocessor': 'PreprocessorBasic', 'tokenizer_name': 'FullTokenizer', 'fusion_method': 'mul', 'dropout_rate': 0.1, 'max_seq_len': 128, 'use_gt_fea': True, 'shufflekeep_across_task': True, 'shuffle_every_epoch': True, 'task_weight': 1.0, 'task_prefix': 'hm'}]\n",
            "2022-05-10 17:12:02,242-WARNING: paddle.fluid.layers.py_reader() may be deprecated in the near future. Please use paddle.fluid.io.DataLoader.from_generator() instead.\n",
            "theoretical memory usage: \n",
            "(3678.2632896423343, 3853.418684387207, 'MB')\n",
            "args.is_distributed: False\n",
            "W0510 17:12:03.093628  2374 device_context.cc:252] Please NOTE: device: 0, CUDA Capability: 60, Driver API Version: 11.2, Runtime API Version: 9.0\n",
            "W0510 17:12:03.105942  2374 device_context.cc:260] device: 0, cuDNN Version: 7.6.\n",
            "SPLIT: test_unseen\n",
            "Start to load Faster-RCNN detected objects from /content/vilio/ernie-vil/data/hm/HM_img.tsv\n",
            "Loaded 2000 images in file /content/vilio/ernie-vil/data/hm/HM_img.tsv in 72 seconds.\n",
            "Start to load Faster-RCNN detected objects from /content/vilio/ernie-vil/data/hm/HM_gt_img.tsv\n",
            "Loaded 2000 images in file /content/vilio/ernie-vil/data/hm/HM_gt_img.tsv in 52 seconds.\n",
            "Load 2600 data from split(s) /content/vilio/ernie-vil/data/hm/test_unseenlong.jsonl.\n",
            "use gt featurre\n",
            "LEN:  2600\n",
            "Load pretraining parameters from /content/vilio/ernie-vil/output_hm/step_2500traindev.\n",
            "testing on hm val split\n",
            "task name list :  ['mean_0.tmp_0', 'accuracy_0.tmp_0', 'arg_max_0.tmp_0', 'read_file_0.tmp_9', 'read_file_0.tmp_8', 'reshape2_120.tmp_0']\n",
            "cur_step: 10 cur_acc: 0.9875\n",
            "cur_step: 20 cur_acc: 0.99375\n",
            "cur_step: 30 cur_acc: 0.9958333333333333\n",
            "cur_step: 40 cur_acc: 0.996875\n",
            "cur_step: 50 cur_acc: 0.9975\n",
            "cur_step: 60 cur_acc: 0.9979166666666667\n",
            "cur_step: 70 cur_acc: 0.9982142857142857\n",
            "cur_step: 80 cur_acc: 0.9984375\n",
            "cur_step: 90 cur_acc: 0.9986111111111111\n",
            "cur_step: 100 cur_acc: 0.99875\n",
            "cur_step: 110 cur_acc: 0.9988636363636364\n",
            "cur_step: 120 cur_acc: 0.9989583333333333\n",
            "cur_step: 130 cur_acc: 0.9990384615384615\n",
            "cur_step: 140 cur_acc: 0.9991071428571429\n",
            "cur_step: 150 cur_acc: 0.9991666666666666\n",
            "cur_step: 160 cur_acc: 0.99921875\n",
            "cur_step: 170 cur_acc: 0.9992647058823529\n",
            "cur_step: 180 cur_acc: 0.9993055555555556\n",
            "cur_step: 190 cur_acc: 0.9993421052631579\n",
            "cur_step: 200 cur_acc: 0.999375\n",
            "cur_step: 210 cur_acc: 0.9994047619047619\n",
            "cur_step: 220 cur_acc: 0.9994318181818181\n",
            "cur_step: 230 cur_acc: 0.9994565217391305\n",
            "cur_step: 240 cur_acc: 0.9994791666666667\n",
            "cur_step: 250 cur_acc: 0.9995\n",
            "cur_step: 260 cur_acc: 0.9990384615384615\n",
            "cur_step: 270 cur_acc: 0.9990740740740741\n",
            "cur_step: 280 cur_acc: 0.9991071428571429\n",
            "cur_step: 290 cur_acc: 0.9991379310344828\n",
            "cur_step: 300 cur_acc: 0.9991666666666666\n",
            "cur_step: 310 cur_acc: 0.9991935483870967\n",
            "cur_step: 320 cur_acc: 0.99921875\n",
            "EXCEPTING\n",
            "LEN: 2000 2000\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2000 entries, 0 to 1999\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   id      2000 non-null   int64  \n",
            " 1   proba   2000 non-null   float32\n",
            " 2   label   2000 non-null   int64  \n",
            "dtypes: float32(1), int64(2)\n",
            "memory usage: 39.2 KB\n",
            "None\n",
            "average_acc: 0.99921875\n",
            "rocauc: 0.2791243158717748\n",
            "Included in Simple Average:  dev_seenES36.csv\n",
            "Included in Simple Average:  dev_seenES72.csv\n",
            "Included in Simple Average:  dev_seenESV50.csv\n",
            "Included in Simple Average:  dev_seenESVCR36.csv\n",
            "Included in Simple Average:  dev_seenESVCR72.csv\n",
            "Included in Simple Average:  test_seenES36.csv\n",
            "Included in Simple Average:  test_seenES72.csv\n",
            "Included in Simple Average:  test_seenESV50.csv\n",
            "Included in Simple Average:  test_seenESVCR36.csv\n",
            "Included in Simple Average:  test_seenESVCR72.csv\n",
            "Included in Simple Average:  test_unseenES36.csv\n",
            "Included in Simple Average:  test_unseenES72.csv\n",
            "Included in Simple Average:  test_unseenESV50.csv\n",
            "Included in Simple Average:  test_unseenESVCR36.csv\n",
            "Included in Simple Average:  test_unseenESVCR72.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(\"/content/vilio/ernie-vil/data/hm\")"
      ],
      "metadata": {
        "id": "rtTPALTGA2fh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/vilio/ernie-vil/data/hm/ES365072/* /content/drive/MyDrive/ernie-vil-results"
      ],
      "metadata": {
        "id": "OcGRPYvuBFZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/vilio/ernie-vil/data/hm/ES365072/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSrSCrlqCAox",
        "outputId": "481a64ce-3f1e-49fd-f912-e352da8caec4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ES365072_dev_seen_SA.csv   ES365072_test_unseen_SA.csv\n",
            "ES365072_test_seen_SA.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "ES365072_dev_seen_SA = pd.read_csv(\"/content/vilio/ernie-vil/data/hm/ES365072/ES365072_dev_seen_SA.csv\")\n",
        "ES365072_test_unseen_SA = pd.read_csv(\"/content/vilio/ernie-vil/data/hm/ES365072/ES365072_test_unseen_SA.csv\")\n",
        "ES365072_test_seen_SA = pd.read_csv(\"/content/vilio/ernie-vil/data/hm/ES365072/ES365072_test_seen_SA.csv\")"
      ],
      "metadata": {
        "id": "_LtJv9FlBwgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dev_seen = pd.read_json(\"/content/vilio/ernie-vil/data/hm/dev_seen.jsonl\", lines = True)\n",
        "test_seen = pd.read_json(\"/content/vilio/ernie-vil/data/hm/test_seen.jsonl\", lines = True)\n",
        "test_unseen = pd.read_json(\"/content/vilio/ernie-vil/data/hm/test_unseen.jsonl\", lines = True)"
      ],
      "metadata": {
        "id": "c6XAqeH1CM1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dev_seen.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKH90cfUCv4p",
        "outputId": "a79e3766-899b-4d90-c409-b9718f1d4ec6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(500, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ES365072_dev_seen_SA.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5i2ojWEPCxTA",
        "outputId": "8d133ef4-61e6-44a4-ee23-89a3b9ff75c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(500, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ES365072_dev_seen_SA"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "ZeKkvqI8DD-D",
        "outputId": "7f4c716d-ff10-4f69-d2b1-fc174fa2a448"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id     proba  label\n",
              "0     8291 -6.674554      0\n",
              "1    46971 -5.701749      0\n",
              "2     3745 -4.890941      0\n",
              "3    83745 -6.876825      0\n",
              "4    80243  3.244227      0\n",
              "..     ...       ...    ...\n",
              "495  83675 -6.290062      0\n",
              "496  37198 -8.780319      0\n",
              "497  48670 -7.524425      0\n",
              "498   9863 -7.005279      0\n",
              "499  97320 -7.885709      0\n",
              "\n",
              "[500 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c1ef13ef-8408-4088-b9a9-d2dd440418c9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>proba</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8291</td>\n",
              "      <td>-6.674554</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>46971</td>\n",
              "      <td>-5.701749</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3745</td>\n",
              "      <td>-4.890941</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>83745</td>\n",
              "      <td>-6.876825</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>80243</td>\n",
              "      <td>3.244227</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>83675</td>\n",
              "      <td>-6.290062</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>37198</td>\n",
              "      <td>-8.780319</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>48670</td>\n",
              "      <td>-7.524425</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>9863</td>\n",
              "      <td>-7.005279</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>97320</td>\n",
              "      <td>-7.885709</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c1ef13ef-8408-4088-b9a9-d2dd440418c9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c1ef13ef-8408-4088-b9a9-d2dd440418c9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c1ef13ef-8408-4088-b9a9-d2dd440418c9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dev_seen"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "YIaIc5OwDE_g",
        "outputId": "13d0554a-b71b-492d-ad3a-2f4165dfa32a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id            img  label  \\\n",
              "0     8291  img/08291.png      1   \n",
              "1    46971  img/46971.png      1   \n",
              "2     3745  img/03745.png      1   \n",
              "3    83745  img/83745.png      1   \n",
              "4    80243  img/80243.png      1   \n",
              "..     ...            ...    ...   \n",
              "495  83675  img/83675.png      0   \n",
              "496  37198  img/37198.png      0   \n",
              "497  48670  img/48670.png      0   \n",
              "498   9863  img/09863.png      0   \n",
              "499  97320  img/97320.png      0   \n",
              "\n",
              "                                                  text  \n",
              "0                white people is this a shooting range  \n",
              "1                                bravery at its finest  \n",
              "2    your order comes to $37.50 and your white priv...  \n",
              "3    it is time.. to send these parasites back to t...  \n",
              "4                               mississippi wind chime  \n",
              "..                                                 ...  \n",
              "495                   i'm gonna be like phelps one day  \n",
              "496  when you're so relaxed you can feel yourself g...  \n",
              "497  look at this sandwich maker club i found on wi...  \n",
              "498                             diverse group of women  \n",
              "499  \"when your dishwasher is broken so you take it...  \n",
              "\n",
              "[500 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3fe1e551-dfc2-44bd-87f7-45d6993ec769\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>img</th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8291</td>\n",
              "      <td>img/08291.png</td>\n",
              "      <td>1</td>\n",
              "      <td>white people is this a shooting range</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>46971</td>\n",
              "      <td>img/46971.png</td>\n",
              "      <td>1</td>\n",
              "      <td>bravery at its finest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3745</td>\n",
              "      <td>img/03745.png</td>\n",
              "      <td>1</td>\n",
              "      <td>your order comes to $37.50 and your white priv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>83745</td>\n",
              "      <td>img/83745.png</td>\n",
              "      <td>1</td>\n",
              "      <td>it is time.. to send these parasites back to t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>80243</td>\n",
              "      <td>img/80243.png</td>\n",
              "      <td>1</td>\n",
              "      <td>mississippi wind chime</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>83675</td>\n",
              "      <td>img/83675.png</td>\n",
              "      <td>0</td>\n",
              "      <td>i'm gonna be like phelps one day</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>37198</td>\n",
              "      <td>img/37198.png</td>\n",
              "      <td>0</td>\n",
              "      <td>when you're so relaxed you can feel yourself g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>48670</td>\n",
              "      <td>img/48670.png</td>\n",
              "      <td>0</td>\n",
              "      <td>look at this sandwich maker club i found on wi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>9863</td>\n",
              "      <td>img/09863.png</td>\n",
              "      <td>0</td>\n",
              "      <td>diverse group of women</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>97320</td>\n",
              "      <td>img/97320.png</td>\n",
              "      <td>0</td>\n",
              "      <td>\"when your dishwasher is broken so you take it...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3fe1e551-dfc2-44bd-87f7-45d6993ec769')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3fe1e551-dfc2-44bd-87f7-45d6993ec769 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3fe1e551-dfc2-44bd-87f7-45d6993ec769');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(ES365072_dev_seen_SA['label'] == dev_seen['label']).sum()/500"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rZEwjTXC1aR",
        "outputId": "ef4f3215-1ab1-49c8-df09-39219d9da8b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.506"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(ES365072_test_unseen_SA['label'] == test_unseen['label']).sum()/2000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhXbbsqzElQh",
        "outputId": "b6a77af5-90dc-46cc-8db1-a42159126570"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.625"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(ES365072_test_seen_SA['label'] == test_seen['label']).sum()/1000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLopqZikEl0P",
        "outputId": "c0bdcbe4-7c4d-4be5-cdcf-ad96555c6a92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.51"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "d6b_VyL_2TaX",
        "ioROtCsx2dxM",
        "ESIwA-mEx7Rv",
        "udCFF9nsxx-O",
        "dp2fgvy2-IWd",
        "jbgyMPys-j8W",
        "l70OCx-t2Pix",
        "_-9Q3p3H0VSx",
        "CDu9x_tvia6F"
      ],
      "name": "Vilio-Feature_extraction_tsv.ipynb",
      "provenance": [],
      "mount_file_id": "1IJt5ViL6tG205209EyGwGp435rIH_tzW",
      "authorship_tag": "ABX9TyOhubqcKqwzT3gfMocI0YcL",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}